[{"title":"CQRS被称为邪教","url":"/blog/cqrs-is-called-a-cult.html","content":"CQRS全称Command Query Responsibility Segregation\n\n在CQRS中，来自客户端的命令通过单独的路径抵达命令模型，而查询操作则采用不同的数据源，这样的好处在于可以优化对查询数据的获取，比如用于展现、用于接口或报告的数据。\nCQRS这些年火起来了，常被人挂在嘴边提起。为什么？因为DDD提倡富模型，但从资源库查找所有需要显示的数据是困难的，特别是在需要显示来自不同聚合类型与实例的数据时。领域越复杂，这种困难程度越大。\n有没有一种完全不同的方法可以将领域数据映射到界面显示中呢？答案正是CQRS。\n在From CRUD to CQRS文章中，作者比对了CRUD模式与CQRS模式\n\n\nCRUD我们传统使用的CRUD风格：\n\n这就是经典的CRUD应用模式。数据流在应用中是这样的：\n\n所有的业务服务与领域服务都在同一条数据流中完成数据的获取与更新操作。\nCQRS相对于CRUD，CQRS应用模型，会有两条数据流：读与写\n\n写命令数据流负责创建&#x2F;更新&#x2F;删除领域模型\n\n读数据流负责从数据源获取数据\n\nCQRS风格整体大概有三种形式：\n1、应用完全分割成两个部分：\n\n2、应用有一个通用的web api层，但业务层分割成两部分：\n\n3、webapi与business都是通用，command和query在通用服务中创建\n\n在DDD实践指南中也引入了CQRS的元素，进行command与query区分。一切都很完美。\n然后，现实并非如此，徐昊老师却称CQRS是邪教\n总结下来有两点原因：\n1、模式滥用\nCQRS是个模式,模式有适用场景,然而现在CQRS成了全能模式，尤其在实践DDD时，更是标配模式。\nCQRS本身是一个对象接口设计原则，把get&#x2F;find和mutable的set分离\n然后自然扩张变成了服务接口设计原则\n有人灵机一动，用domain model做command，用query model做查询和报表\n整套系统俩模型\n这就是把一个限定概念无限扩大\n到现在，有人说graphql做query，domain model做command\n然而实际上，想解决的都是报表 特别是ad hoc报表\n用一个特别复杂的方案，解决个简单的问题（还比一定解决得了），逢人就说，这是应该的方案，这不是邪教是什么\n为什么说CQRS是复杂的？\nUdi Dahan绘制了一张图：\n\n图中可以看到Cache,写模型也要读有cache，然后你的读模型也有cache，俩cache不一致\n特别是用jpa&#x2F;hibernate之类的框架，cache行为很难控制，不加cache性能不好，加了cache，俩模型不一致。\n而且代码量也增加，从多个聚合取数据拼装一起的代码量多，你分成cqrs代码不多吗？多一套model，代码不多吗\ncqrs作为模式，是一种分布式架构模式，一个单体里大概率就是用错了\nMartin Fowler也表明了这个观点：\n\n“By separate models we most commonly mean different object models, probably running in different logical processes, perhaps on separate hardware. ”- Martin Fowler. \n\n把repo分成xxxquery 放各种find和xxxupdate 放save,理论上也叫cqrs\n底层模型还是一样 只是接口分一下,那有啥用\ncqrs重点在有两套模型\n如果是cqrs 我建议你用独立的查询数据库或者搜索引擎\n一个最典型的cqrs，cms&#x2F;blog系统，读模型，file缓存，搜索引擎；写模型，后台domain，分得干干净净\n2、把view model当query model\n把view model当query model，本来mvc,mvp,mvvm的问题，硬拗成cqrs\n围绕domain做read model，第一选择是细化domain 调整各种聚合\n必须在限定问题领域内使用\n行业里说cqrs的，大部分是因为 domain model提炼不力，绕过domain直接查询数据库\n何时使用既然CQRS是种模式，就得像任何模式一样，有适用场景，也有不适用场景。\n很多系统很适合CRUD模式，就应该使用CRUD，那么什么场景下适合CQRS呢？\nMartin Fowler指出了两个场景\n1、比较复杂的领域模型\n这种场景需要强调的是，使用CQRS还是很少的场景。当读写模型比较重叠时，使用共享模式相对简单些。\n不然会增加复杂性，从而减小生产力并增加风险。\n2、高性能应用\nCQRS可以隔离读与写负载，并独立扩容。\n当读与写模型有明显区别时，会很方便。即使没有，读写也可以使用不同的优化策略。\n总结可以联想到在数据库架构时，也常使用主写从读架构。那是不是也称为CQRS呢？\n我们在一个应用中，真的同时使用了这两种模型吗？其实也未必，只是某些小点，借鉴了CQRS思想。\nCQRS作为模式，是一种分布式架构模式，而且是很复杂的模式。流行的CQRS不过是为了查询而绕开domain的做法，不过是因为domain提炼不到位。\n正常的程序，都有读写功能，不需要分成皆然不同的两套模型，就无所谓是不是CQRS了。\n这也说明了一个问题，大佬说的CQRS与普通人说的CQRS其实不是一个东西，普通人为了轻松理解，就简单理解为读写分离，并且自以为这就是全部，变成了全知全能，其实这只是个开始。\n"},{"title":"CTO的三件要务","url":"/blog/cto's-three-priorities.html","content":"老施现在是一家高速发展的互联网公司CTO，去年约他喝茶，聊到这几年在公司的三个方向稳定性、透明性、独立性\n这三性对很多公司也很有代表性，最近公司也在提要把项目销售情况与研发部门同步，想起来老施讲的这三性，写出来回顾一下，这三点相辅相成，每个阶段重点不同而已\n稳定性提到稳定性，第一个想到的就是系统稳定，这是必然。怎么才算稳定呢？\n这就是具体技术范畴，高可用、高可靠、可扩展、可维护…\n除了系统本身稳定性，还需要APM，以及主动或被动系统探针\n还有一种就是资产的稳定，各个服务不单软件还有硬件，是否都有人管控\n\n其次就是人员稳定，每个人都得有backup，包括CTO本人，这主要是讲在master临时有事时，不至于事项被中断\n还有更高阶的，企业文化是否吸引人才、配套人才发展机制\n透明性透明性，也有几方面\n公司战略透明性，公司每月会开通告性会议，这已经不单单是研发部门，各个一级部门都要向一线员工去宣讲公司战略，各部门最近落地产出，虽然这成本有点高，但有价值，也防止中层管理信息隔断\n团队财务透明，每个团队都在不停赶时间，不管是项目还是活动，那么怎么分配资源？是因为公司战略需要，还是因为项目负责人嗓门大。不管是拉新，拉营收，项目运营状态如何？投入产出比如何，需要从运营端同步到研发端，不仅激发一线研发热情，还能知道项目负责人是不是真的只是嗓门大\n独立性团队人员独立，常碰到一个团队A承接了紧急项目，去别的团队B借人，人刚借走，团队B也来大活了，去要回人还是再去借人？人开发完回来了，却常被对方人拉去联调，修bug\n独立性也配合了稳定性\n团队财务独立，公司整体是向上发展的，算总帐帐面都不错，其实好些团队财务是严重透支的，与上现的透明性相呼应\n","tags":["管理"]},{"title":"Clean Code系列之DDD分层参数转换","url":"/blog/ddd-layered-parameter-conversion-of-clean-code-series.html","content":"先看一段简单的代码：\npackage com.zhuxingsheng.adapter@PostMapping(&quot;/login&quot;)public LoginResponse login(LoginRequest loginRequest) &#123;    return loginService.login(loginReqeust);&#125;\n\n从代码中，可以明显看出这是一段处理登陆请求的方法。在大多数项目中，这种代码很常见。\n它有什么坏味道呢？\n分层穿透了，LoginRequest类本应该属于入口层，结果穿透到了service层。\n细细追究，需要明确的问题：\n1、LoginRequest到底属于哪一层，是resource层，还是service层？\n2、没有达到DDD防腐层的意义，resource是隔离外部与核心业务的，但却变成了透传。\n\n\n归属哪一层在《再议DDD分层》中，也讨论过。\n当前系统是以REST方式对外提供服务，如果后面需要以RPC方式对个提供服务，显示LoginRequest可能不再适用。\n\n从图中可以看出REST方式是Controller，而如果是thrift方式是TService。controller的LoginRequest参数，会在TService中失效。在实现层面，LoginRequest本质上就是个DTO，传输数据。而且不再像过去原始servlet，传输数据时会有很多原生API类型，现在的框架都进化了，request对象中只有业务属性。\n从这个角度讲，request对象是在resource层，并且是与各个实现框架绑定的。\n另外，resource层还需要处理request参数的检验与转换。如果直接透传到service层，不仅加重了service的职责，而且对于service层，我们更推荐使用ADT方式，让代码更有业务语义，不使用单纯的技术基础类型。\n总结一下整体结构就是这样：\n\nDDD防腐层DDD中有限界上下文，而且限界上下文之间需要高度自治、隔离变化，防腐层因运而生。\n而这儿的LoginRequest就是两个限界上下文的通信数据，而核心业务层是有对应的业务对象承接数据。\n这样有常见的两个问题\n1、代码重复《DDD实战指南》中提出，我们引入CQRS架构中的概念，业务层有对应cmd和query对象。\n如LoginRequest到LoginCmd转换，但两个类的内容都一样\npackage com.zhuxingsheng.adapter.plpublic class LoginCmd &#123;    private String username;    private String password;&#125;\n\n如果是这样，那我们参数校验逻辑是不是得写到service里面，不然校验逻辑也要重复了。\n当测试代码时，controller的测试与service的测试是一致的，use case是相同的。\n怎么应对，还是上文提到的ADT方式，对于service层，不再提倡使用技术层面的基本类型，如username属性包装成Username类，而校验逻辑可以封装在Username中\npackage com.zhuxingsheng.adapter.plpublic class Username &#123;    private String username;        public Username(String username) &#123;        if (username == null) &#123;            throw   new ValidationException(&quot;username不能为空&quot;);        &#125; else if (isValid(username)) &#123;            throw   new ValidationException(&quot;username格式错误&quot;);        &#125;        this.username = username;    &#125;    &#125;\n\n这样对于service层的方法业务语义更加显现化。\npublic void login(Username username,Password password) &#123;    &#125;\n\n对于login方法的测试，use case数量相对基础类型也变少了。\n对于复杂对象的转换，可以使用mapstruct，既方便，性能也高效。\n2、代码复用比如创建文章，编辑文章，两者入参差不多，只是创建时没有id,而编辑时有id，从代码复用角度，不想类的膨胀，DTO只创建一个。会出现一个dto会有很多很多的属性。\n但从业务语义角度，两个业务行为就不应该共用同一个对象。需要有CreateArticleCmd和EditArticleCmd\n而对于request dto的数量，从友好API角度，应该要有两个DTO，但如果是复杂的查询操作，query dto属性数量比command dto更多些。\n总结clean code，这篇主要阐述了分层架构中传输对象与业务对象职责不清问题。\n应对策略：\n大到一个微服务，小到一个变量，SRP原则无处不在。\nDTO属性要明确简单，业务对象要语义清晰显现化。\n","tags":["Clean Code","DDD"]},{"title":"API如何设计","url":"/blog/how-are-apis-designed.html","content":"在之前《应对变化》中提到模块之间合的策略：缩小依赖范围，API是两个模块间唯一的联结点\n\n怎么才是一个好的API设计呢？最近项目中正好碰到一件关于一个API引起的相爱相恨的事件\n数据来源于外部系统，外部系统通过回调把数据传输过来，内部系统通过系统A进行接受，接受完之后，转发给系统B\n\n接受回调api大概是：\nsystemA.callback(long userId,Object data);\n整体两个参数，一个userId表示这个数据是谁的、一个data表示数据本身\n对于系统B来讲，他的业务要求，这数据必须要知道用户名字，必须在数据上打标签，所以跟系统A商量，要不你把username也随便转给我吧\n系统A一想，那也是两秒的事，因为本身在接受数据时也得对userId校验，取个username也不麻烦，不废话了，你要就给你\n因此系统B接受数据api设计成：\nsystemB.receive(long userId,String username,Object data);\n\n一切都是行云流水，大家都很happy，如期发布上线\n爱情总是在转角处遇到，上线完，QA同学一顿操作，却发现系统B没有如期显示出数据，系统B觉得是系统A没传来数据；咋办呢？心虚的系统A只能查查日志\nlog:systemB return error,username is empty \n\n原来原来是因为这个用户的username是空，系统B拒绝接受了，怎么username会为空呢？username怎么能为空呢？\n找到用户系统，用户系统解释了，一个用户在注册时并不一定有username,有username,email,usercode三个值中的任何一个值就可以了\n这时该怎么办呢？相爱相杀时刻到了\n系统B：要不你把这三个值都传给我？\n系统A：我还得再改下代码，测试后发版本，要不你自己从用户系统取吧\n系统B：传一个可以，怎么三个就不可以了，不都一样吗？\n系统A：太麻烦了，你自己取了，想怎么控制就怎么控制\n系统B：你是不爱我了\n系统A：你怎么就不理解我呢\n\n温习一下一个好的API设计要求：\n缩小依赖范围，就是要精简API；API要稳定得站在需求角度，而不是how角度\n\nAPI包含尽可能小的知识。因为任何一项知识的变化都会导致双方变化\nAPI也要高内聚，不应强迫API的客户依赖不需要的东西\n站在what角度；而不是how，怎么技术实现的角度\n\n上面示例的问题就在系统B接受数据api：\nsystemB.receive(long userId,String username,Object data);\n关照上面的要求：\n问题一：API中包含的知识有重复：userid,username\n问题二：客户端也就是systemA并不需要username，但被强迫要知晓并要按规则赋值\n问题三：站在设术实现角度，api中增加参数username，而不是需求角度\n总结示例虽小，日常工作中常常碰到这类问题，如果这个例子上线成功，每个人都觉得这是一次成功的交付，但回头复盘，发现了很多理论缺乏，惯性思维使然造成的不合理，难维护，难扩展的设计\n由此看出，日常的CRUD并不是没有技术含量，而是我们有没有深刻认知\n","tags":["SOLID"]},{"title":"Clean Code系列之坏味道及重构","url":"/blog/bad-taste-and-clean-code-series.html","content":"几乎在每个团队，都至少有一份代码规范，或者代码的check list。然也就仅仅是一份清单。\n每次团队复盘时，都会有一条，我们要写好代码，然“好代码”是什么样子，什么标准，全取决于各人的水平。\n每个程序员也都知道code review的重要性，然排期很紧张，难得做一次。宁可花时间追查问题，也不做防御性准备。\n这些现象，是不是特别平常，虽然很想改变，但又是无力感呢。\n程序员对代码的追求态度决定了职业生涯的高度，代码的质量决定了生活质量。\n为什么会有上面提到的现象，大概有这两方面的原因：\n1、每个人对“好代码”的观念不一样\n2、对于“坏味道”缺乏明确的表象判断，也就很难提出明确的改进措施\n\n\n好代码什么样的才是好代码，耳朵听出老茧的那句话“高内聚，低耦合”，可是这句话，太抽象了，类似之前总结的SOLID原则，需要更具体的特征。这也类似于要先把书读厚的原因。\n怎么培养对代码的审美高度？\n首先需要大量阅读好代码，可以去阅读很多开源项目。\n其次找个导师，让自己的代码多被审视。\n坏味道如果说好是没有标准的，那坏是有限的。\n对象健身操这是Thoughtworks文集中，有一套对象健身操。保持9条规则。\n1、 方法只使用一级缩进\n2、 拒绝使用else关键字\n3、 封装所有原生类型和字符串\n4、 一行代码只有一个“.”运算符\n5、 不要使用缩写\n6、 保持实体对象简单清晰\n7、 任何类中的实例变量都不要超过两个\n8、 使用一流的集合\n9、 不要使用任何Getter&#x2F;Setter&#x2F;Property\n\n重构经典书籍《重构》、《Clean Code》都是让代码质量提升的优秀教材。它们都是工具书，时时拿出来对照书本检查代码。\n在《重构》中，明确列出了多项“坏味道”，并给出了重构方法：\n1、 Duplicated Code（重复的代码）\n2、 Long Method（过长函数）\n3、 Large Class（过大类）\n4、 Long Parameter List（过长参数列）\n5、 Divergent Change（发散式变化）\n6、 Shotgun Surgery（霰弹式修改）\n7、 Feature Envy（依恋情绪）\n8、 Data Clumps（数据泥团）\n9、 Primitive Obsession（基本型别偏执）\n10、 Switch Statements（switch惊悚现身）\n11、 Parallel Inheritance（平行继承体系）\n12、 Lazy Class（冗赘类）\n13、 Speculative Generality（夸夸其谈未来性） \n14、 Temporary Field（令人迷惑的暂时值域）\n15、 Message Chains（过度耦合的消息链）\n16、 Middle Man（中间转手人）\n17、 Inappropriate Intimacy（狎昵关系）\n18、 Alternative Classes with Different Interfaces（异曲同工的类）\n19、 Incomplete Library Class（不完整的程序库类）\n20、 Data Class（单纯的数据类）\n21、 Refused Bequest（被拒绝的遗赠）\n22、 Comments（过多的注释）\n当然，实际工作中，不能消除所有坏味道，但只要能做到命名合理、没有重复、各个代码单元(类、函数)体量适当、各个代码单元有明确且单一的职责、各个代码单元之间有恰当的交互，就已经是质量相当高的代码了。\n我会按上面的内容结合实际工作，出一份Clean Code系列，早日让代码摆脱坏味道。\n","tags":["Clean Code"]},{"title":"Clean Code系列之异常处理","url":"/blog/exception-handling-of-clean-code-series.html","content":"先前已经对异常如何设计，如何实践异常都写了几篇阐述了。再一次从Clean Code角度来谈谈异常的使用。\n\n\n1、使用异常替代返回错误码为什么？是从函数的角度去考虑：\n函数要么做什么事，要么回答什么事，但二者不可得兼。也就是修改某对象状态，或者是返回该对象的有关信息。也就是指令与询问分隔开来。\n如\nboolean set(String attribute,String value);\n\n该函数设置某个指定属性，如果成功，就返回true，如果不存在那个属性，就返回false。\nif(set(&quot;website&quot;,&quot;zhuxingsheng.com&quot;))&#123;    //&#125;\n但从读者角度考虑一下，它是在问websit属性值是否之前已经设置为zhuxingsheng.com，还是在问websit属性值是否成功设置为zhuxingsheng.com呢？从该行语句很难判断其含义，因为set是动词还是形容词并不清楚。\n作者本意是，set是一个动词，但在if语句的上下文中，感觉它是一个形容词。该语句读起来像是在说“如果websit属性值之前已经被设置为zhuxingsheng.com”，而不是“设置websit属性值为zhuxingsheng.com，看看是否可行，然后…”。\n要解决这个问题，可以将set函数重命名为setAndCheckIfExists，但这对提高if语句的可读性帮助不大。真正的解决方案是把指令与询问分隔开来，防止产生混淆：\nif(attributeExists(&quot;website&quot;)&#123;    setAttribute(&quot;website&quot;,&quot;zhuxingsheng.com&quot;);&#125;\n\n在《领域服务是抛出异常还是返回错误码》，提到过如何编写返回错误码\nif(deletePage(page)) == OK)&#123;    &#125;\n但这样，从指令式函数返回错误码，有些违反指令与询问分隔的规则。\n虽然这儿没有像上面的示例一样，引起动词与形容词的混淆，却会导致更深层次嵌套结构\nif(deletePage(page) == OK)&#123;    if(deleteRefrence(page.name) == OK) &#123;        if (deleteKey(page.name.key()) == OK) &#123;            //        &#125; else &#123;          //          &#125;    &#125; else &#123;        //    &#125;&#125; else &#123;    //&#125;\n\n使用异常替代错误码，错误处理代码能从主路径代码中分离出来：\ntry &#123;    deletePage(page);    deleteRefrence(page.name);    deleteKey(page.name.key());&#125; catch (Exception e) &#123;    &#125;\n\n抽离try&#x2F;catch 代码块try&#x2F;catch代码块丑陋不堪，搞乱了代码结构，把错误处理与正常流程结构分离开来。\nvoid delete(Page page) &#123;    try &#123;        deltePageAndAllReferences(page)    &#125; catch(Exception e) &#123;        log;    &#125;&#125;\n正常流程结构：\nvoid deletePageAndAllReferences(Page page) &#123;    deletePage(page);    deleteRefrence(page.name);    deleteKey(page.name.key());&#125;\n\n这样子代码干净了些，而且函数只干一件事。错误处理就是一件事。\n想要更简化一下try&#x2F;catch代码块，可以使用vavr工具包中的Try类\nTry.of((page) -&gt; deltePageAndAllReferences(page)).onFailure(e -&gt; log(e));\n\nErrorCode枚举类返回的错误码，我们常会使用一个常量类或者枚举定义所有错误码。\n当新增逻辑需要增加新错误码时，就会增加新代码，而且还要来修改这个错误码类。\n这样的类被称为依赖磁铁，当这个类修改时，其他所有类都需要重新编译和部署。\n使用异常类代替错误码，新异常可以从异常类派生出来，而无须重新编译或重新部署。\n2、使用未检查异常在之前的异常文章中，提到检查异常有很强的穿透力，当类调用链路长，在底层方法上增加新检查异常就会导致上层所有方法修改声明，有点违反OCP。\n3、异常防腐在DDD中有防腐层的概念，通过防腐层去隔离两个界限上下文的变化。\n异常也有类似的情况。\n当调用第三方API时，会需要处理异常情况。\nThirdPartAPI third = new ThirdPartAPI();try &#123;    third.open();&#125; catch (Third1Exception e) &#123;    //&#125; catch (Thrid2Exception e) &#123;    //&#125; catch (Third3Exception e) &#123;    //&#125; finally &#123;    &#125;\n\n首先我们需要打包这个第三方API，降低对它的依赖；也不必绑死在某一特定供应商API上，定义自己的API还要抽象异常\nclass ThirdPartService &#123;    public void open() &#123;        try &#123;            third.open();        &#125; catch (Third1Exception e) &#123;            //            throw new SelfException(e);        &#125; catch (Thrid2Exception e) &#123;            //            throw new SelfException(e);        &#125; catch (Third3Exception e) &#123;            //            throw new SelfException(e);        &#125; finally &#123;                    &#125;    &#125;&#125;\n上面代码，定义了抽象的ThirdPartSevice,并且抽象出SelfException。\n总结经过上面的三种手法，可以让代码在处理异常时，更加整洁。\n","tags":["Clean Code"]},{"title":"DDD之Repository","url":"/blog/ddd-repository.html","content":"之前的DDD文章中也指出过，现在从理论角度对于repository是错误，但一直没有摸索出最佳实践，都是当DAO使用，区别在于repository是领域层，也没有深入思考过\n最近再次温习《DDD第二弹》时，看到了这个评论\n\ndomain service不应该直接调用repository，这打破了我对repository的认知，对此让我不得不纠结一下repository,在之前的学习中，从没有听到此规则，repository与domain service都是领域层的，为什么两都不能相互调用呢？\n从源头重新梳理一下repository的知识，重新翻阅Eric Evans的《领域驱动设计》和Vaughn Vernon的《实现领域驱动设计》\nrepositoryrepository是在《领域驱动设计》第六章领域对象的生命周期提出\n\n\nfactory用来创建领域对象，而repository就是在生命周期的中间和末尾使用，来提供查找和检索持久化对象并封装庞大基础设施的手段\n\n这句话就把repository的职责讲清楚了：\n\n提供查找和检索对象\n协调领域和数据映射层\n\n在现有技术范畴中，都使用DAO方式，为什么还需要引入repository呢？\n\n尽管repository和factory本身并不是来源于领域，但它们在领域设计中扮演着重要的角色。这些结构提供了易于掌握的模型对象处理方式，使model-driven design更完备\n\n\n领域驱动设计的目标是通过关注领域模型(而不是技术)来创建更好的软件。假设开发人员构造了一个SQL查询，并将它传递给基础设施层中的某个查询服务，然后再根据得到的表行数据的结果集提取出所需信息，最后将这些信息传递给构造函数或factory。开发人员执行这一连串操作的时候，早已不再把模型当作重点了。我们很自然地会把对象看作容器来放置查询出来的数据，这样整个设计就转向了数据处理风格。虽然具体的技术细节有所不同，但问题仍然存在–客户处理的是技术，而不是模型概念\n\n在DDD思想中，领域模型是最重要的，所有的一切手段都是为了让团队专注于模型，屏蔽一切非模型的技术细节，这样也才能做到通用语言，交流的都是模型\nVS DAO有人总结DDD就是分与合，分是手段、合是目的；对于DDD战略来讲，就是通过分来形成各个上下文界限，在各个上下文中，再去合，很类似归并算法\n而聚合就是最小的合，repository相对dao，是来管理聚合，管理领域对象生命周期\n\n为客户提供简单的模型，可用来获取持久化对象并管理生命周期\n使应用程序和领域设计与持久化技术（多种数据库策略甚至是多个数据源）解耦\n体现对象访问的设计决策\n可以很容易将它们替换为“哑实现”，以便在测试中使用（通常使用内存中的集合）\n\n\n而DAO的核心价值是封装了拼接SQL、维护数据库连接、事务等琐碎的底层逻辑，让业务开发可以专注于写代码。但是在本质上，DAO的操作还是数据库操作，DAO的某个方法还是在直接操作数据库和数据模型，只是少写了部分代码,并且可以操作任意表对象；在Uncle Bob的《代码整洁之道》一书里，作者用了一个非常形象的描述：\n\n硬件（Hardware）：指创造了之后不可（或者很难）变更的东西。数据库对于开发来说，就属于”硬件“，数据库选型后基本上后面不会再变，比如：用了MySQL就很难再改为MongoDB，改造成本过高。\n软件（Software）：指创造了之后可以随时修改的东西。对于开发来说，业务代码应该追求做”软件“，因为业务流程、规则在不停的变化，我们的代码也应该能随时变化。\n固件（Firmware）：即那些强烈依赖了硬件的软件。我们常见的是路由器里的固件或安卓的固件等等。固件的特点是对硬件做了抽象，但仅能适配某款硬件，不能通用。所以今天不存在所谓的通用安卓固件，而是每个手机都需要有自己的固件。\n\n从上面的描述我们能看出来，数据库在本质上属于”硬件“，DAO 在本质上属于”固件“，而我们自己的代码希望是属于”软件“。但是，固件有个非常不好的特性，那就是会传播，也就是说当一个软件强依赖了固件时，由于固件的限制，会导致软件也变得难以变更，最终让软件变得跟固件一样难以变更\n举个软件很容易被“固化”的例子：\nprivate OrderDAO orderDAO;public Long addOrder(RequestDTO request) &#123;    // 此处省略很多拼装逻辑    OrderDO orderDO = new OrderDO();    orderDAO.insertOrder(orderDO);    return orderDO.getId();&#125;public void updateOrder(OrderDO orderDO, RequestDTO updateRequest) &#123;    orderDO.setXXX(XXX); // 省略很多    orderDAO.updateOrder(orderDO);&#125;public void doSomeBusiness(Long id) &#123;    OrderDO orderDO = orderDAO.getOrderById(id);    // 此处省略很多业务逻辑&#125;\n在上面的这段简单代码里，该对象依赖了DAO，也就是依赖了DB。虽然乍一看感觉并没什么毛病，但是假设未来要加一个缓存逻辑，代码则需要改为如下：\nprivate OrderDAO orderDAO;private Cache cache;public Long addOrder(RequestDTO request) &#123;    // 此处省略很多拼装逻辑    OrderDO orderDO = new OrderDO();    orderDAO.insertOrder(orderDO);    cache.put(orderDO.getId(), orderDO);    return orderDO.getId();&#125;public void updateOrder(OrderDO orderDO, RequestDTO updateRequest) &#123;    orderDO.setXXX(XXX); // 省略很多    orderDAO.updateOrder(orderDO);    cache.put(orderDO.getId(), orderDO);&#125;public void doSomeBusiness(Long id) &#123;    OrderDO orderDO = cache.get(id);    if (orderDO == null) &#123;        orderDO = orderDAO.getOrderById(id);    &#125;    // 此处省略很多业务逻辑&#125;\n\n这时，你会发现因为插入的逻辑变化了，导致在所有的使用数据的地方，都需要从1行代码改为至少3行。而当你的代码量变得比较大，然后如果在某个地方你忘记了查缓存，或者在某个地方忘记了更新缓存，轻则需要查数据库，重则是缓存和数据库不一致，导致bug。当你的代码量变得越来越多，直接调用DAO、缓存的地方越来越多时，每次底层变更都会变得越来越难，越来越容易导致bug。这就是软件被“固化”的后果。\n所以，我们需要一个模式，能够隔离我们的软件（业务逻辑）和固件&#x2F;硬件（DAO、DB），让我们的软件变得更加健壮，而这个就是Repository的核心价值\n\n这也是上面所述的第二点：协调领域和数据映射层\n如果说DAO是低层抽象，那么Repository是高层抽象，也更衬托出repository的本质：管理领域的生命周期，不管数据来源于何方，只要把聚合根完整地构建出来就可以\ndata model与domain model数据模型与领域模型，按照Robert在《整洁架构》里面的观点，领域模型是核心，数据模型是技术细节。然而现实情况是，二者都很重要\n\n数据模型负责的是数据存储，其要义是扩展性、灵活性、性能\n而领域模型负责业务逻辑的实现，其要义是业务语义显性化的表达，以及充分利用OO的特性增加代码的业务表征能力\n调用关系对于domain service不要调用repository，这个规则我不太明白，只能请教作者了，为什么要这样限制？ 作者回复：\n\nDomain Service是业务规则的集合，不是业务流程，所以Domain Service不应该有需要调用到Repo的地方。如果需要从另一个地方拿数据，最好作为入参，而不是在内部调用。DomainService需要是无状态的，加了Repo就有状态了。\n\n\n我一般的思考方式是：domainService是规则引擎，appService才是流程引擎。Repo跟规则无关\n\n业务规则与业务流程怎么区分？\n\n有个很简单的办法区分，业务规则是有if&#x2F;else的，业务流程没有\n\n作者这样回答，我还是觉得太抽象了，在domain service拿数据太常见，还在看DDD第四讲时，作者有个示例是用domain service直接调用repository的，以此为矛再次追问作者\n\n这儿的domain service是直接使用repo的，如果里面的数据都使用入参，结构就有些怪啊\n\n在这个例子里确实是有点问题的（因为当时的关注点不是在这个细节上），一个更合理的方法是在AppService里查到Weapon，然后performAttack(Player, Monster, Weapon)。如果嫌多个入参太麻烦，可以封装一个AttackContext的集合对象。\n\n\n为什么要这么做？最直接的就是DomainService变得“无副作用”。如果你了解FP的话，可以认为他像一个pure function（当然只是像而已，本身不是pure的，因为会变更Entity，但至少不会有内存外的调用）。这个更多是一个选择，我更倾向于让DomainService无副作用（在这里副作用是是否有持久化的数据变更）。\n\n\n如果说Weapon无非是提供一些数据而已，那么我们假设扩展一下，每次attack都会降低Weapon的durability，那你在performAttack里面如果用了repo，是不是应该调用repo.save(weapon)？那为什么不直接在完成后直接用UserRepo.save(player)、MonsterRepo.save(monster)？然后再延伸一下，如果这些都做了，还要AppService干啥？这个Service到底是“业务规则”还是“业务流程”呢？\n\n\n从另一个角度来看，有的时候也不需要那么教条。DomainService不是完全不能用Repo，有时候一些复杂的规则肯定是要从”某个地方“拿数据的，特别是“只读”型的数据。但是我说DomainService不要调用repo时的核心思考是不希望大家在DomainService里有“副作用”。\n\n对于这种限制，我现在只能想到domain service要纯内存操作，不依赖repository可以提升可测试性\n性能安全这是在落地时，很多人都会想到的问题\n性能查询聚合与性能的平衡，比如Order聚合根，但有时只想查订单主信息，不需要明细信息，但repository构建Order都全部查出来了，怎么办？在《实现领域驱动设计》中，也是不推荐这么干的，使用延迟加载，很多人也觉得这应该是设计问题，不能依赖延迟加载\n对此问题请教了作者：\n\n在业务系统里，最核心的目标就是要确保数据的一致性，而性能（包括2次数据库查询、序列化的成本）通常不是大问题。如果为了性能而牺牲一致性，就是捡了芝麻漏了西瓜，未来基本上必然会触发bug。\n\n\n如果性能实在是瓶颈，说明你的设计出了问题，说明你的查询目标（主订单信息）和写入目标（主子订单集合）是不一致的。这个时候一个通常的建议是用CQRS的方式，Read侧读取的可能是另一个存储（可能是搜索、缓存等），然后写侧是用完整的Aggregate来做变更操作，然后通过消息或binlog同步的方式做读写数据同步。\n\n这也涉及到业务类型，比如电商，一个订单下的订单明细是很少量的，而像票税，一张巨额业务单会有很多很多的订单明细，真要构建一个完整的聚合根相当吃内存\n对象追踪repostiory都是操作的聚合根，每次保存保存大多只会涉及部分数据，所以得对变化的对象进行追踪\n《实现领域驱动设计》中提到两种方法：\n\n隐式读时复制（Implicit Copy-on-Read）[Keith &amp; Stafford]：在从数据存储中读取一个对象时，持久化机制隐式地对该对象进行复制，在提交时，再将该复制对象与客户端中的对象进行比较。详细过程如下：当客户端请求持久化机制从数据存储中读取一个对象时，该持久化机制一方面将获取到的对象返回给客户端，一方面立即创建一份该对象的备份（除去延迟加载部分，这些部分可以在之后实际加载时再进行复制）。当客户端提交事务时，持久化机制把该复制对象与客户端中的对象进行比较。所有的对象修改都将更新到数据存储中。\n隐式写时复制Implicit Copy-on-Write）[Keith &amp; Stafford]：持久化机制通过委派来管理所有被加载的持久化对象。在加载每个对象时，持久化机制都会为其创建一个微小的委派并将其交给客户端。客户端并不知道自己调用的是委派对象中的行为方法，委派对象会调用真实对象中的行为方法。当委派对象首次接收到方法调用时，它将创建一份对真实对象的备份。委派对象将跟踪发生在真实对象上的改变，并将其标记为“肮脏的”（dirty）。当事务提交时，该事务检查所有的“肮脏”对象并将对它们的修改更新到数据存储中。\n\n以上两种方式之间的优势和区别可能会根据具体情况而不同。对于你的系统来说，如果两种方案都存在各自的优缺点，那么此时你便需要慎重考虑了。当然，你可以选择自己最喜欢的方式，但是这不见得是最安全的选择。无论如何，这两种方式都有一个相同的优点，即它们都可以隐式地跟踪发生在持久化对象中的变化，而不需要客户端自行处理。这里的底线是，持久化机制，比如Hibernate，能够允许我们创建一个传统的、面向集合的资源库。另一方面，即便我们能够使用诸如Hibernate这样的持久化机制来创建面向集合的资源库，我们依然会遇到一些不合适的场景。如果你的领域对性能要求非常高，并且在任何一个时候内存中都存在大量的对象，那么持久化机制将会给系统带来额外的负担。此时，你需要考虑并决定这样的持久化机制是否适合于你。当然，在很多情况下，Hibernate都是可以工作得很好的。因此，虽然我是在提醒大家这些持久化机制有可能带来的问题，但这并不意味着你就不应该采用它们。对任何工具的使用都需要多方位权衡\n《DDD第二弹》中也提到 业界有两个主流的变更追踪方案：这两个方案只是上面两种方案另取的两外名字而已，意思是一样的\n\n基于Snapshot的方案：当数据从DB里取出来后，在内存中保存一份snapshot，然后在数据写入时和snapshot比较。常见的实现如Hibernate\n基于Proxy的方案：当数据从DB里取出来后，通过weaving的方式将所有setter都增加一个切面来判断setter是否被调用以及值是否变更，如果变更则标记为Dirty。在保存时根据Dirty判断是否需要更新。常见的实现如Entity Framework\n\nSnapshot方案的好处是比较简单，成本在于每次保存时全量Diff的操作（一般用Reflection），以及保存Snapshot的内存消耗。Proxy方案的好处是性能很高，几乎没有增加的成本，但是坏处是实现起来比较困难，且当有嵌套关系存在时不容易发现嵌套对象的变化（比如子List的增加和删除等），有可能导致bug。\n由于Proxy方案的复杂度，业界主流（包括EF Core）都在使用Snapshot方案。这里面还有另一个好处就是通过Diff可以发现哪些字段有变更，然后只更新变更过的字段，再一次降低UPDATE的成本。\n安全设计聚合时，聚合要小，一是事务考虑，二是安全性考虑。当并发高时，对聚合根操作时，都需要增加乐观锁\nReference一文教你认清领域模型和数据模型\n第三讲 - Repository模式\n","tags":["DDD"]},{"title":"DDD分层","url":"/blog/ddd-layering.html","content":"为什么分层引用《领域驱动设计模式、原理与实践》\n\n为了避免将代码库变成大泥球（BBoM）并因此减弱领域模型的完整性且最终减弱可用性，系统架构要支持技术复杂性与领域复杂性的分离。引起技术实现发生变化的原因与引起领域逻辑发生变化的原因显然不同，这就导致基础设施和领域逻辑问题会以不同速率发生变化\n\n每一层都有各自的职责，显然这也是符合SRP的\n如何分层DDD的标准形态\n\n\nUser Interface是用户接口层，主要用于处理用户发送的Restful请求和解析用户输入的配置文件等，并将信息传递给Application层的接口\nApplication层是应用层，负责多进程管理及调度、多线程管理及调度、多协程调度和维护业务实例的状态模型。当调度层收到用户接口层的请求后，委托Context层与本次业务相关的上下文进行处理\nDomain层是领域层，定义领域模型，不仅包括领域对象及其之间关系的建模，还包括对象的角色role的显式建模\nInfrastructure层是基础实施层，为其他层提供通用的技术能力：业务平台，编程框架，持久化机制，消息机制，第三方库的封装，通用算法，等等\n\n根据DDD细化业务逻辑层\n\n模块结合maven的module,项目中现在分了八个module\n&lt;modules&gt;    &lt;module&gt;generator-assist-dao&lt;/module&gt;     &lt;module&gt;generator-assist-client-api&lt;/module&gt;     &lt;module&gt;assist-client-api&lt;/module&gt;     &lt;module&gt;assist-controller&lt;/module&gt;     &lt;module&gt;assist-service&lt;/module&gt;     &lt;module&gt;assist-infrastructure&lt;/module&gt;     &lt;module&gt;assist-common&lt;/module&gt;     &lt;module&gt;start&lt;/module&gt; &lt;/modules&gt;\n\nstart入口模块\n包结构：\n\nstart  只有一个启动类\ntest 单元测试\n\n除了启动类，还有单元测试\ngenerator-assist-dao生成的dao类\n包结构：\n\nrepository\nmodel  与数据库对应的实体类\n\n\nrepository\nmapper  mybatis的mapper\n\n\n\n现在实践落地时，这个模块是个空模块，why?\nDDD中明确了repository概念，并属于domain层，但dao是对底层数据库的封装，具体实现类放在infrastructure层更合理\n在COLA中，作者也是为了领域层的纯洁性，依赖反转了，repository接口定义在domain层，而实现在infra层\n\n但在落地时，domain与infra出现了循环依赖，COLA把实现放在了app层，这样有些另类，所以暂时先把repository全部放在了service层\n迷思：\n1、基于mybatis的实现，mapper本身是接口，repository实现类放在domain层，不要接口，这样满足DDD分层规则，但离DIP差了一步\n2、在《DDD之熵》中提过\n\nDDD引入repository放在了领域层，一是对应聚合根的概念，二是抽象了数据库访问，，但DDD限界上下文可能不仅限于访问数据库，还可能访问同样属于外部设备的文件、网络与消息队列。为了隔离领域模型与外部设备，同样需要为它们定义抽象的出口端口，这些出口端口该放在哪里呢？如果依然放在领域层，就很难自圆其说。例如，出口端口EventPublisher支持将事件消息发布到消息队列，要将这样的接口放在领域层，就显得不伦不类了。倘若不放在位于内部核心的领域层，就只能放在领域层外部，这又违背了整洁架构思想\n\n3、是不是有别的理论支撑解决问题2\ngenerator-assist-client-api为了生成api的swagger yaml文件\n包结构：\n\nswagger-spec\nall  swagger所有yaml文件的整合文件\napis swagger定义的api\nmodels swagger定义的api中的model\n\n\nswagger-templates 模板文件\n\nassist-client-api通过swagger生成的api接口与api中的model\n包结构：\n\nclient\napi swagger生成的api接口\nmodel  swagger生成的request,response对象\n\n\n\nassist-controllercontroller层，放置controller\n包结构：\n\ncontroller 所有的controller\nxxljob  xxljob补偿任务\n\n按DDD分层规范，controller属于ui层，处理restful请求\n\n接受请求 —— 由spring提供能力\n请求格式校验及转换 —— 格式校验遵循java Validation规范\n权限校验 —— 由网关处理\n路由请求 —— 网关处理\n记录请求 —— 专门Accessfilter处理\n回复响应 —— 由spring提供能力\n\n为什么还有一个xxljob包，从能力区分，xxljob放到infra层才对。这个原因类似generator-assist-dao模块，xxljob的handler需要调用application service，需要依赖service module\n因此可以把xxljob作为远程请求的一个入口，与controller一样归在ui层\n这儿引出一点思考，controller真的是ui层吗？能划分到别的层吗？\n有几种设计思路\n\nui层完全归属于大前端，不在后端，也就不在ddd中，后端都是从application service开始\ncontroller归于ui\ncontroller归于infra，controller毕竟是依赖具体底层框架能力的adapter\n\n\ncontroller是基于springboot的具体实现\n从上面的分析，可以看出controller逻辑上是归到infra层，但物理上不能放到infra模块；也不能简单把controller看作MVC中的C，还有很多像xxljob样的入口\n\n入口会有很多，如controller、xxljob，还有mq等等\n还有进程内的，如event，应用层，基础设施层，领域层都有event，怎么区分event是个问题\napplication serivce与domain service区分也常常给人带来烦恼\n\n这儿是否可以借鉴《DDD之形》中的端口和适配器架构\n\n把controller看作driving adapter，既然区分这么复杂，那可不可以简单点，加厚controller，整合入口与application service\n简单点分成两部分：远程服务与本地服务\n\n远程服务：定义会跨进程服务，分为资源（Resource）服务、供应者（Provider）服务、控制器（Controller）服务与事件订阅者（Event Subscriber）服务\n本地服务：所有远程服务需要调用领域服务，必须经过本地服务才能调用；明确隔离外界与领域，防止领域模型外泄\n\nassist-servicedomain层，但现在还是三层结构的思路，什么类都有，app service，domain service，dto,event 甚至还有基础设施层类\n包结构\n\nBO\nbuilder\ncommon\ncomponent\nconvertor\ndomain\ndto\nevent\ninterceptor\nlistener\nmodel\nrepository\nservice\nthrid\nvalid\n\nassist-infrastructure基础设施层\n包结构\n\nconfig  配置信息\nadapter  外部调用封装\nclients 外部调用实现\npl 服务接口的契约 published language\n\n\ndp domain primitive  这是不是应该在domain层\ncommon 公共类，(InvoiceType与InvoiceTypeEnum的问题)\nevent\npublish 事件发布者，此包为空，直接依赖spring不需要自实现了\n\n\nexception 异常类\ngateway  网关，封装访问外部系统或资源行为的对象\nwechat  外部名称\napi 外接接口\ndto 外接接口dto\n\n\n\n\nlocal\npl\n\n\nports\nclients 外部调用接口\n\n\nrepository\nmodel\n\n\nresources 资源\nservice 依赖外部的service\nutil 工具类\n\n现在的包结构很丰富，最常见的包就是gateway，配合acl与外部交互\n\nU表示上游（Upstream）的被依赖方，D表示下游（Downstream）的依赖方。防腐层（ACL）放在下游，将上游的消息转化为下游的领域模型\n结合generator-assist-dao模块的问题，是否可以扩大ACL，而不仅限于gateway中,像资源库一样，不必完全遵循DDD只抽象repository，像访问第三方应用，缓存，消息都可以抽象出来，契合端口履行的职责一样\n\n改造&lt;modules&gt;    &lt;module&gt;generator-assist-dao&lt;/module&gt;     &lt;module&gt;generator-assist-client-api&lt;/module&gt;     &lt;module&gt;assist-client-api&lt;/module&gt;     &lt;module&gt;assist-ohs&lt;/module&gt;     &lt;module&gt;assist-service&lt;/module&gt;     &lt;module&gt;assist-acl&lt;/module&gt;     &lt;module&gt;start&lt;/module&gt; &lt;/modules&gt;\n\nassist-controller根据上面的分析，这一层可以更厚实些\n改名为assist-ohs\nOHS,open host service 开放主机服务，定义公开服务的协议，包括通信的方式、传递消息的格式（协议）\n包结构\n\nremote\ncontroller\nopenapi\nxxljob\nsubscribe\n\n\nlocal\nappservices\npl (plush language)   request,response\nconvertor\n\n\n\nassist-servicedomain层\n包结构\n\ndomain 领域对象\nservice 领域服务\nfactory 领域对象工厂\nbuilder 领域对象构造器\n\nassist-acl扩大了基础设施层，隔离领域层与外部依赖，对所有外部环境一视同仁，无需针对资源库做特殊化处理，如此也可保证架构的简单性，repository、client、cahce…\n领域层依赖port接口\n包结构\n\nconfig 配置信息\nport 依赖外部接口\nrepository 数据库接口\nclient 第三方系统接口\npublisher 消息接口\ncache 缓存接口\n\n\nadapter port的具体实现\nrepository\npl\nclient\n\n\n\n总结模块划分以及包结构还只是一家之言，一是有充足的理论体系支撑，不管按DDD标准，还是变形，更多地有理有据，与团队、也与自己达成一致；二是domain的抽象，一切都是为了领域模型的稳定性和扩展性，形只是表象\n我们这个项目还是太注重了形，最重要的domain还是过弱\n","tags":["DDD"]},{"title":"DDD之Repository对象生命周期管理","url":"/blog/ddds-repository-object-lifecycle-management.html","content":"在DDD中Repository是一个相当重要的概念。聚合是战略与战术之间的交汇点。而管理聚合的正是Repository。\n因为从战略层次，分而治之，我们会按领域、子域、界限上下文、聚合逐步划分降低系统复杂度；从战术层次，我们会从实体、值对象、聚合逐步归并，汇合。\n也因此有人解析DDD关键就是两个字：分与合，分是手段，合是目的。\n之前写的《DDD之Repository》，大致介绍了Repository作用。\n\n一是从“硬件”、“软件”、“固件”阐述了Repository的必要性，相对DAO，具有更高抽象，不再关心数据是从db,cache甚至第三方系统，Repository管理着数据在存档态与活跃态之间的转换\n二是Respository与Domain Service之间的调用关系\n\n\n虽然解释了不少，但也有些问题没有阐述清楚，借这篇再进一步详情补充说明下\n常见的两个错误：\n1、领域模型中不能出现技术词，所以在设计模型时，不要出现DAO之类的技术词。而在DDD中提出了Repository，一是从DDD统一语言角度，数据具体技术存储抽象为Repository；二是Repsotiory也表达模型概念。\n2、Repository是DDD中作为DAO的替身，换汤不换药，所以从以前的XXXDao,变成了XXXRepository，然而Repository在DDD中并不是这么简单，它管理着聚合的生命周期，而其他实体对象由对应的聚合对象管理。\n对于第一点，再详述下。在面向对象中有两种对象逻辑：单对象逻辑和集合对象逻辑。\n如单纯的User对象，还有表示Collection users逻辑，如年龄最大最小的用户，是集合逻辑\n如果把Collection变成PersistentCollection，就是DB。\n再进一步，看个小示例,一个办事处有很多的员工，以往模型表达为：\nclass Office &#123;    List&lt;User&gt; users;&#125;\n\n换一种方式：\nclass Office &#123;    Users users;&#125;\n\n使用Users来表达集合对象，这样原先使用List不能表达的模型，在抽象集合对象Users上可以很好的表达出来。\n而Repository就是代表了一种集合领域逻辑，如我们直接把UserRespository想像为Users处理。\n使用这种方式一是能更好地表达模型，二也能解决在《处理业务逻辑的三种方式》 中提到的性能问题。\n性能与模型的选择其实是在实践DDD过程中很多人的拦路虎。\n如上面的Office对象，如果使用List来表达users集合数据，那当加载Office对象，users是不是必须加载出来，从模型完整性角度必须得加载出来，但加载出来必须带来性能损耗，如果users数量很大，不借助类似hibernate提供的懒加载机制来规避N+1带来的性能损耗，这个模型根本不可行。\n这也是Repository不能按DDD原意来落地的原因。\n进一步思考，其实上面的原因只是表象，背后是生命周期的管理。\n生命周期管理不论是设计，还是性能，对于聚合，除了显现的要求是聚合内的数据一致性。在数据库体系中，我们都是使用事务一致性来管理一致性和完整性。也是变相得把实体一致性与事务一致性两者的边界在同一边界上。\n还有隐含的构建关系和级联生命周期。\n比如：Order 与 OrderItem\n创建：\nOrder &#123;    List&lt;OrderItem&gt; items;        public OrderItem newItem(String itemName,String price)&#123;            OrderItem item = new OrderItem(this);        items.add(item);        return item;            &#125;    &#125;\n\n那么当domain service去处理Order业务时\nOrderService &#123;        void doOrder() &#123;        Order order = new Order(orderId);        // order do something        order.newItem(name,price);                orderRepository.save(order);    &#125;&#125;\n当orderRepository.save()时，不仅让order从活跃态变成持久态，还会把orderItem也由活跃态变成持久态。\n当orderRepository.delete()时，也不仅删除了order，也得删除orderItem。才能保持一致性。\n自然读取Order时，orderItems也得加载完整，保持模型的完整性。\n这就是构建关系与级联生命周期。\n怎么处理呢？\n大致有三种方法\n技术手段在《DDD之Repository》提到的对象追踪，其实有很多的名字，也有叫Dirty Tracking\n再配合延迟加载技术，达到了我们的目标：模型完整，落地可控。\n失联领域 disconnected aggregateOrder &#123;    List&lt;Item&gt; items;    addItem(amount) &#123;      Item item = new Item(orderId,amount)      items.add(item)      this.jpa.insert(item);    &#125;&#125; \n\n在《IDDD》也提到，在聚合中使用 repository 来操作聚合。但不推荐，这只是延迟加载的一种形式。\n把聚合看作一个整体，不用关心聚合内实体的改变，将所有改变，看作是聚合本身的改变。\n在《IDDD》中也不推荐这样，给出的做法是在调用聚合方法前，先取出所需要的实体，也就是像在上述文章中所讲：Domain service不要依赖Repository。可以在application service里通过repository查出需要数据，再传给domain service，让domain service变得无状态。\n但这种方式，看着是个方法，但实践时，有违直觉。什么意思呢？就是Aggregate依赖了Repository。相当于实体依赖了DAO，是不是很不应该？\n其实domain service, entity, repository都属于domain层，那为什么同一层的类不能相互调用呢？\n制定规则是来协调处理复杂性，都是基于认知或经验制定的，而不是为了规则而规则。\n既然我们的认知是他们都在一层，应该可以调用，凭什么不能调用，不违背降低复杂性的前提下不要特意限制。\n上文讲过Repository其实包含了一种集合逻辑，那我们把OrderRepository变名为Orders，也是一样的。\n那么下面的代码是没有毛病的\nUser &#123;   List&lt;User&gt; users; &#125;\n\n把List抽象成Users集合对象\nUsers implements List&lt;User&gt; &#123;    &#125;\n\n到这儿，自然第一段代码，就变成了\nUser &#123;    Users users;&#125;\n这样写，是不是也没毛病？ 把Users再替换成Repository\nUser &#123;    UserRepository repository;&#125;\n是不是也没问题了，也就是User依赖了UserRepository。\n由上面四段小代码，推导出了User依赖UserRepository的合理性与可行性，只是平常被DAO方式习惯了，以致于心理上有点别扭而已。这也变相说明了Repository不是DAO。\n再进一步：\nOrders &#123;        void addOrder(order) &#123;            this.dao.insert(order);    &#125;&#125; \n\n这段代码，如果没有使用jpa,orm框架，也是有问题的。\n为何？破坏了封装性。\n因为在dao.insert里面必然会暴露order的内部数据\nOrderDao &#123;    void insert(order) &#123;        db.execute(order.getId(),order.getTime(),...);    &#125;&#125;\n\n我们使用对象建模，就是把业务逻辑 建模为数据变化，然后把数据的改变和改变数据的行为放一起\n不同于面向过程是建模业务流程。\n数据变化，以及生命周期变化是业务的核心逻辑。\n对象状态变化来自队列和缓存，那么也要被domain封装对象生命周期。\n因此代码得这样写，才不被破坏封装性：\nOrder &#123;   void save(OrderRepo) &#123;        orderRepo.save(thid.id,thid.time,...);   &#125;&#125;\n\nrepo.save(order) 与 order.save(repo) 两种写法看似简单，背后的思想却让人的思考变得如此肤浅。\n前一种写法，如果不与orm绑定，会造成封装性破坏，而且会从充血模型变成了贫血模型，table module。\n后一种写法，在不与orm绑定前提下保护了封装性，但save行为赋给了当前对象，这是在面向对象早期流行的真实世界建模。\n不管怎么写，从活跃态到归档态是很重要的行为，因为数据一致性是业务逻辑的核心。也说明了不管如何建模，都要考虑到技术实现，domain不是一片静土，没有约束的理想化实现，而是受特定技术栈与技术生态环境约束的实现。所以在分层时，有人认为基础设施层不是层的原因。\n关联对象 association object除了上面两种方式，还有在《分析模式》中提到的关联对象模式。\n关联对象，顾名思义，就是将对象间的关联关系直接建模出来，然后再通过接口与抽象的隔离，把具体技术实现细节封装到接口的实现中。这样既可以保证概念上的统一，又能够避免技术实现上的限制。\n总结DDD中实体大致分成了两种：一是聚合根，二是聚合内实体。两者的生命周期管理也不一样，聚合根由repository管理，而其他实体由聚合根管理。\n因此当在创建聚合根的时候，聚合根与其内部实体的生命周期有级联关系。通过三种方式可以实现这种级联关系。不管是何方式，要达到的目标：一是数据一致性，二是模型显现表达出来。\n","tags":["DDD"]},{"title":"DDD之形","url":"/blog/form-of-ddd.html","content":"DDD现在已然变成哲学，正因为是哲学，所以法无定法，到底怎么具体怎么实施，各显神通，心法固然重要，但心法有几人能真正领悟，一说就懂，一问就不会，一讨论就吵架；所以还是从外形看看，收集一些实践后的形态，由表入里，以形学形，慢慢品\n看下面两个分层，左边是Vaughn Vernon 在《实现领域驱动设计》一书中给出了改良版的分层架构，他将基础设施层奇怪地放在了整个架构的最上面；右边就是DDD最标准的分层形态\n\n形一这是DDD专家张逸老师形态之一，除了controller在gateway中，其它还算常态\n\necommerce\ncore\nIdentity\nValueObject\nEntity\nDomainEvent\nAggregateRoot\n\n\ncontrollers\nHealthController\nMonitorController\n\n\napplication（视具体情况而定）\ninterfaces\nio\ntelnet\nmessage\n\n\ngateways\nio\ntelnet\nmessage\n\n\nordercontext\napplication\ninterfaces\ndomain\nrepositories\ngateways\n\n\nproductcontext\napplication\ninterfaces\ndomain\n\n\n\n\n\n\n除了限界上下文自身需要的基础设施之外，在系统架构层面仍然可能需要为这些限界上下文提供公共的基础设施组件，例如对 Excel 或 CSV 文件的导入导出，消息的发布与订阅、Telnet 通信等。这些组件往往是通用的，许多限界上下文都会使用它们，因而应该放在系统的基础设施层而被限界上下文重用，又或者定义为完全独立的与第三方框架同等级别的公共组件。理想状态下，这些公共组件的调用应由属于限界上下文自己的基础设施实现调用。倘若它们被限界上下文的领域对象或应用服务直接调用（即绕开自身的基础设施层），则应该遵循整洁架构思想，在系统架构层引入 interfaces 包，为这些具体实现定义抽象接口\n\n\ncontroller被放到了gateway中，包含远程调用，数据库；所有对外的接口都属于一种网关\n形二cola在github开源，作者模块与包划分，每个架构元素都很明确\n\n\ncontroller这是一个可选层，正如《分层架构》所讲，现在的框架都已经帮助从底层的具体HttpRequest转换成了requestDto，很多时候都是透传service，而像thrift类的框架，为了透明化入口，需要转换一下，\n包xxx.controller\nclient二方库，里面存放RPC调用的DTO\n包xxx.api:存放应用对外接口\nxxx.dto.domainmodel：数据传输的轻量级领域对象\nxxx.dto.domainevent:数据传输的领域事件\napplication应用层\n包xxx.service：接口实现的facade，没有业务逻辑，可以对应不同的adapter\nxxx.event.handler:处理领域事件\nxxx.interceptor:对所有请求的AOP处理机制\ndomain领域层\n包xxx.domain:领域实现\nxxx.service:领域服务，用来提供更粗粒度的领域能力\nxxx.gateway:对外依赖的网关接口，包括存储、RPC等\ninfrastructure基础层\n包xxx.config:配置信息相关\nxxx.message:消息处理相关\nxxx.repository:存储相关，gateway的实现类，主要用来做数据的CRUD操作\nxxx.gateway:对外依赖网关接口(domain里面的gateway)的实现\n形三这是张逸老师课程的又一形态\n\n六边形架构仅仅区分了内外边界，提炼了端口与适配器角色，并没有规划限界上下文内部各个层次与各个对象之间的关系；而整洁架构又过于通用，提炼的是企业系统架构设计的基本规则与主题。因此，当我们将六边形架构与整洁架构思想引入到领域驱动设计的限界上下文时，还需要引入分层架构给出更为细致的设计指导，即确定层、模块与角色构造型之间的关系\n\n\n\n\n这是老师最新总结的菱形对称架构\n\n南向网关引入了抽象的端口来隔离内部领域模型对外部环境的访问。这一价值等同于上下文映射的防腐层（Anti-Corruption Layer，简称为 ACL） 模式，只是它扩大了防腐层隔离的范围\n形态四\n该架构由端口和适配器组成，所谓端口是应用的入口和出口，在许多语言中，它以接口的形式存在\nMartin Fowler将“封装访问外部系统或资源行为的对象”定义为网关（Gateway），在限界上下文的内部架构中，它代表了领域层与外部环境之间交互的出入口，即：\ngateway &#x3D; port + adapter\n这个形态，简单入里，算是菱形对称架构的简易形，甚至可以说是菱形的初形\ndriving adapter + domain + driven adapter\n总结形态之多，背后的理论支撑之丰富，可见DDD的博大精深，谁能说是正宗，就算是Eric Evans都要怀疑人生，但不迷信，没有银弹。自己实践的才是最合适的\n","tags":["DDD"]},{"title":"DDD之熵","url":"/blog/entropy-of-ddd.html","content":"《DDD之形》把当前一些流行的架构给通览了一篇，那是不是万事大吉，随便挑一个形态实践就行呢？\n正常情况对于有追求的程序员来讲，肯定不行，有两个原因\n一因为完美，人人都是想要完美，每个架构实践都不是完美的，尤其离开业务场景去探讨架构，会使架构没法落地；因此你小抄的时候会变形，想把原先至少不太好的地方改得相对好些，但这样可能造成四不像\n二因为没有意的形，只知其形，不得其意，必然会东施效颦；类似于第一点，完美，何为完美，还是得根据自身经验理解程序得出的结论，如果高度不够必然会画蛇添足\n标准形态根据DDD的理论，或者说DDD带来的优势，将三层架构进行演化，把业务逻辑层再细拆分成三层：应用层、领域层和基础设施层\n分离业务逻辑与技术细节\n\nDDD的标准形态\n\n分层架构分为两种：严格分层架构和松散分层架构\n严格分层，某层只能与直接位于其下方的层发生耦合；松散分层，允许任意上方层与任意下方层发生耦合\n\nUser Interface是用户接口层，主要用于处理用户发送的Restful请求和解析用户输入的配置文件等，并将信息传递给Application层的接口\nApplication层是应用层，负责多进程管理及调度、多线程管理及调度、多协程调度和维护业务实例的状态模型。当调度层收到用户接口层的请求后，委托Context层与本次业务相关的上下文进行处理\nDomain层是领域层，定义领域模型，不仅包括领域对象及其之间关系的建模，还包括对象的角色role的显式建模\nInfrastructure层是基础实施层，为其他层提供通用的技术能力：业务平台，编程框架，持久化机制，消息机制，第三方库的封装，通用算法，等等\n\nDIP上面的标准形态图形的左半边图，跟以往的很不一样，但从DIP角度看，低层服务应该依赖于高层组件\n\n这是COLA2.0的分层，作者利用DIP对1.0版本进行了优化\n\n1、核心业务逻辑和技术细节相分离，使用DIP，让Infrastructure反向依赖Domain\n\n\n2、将repository上移到application层，把组装entity的责任转移到application\n\n\n到此一切都很常规，很标准，但在落地时有几个问题：\n一、Controller是哪一层，user interface层？还是infrastructure层？\n这好像不是个问题，一般都放在user interface层，负责向用户展现信息以及解释用户命令；但细想一下，我们的controller都是基于底层框架，是框架提供的能力，那理论上放在infrastructure更合理一些。\n二、再细化的架构元素放哪里？\n其实这只是分层的大体方向，还有更细节的元素，在实践DDD的过程中，最常见的问题就是元素到底放在哪儿，比如Event,有各样的event，eventHandler，应用层、领域层都有，怎么区分呢？貌似回到了怎么区分应用服务与领域服务；还有各处javabean，哪些层能复用，谁复用谁\n再比如COLA2.0，单从层次依赖图明显形成了循环依赖，落地不了；但作者把repository上移到了application层，又有些走不寻常路，一般来讲repository是放在domain层\n如何办呢？大方向有了，但到小细节时，又有各种困惑，《SOLID之DIP》文中提到，分层至少有两层，一是业务领域层，二是其它层\n\n这就是端口和适配器架构，可以算是六边形的简化版，但也从整体方向分成了两层，对应用层与用户接口层以及基础设施层进行了合并，无论是接受请求，还是输出数据都是gateway\n但六边形架构仅仅区分了内外边界，提炼了端口与适配器角色，并没有规划限界上下文内部各个层次与各个对象之间的关系；怎么破？\n\n这似乎是两个矛盾体，标准的层次分明了，但还是有些不确定性，对象放在哪个包不明确；而端口与适配器架构又太粗放；如何平衡？\n本质上，领域驱动设计的限界上下文同样是对软件系统的切割，依据的关注点主要是根据领域知识的语境，从而体现业务能力的差异。在进入限界上下文内部，我们又可以针对限界上下文进行关注点的切割，并在其内部体现出清晰的层次结构，这个层次遵循整洁架构\n\n根据张逸老师DDD课程中的案例\n\n\n领域层：包含 PlaceOrderService、Order、Notification、OrderConfirmed 与抽象的 OrderRepository，封装了纯粹的业务逻辑，不掺杂任何与业务无关的技术实现。\n应用层：包含 OrderAppService 以及抽象的 EventBus 与 NotificationService，提供对外体现业务价值的统一接口，同时还包含了基础设施功能的抽象接口。\n基础设施层：包含 OrderMapper、RabbitEventBus 与 EmailSender，为业务实现提供对应的技术功能支撑，但真正的基础设施访问则委派给系统边界之外的外部框架或驱动器\n\n\n重新审视六边形架构，匹配分层架构，两者可以融合\n\n位于六边形边线之上的出口端口就应该既不属于领域层，又不属于基础设施层。它的职责与属于应用层的入口端口也不同，因为应用层的应用服务是对外部请求的封装，相当于是一个业务用例的外观\nDDD引入repository放在了领域层，一是对应聚合根的概念，二是抽象了数据库访问，，但DDD限界上下文可能不仅限于访问数据库，还可能访问同样属于外部设备的文件、网络与消息队列。为了隔离领域模型与外部设备，同样需要为它们定义抽象的出口端口，这些出口端口该放在哪里呢？如果依然放在领域层，就很难自圆其说。例如，出口端口EventPublisher支持将事件消息发布到消息队列，要将这样的接口放在领域层，就显得不伦不类了。倘若不放在位于内部核心的领域层，就只能放在领域层外部，这又违背了整洁架构思想\n","tags":["DDD"]},{"title":"DDD工程代码模型的几种包风格","url":"/blog/several-package-styles-of-ddd-project-code-model.html","content":"在团队中，一直在灌输DDD的理念，最近review一些新开发的项目时，发现工程包结构每个人的理解都是不一样的，命名也是各有特色。\n因此，觉得有必要把之前整理的工程结构重新梳理下。\n而在梳理的过程中，恍惚间，有种看山是山、看山不是山、看山还是山的体会。特别有意思。\n传统风格\n之前的总结DDD分层，每一层都是明确的。\n整个工程的包结构就是这样的：\n\ninterface\napplication\ndomain\ninfrastraction\n\n但是在落地时遇到了很多的问题，在DDD系列文章中也提到过：\n1、循环依赖：\ndomain是依赖于infrastraction，但如repository接口是在domain层的，DDD也是这么定义的，但具体的ORM实现是在infrastraction。因此infrastraction又需要依赖domain。形成循环依赖。\n2、domain的厚度\n以前都是MVC，贫血模型。所以刚开始时，domain是很薄的，以致于没有存在感。很多service都被application干完了。常有application service与domain service区别的讨论。落地时也常搞混。\n依赖倒置不知道是不是整洁架构，还是洋葱架构之后或之前吧，依赖倒置成了程序员认知的共识。\n\n为了脱离大泥球，人们注意到整体中各个部分的需求变化速率不同，进而通过关注点分离来降低系统复杂度。这是分层架构的起源。\n倒置的原因，是因为领域层被赋于最稳定层。\n1、展现层\n逻辑是最容易改变的，新的交互模式以及不同视觉模板。\n2、应用层\n随着业务流程以及功能点的变化而改变。如流程重组和优化、新功能点引入，都会改变应用层逻辑。\n3、领域层\n核心领域概念的提取，只要领域概念和核心逻辑不变，基本是不变的。一旦领域层出现重大改变，就意味着重大业务调整，整个系统都被推倒重来。\n4、基础设施层\n逻辑由所选择的技术栈决定，更改技术组件、替换所使用的框架，都会改变基础设施层的逻辑。因而基础设施层的变化频率跟所用的技术组件有很大关系。越是核心的组件，变化就越缓慢，比如待定数据库系统后，不太可能频繁更换它，不太可能频繁地更换它。而如果是缓存系统，那么变化的频率会快很多。\n但基础设施层可能存在不可预知的突变。历数过往诸多思潮，NoSQL、大数据、云计算等等，都为基础设计层带来过未曾预期的突变。\n此外，周围系统生态的演化与变更，也会给基础设施层带来不可预知的突变的可能。比如，所依赖的消息通知系统从短信变成微信，支付方式从网银支付变成移动支付，等等。\n整个工程的包结构就是这样的：\n\ninfrastraction\ninterface\napplication\ndomain\n\n整体包结构是没有变化的，虽然理论是美好的，落地时问题依旧存在。尤其infrastraction与其它三层的不可调和的关系更浓烈了。\n从以往感观，其他三层是必须要依赖infrastraction的，结果现在却在最顶层。\n其实在之前文章中就提到，controller是在interface还是infrastraction，角度不同，在哪一层都可以。\n而像一些基础的，如mq，应用层要发消息，怎么办呢？依赖结构决定了无法使用。\n因此有人提出，基础设施层不是层的结论。每一层都是要依赖基础设施的。\n菱形架构\n经过了一番学习，发现了菱形架构，解决了之前的很多问题。\nOHS：\n对外主机服务，提供一切入口服务，分为remote和local.\nremote:\n提供一切对外服务，来源有传统的web，还是MQ的订阅等等。\nlocal:\n本地服务，是application的演变，如果远程服务要访问domain，必须通过local才能到达。\ndomain:\n意义不变，就是domain\nacl:\n是原先infrastraction,但把范围给扩大了。把所有对外部的依赖都纳入其中，甚至repository。\nport是表示接口，而adapter表示具体实现。\n在《DDD实践指南》中有对菱形架构更详细的介绍。\n这样解决了上述两种方案的缺点，理解起来也简单。\n但后来还是不太喜欢，为啥，因为传统，传统的DDD理论中，repository是领域层，这儿却在acl中，所以一直在寻找别的方式来解决。\n六边形风格\ninputadapter\napplication\ndomain\noutputadapter\n\n这也是有相当数量受众的架构风格，类似于菱形风格，从外形理解也简单。\nfacade风格\nfacade\nquery\nentity\nappliation\nadapter\n\n\n\n这是在实践中，演变来的一种风格，对外一切都是facade，受CQRS影响\n分为query查询与entity单对象的创建、更新操作；\napplication刚是业务原语的操作，简单理解为一个业务行为，会操作多个单entity；\nadapter刚是封装的infrastraction或第三方接口,提供给外部使用。\n混合格斗风格经过一系列的学习，输出一个融合风格。\n\nohs\ncontroller\npl\n\n\nopenapi\npl\n\n\nxxljob\nsubscriber\nmq\nevent\n\n\n\n\napplication\nservice\n\n\ndomain\nentity\nvo\naggregate\nrepository\n\n\nacl\nport\nadapter\n\n\npersistent\nfoundation\ninfrastraction\nconfiguration\n\n\n\n依赖关系：\nohs -&gt; application\nohs -&gt; infrastraction\n请求入口都在ohs，不然是api，还是队列监听。\n像队列底层属于infrastraction,但只面向接口编程，由ohs层实现。\napplication -&gt; domain\ndomain -&gt; foundation\napplication是domain的facade\ndomain -&gt; acl\n虽然可以通过供应商模式，其他层都依赖domain，但还有是会出来一些domain的依赖。放在acl中，供所有层使用。\n这样也可以把需要主动调用的内容从infrastraction中剥离开，解决掉了以往提到的循环依赖。\n回归传统风格经过以上一系列的变化，可以说是由简到繁的过程。\n再回头看经历过的项目现状，想想每次项目初始化，自己内心的纠结，在团队中也需要宣贯，需要解释，需要深化。\n不如来得简单明了些，就使用最经典的DDD风格，只要有一点DDD理论知识，大家都看得明白。不会去问ohs是啥。\n\ninterface:有api、dto、assembler三个包，api接受外部请求，有传统的controller，还有rpc,callback,listener来的消息。dto就是传输对象。assembler则是interface-&gt;application时，把dto转换成application的command、query。\napplication: 还是CQRS的思路，分成query、command;还有event，由内部及domain抛出的event。\ndomain:还是核心概念，entity、vo、aggregate。但没有service，为啥，当有service时，经常会与application service相互干扰，并且会慢慢回到贫血模型。通过强制没有service，可以更加OO。\ninfrastraction:被拆成不同部分。\n基础设施层，不单单是基础设施。得分成两种，一种像是acl,封装第三方接口；另一种像是mq,email等基础设施。\n1、我们常见的mq,cache,io,email等等都是基础设施层，domain不是直接依赖他们，而是通过DIP来倒置。表现形式是domain都是接口，而基础设施变成了能力供应商。\n2、而依赖的第三方接口，则是直接被domain,application调用。\n因此infrastraction被分成两部分，同时解除了循环依赖的困境。\n在之前文章中，提到过COLA的持久操作在application,当时很反感，后来感觉好像也对，也是供应商模式的一种体现。\n\n总结当然，最核心的还是domain的设计，专注修炼OO，没有丰满的domain，一切都是花架子，形似无神。\n","tags":["DDD"]},{"title":"DDD开篇","url":"/blog/ddd-opening.html","content":"从知道DDD到现在已经很多年了，看了不少理论知识，在项目中也使用了DDD，碰到些问题，也有些思考，整理一下，上升一下，形成一种适合自身的方法论\n在回顾过程中，首先追根溯源，什么是DDD？为什么要使用DDD？如何给别人阐述这些最基本的概念与理念，真是个难题\n什么是DDDDDD已经发展了很多年，现在的一些书也已经不太关注这个基本概念，平时闲聊时，开口闭口都是DDD，已经不知道DDD的本体是什么，只是听得耳熟，说得顺口了，细细回想下，DDD是个什么？一时语顿，不得找一下Eric Evans大神最原味的解答\nDDD来源于Eric Evans的书：《Domain-Driven Design - Tackling Complexity in the Heart of Software》领域驱动设计 - 软件核心复杂性应对之道\n由此可看出DDD的全称Domain-Driven Design，之前常听到TDD，那何为Domain呢？\n书中解释：\n\n每人软件程序都会与其用户的活动或兴趣相关。用户在其中使用程序的主要环境称为软件的领域(domain)\n\n\n一些领域会涉及到物质世界：航线预订程序的领域涉及到现实中登机的人。一些领域是无形的：财务程序的领域就是货币和金融\n\n\n领域模型并不是某种特殊的图，而是图所要表达的思想。它并不仅仅是某个领域专家头脑中的知识，而是对相关知识进行严格的组织与选择性抽象\n\n\n领域模型并不是尽可能地制作一个逼真的模型。即使在一个可触及的真实世界事物的领域中，我们的模型也只是一个仿真的创造物\n\n看到这些，应该还是有点晕，到底是什么？解释这种基本元语，特别的难,有人感觉领域就是业务，那为什么不叫Business Driven Design呢？\n有点钻牛角尖的意思，这其实是人类学习新知识的一种惯性思维，从以往经验中寻求类似的事物，帮助理解新事物，好处就可以快速认知新知识，坏处可能永远掌握不了新知识。既然给不了一种清晰的类比解释，那就不求甚解地理解，这个新事务的代名词叫DDD，随着认识的深入，慢慢就会从抽象到具体\n但为了提前更好地理解DDD，还是有必要把一些现流行的解读罗列出来\n\n银行业务被银行的内部人员和专家所熟知。他们知道所有的细节、所有的困难、所有可能 出现的问题、所有的业务规则。这些就是我们永远的起始点：领域\n\n\n领域驱动设计当然不是架构方法，也并非设计模式。准确地说，它其实是“一种思维方式，也是一组优先任务，它旨在加速那些必须处理复杂领域的软件项目的开发”。领域驱动设计贯穿了整个软件开发的生命周期，包括对需求的分析、建模、架构、设计，甚至最终的编码实现，乃至对编码的测试与重构\n\n\n领域模型是关于某个特定业务领域的软件模型。通常，领域模型通过对象模型来实现，这些对象同时包含了数据和行为，并且表达了准确的业务含义\n\n\nDDD专门解决复杂性的方法论\n\n\nDDD是面向对象分析的方法论，它可以利用面向对象的特性（封装，多态）有效地化解复杂性，而传统的J2EE等事务性编程只关心数据\n\n\nDDD作为一种软件开发方法，它可以帮助我们设计高质量的软件模型\n\n由前人的种种总结，粗略可以把DDD理解为一种方法论，一种构造软件模型的方法论\n模型软件的开发目的是什么？软件开发是为了解决由需求带来的各种问题，而解决的结果是一个可以运行的交付物。那么软件设计就是在需求和解决方案之间架设一座桥梁\n区别于解决简单的问题，软件的开发往往是一项长期的工作，会有许多人参与其中。在这种情况下，就需要建立起一个统一的结构，以便于所有人都能有一个共同的理解。这就如同建筑中的图纸，懂建筑的人看了之后，就会产生一个统一的认识。而在软件的开发过程中，这种统一的结构就是模型，而软件设计就是要构建出一套模型\n模型是对现实世界的简化抽象\n根据使用场景的不同，模型大致可以分为物理模型、概念模型、数学模型和思维模型等等\n物理模型是拥有体积及重量的物理形态概念实体物体，是根据相似性理论制造的按原系统比例缩小的实物\n概念模型是对真实世界中问题域内的事物的描述，是领域实体，而不是对软件设计的描述，它与技术无关。\n数学模型是用数学语言描述的一类模型，可以是一个或一组代数方程，微分方程、差分方程、积分方程或统计学方程，也可以是某种适当的组合数学模型\n思维模型是用简单易懂的图形、符号或者结构化语言等表达人们思考和解决问题的形式\n建立模型有很多方法，并不意味着要用特定符号、工具和流程。无论使用何种建模工具和表示法，只要有助于我们对问题域的理解，均可认为是好的模型。在处理问题时，我们最好隐藏那些不必要的细节，只专注于重要的方面，抓住问题的本质。这就是建模和抽象的价值所在\n在软件领域，影响最强的建模工具当属统一建模语言(Unified Modeling Language,UML)\n模型，是一个软件的骨架，是一个软件之所以是这个软件的核心。一个电商平台，它不用关系型数据库，还可以用 NoSQL，但如果没有产品信息，没有订单，它就不再是电商平台了\n模型的粒度可大可小，一个类是模型，把一整个系统当作一个整体理解，就是个大模型。而常听说的“高内聚、低耦合”其实就是对模型的要求。一个高内聚低耦合的模型能够有效地隐藏细节，让人理解起来也更容易，甚至还可以在上面扩展\n在DDD中，模型的选择取决于三个基本用途：\n\n模型与设计核心的相互塑型。正是模型与实现之间密切的联系使得模型与现实相关并且保证对于模型的讨论分析能够应用于最终产品–可运行的程序\n模型是所有团队成员所使用语言的核心。由于模型与实现是相互绑定的，因此开发人员可以用这种语言来讨论程序\n模型用来提炼知识。模型是团队在组织领域知识和辨别最感兴趣的原理时一致同意的方式\n\n方法论由上文可知DDD是一种开发方法，那在DDD之前，是怎么进行软件分析设计的呢？一般有两种方法：ER数据建模法和面向对象建模法\n在软件的世界里，任何的方法论如果最终不能落在“减少代码复杂度”这个焦点上，那么都是有待商榷的。\nER这是大多数人进行软件行业时，必学的方法，并且在学生时代，实践课程都是以此为示例，导致这种方法在脑海中根深蒂固\nER数据建模法是在接受到需求以后直接开始数据表ER模型的设计、实体表和表关系的设计\n建模过程是一种翻译再表达的过程，其唯一要点就是翻译不走样，如果翻译过程过多引入其他干扰因素和知识，那么无疑会增加翻译的难度和复制的精确性\n由于人们对数据库特别看重，SQL普及化，以至将软件的理解浓缩成了CRUD\n但由于过于注重数据库技术而忽视了业务上下文。使用CRUD代替业务用语，例如使用“创建订单”替代“下单”，使用“创建帖子”代替“发贴”，使用“创建发票”替代“开票”，虽然也容易让人明白，但“开票”等用语才是真正的业务术语、业务行话，是这个行业内每个人都知晓的。作为软件系统不是去遵循这些用语习惯，而是进行转换改造，按照自己的理解生造出一些词，是不是会潜移默化地将业务需求引导到不同方向呢？\n这种方法门槛低，带来了效率的提升，但是高效率不代表高质量，而软件高质量却能带来高效率\nOOAD业务初期，功能比较简单，CRUD基本可以满足。但随着系统的不断演化，业务系统越来越复杂，各模块间有着千丝万缕的关系，如何提升其扩展性\nOO最大的宣言就是Everything is object。所有的事物都有两个方面：有什么（属性）：用来描述对象；能够做什么（方法）：告诉外界对象有那些功能。\n把人们从低层的SQL计算机语言更加面向人类思维\nObject-Oriented Analysis (OOA)：面向对象的分析与设计的侧重点是业务领域分析，与软件所要应用的行业领域相关，而与软件技术关系不大，需要由领域专家进行。这一部分的工作被称为“需求分析”\nOOA的成果：\n业务领域用例图、活动图、协作图、大量的业务文档资料\nObject-oriented design (OOD)，用面向对象的方法为真实世界建立一个计算机中的虚拟模型，OOD的主要任务是跨越业务领域模型与可实际运行的软件系统之间的鸿沟，OOD的难度是非常大的，负责OOD工作的人被称为系统架构设计师\n系统架构设计师的任务：\n\n确定系统的总体框架—大多采用已有的领域框架\n正确理解需求分析得出的领域模型，用面向对象的思想设计出软件体系结构—系统概要设计\n分析现实的可获取的技术资源，分解出软件的各个组件，安排好开发任务流程—系统详细设计\n\n\n\n从上面的表述，可以看出面向对象相比ER模型强大多了，但其实面向对象的思想至今都没有真正意义得到普及，至少我是这么认为的。为什么呢？看多少人在进行CRUD这种面向过程式编程就知道了，而且早年的J2EE开发模式，讲究 Web&#x2F;Service&#x2F;Dao三层结构。面向过程编程，对象只是数据的载体，没有行为。以数据为中心，以数据库ER设计作驱动。分层架构在这种开发模式下，可以理解为是对数据移动、处理和实现的过程。该对象我们称之为贫血领域对象\n贫血领域对象（Anemic Domain Object）：是指仅用作数据载体，而没有行为和动作的领域对象。大量的业务逻辑写在了Service层中，随着业务逻辑复杂，业务逻辑、状态会散落在Service层中的很多处理类或方法中。将数据和行为割裂，原来的代码意图会越来越模糊，代码的理解和维护成本会越来越高。\n虽然面向对象没有得到真正的普及，但面向对象还是带来了很多思想，我不确定这些思想是不是面向对象之后才有的，但至少很多思想的确是在学习面向对象后才知道的\n比如之前写过一个系列《SOLID》，就是面向对象设计原则\n而且像Robert C.Martin认为一个可维护性较低的软件设计，通常由于如下4个原因造成：\n\n过于僵硬Rigidity\n过于脆弱Fragility\n复用率低Immobility\n黏度过高Viscosity\n\n软件工程和建模大师Peter Coad认为，一个好的系统设计应该具备如下三个性质：\n\n可扩展性\n灵活性\n可插入性\n\n而想规避缺点拥有优点，面向对象设计提供很大的便利，软件的复用(Reuse)或重用拥有众多优点，如可以提高软件的开发效率，提高软件质量，节约开发成本，恰当的复用还可以改善系统的可维护性，这些都是以面向对象设计原则为基础而来\n对象与数据表的关系？在从ER建模转向OOAD时，常把对象类比成表，以前称为表，现在换个名字叫对象，他们好似是一样的，但其实他们的差别很大，就文章开关所述，这是人的经验主义，可能永远掌握不了新知识\n数据表是一种数据结构，数据表中的数据是需要SQL去操作的，也就是说，数据结构中的数据是被外部某些行为或函数操作的；虽然对象或类中封装的属性其实也是数据，但对象或类有行为方法，这些行为可以保护被封装的属性数据，外界需要改变对象中的属性数据时，必须通过公开的行为方法才能实现。因此，对象和数据结构两者的区别之一就于在对数据操作是主动还是被动，对象是主动操作数据，而数据结构是被动操作，这一区别使得两种方式下的分析设计思路和编程范式完全不同\n表达业务领域中的业务概念时，强调主动操作数据的类或对象更适合表达业务概念，因为业务领域中的业务策略或业务规则都需要动态操作，它们的逻辑性需要主动操作数据完成\n设计时，业务对象是定义业务行为，而数据表是定义业务数据结构。一个注重行为，一个注重数据。着重点不同，导致设计要求不同，数据表一旦形成，就不会因为一个特定的应用而进行调整，它必须服务于整个企业，因此，这种结构是许多不同应用之间平衡的选择；而使用对象可以针对具体应用进行设计，将业务行为放入对象中，更能精确反映领域概念，保证业务规则的真正逻辑一致地实现\n虽然OOAD很不错，但分析和设计之间常常落差很大，甚至是分裂的。分析阶段的成果不能顺利导入设计阶段，设计阶段引入太多细节而歪曲了分析的宗旨。分析和设计分裂的根本原因是它们导向目标不同，分析人员的目标是从需求领域收集基本概念，是面向需求的，而设计人员则不同，他们负责用代码实现这些概念，因此必须指明能在项目中使用编程工具构建的组件，这些组件必须能够在目标环境(比如java)中有效执行，并能够正确解决应用程序出现的问题。条条大路通罗马，分析人员负责指出罗马方向，而设计人员负责找出通往罗马的某条道路，但是技术细节有时会让这个过程中产生绕路和不必要的复杂性，甚至走错方向，南辕北辙\n\nDDD【程序员其实不是在编写代码，面是在摸索业务领域知识】\n这是很多程序员的真实写照，尤其复杂业务，为什么呢？\n很多时候你会遇到这样的情况：一个函数写了几百行，里面的if-else写了一大堆，计算各种业务规则。另一个人接手之后，分析了好几天，才把业务逻辑彻底理清楚。\n这个问题从表面来看，是代码写的不规范，要重构，把一个几百行的函数拆成一个个小的函数。从根本上来讲，就是“重要逻辑”隐藏在代码里面，没有“显性”的表达出来\n这只是一个函数，推而广之，到类、到模块、到系统，是同样的道理，比如：\n业务流程隐藏在多个对象的复杂调用关系里面；某个业务核心概念没有提取出来，其职责分摊到了其他几个实体里面；系统耦合，职责边界不清\n所以，建模的本质就是把“重要的东西进行显性化，并进而把这些显性化的构造块，互相串联起来，组成一个体系”\n而DDD就是为了解决这些痛点，DDD建模思想不同于以往的面向对象分析设计思想，建模和代码之间还存在落差，无法平滑衔接。它将分析和设计完美结合起来，通过引入上下文的特殊性，将项目的真正业务背景和集成复杂性引入设计建模阶段，虽然增加了设计的复杂性，但也提高 了设计的实用性。\n领域驱动设计当然不是架构方法，也并非设计模式。准确地说，它其实是“一种思维方式，也是一组优先任务，它旨在加速那些必须处理复杂领域的软件项目的开发”。领域驱动设计贯穿了整个软件开发的生命周期，包括对需求的分析、建模、架构、设计，甚至最终的编码实现，乃至对编码的测试与重构。\n领域驱动设计强调领域模型的重要性，并通过模型驱动设计来保障领域模型与程序设计的一致。从业务需求中提炼出统一语言（Ubiquitous Language），再基于统一语言建立领域模型；这个领域模型会指导着程序设计以及编码实现；最后，又通过重构来发现隐式概念，并运用设计模式改进设计与开发质量。这个过程如下图所示：\n\n这个过程是一个覆盖软件全生命周期的设计闭环，每个环节的输出都可以作为下一个环节的输入，而在其中扮演重要指导作用的则是“领域模型”。这个设计闭环是一个螺旋式的迭代设计过程，领域模型会在这个迭代过程中逐渐演进，在保证模型完整性与正确性的同时，具有新鲜的活力，使得领域模型能够始终如一的贯穿领域驱动设计过程、阐释着领域逻辑、指导着程序设计、验证着编码质量。\n如果仔细审视这个设计闭环，会发现在针对问题域和业务期望提炼统一语言，并通过统一语言进行领域建模时，可能会面临高复杂度的挑战。这是因为对于一个复杂的软件系统而言，我们要处理的问题域实在太庞大了。在为问题域寻求解决方案时，需要从宏观层次划分不同业务关注点的子领域，然后再深入到子领域中从微观层次对领域进行建模。宏观层次是战略的层面，微观层次是战术的层面，只有将战略设计与战术设计结合起来，才是完整的领域驱动设计\n\n","tags":["DDD"]},{"title":"DDD应对复杂","url":"/blog/ddd-coping-with-complex.html","content":"复杂Eric Evans所著副标题–Tackling Complexity in the Heart of Software，对于简单系统其实没有必要使用DDD，只有在复杂系统中，才能体现DDD的价值\n那么何为“复杂”，或者说为什么软件是复杂的呢？\n即使是研究复杂系统的专家，如《复杂》一书的作者 Melanie Mitchell，都认为复杂没有一个明确得到公认的定义。不过，Melanie Mitchell 在接受 Ubiquity 杂志专访时，还是“勉为其难”地给出了一个通俗的复杂系统定义：由大量相互作用的部分组成的系统，与整个系统比起来，这些组成部分相对简单，没有中央控制，组成部分之间也没有全局性的通讯，并且组成部分的相互作用导致了复杂行为。\n这个定义同样可以表达软件复杂度的特征。定义中的组成部分对于软件系统来说，就是我所谓的“设计单元”，基于粒度的不同可以是函数、对象、模块、组件和服务。这些设计单元相对简单，然而彼此之间的相互作用却导致了软件系统的复杂行为。\n《管理3.0：培养和提升敏捷领导力》中从两个维度分析复杂：行为（预测能力）和结构（理解能力），分别举了实际生活中简单的例子\n\n理解力维度分为 Simple 与 Comlicated 两个层次，预测能力维度则分为 Ordered、Complex 与 Chaotic 三个层次\n在英文中，表示复杂的有Complicated和Complex\n\nSimple &#x3D; easily knowable.\nComplicated &#x3D; not simple, but still knowable.\nComplex &#x3D; not fully knowable, but reasonably predictable.\nChaotic &#x3D; neither knowable nor predictable.\n\n参考复杂的含义，Complicated 与 Simple（简单）相对，意指非常难以理解，而 Complex 则介于 Ordered（有序的）与 Chaotic（混沌的）之间，认为在某种程度上可以预测，但会有很多出乎意料的事情发生\n针对复杂的定义，分析角度以及应对的方法，绘制一张表格:\n\n    \n        角度\n        维度\n        表象\n        应对\n    \n    \n        理解力\n        规模软件的需求决定了系统的规模。当需求呈现线性增长的趋势时，为了实现这些功能，软件规模也会以近似的速度增长\n        \n函数存在副作用，调用时可能对函数的结果作了隐含的假设；\n\n类的职责繁多，不敢轻易修改，因为不知这种变化会影响到哪些模块；\n\n热点代码被频繁变更，职责被包裹了一层又一层，没有清晰的边界；\n\n在系统某个角落，隐藏着伺机而动的bug，当诱发条件具备时，则会让整条调用链瘫痪\n\n不同的业务场景包含了不同的例外场景，每种例外场景的处理方式都各不相同；\n\n同步处理与异步处理代码纠缠在一起，不可预知程序执行的顺序\n分而治之，控制规模\n    \n    \n        结构\n        结构之所以变得复杂，在多数情况下还是因为系统的质量属性决定的\n        \n        \n代码没有显而易见的进入系统中的路径；\n\n不存在一致性、不存在风格、也没有统一的概念能够将不同的部分组织在一起；\n\n系统中的控制流让人觉得不舒服，无法预测；\n\n系统中有太多的“坏味道”，整个代码库散发着腐烂的气味儿\n\n数据很少放在使用它的地方，经常引入额外的巴罗克式缓存层，目的是试图让数据停留在更方便的地方\n        \n        保持结构的清晰与一致\n所有设计质量高的软件系统都有相同的特征，就是拥有清晰直观且易于理解的结构。\n\n    \n    \n        预测能力\n        变化\n        在设计软件系统时，变化让我们患得患失，不知道如何把握系统设计的度。若拒绝对变化做出理智的预测，系统的设计会变得僵化，一旦变化发生，修改的成本会非常的大；若过于看重变化产生的影响，渴望涵盖一切变化的可能，一旦预期的变化不曾发生，我们之前为变化付出的成本就再也补偿不回来了。这就是所谓的“过度设计”\n        拥抱变化\n        可进化性（Evolvability）\n可扩展性（Extensibility）\n可定制性（Customizability）\n    \n\n\n根据上面的总结，想起《架构与架构师》中提到的架构师需要面对应用程序的两个层面需求：功能需求与非功能需求，功能性需求越多越大那对应的软件规模增长越快，可变性越大；非功能需求就要考虑质量属性，也就是整体结构要清晰，明确的规范约束，易于理解好维护。而这两个层面需求正好又对应着业务复杂度与技术复杂度\n技术复杂度与业务复杂度并非完全独立，二者混合在一起产生的化合作用更让系统的复杂度变得不可预期，难以掌控。同时，技术的变化维度与业务的变化维度并不相同，产生变化的原因也不一致，倘若未能很好地界定二者之间的关系，系统架构缺乏清晰边界，会变得难以梳理。复杂度一旦增加，团队规模也将随之扩大，再揉以严峻的交付周期、人员流动等诸多因素，就好似将各种不稳定的易燃易爆气体混合在一个不可逃逸的密闭容器中一般，随时都可能爆炸：\n\nDDD应对这让我回想起了“结构化思维”，逻辑+套路\n逻辑是一种能力，而套路是方法论，是经验。逻辑是道，方法论是术；逻辑可以学习很多思维模型理论，但套路有路径依赖，这也是去大厂的好处，可以接触到各种大牛，直接获取他们的经验和方法\nDDD是如何应对这些复杂性的呢？\n\n限界上下文分而治之，边界划分后，各子域相对整体规模就小了\n结构方面通过技术角度：分层架构、六边形架构…分离技术实现与业务逻辑\n变化，不再过程式编程，加强抽象领域模型，通过过程分解+对象模型，拆解并业务显示化，达到更好的复用性和易理解性\n\nbanq提出类似总结解决复杂性两种方法：拆解成松耦合的组件+使用容易让人明白的套路表达出来\n拆解也就是引入了“领域或子域”以及“有界上下文”划分边界；再引入各种模式名词，比如聚合、实体、值对象、工厂、仓储、领域事件，让知晓这些模式的人能够一下子定位到功能对应实现的组件，随着人们逐步了解，对于理解DDD系统来说，就不再是复杂的\n开发流程我们在开发、运营、维护软件的过程中很多技术、做法、习惯和思想。软件工程把这些相关的技术和过程统一到一个体系中，叫“软件开发流程”，软件开发流程的目的是为了提高软件开发、运营和维护的效率，以及提升用户满意度、软件的可靠性和可维护性\n发展了很多的流程，这儿复习一下最资深的瀑布模型\n瀑布模型瀑布模型(Waterfall Model)1970年温斯顿·罗伊斯(Winston Royce)提出了著名的“瀑布模型”,直到80年代早期,它一直是唯一被广泛采用的软件开发模型\n当软件行业还在年幼时期，它从别的成熟行业(硬件设计，建筑工程)借用了不少经验和模型。在那些“硬”的行业中，产品大多数遵循[分析-&gt;设计-&gt;实现(制造)-&gt;销售-&gt;维护]这个流程\n\n软件系统很难做到像建筑行业一样，程序员只要根据图样一步步实施就能完成项目。没人可以完整设计出一个大型项目的图样，这是瀑布软件工程方法的致命问题\n\n比如A拥有一家跑车公司，可以给客户自定义生产跑车。有一天一土豪来到A的公司，跟A商谈了一个跑车项目，他们谈好了车型，材料，马力等等细节。之后，A带着团队做了6个月，做成了这架跑车，交给了土豪。可是土豪开了一天之后回来要求重做，原因是当讨论方案的时候，双方都忘记给跑车安尾灯了！\n但是给跑车安装尾灯，需要重新设计车尾部，加上倒车灯，把车底拆开，安装线路，修改传动装置把倒车档和倒车灯联系起来\n\n软件多变，而且很长周期后才让用户看到最终产品，反反复复\n瀑布模型只能在产品的定义非常稳定；产品模块之间的接口、输入和输出能很好地用形式化的方法定义和验证\n统一语言软件行业相对其它传统行业有独特的难，同为构建，建筑工程在施工队进场开始构造之前，各种工程图样和材料都已经非常精确地准备到位，但在软件中没有足够时间收集所有需地，即使收集了，需求也不是从创建软件角度去描述\n软件项目团队，从产品 到 开发，再到测试，应了那句不怕神一样的对手，就怕猪一样的队友，层层兜底，产品考虑不到的，开发帮兜底，开发不给力时，靠测试兜底，测试不走心的，那只能客户买单，名为兜底大队\n项目开始，产品没有足够时间收集需求，但快速行动的重要性扎根程序员内心，没有足够信息来构建，可项目有交付期限，程序员只能进行创造性假设，填补产品经理留下的空白，只是为了保持项目不断推进。但产品经理或者客户经常改变主意，这意味着程序员对留白处的创建性假设经常夭折\n项目实践需求与程序员的理解之间存在客观落差，但程序员负责最终完成项目，如果这种落差没有被注意或发现，就只能由程序员自己创造。这种创造是在没有指导或指示的情况下进行，当项目展示给客户时，客户才发现不是自己想要的，双方就容易争执\n更多时候，程序员之所以在项目开始迟迟不亡友，是因为他们希望有人告诉该怎么做，但这种情况一般不会发生，这时就发挥自己的创造力，但这个创造有时会使项目偏离正确方向。如何发挥程序员创造力，同时又能保持项目的方向不被程序员带偏呢？\n解决方法就是让程序员迟早参与创意过程，与业务专家、客户、产品经理一起参加头脑风暴会议，不断缩小双方思考或理解偏差。有逻辑性的正确设计会节省大量代码，因为编码实践来试错的代价是昂贵的。编码涉及大量技术细节，细到一个字段的字节数都需要考虑，一旦发现代码实现的功能完全不是客户要求的，就只能全部推倒重来。成千上万行代码被删除，好像它们没存在过，他们存在过的意义仅是让程序员明白：此路不通\n程序员需要将业务知识的学习和思考结合起来，领域驱动核心就是多了一个领域层，这个领域是业务相关原语，随着业务价值变化而变化，通常每个企业的核心业务域是千差万别的，所以，在技术实现的时候，反复要问我们团队，我们多少比例的代码是针对业务本身，而业务本身对业务消费者有多大的价值？作为业务的技术实现方，一定要有手段通过量化方法，衡量你的业务价值，从而能精细化迭代升级\n统一语言，并不是把从客户那里听到的内容翻译成程序自己的语言，减少误解，让客户更容易理解我们的草图，并且真正帮助纠正错误，帮助我们获取有关领域新知识，目标是创造可以被业务、技术和代码自身无歧义使用的共同术语\n\n在PRD文档，设计文档，代码以及团队日常交流中，都使用同一套领域术语，极大地提升沟通和工作效率\n简单理解起来的话，也就是把业务人员和开发人员的语言统一起来，用代码来感受一下大概就是：\nuserService.love(Jack, Rose) =&gt; Jack.love(Rose)companyService.hire(company,employee) =&gt; Company.hire(employee)\n\n通过统一语言，领域驱动设计的核心是建立统一的领域模型。领域模型在软件架构中处于核心地位，软件开发过程中，必须以建立领域模型为中心，以保障领域模型的忠实体现，解决OOAD中OOA分析模型与OOD设计模型割裂的弊端\n\n","tags":["DDD"]},{"title":"DDD开篇总结","url":"/blog/ddd-opening-summary.html","content":"之前写了两篇《DDD开篇》与《DDD应对复杂》，是时候总结一下了\n对于DDD的启蒙，不管是国内还是国外思维逻辑都是一样的。或者说如果你想写本关于DDD的书，大纲似乎是一样的\n首先DDD是什么？给出定义，定义有些抽象，难以一次性接受，那就通过以往问题引出DDD，这时模型、复杂度、开发流程都是自然附带出的概念，再后面就是DDD的知识结构是什么，最后就是讲解一个实例，也有些会把实例穿插到各个篇章中\n在DDD这个系列中，我也打算是这种思路，很平易近人\n经过了之前两篇，对于第一部分的DDD是什么？为什么需要DDD基本都问答清楚了。\nDDD是什么DDD根本上是一种软件开发的建模方法论，其中使用了面向对象分析思想，并不是独立于外全新的体系\n模型是对现实世界的抽象，那建模是对现实世界的抽象过程，但模型毕竟是模型，不能代替现实，就像类比不能代替问题本身一样。建模过程与建模者的观察视角和对问题的认知有直接关系,所以我们要带着审视的眼光看待模型\n软件开发的最大问题之一便是业务人员和技术人员需求某种翻译才能交流，那么模型的质量就取决于翻译的还原度\n建模不仅要还原实现世界，更要把重要的东西进行显示化。是一个软件之所以是这个软件的核心\n建模可以通过建模&#x3D;构造块+语法范式表达，各类语言都可以通过这种范式表达出来\n\n(1) 自然语言建模 \n构造块：常用的那几千个汉字（或者英语的10万单词）\n语法规则：主谓宾定状补\n(2)计算机语言建模 \n构造块：加&#x2F;减&#x2F;乘&#x2F;除，if-else, for, while.. \n语法规则：程序员最熟悉，此处就不说了\n(3)过程建模 \n构造块：函数 \n语法规则：整个系统描述成一个个过程，每个过程通过函数的层层调用组成\n(4)对象建模 \n构造块：对象 \n语法规则: 整个系统描述成对象与对象之间的关系\n(5) DDD领域建模 \n构造块：实体&#x2F;值对象&#x2F;领域服务&#x2F;领域事件&#x2F;聚合根&#x2F;工厂&#x2F;仓库&#x2F;限界上下文 \n语法规则：就是“构造块”之间的联系（不是很明显，这个需要深入研究。也正是DDD难掌握的地方）\n为什么需要DDD之前介绍过软件复杂度以及应对复杂度之道，DDD是其中一种术\n\n使领域专家和开发者在一起工作，这样开发出来的软件能够准确地传送业务规则\n“准确传达业务规则”意思是说此时的软件就像如果领域专家是编码人员时所开发出来的一样\n帮助业务人员自我提高。没有任何一个领域专家或管理者敢说他对业务已经了如指掌，业务知识需要长期学习过程，在DDD中，每个人都在学习，同时每个人又是知识贡献者\n关键在于对知识的集中，因为这样可以确保软件知识并不只是掌握在少数人手中\n在领域专家、开发者和软件本身之间不存在“翻译”，意思是当大家都使用相同的语言进行交流时，每个人都能听懂他人所说\n设计就是代码，代码就是设计。设计是关于软件如何工作的，最好的编码设计来自多次试验，这得益于敏捷的发现过程\nDDD同时提供了战略设计和战术设计两种方式,战略设计帮助我们理解哪些投入是最重要的，哪些既有软件资产是可以重新拿来使用的，哪些人应该被加到团队中？战术设计帮助我们创建DDD模型中各个部件\n\n上面的比较学术，简单讲：理解DDD的本质是统一语言、边界划分和面向对象分析的方法\n\n统一语言，主要思想是让应用能和业务相匹配，这是通过在业务与代码中的技术之间采用共同的语言达成的。也就是设计及代码，代码及设计\n面向对象，DDD核心是领域模型，先找到业务中的领域模型，以领域模型为中心，驱动项目开发，指引我们如何实现面向服务架构或业务驱动架构。领域模型设计精髓在于面向对象分析，对事物的抽象能力，一个领域驱动架构师必然是一个面向对象分析大师\n业务语义显示化，统一语言也好，面向对象也好，最终目标都是为代码可读性和可维护性服务，统一语言使得核心领域概念无损地在代码中呈现，从而提升代码的可理解性\n分离业务逻辑和技术细节，让两个维度的复杂度被解开和分治，比如整洁架构\n\n对于最终目标来讲，在软件项目中，任何方法论如果最终不能落在“减少代码复杂度”，都是有待商榷的\nDDD挑战DDD在实践中有很高的门槛\n\n\n持续地将领域专家引入项目\n为创建通用语言腾出时间和精力\n改变开发者对领域的思考方式\n\n最大挑战之一便是：需要花费大量的时间和精力来思考业务领域，研究概念和术语，并且和领域专家交流，以发现、捕捉和改进通用语言\n在开发过程中，最大的鸿沟之一便是在于领域专家和开发者之间，通常领域专家关注放在交付业务价值上，而开发者则将注意力放在技术实现上。并不是说开发者动机是错误的，面是说开发者的眼光被自然而然地吸引到实现层面。即使让领域专家与开发者一同工作也只是表面协作，这样在开发的软件中产生了一种映射：业务人员所想的映射到开发者所理解的，软件便不能完全反映领域专家的思维模型，随着时间推移，这种鸿沟将增加软件开发成本\nDDD将领域专家与开发人员聚焦在一起，这样所开发的软件能够反映出领域专家的思维模型，这并不意味着我们将精力都花在对“真实世界”的建模上，而是交付最具业务价值的软件，在实用和理想之间存在冲突时，根据它们的互异程序，在DDD中选择实用性\n领域专家与开发人员一起创建一套适用于领域建模的通用语言。通用语言必须在全队范围之内达成一致；所有成员都使用通用语言进行交流，通用语言是对软件模型的直接反映\n作为开发者，我们都是技术思想者，技术实现对于我们来说并不是什么难事。并不是说技术地思考不好，只是说有时少从技术层面去思考会更好。这么多年来，我们习惯了单从技术层面完成软件开发，那现在是时候考虑一种新的思考方式了。为你的业务领域开发一门通用语言便是一个好的出发点\n技术负债程序员工作时间大部分在新增新功能，996式加班大多为了赶工上线，而对赶工出来的软件质量是在打个问题，而技术负债在软件质量领域是一个很能重要概念，对于软件工程来讲，这真是个特别的东西\nMartin Fowler定义技术负债就是增加新功能所需要的额外成本\n软件质量不同于其他商品质量。购买一个商品，在使用过程中会直接发现该商品质量问题，而软件质量不是直接被软件系统的使用者所感知的，也就是说客户如果同时使用两种质量不同的系统，用户是无法发现两者的区别，不过随着时间推移，自己的产品交付过程越来越长了\n软件质量问题不是直接面向用户，而是面向软件的开发团队。因为软件质量差，新程序员很难快速上手，无法形成生产力；修改别人的代码时可能一走在不得要领；bug丛生，修复一个可能使得系统崩溃，一个都不修复系统反而正常工作；修复bug时牵一动百，修改一处却引起其他连锁故障反应。。。，这些都是软件质量低下的外在表现\n正是由于软件质量不是最终用户所能感知的，导致行业内对软件质量没有过多重视–客户都没有提出改进要求，那么一切为客户服务的软件公司自然没有动力去提升软件质量，而且行业内对软件质量存在认知误区：便宜确实没好货，但是质量高必然导致成本 上升，而客户又不会察觉质量好坏，那么产品如何卖出好价格\n软件并不是质量越高，成本就越高。这似乎违反常识，背后其实也与技术负债有关。如果将技术负债看成是一种前进中的累赘，累赘遍布于代码各处，那么提高软件质量就是通过良好设计或重构来减轻这种累赘，从而能轻装上阵，新增功能就能更加快捷，交付效率也会大大提升。\n降低技术负债意味着软件质量提高，软件质量越高，修改拓展起来就越方便。\n如何降低技术负债？这存在一个适度问题，代码越多，复杂性越高，技术负债肯定越高，那么就需要惜墨如金。有时为了写正确可运行的简洁代码，可能要删除数十倍的代码，但也不是代码越少越好。有的代码只是考虑功能实现，没有考虑到功能的对接或扩展，那么当需要对功能实现扩展时，就发现难以下手，甚至需要采取黑客破解方式强行入侵系统，这此都是原来代码过于简单僵化的表现\n适度是在过度和不足中探索平衡的结果。代码适度的一个衡量标准是单一职责原则，即每个函数或类只能有一个职责。\n面向对象编程中还有另一个原则：DRY原则。对这个原则的共同理解是代码不应该重复，如果两段代码表示的是同一个职责，那么合并它们。但这种抽象合并导致共享内核或共享库，最张造成代码各处对共享库或内核的依赖，这就很自然地引入了不必要的、偶然的复杂性–一旦共享库发生修改，牵一动百的事情就可能发生。很多时候重复的代码可能会带来相当大的优势，重复能拖延决策，这是软件开发的黄金。这样，延迟到适当时机从多个专业化角度重构，这比从单个方法层面进行抽象的重构要容易数倍。\n","tags":["DDD"]},{"title":"DDD战略战术","url":"/blog/ddd-strategy-and-tactics.html","content":"《DDD开篇总结》的前三篇已经阐述了几个内容\n\nDDD是什么\n复杂系统的特征\nDDD如何应对复杂系统\n模型概念\n软件开发流程\n\n但一般DDD资料中都会分为两部分讲述：战略和战术，所以按这两种分类，重新归纳整合一下\n道在讨论战略和战术前，先表述一下“道”\nDDD是一种软件开发的方法论，任何方法论，都必须落实到“减少代码复杂度”\n那么“道”是什么呢？\n一直认为DDD的战略就是道，结果搞错了\n软件开发的终极“道”就是“高内聚、低耦合”，它是任何有价值思想和方法的具象\n如何才能达到这个终极道呢？\n\n\nDRY\n\n\n\n分离关注点\n\n\n2.1. 业务和技术分离\n2.2. 业务和部署分离\n2.3. 变与不变分离\n\n\n\n缩小依赖范围\n\n\n\n向稳定方向依赖\n\n\n\n\n战略DDD战略主要包含统一语言和限界上下文\n统一语言\n在以往OO开发过程中，会经过OOA，再到OOD，复杂系统中，没有人能全方位了解系统并实现系统，术业有专工，专业人士干伟业事，这是正确的\n但分工后，团队合作时沟通至关重要，，在整个系统开发过程中，是有一根主线的，那就是业务知识，业务知识在系统落地前经过层层传递，走样变形是常有的事，从开发人员经过多少次的返工情况就很清楚\n如果解决这个问题呢？DDD引入了统一语言，把业务名词含义事先确定好，减少不必要的翻译过程，车同轨，书同文，行同伦\n这也消除了业务与技术之间的重复，共同使用业务原语对话\n代码就是文档，代码就是领域知识\nuserService.love(Jack, Rose) =&gt; Jack.love(Rose)companyService.hire(company,employee) =&gt; Company.hire(employee)\n\n界限上下文界限上下文囊括了实现道的方方面面，如分离关注点，每个上下文围绕一个关注点，通过整洁架构让各层向稳定方向依赖，合理的划分界限，使各个上下文之间减小依赖\n说白了界限上下文就是把一个大系统分而治之\n界限上下文算是DDD中的核心知识点，但常被技术人员忽视，对于实用主义的程序员来讲，战术常常更吸引人，其实大到微服务，小到实体类，背后都渗透着上下文的概念\n引入限界上下文的目的，不在于如何划分边界，而在于如何控制边界\nAlberto Brandolini认为bounded context are a mean of safety（限界上下文意味着安全），safety的意思是being in control and no surprise，对限界上下文是可控制的，就意味着你的系统架构与组织结构都是可控的\n显然，限界上下文并不是像大多数程序员理解的那样，是模块、服务、组件或子系统，而是你对领域模型、团队合作以及技术风险的控制\n限界上下文是“分而治之”架构原则的体现，我们引入它的目的其实为了控制（应对）软件的复杂度，它并非某种固定的设计单元，我们不能说它就是模块、服务或组件，而是通过它来帮助我们做出高内聚低耦合的设计。只要遵循了这个设计，则限界上下文就可能成为模块、服务或组件。所以，文章《Bounded Contexts as a Strategic Pattern Beyond DDD》才会写到：“限界上下文体现的是高层的抽象机制，它并非编程语言或框架的产出工件，而是体现了人们对领域思考的本质。”\n战术对于开发人员而，战术是最实用的，比如聚合、实体、值对象、工厂、仓储、领域事件等等，使用这些战术组件建模工具，DDD满足了软件真正的技术需求。这些战术设计工具使开发人员能够按照领域专家的思维开发软件\n战略部分讲了，界限上下文的思想是核心，在战术组件中都有体现，比如实体，实体就是一个最小上下文，聚合就是相对实体大一点的上下文\n但残酷的现实是，花费了大量的精力来学习这些DDD战术组件，却在实现项目中却用不上，为什么呢？因为事务脚本思维太深，分层也大多是从技术角度出发，没有抽象出领域模型，也就是没有OO抽象，没有一个完整的对象，实体都没有，像工厂，值对象也就成了水中花\n这也是我们虽然常重构代码，也不过是大类变小类，大函数拆分成小函数，符合一下代码规范，但对整个项目而言，其实没有实质性改进\n如何能有实质性改进，对于复杂系统如何运用上这些战术组件呢？\n此时，结构性思维发挥作用了\n第一步：过程分解，把一个复杂的系统按流程拆解成各个阶段和步骤，这也是事务脚本的强项\n第二步：对象建模，过程性拆解虽然可以降低了开发难度，但领域知识被割裂，代码的业务语义也不明确，在这方面OO是强项，提升代码复用性和内聚性\n\n结合这两步，自上而下的结构化分解+自下而上的面向对象建模，过程化分析更好地清理了模型之间的关系，而对象模型提升代码复用性和业务语义表达能力\n总结DDD是一套很好的方法论，有时我们常在理论纯洁性与实战性之间徘徊。这也许是初级阶段常有的纠结点\nDDD有适用场景，事务脚本有存在的优势\n\n不能因为现在人们开口闭口都是DDD，就硬要开展DDD\nDDD难以落地除了本身带来了很多概念，还需要团队整体素质\n软件开发没有银弹，不能偏执于一种理论，实际开发是场硬仗，像混合格斗一样，不在于一招一式是哪门哪派，制敌才是终极目标，所以需要根据自身情况进行裁剪，灵活运用\n","tags":["DDD"]},{"title":"DDD聚合设计的困境","url":"/blog/the-dilemma-of-ddd-aggregation-design.html","content":"为什么学了一堆DDD理论，但就是无法落地呢？很多人认为它只是个理论。\n最近又看了一遍《IDDD》第十章聚合，结合已有的理论知识，来反思下这个问题。\nDDD聚合是什么？最容易与DDD聚合混淆的就是OO聚合关系。\n\n由上图可以看出，OO聚合表示了一种关联关系；而DDD聚合表示了一种边界。\nOO聚合关系(Aggregation) 表示一个整体与部分的关系。通常在定义一个整体类后，再去分析这个整体类的组成结构，从而找出一些成员类，该整体类和成员类之间就形成了聚合关系。\n如上图中Question与Answer的关系。一个问题与很多的回答构成一个完整的问答关系。\n在OO中还有一种比聚合关系更强的关联关系：\n组合关系(Composition)也表示类之间整体和部分的关系，但是组合关系中部分和整体具有统一的生存周期。一旦整体对象不存在，部分对象也将不存在，部分对象与整体对象之间具有相同的生命周期。\n继续以上图为例，Answer都是因Question存在而存在，当Question消亡时，Answer也自然消亡。\n但像知乎，就算Question没了，Answer也会留存。\nOO聚合与DDD聚合是什么样的关系呢？\n因为聚合有隐含的构建关系和级联生命周期，通常会把OO组合关系构建成DDD聚合，其实组合关系只是聚合的必要条件，而非充分条件。\n如果是聚合，那么聚合根与实体自然是组合，存在级联生命周期，但不代表存在级连生命周期都是聚合。\n特别是，混淆了数据生命周期和对象生命周期，\n例如在“获取客户订单”这一业务场景下，Customer 与 Order 之间也存在整体&#x2F;部分的组合关系，但它们却不应该放在同一个 DDD 聚合内。\n从数据生命周期看，一般如果数据库中顾客数据删除了，那么他对应的订单也会删除。\n但不适合建模成聚合。\n因为这两个类并没有共同体现一个完整的领域概念；同时，这两个类也不存在不变量的约束关系。\n而且聚合后，订单就不再具有独立身份，每次查询订单时候，必须提供客户身份和订单身份，构成级连身份才可以。类似于当仅仅使用订单号查询订单时，是不行的，必须带上身份证和订单号一起，才能查询到订单。\n聚合困境看似把一堆实体和值对象放一起就组成聚合，在《IDDD》中提供了一个示例。使用过JIRA的人应该很容易理解。我简单按书中的思路叙述下。\n第一次尝试\n这次尝试，应该是完全按产品需求直接建模。\nProduct,BacklogItem,Release,Sprint的确是一组组合关系。\n而且Product是聚合根。\npublic class Product &#123;    private Set&lt;BacklogItem&gt; backlogItems;        private Set&lt;Release&gt; releases;        private Set&lt;Sprint&gt; sprints;    &#125;\n\n虽然这完整表达了模型，但实现很残酷。不得不考虑的问题：\n1、持久化时，乐观并发，增加了操作失败概率\n2、影响系统性能和可伸缩性\n第二次尝试\n将一个大的Product聚合拆分成了4个相对较小聚合。\n虽然解决了事务问题，多个用户请求可以同时创建任何数量的BacklogItem、Release和Sprint实例。\n但对客户端来说，这4个较小的聚合却多少会带来一些不便。\n设计小聚合一个完整的聚合\n\n如果要加载一个完整的聚合，需要把所有这些实体与值对象都加载出来。那系统性能和可伸缩性大受影响。\n为了解决这些问题，所有提出要设计小聚合。\n小聚合不仅有性能和可伸缩性上的好处，它还有助于事务的成功执行，即它可以减少事务提交冲突。这样一来，系统的可用性也得到增强。在你的领域中，迫使你设计大聚合的不变条件约束并不多。当你遇到这样的情况时，可以考虑添加实体或者是集合，但无论如何，我们都应该将聚合设计得尽量小。\n聚合之间不能直接加载到同一个边界之内，得通过唯一标识引用其他聚合。\n\n通过标识引用并不意味着完全丧失了对象导航性。有时在聚合中使用Repository来定位其他聚合。这种作法也被称为失联领域模型(Disconnected Domain Model)。\n这就是矛盾体，一方面希望保障模型的完整性，我们需要完整的聚合；另一方面又有各种实现限制条件。\n这些原因正是《实现业务逻辑的本种方式》中提到的单体架构演变为分层架构的局限性。\n总结越来，聚合有三点特性：\n1、Global entities(aggregation root and entity) is the boundary of consistency\n2、Global entities(aggregation root and entity) is the boundary of lifecycle\n3、Object model assumes same lifecycle boundary within the global entity\nDDD困境由聚合的困境，管窥一斑，DDD落地的困境何尝不是类似原因：\n1、Domain Driven Design,but technology may have a say\n2、Using fundamentalism DDD,it only works for simple cases,so does transaction script,procedure of oriented programming\n3、Smaller aggregation works as fine as a EJB2-refurbished architecture\n由上面的聚合示例观察，第一点的确是现实。\n我们使用DDD，就是想Domain Driven，可考虑了很多技术落地因素，打破了完整的模型。选择模型还是选择性能，是放在我们面前的第一道选择题。\n而第二点在现如今多运行时分布式架构中，肯定不可能像在一个单休中加载完整的聚合对象。因此当要使用原味的DDD时，只能在简单的项目中，而DDD却说要在复杂场景下再去使用。不要简单问题复杂化。这又是个矛盾体。\n这些问题怎么解决？\n当前能想到的解决方案似乎只有在《DDD对象生命周期管理》提到的关联对象模式。既能保证模型的完整，又能兼顾性能。\n总结聚合设计时，尽量使用小聚合。这对吗？解决设计困境了吗？\n如果使用小聚合，会造成一种现象。会出现很多的service。\n只有使用service，才能在聚合间跨越对象生命周期，维持一致性。\n这会慢慢演化成贫血模型，因为一部分逻辑在对象中，另一部分会放到service中。\n所以我们得重新审视一些指导原则。或者时时提醒是不是过多的考虑了实现细节，破坏了模型。\n怎么才能更好地保证模型完整性，而兼顾当前的技术限制。\n","tags":["DDD"]},{"title":"FastThreadLocal解析","url":"/blog/fastthreadlocal-parsing.html","content":"前言之前《TreadLocal解析》说过Threadlocal的结构：\n\n但netty却重新搞了一个fastthreadlocal,从各方面对比一下两者的区别。也不得不说一下netty真不愧是款优秀框架，里面中有很多优秀类和方法值得细品\nVS ThreadLocal1、性能第一点，从性能开始，为什么要重造轮子，可能就是之前的轮子达不到性能要求\npublic class FastThreadLocalTest &#123;    public static void main(String[] args) &#123;        testFast(100);        testSlow(100);    &#125;    private static void testFast(int threadLocalCount) &#123;        final FastThreadLocal&lt;String&gt;[] caches = new FastThreadLocal[threadLocalCount];        final Thread mainThread = Thread.currentThread();        for (int i = 0; i &lt; threadLocalCount; i++) &#123;            caches[i] = new FastThreadLocal();        &#125;        Thread t = new FastThreadLocalThread(new Runnable() &#123;            @Override            public void run() &#123;                for (int i = 0; i &lt; threadLocalCount; i++) &#123;                    caches[i].set(&quot;float.lu&quot;);                &#125;                long start = System.nanoTime();                for (int i = 0; i &lt; threadLocalCount; i++) &#123;                    for (int j = 0; j &lt; 1000000; j++) &#123;                        caches[i].get();                    &#125;                &#125;                long end = System.nanoTime();                System.out.println(&quot;take[&quot; + TimeUnit.NANOSECONDS.toMillis(end - start) +                        &quot;]ms&quot;);                LockSupport.unpark(mainThread);            &#125;        &#125;);        t.start();        LockSupport.park(mainThread);    &#125;    private static void testSlow(int threadLocalCount) &#123;        final ThreadLocal&lt;String&gt;[] caches = new ThreadLocal[threadLocalCount];        final Thread mainThread = Thread.currentThread();        for (int i=0;i&lt;threadLocalCount;i++) &#123;            caches[i] = new ThreadLocal();        &#125;        Thread t = new Thread(new Runnable() &#123;            @Override            public void run() &#123;                for (int i=0;i&lt;threadLocalCount;i++) &#123;                    caches[i].set(&quot;float.lu&quot;);                &#125;                long start = System.nanoTime();                for (int i=0;i&lt;threadLocalCount;i++) &#123;                    for (int j=0;j&lt;1000000;j++) &#123;                        caches[i].get();                    &#125;                &#125;                long end = System.nanoTime();                System.out.println(&quot;take[&quot; + TimeUnit.NANOSECONDS.toMillis(end - start) +                        &quot;]ms&quot;);                LockSupport.unpark(mainThread);            &#125;        &#125;);        t.start();        LockSupport.park(mainThread);    &#125;&#125;//输出fast[15]msslow[302]ms\n从输出可见性能提升很大\n2、数据结构两者的数据结构大体相似，都是thread带上map属性，threadlocal实例为key；但在细节算法处理时，不一样\nget()整体思路：通过thread取到map，再从map中取value\nThreadLocal.get()public T get() &#123;        Thread t = Thread.currentThread();        ThreadLocalMap map = getMap(t);        if (map != null) &#123;            ThreadLocalMap.Entry e = map.getEntry(this);            if (e != null) &#123;                @SuppressWarnings(&quot;unchecked&quot;)                T result = (T)e.value;                return result;            &#125;        &#125;        return setInitialValue();    &#125;\n\n从map中取值：\nprivate Entry getEntry(ThreadLocal&lt;?&gt; key) &#123;            int i = key.threadLocalHashCode &amp; (table.length - 1);            Entry e = table[i];            if (e != null &amp;&amp; e.get() == key)                return e;            else                return getEntryAfterMiss(key, i, e);        &#125;        private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123;            Entry[] tab = table;            int len = tab.length;            while (e != null) &#123;                ThreadLocal&lt;?&gt; k = e.get();                if (k == key)                    return e;                if (k == null)                    expungeStaleEntry(i);                else                    i = nextIndex(i, len);                e = tab[i];            &#125;            return null;        &#125;\n如果key值相等，直接返回value\n如果key不相等，使用循环线性探测，一直找到最后一个元素\nFastThreadLocal.get()public final V get(InternalThreadLocalMap threadLocalMap) &#123;        Object v = threadLocalMap.indexedVariable(index);        if (v != InternalThreadLocalMap.UNSET) &#123;            return (V) v;        &#125;        return initialize(threadLocalMap);    &#125;    public Object indexedVariable(int index) &#123;        Object[] lookup = indexedVariables;        return index &lt; lookup.length? lookup[index] : UNSET;    &#125;\n这个明显就快些，有index,直接数组拿值,不需要再去处理循环\nset()主要在于向map中放值\nThreadLocal.set()public void set(T value) &#123;        Thread t = Thread.currentThread();        ThreadLocalMap map = getMap(t);        if (map != null)            map.set(this, value);        else            createMap(t, value);    &#125;    private void set(ThreadLocal&lt;?&gt; key, Object value) &#123;            // We don&#x27;t use a fast path as with get() because it is at            // least as common to use set() to create new entries as            // it is to replace existing ones, in which case, a fast            // path would fail more often than not.            Entry[] tab = table;            int len = tab.length;            int i = key.threadLocalHashCode &amp; (len-1);            for (Entry e = tab[i];                 e != null;                 e = tab[i = nextIndex(i, len)]) &#123;                ThreadLocal&lt;?&gt; k = e.get();                if (k == key) &#123;                    e.value = value;                    return;                &#125;                if (k == null) &#123;                    replaceStaleEntry(key, value, i);                    return;                &#125;            &#125;            tab[i] = new Entry(key, value);            int sz = ++size;            if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)                rehash();        &#125;\n\n通过取模，得到index\nkey相等，直接赋值value\nkey不相等，那就线性探测存放\n\nFastThreadLocal.set()public final void set(V value) &#123;        if (value != InternalThreadLocalMap.UNSET) &#123;            InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get();            if (setKnownNotUnset(threadLocalMap, value)) &#123;                registerCleaner(threadLocalMap);            &#125;        &#125; else &#123;            remove();        &#125;    &#125;    public boolean setIndexedVariable(int index, Object value) &#123;        Object[] lookup = indexedVariables;        if (index &lt; lookup.length) &#123;            Object oldValue = lookup[index];            lookup[index] = value;            return oldValue == UNSET;        &#125; else &#123;            expandIndexedVariableTableAndSet(index, value);            return true;        &#125;    &#125;\n这类似就是放入到数组中\n总结到此可以看出二者的区别\n\n\n\n区别\nThreadLocal\nFastThreadLocal\n\n\n\nmap\nThreadLocalMap\nInternalThreadLocalMap extends UnpaddedInternalThreadLocalMap\n\n\n线程\nThread\nFastThreadLocalThread extends Thread\n\n\n主要还是在内部map的处理逻辑上，两者都没有使用hashmap，但是自定义了map结构与行为，在《hashmap源码解析》中指出map结构的两种处理方式：拉链法与线性探测法；在hasmap中使用的是拉链法，而threadlocal中使用的是线性探测法\n\n线性探查（Linear Probing）方式虽然简单，但是有一些问题，它会导致同类哈希的聚集。在存入的时候存在冲突，在查找的时候冲突依然存在\n\n冲突也就造成了性能损耗，而FastTreadLocal就更简单，直接使用数组\npublic FastThreadLocal() &#123;        index = InternalThreadLocalMap.nextVariableIndex();    &#125;\n\n\nUnpaddedInternalThreadLocalMap\nObject[] indexedVariables;public static int nextVariableIndex() &#123;        int index = nextIndex.getAndIncrement();        if (index &lt; 0) &#123;            nextIndex.decrementAndGet();            throw new IllegalStateException(&quot;too many thread-local indexed variables&quot;);        &#125;        return index;    &#125;\n\n整个map就是一个数组结构，在每个thread中，每一个FastThreadLocal在创建时就指定了index,value就是数组元素\n","tags":["ThreadLocal"]},{"title":"DDD战术实践指南","url":"/blog/ddd-tactical-practice-guide.html","content":"DDD这个主题已经写了好多篇文章了，结合最近的思考实践是时候总结一下，对于战略部分有点宏大，现在都是在微服务划分中起着重要作用，暂且总结战术部分\nDDD意义每种理论的诞生都是站在前人的基础之上，总得要解决一些痛点；DDD自己标榜的是解决复杂软件系统，对于复杂怎么理解，至少在DDD本身理论中并没有给出定义，所以是否需要使用DDD并没有规定，事务脚本式编程也有用武之地，DDD也不是放之四海皆准，也就是常说的没有银弹\n但重点是每种方法论都得落地，必须要以降低代码复杂度为目标，因此对于“统一语言”、“界限上下文”对于一线码农有点远，那战术绝对是一把利剑\n回顾一下，在没有深入DDD之前，基本上就是事务脚本式编程，当然还会重构，怎么重构呢？基本也是大方法变小方法+公共方法\n随着业务需求越来越多，代码自然伴随增长，就算重构常相伴，后期再去维护时也是力不从心，要么小方法太多，要么方法太大，老人也只能匍匐前行，新人是看得懂语法却不知道语义，这也是程序员常面对的挑战，不是在编写代码，而是在摸索业务领域知识\n那怎么办呢？有没有其它模式，把代码写漂亮，降低代码复杂度，真正的可扩展、可维护、可测试呢？\n很多人会说面向对象啊，可谁没在使用面向对象语言呢？可又怎样。事实是不能简单的使用面向对象语言，得要有面向对象思维，还得再加上一些原则，如SOLID\n但虽然有了OOP，SOLID，设计模式，还是逃不脱事务脚本编程，这里面有客观原因，业务系统太简单了，OO化不值得，不能有了锤子哪里都是钉子；主观原因，长时间的事务脚本思维实践，留在了舒适区，缺乏跳出的勇气\nDDD战术部分给了基于面向对象更向前一步的范式，这就是它的意义\n\n在实践DDD过程中，我也一直在寻找基于完美理论的落地方案，追求心中的那个DDD，常常在理论与实践的落差间挣扎，在此过程中掌握了一些套路，心中也释然了对理论的追求，最近关注到业务架构，看到一张PPT，更是减少了心中的偏执，这份偏执也是一种对银弹的追求，虽然嘴大多数时候说没有，但身体很诚信\n\n在这张方法融合论里面，DDD只是一小块，为什么要心中充满DDD呢，不都是进阶路上的垫脚石。想起牛人的话，站到更高的维度让问题不再是问题才是最牛的解决问题之道\n事务脚本式@RestController@RequestMapping(&quot;/&quot;)public class CheckoutController &#123;    @Resource    private ItemService itemService;    @Resource    private InventoryService inventoryService;    @Resource    private OrderRepository orderRepository;    @PostMapping(&quot;checkout&quot;)    public Result&lt;OrderDO&gt; checkout(Long itemId, Integer quantity) &#123;        // 1) Session管理        Long userId = SessionUtils.getLoggedInUserId();        if (userId &lt;= 0) &#123;            return Result.fail(&quot;Not Logged In&quot;);        &#125;                // 2）参数校验        if (itemId &lt;= 0 || quantity &lt;= 0 || quantity &gt;= 1000) &#123;            return Result.fail(&quot;Invalid Args&quot;);        &#125;        // 3）外部数据补全        ItemDO item = itemService.getItem(itemId);        if (item == null) &#123;            return Result.fail(&quot;Item Not Found&quot;);        &#125;        // 4）调用外部服务        boolean withholdSuccess = inventoryService.withhold(itemId, quantity);        if (!withholdSuccess) &#123;            return Result.fail(&quot;Inventory not enough&quot;);        &#125;              // 5）领域计算        Long cost = item.getPriceInCents() * quantity;        // 6）领域对象操作        OrderDO order = new OrderDO();        order.setItemId(itemId);        order.setBuyerId(userId);        order.setSellerId(item.getSellerId());        order.setCount(quantity);        order.setTotalCost(cost);        // 7）数据持久化        orderRepository.createOrder(order);        // 8）返回        return Result.success(order);    &#125;&#125;\n\n这是经典式编程，入参校验、获取数据、逻辑计算、数据存储、返回结果，每一个use case基本都是这样处理的，套路就是取数据、计算数据、存数据；当然，有时我们常把中间的一块放到service中。随着use case越来越多，会把一些重复代码提取出来，比如util,或者公共的service method，但这些仍然是一堆代码，可读性、可理解性还是很差，这两个很差，那可维护性就没法保证，更不用提可扩展性，为什么？因为这些代码缺少了灵魂。何为灵魂，业务模型。\n对于事务脚本式也有模型，单只有数据模型，而没有对象模型。模型是对业务的表达，没有了业务表达能力的代码，人怎么能读懂\n而DDD在领域模型方式就有很强的表达能力，当然在编码时也不会以数据流向为指导。先写Domain层的业务逻辑，然后再写Application层的组件编排，最后才写每个外部依赖的具体实现，这就是Domain-Driven Design，其实这类似于TDD，谁驱动谁就得先行\n反DDD任何事物都是过犹不及，如文章开头所述，没有银弹，千万别因为DDD的火热而一股脑全身心投入DDD，不管场景是否适合，都要DDD；犹如设计模式，后面出现了大量的反模式。\n错误的抽象比没有抽象伤害力更大\nDDD分层\nInterface层对于这一层的作用就是接受外部请求，主要是HTTP和RPC，那也就依赖于具体的使用技术，是spring mvc、还是dubble\n在DDD正统分层里面是有这一层的，但实践时，像我们的controller却有好几种归类\n一、User Interface归属于大前端，不在后端服务，后端服务从application层开始\n二、正统理论，就是放在interface层\n三、controller毕竟是基于具体框架实现，在六边形架构中就是是个 adapter，归于 Infrastructure 层\n对于以上三种归类，都有实践，都可以，但不管怎么归属，他的属性依然是 Interface\n对于Interface落地时指导方针：\n\n统一返回值，interface是对外，这样可以统一风格，降低外部认知成本\n全局异常拦截，通过aop拦截，对外形成良好提示，也防止内部异常外溢，减少异常栈序列化开销\n日志，打印调用日志，用于统计或问题定位\n遵循ISP,SRP原则，独立业务独立接口，职责清晰，轻便应对需求变更，也方便服务治理，不用担心接口的逻辑重复，知识沉淀放在application层，interface只是协议，要薄，厚度体现在application层\n\n@Datapublic class Result&lt;T&gt; &#123;     /** 错误码 */    private Integer code;     /** 提示信息 */    private String msg;     /** 具体的内容 */    private T data;&#125;\n\nApplication层应用层主要作用就是编排业务,只负责业务流程串联，不负责业务逻辑\napplication层其实是有固定套路的，在之前的文章有过阐述，大致流程：\napplication service method(Command command) &#123;    //参数检验    check(command);        Aggregate aggregate = repository.findAggregate(command);        //复杂的需要domain service    aggregate.operate(command);        repository.saveOrUpdate(aggregate);        publish(event);        return DTOAssembler.to(aggregate);    &#125;\n\n业务流程 VS 业务规则对于这两者怎么区分，也就是application service 与 domain service 的区分，最简单的方式：业务规则是有if&#x2F;else的，业务流程没有\n现在都是防御性编程，在check(command)部分，会做很多的precondition\n比如转帐业务中，对于余额的前提判断：\npublic void preDebit(Account account, double amount) &#123;    double newBalance = account.balance() - amount;    if (newBalance &lt; 0) &#123;      throw new DebitException(&quot;Insufficient funds&quot;);    &#125;&#125;\n\n这算是业务规则还是业务流程呢？这一段代码可以算是precondition，但也是业务规则的一部分，颇有争议，但没有正确答案，只是看你代码是否有复用性，目前我个人倾向于放在业务规则中，也就是domain层\n厚与薄常人讲，application service是很薄的一层，要把domain做厚，但从最开始的示例，发现其实application service特别多，而domain只有一行代码，这不是application厚了，domain薄了\n对于薄与厚不再于代码的多与少，application层不是厚，而是编排多而已，逻辑很简单，一般厚的domain大多都是有比较复杂的业务逻辑，比如大量的分支条件。一个例子就是游戏里的伤害计算逻辑。另一种厚一点的就是Entity有比较复杂的状态机，比如订单\n出入参数先讲一个代码示例：\n从controller接受到请求，传入application service中，需要做一层转换，controller层\n示例一段创建目录功能的对象转换：\n@Datapublic class DirectoryDto extends BaseRequest &#123;    private long id;    @NotBlank    @ApiModelProperty(&quot;目录编号&quot;)    private String directoryNo;    @NotBlank    @ApiModelProperty(&quot;目录名称&quot;)    private String directoryName;    private String directoryOrder;    private String use;    private Long parentId;&#125;com.jjk.application.dto.directory.DirectoryDto to(com.jjk.controller.dto.DirectoryDto directoryDto);\n\n创建目录，入参只需要directoryNo,directoryName，为了少写代码，把编辑目录(directoryDto中带了id属性)，response(directoryDto包含了目录所有信息)都揉合在一个dto中了\n这样就会有几个问题：\n\n违背SRP，创建与编辑两个业务功能却混杂在了一个dto中\n相对SRP，更大的问题是业务语义不明确，DDD中一个优势就是要业务语义显示化\n\n怎么解决呢？\n引入CQRS元素：\n\nCommand指令：指调用方明确想让系统操作的指令，其预期是对一个系统有影响，也就是写操作。通常来讲指令需要有一个明确的返回值（如同步的操作结果，或异步的指令已经被接受）\nQuery查询：指调用方明确想查询的东西，包括查询参数、过滤、分页等条件，其预期是对一个系统的数据完全不影响的，也就是只读操作\n\n这样把创建与编辑拆分，CreateDirectoryCommand、EditDirectoryCommand，这样有了明确的”意图“，业务语义也相当明显；其次就是这些入参的正确性，之前事务脚本代码中大量的非业务代码混杂在业务代码中，违背SRP；可以利用java标准JSR303或JSR380的Bean Validation来前置这个校验逻辑，或者使用Domain Primitive，既能保证意图的正确性，又能让application service代码清爽\n而出参，则使用DTO，如果有异常情况则直接抛出异常，如果不需要特殊处理，由interface层兜底处理\n对于异常设计，可根据具体情况处理，整体由业务异常BusinessException派生，想细化可以派生出DirectoryNameExistException，让interface来定制exception message,若无需定制使用默认message\nDomain层domain层是业务规则的集合，application service编排业务，domain service编排领域；\ndomain体现在业务语义显现化，不仅仅是一堆代码，代码即文档、代码即业务；要达到高内聚就得充分发挥domain层的优势，domain层不单单是domain service，还有entity、vo、aggregate\ndomain层是最最需要拥抱变化的一层，为什么？domain代表了业务规则，业务规则来自于需求，日常开发中，需求是经常变化的\n我们需要逆向思维，以往我们去封装第三方服务，解耦外部依赖，大多数时候是考虑外部的变化不要影响自身，而现实中，更多的变化来自内部：需求变了，所以我们应该更多关注一个业务架构的目标：独立性，不因外部变化而变化，更要不因自身变化影响外部服务的适应性\n在《DDD之Repository》中指出Domain Service是业务规则的集合，不是业务流程，所以Domain Service不应该有需要调用到Repo的地方。如果需要从另一个地方拿数据，最好作为入参，而不是在内部调用。DomainService需要是无状态的，加了Repo就有状态了。domainService是规则引擎，appService才是流程引擎。Repo跟规则无关\n也就是domain层应该是一个纯内存操作，不依赖外部任何服务，这样提高了domain层的可测试性，拥抱变化的底气也来自于完整的UT，而application层UT全部得mock\nInfrastructure层Infrastructure层是基础实施层，为其他层提供通用的技术能力：业务平台，编程框架，持久化机制，消息机制，第三方库的封装，通用算法，等等\nMartin Fowler将“封装访问外部系统或资源行为的对象”定义为网关（Gateway），在限界上下文的内部架构中，它代表了领域层与外部环境之间交互的出入口，即：\ngateway &#x3D; port + adapter\n这一点契合了六边形架构\n在实际落地时，碰到的问题就是DIP问题，Repository在DDD中是在Domain层，但具体实现，如DB具体实现是在Infrastructure层，这也是符合整洁架构，但DDD限界上下文可能不仅限于访问数据库，还可能访问同样属于外部设备的文件、网络与消息队列。为了隔离领域模型与外部设备，同样需要为它们定义抽象的出口端口，这些出口端口该放在哪里呢？如果依然放在领域层，就很难自圆其说。例如，出口端口EventPublisher支持将事件消息发布到消息队列，要将这样的接口放在领域层，就显得不伦不类了。倘若不放在位于内部核心的领域层，就只能放在领域层外部，这又违背了整洁架构思想\n这个问题张逸老师提出了菱形架构，后面的章节中再论述\n再次比较interface与infrastructure，在前面讲述到controller的归属，其实就隐含了interface与infra的关联，这两者都与具体框架或外部实现相关，在六边形架构中，都归属为port与adapter\n我一般的理解：从外部收到的，属于interface层，比如RPC接口、HTTP接口、消息里面的消费者、定时任务等，这些需要转化为Command、Query，然后给到App层。\nApp主动能去调用到的，比如DB、Message的Publisher、缓存、文件、搜索这些，属于infra层\n所以消息相关代码可能会同时存在2层里。这个主要还是看信息的流转方式，都是从interface -&gt; Application -&gt; infra\n整洁架构\n一个好的架构应该需要实现以下几个目标：\n\n独立于框架：架构不应该依赖某个外部的库或框架，不应该被框架的结构所束缚\n独立于UI：前台展示的样式可能会随时发生变化\n独立于底层数据源：无论使用什么数据库，软件架构不应该因不同的底层数据储存方式而产生巨大改变\n独立于外部依赖：无论外部依赖如何变更、升级，业务的核心逻辑不应该随之而大幅变化\n可测试：无论外部依赖什么样的数据库、硬件、UI或服务，业务的逻辑应该都能够快速被验证正确性\n\n这几项目标，也对应我们对domain的要求：独立性和可测试；我们的依赖方向必须是由外向内\nDIP与Maven要想实现整洁架构目标，那必须遵循面向接口编程，达到DIP\n&lt;modules&gt;    &lt;module&gt;assist-controller&lt;/module&gt;     &lt;module&gt;assist-application&lt;/module&gt;     &lt;module&gt;assist-domain&lt;/module&gt;     &lt;module&gt;assist-infrastructure&lt;/module&gt;     &lt;module&gt;assist-common&lt;/module&gt;     &lt;module&gt;starter&lt;/module&gt; &lt;/modules&gt;\n\n在使用maven构建项目时，整个依赖关系是：starter -&gt; assist-controller -&gt; assist-application -&gt; assist-domain -&gt; assit-infrastructure\ndomain层并不是中心层，为什么呢？为什么domain不在最中心？\n主要是存在一个循环依赖问题：repository接口在domain层，但现实在infra层，可从maven module依赖讲，domain又是依赖infra模块，domain依赖infra的原由是因为前文所述\nDDD限界上下文可能不仅限于访问数据库，还可能访问同样属于外部设备的文件、网络与消息队列。为了隔离领域模型与外部设备，同样需要为它们定义抽象的出口端口，这些出口端口该放在哪里呢\n按此划分module，这些出口端口都放在了infra层，当domain需要外部服务时，不得不依赖infra module\n对此问题的困惑持续很久，一直认为菱形架构是个好的解决方案，但今年跟阿里大佬的交流中，又得到些新的启发\nEventPublisher接口就是放在Domain层，只不过namespace不是xxx.domain，而是xxx.messaging之类的\n像repsoitory是在Domain层，但是从理论上是infra层，混淆了两个概念一个是maven module怎么搞，一个是什么是Domain层\n以namespace区分后，得到的依赖关系就是DIP后的DDD\n\n菱形架构上文中多次提到菱形架构，这是张逸老师发明的，去年项目中，我一直使用此架构\n一是解决了上文中的DIP问题，二是整个架构结构清晰职责明确\n简单概述一下：\n\n\n\n把六边形架构与分层架构整合时，发现六边形架构与领域驱动设计的分层架构存在设计概念上的冲突\n\n\n出口端口用于抽象领域模型对外部环境的访问，位于领域六边形的边线之上。根据分层架构的定义，领域六边形的内部属于领域层，介于领域六边形与应用六边形的中间区域属于基础设施层，那么，位于六边形边线之上的出口端口就应该既不属于领域层，又不属于基础设施层。它的职责与属于应用层的入口端口也不同，因为应用层的应用服务是对外部请求的封装，相当于是一个业务用例的外观。\n\n\n根据六边形架构的协作原则，领域模型若要访问外部设备，需要调用出口端口。依据整洁架构遵循的“稳定依赖原则”，领域层不能依赖于外层。因此，出口端口只能放在领域层。事实上，领域驱动设计也是如此要求的，它在领域模型中定义了资源库（Repository），用于管理聚合的生命周期，同时，它也将作为抽象的访问外部数据库的出口端口。\n\n\n将资源库放在领域层确有论据佐证，毕竟，在抹掉数据库技术的实现细节后，资源库的接口方法就是对聚合领域模型对象的管理，包括查询、修改、增加与删除行为，这些行为也可视为领域逻辑的一部分。\n\n\n然而，限界上下文可能不仅限于访问数据库，还可能访问同样属于外部设备的文件、网络与消息队列。为了隔离领域模型与外部设备，同样需要为它们定义抽象的出口端口，这些出口端口该放在哪里呢？如果依然放在领域层，就很难自圆其说。例如，出口端口EventPublisher支持将事件消息发布到消息队列，要将这样的接口放在领域层，就显得不伦不类了。倘若不放在位于内部核心的领域层，就只能放在领域层外部，这又违背了整洁架构思想。\n\n\n如果我们将六边形架构看作是一个对称的架构，以领域为轴心，入口适配器和入口端口就应该与出口适配器和出口端口是对称的；同时，适配器又需和端口相对应，如此方可保证架构的松耦合。\n\n\n\n&lt;modules&gt; &lt;module&gt;assist-ohs&lt;/module&gt;  &lt;module&gt;assist-service&lt;/module&gt;  &lt;module&gt;assist-acl&lt;/module&gt;  &lt;module&gt;starter&lt;/module&gt; &lt;/modules&gt;\n\n这有点类似《DDD之形》中提到的端口模式，把资源库Repository从domain层转移到端口层和其它端口元素统一管理，原来的四层架构变成了三层架构，对repository的位置从物理与逻辑上一致，相当于扩大了ACL范围\n这个架构结构清晰，算是六边形架构与分层架构的融合体，至于怎么选择看个人喜爱\nEvent相对Event Source，这儿更关注一下event的发起，是不是需要区分应用事件和领域事件\n根据application的套路，会publish event，那在domain service中要不要publish event呢？\nDomain Event更多是领域内的事件，所以应该域内处理，甚至不需要是异步的。Application层去调用消息中间件发消息，或调用三方服务，这个是跨域的。\n从目前的实践来看，直接抛Domain Event做跨域处理这件事，不是很成熟，特别是容易把Domain层的边界捅破，带来完全不可控的副作用\n所以结合application，除了Command、Query入参，还需要Event入参，处理事件\n总结本文主要是按DDD分层，介绍各层落地时的具体措施，以及各层相应的规范，引入CQRS使代码语义显现化，通过DIP达到整洁架构的目标\n对于domain层，有个重要的aggregate,涉及模型的构建，千人千模，但domain层的落地是一样的\n在业务代码中有几个比较核心的东西：抽象领域对象合并简单单实体逻辑，将多实体复杂业务规则放到DomainService里、封装CRUD为Repository，通过App串联业务流程，通过interface提供对外接口，或者接收外部消息\n其实不论使用DDD，还是事务脚本，合适的才是最好的，任何方法论都得以降低代码复杂度为目的\n","tags":["DDD"]},{"title":"Hashmap源码解析","url":"/blog/hashmap-source-code-analysis.html","content":"前言做什么都怕进入狗咬尾巴的怪圈，上次看hashmap源码还是2012年，这次出去面试时被问到了hashmap的问题，整体思路还是记得的，巴拉巴拉一堆。回来再看一下源码，温习一下\n想要了解hashmap，就得先知道一下他的数据结构理论\n哈希数据结构哈希表（Hash table，也叫散列表），是根据key而直接进行访问的数据结构。也就是说，它通过把key映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。\n哈希表的做法其实很简单，就是把key通过一个固定的算法函数即所谓的哈希函数转换成一个整型数字，然后就将该数字对数组长度进行取余，取余结果就当作数组的下标，将value存储在以该数字为下标的数组空间里。\n哈希表是一个在时间和空间上做出权衡的经典例子。如果没有内存限制，那么可以直接将键作为数组的索引。那么所有的查找时间复杂度为O(1)；如果没有时间限制，那么我们可以使用无序数组并进行顺序查找，这样只需要很少的内存。哈希表使用了适度的时间和空间来在这两个极端之间找到了平衡。只需要调整哈希函数算法即可在时间和空间上做出取舍。\n哈希函数哈希查找第一步就是使用哈希函数将键映射成索引。这种映射函数就是哈希函数。如果我们有一个保存0-M数组，那么我们就需要一个能够将任意键转换为该数组范围内的索引（0~M-1）的哈希函数\nR.W.Floyed给出的衡量散列思想的三个标准：\n\n一个好的hash算法的计算应该是非常快的\n一个好的hash算法应该是冲突极小化， 如果存在冲突，应该是冲突均匀化。\n\n哈希冲突通过哈希函数，我们可以将键转换为数组的索引(0-M-1)，但是对于两个或者多个键具有相同索引值的情况，我们需要有一种方法来处理这种冲突。\n拉链法一种比较直接的办法就是，将大小为M 的数组的每一个元素指向一个条链表，链表中的每一个节点都存储散列值为该索引的键值对，这就是拉链法\n\n该方法的基本思想就是选择足够大的M，使得所有的链表都尽可能的短小，以保证查找的效率。对采用拉链法的哈希实现的查找分为两步，首先是根据散列值找到等一应的链表，然后沿着链表顺序找到相应的键。\n实现基于拉链表的散列表，目标是选择适当的数组大小M，使得既不会因为空链表而浪费内存空间，也不会因为链表太而在查找上浪费太多时间。拉链表的优点在于，这种数组大小M的选择不是关键性的，如果存入的键多于预期，那么查找的时间只会比选择更大的数组稍长，另外，我们也可以使用更高效的结构来代替链表存储。如果存入的键少于预期，索然有些浪费空间，但是查找速度就会很快。所以当内存不紧张时，我们可以选择足够大的M，可以使得查找时间变为常数，如果内存紧张时，选择尽量大的M仍能够将性能提高M倍。\n线性探测法线性探测法是开放寻址法解决哈希冲突的一种方法，基本原理为，使用大小为M的数组来保存N个键值对，其中M&gt;N，我们需要使用数组中的空位解决碰撞冲突。如下图所示：\n\n对照前面的拉链法，在该图中，”Ted Baker” 是有唯一的哈希值153的，但是由于153被”Sandra Dee”占用了。而原先”Snadra Dee”和”John Smith”的哈希值都是152的，但是在对”Sandra Dee”进行哈希的时候发现152已经被占用了，所以往下找发现153没有被占用，所以存放在153上，然后”Ted Baker”哈希到153上，发现已经被占用了，所以往下找，发现154没有被占用，所以值存到了154上。\n开放寻址法中最简单的是线性探测法：当碰撞发生时即一个键的散列值被另外一个键占用时，直接检查散列表中的下一个位置即将索引值加1，这样的线性探测会出现三种结果：\n\n命中，该位置的键和被查找的键相同\n未命中，键为空\n继续查找，该位置和键被查找的键不同。\n\n线性探查（Linear Probing）方式虽然简单，但是有一些问题，它会导致同类哈希的聚集。在存入的时候存在冲突，在查找的时候冲突依然存在。\nhashmap 源码分析hashmap原理角度看就是基于哈希数据结构的一种实现，解决冲突的办法是使用拉链法\n从源码基于JDK1.7看\npublic class HashMap&lt;K,V&gt;    extends AbstractMap&lt;K,V&gt;    implements Map&lt;K,V&gt;, Cloneable, Serializable\nHashMap是基于哈希表的Map接口的非同步实现，它提供所有可选的映射操作，并允许使用null键和null值。此集合不保证映射的顺序，特别不保证其顺序永久不变。\n初始化public HashMap(int initialCapacity, float loadFactor) &#123;        if (initialCapacity &lt; 0)            throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; +                                               initialCapacity);        if (initialCapacity &gt; MAXIMUM_CAPACITY)            initialCapacity = MAXIMUM_CAPACITY;        if (loadFactor &lt;= 0 || Float.isNaN(loadFactor))            throw new IllegalArgumentException(&quot;Illegal load factor: &quot; +                                               loadFactor);        this.loadFactor = loadFactor;        threshold = initialCapacity;        init();    &#125;\n两个重要的初始化参数，[初始容量，负载因子]\n这个JDK7大版本里面的小版本对hashmap改动好好几次。\n这个源码是基于JDK7.0_80的。有些版本在构造函数里面就确保容量是2的N次方，但这个版本没有，很简单的赋值\n初始容量16，负载因子0.75\n/**    * The default initial capacity - MUST be a power of two.    */   static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16   /**    * The maximum capacity, used if a higher value is implicitly specified    * by either of the constructors with arguments.    * MUST be a power of two &lt;= 1&lt;&lt;30.    */   static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;   /**    * The load factor used when none specified in constructor.    */   static final float DEFAULT_LOAD_FACTOR = 0.75f;\n\n2的N次方很多算法书上都认为想要降低key冲突，最好容量为素数。为什么java却取了个2的N次方呢。\n为了将各元素的hashCode保存至长度为Length的key数组中，一般采用取模的方式，即index &#x3D; hashCode % Length。不可避免的，存在多个不同对象的hashCode被安排在同一位置，这就是我们平时所谓的“冲突”。如果仅仅是考虑元素均匀化与冲突极小化，似乎应该将Length取为素数（尽管没有明显的理论来支持这一点，但数学家们通过大量的实践得出结论，对素数取模的产生结果的无关性要大于其它数字）。为此，Craig Larman and Rhett Guthrie《Java Performence》中对此也大加抨击。\n为了弄清楚这个问题，Bruce Eckel（Thinking in JAVA的作者）专程采访了java.util.hashMap的作者Joshua Bloch,此设计的原因取模运算在包括Java在内的大多数语言中的效率都十分低下，而当除数为2的N次方时，取模运算将退化为最简单的位运算，其效率明显提升（按照Bruce Eckel给出的数据，大约可以提升5～8倍）\n/**     * Returns index for hash code h.     */    static int indexFor(int h, int length) &#123;        // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;;        return h &amp; (length-1);    &#125;\n\n看下图，左边两组是数组长度为16（2的4次方），右边两组是数组长度为15。两组的hashcode为8和9，但是很明显，当它们和1110“与”的时候，产生了相同的结果，也就是说它们会定位到数组中的同一个位置上去，这就产生了碰撞，8和9会被放到同一个链表上，那么查询的时候就需要遍历这个链表，得到8或者9，这样就降低了查询的效率。同时，我们也可以发现，当数组长度为15的时候，hashcode的值会与14（1110）进行“与”，那么最后一位永远是0，而0001，0011，0101，1001，1011，0111，1101这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率，减慢了查询的效率！ \n\nput操作/**     * Associates the specified value with the specified key in this map.     * If the map previously contained a mapping for the key, the old     * value is replaced.     *     * @param key key with which the specified value is to be associated     * @param value value to be associated with the specified key     * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or     *         &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;.     *         (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map     *         previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.)     */    public V put(K key, V value) &#123;        if (table == EMPTY_TABLE) &#123;            inflateTable(threshold);        &#125;        if (key == null)            return putForNullKey(value);        int hash = hash(key);        int i = indexFor(hash, table.length);        for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123;            Object k;            if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123;                V oldValue = e.value;                e.value = value;                e.recordAccess(this);                return oldValue;            &#125;        &#125;        modCount++;        addEntry(hash, key, value, i);        return null;    &#125;\n当table &#x3D;&#x3D; EMPTY_TABLE时，先填充table\n/**     * Inflates the table.     */    private void inflateTable(int toSize) &#123;        // Find a power of 2 &gt;= toSize        int capacity = roundUpToPowerOf2(toSize);        threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1);        table = new Entry[capacity];        initHashSeedAsNeeded(capacity);    &#125; \n这儿看到了2的N次方，没有跟之前一样使用while循环\nint capacity = 1;  while (capacity &lt; initialCapacity)   capacity &lt;&lt;= 1;    \nthreshold的值&#x3D;容量*负载因子\n看下roundUpToPowerOf2()\nprivate static int roundUpToPowerOf2(int number) &#123;        // assert number &gt;= 0 : &quot;number must be non-negative&quot;;        return number &gt;= MAXIMUM_CAPACITY                ? MAXIMUM_CAPACITY                : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1;    &#125;\n主要是Integer.highestOneBit\npublic static int highestOneBit(int i) &#123;        // HD, Figure 3-1        i |= (i &gt;&gt;  1);        i |= (i &gt;&gt;  2);        i |= (i &gt;&gt;  4);        i |= (i &gt;&gt;  8);        i |= (i &gt;&gt; 16);        return i - (i &gt;&gt;&gt; 1);    &#125;\n这个方法单纯的使用位运算，性能自然提高解析下这个方法，这个方法的作用是求构成一个整数的最大的位所代表的整数的值接下来举个简单的例子，128来讲二进制是1000 0000。下面以他为例子算下：    移1位    1000 0000    0100 0000    |————-    移2位    1100 0000    0011 0000    |————    移4位    1111 0000    0000 1111    |————    移8位    1111 1111    0000 0000    |————    移动16位    1111 1111    0000 0000    |————    1111 1111最终的结果如你所看到的，后面的位全部填充为1，把后面的位全部减掉就得到了最高的位代表的整数。\n回到put方法，如果key&#x3D;&#x3D;null，putForNullKey(value);说明hashmap支持key为null\n/**     * Offloaded version of put for null keys     */    private V putForNullKey(V value) &#123;        for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123;            if (e.key == null) &#123;                V oldValue = e.value;                e.value = value;                e.recordAccess(this);                return oldValue;            &#125;        &#125;        modCount++;        addEntry(0, null, value, 0);        return null;    &#125;\n这个逻辑比较简单\n\n第一步，如果找到之前有key为null的key,进行一下value替换，返回oldValue\n如果没有为null的key,那进行addEntry() 添加元素的主要方法\n\n/** * Adds a new entry with the specified key, value and hash code to * the specified bucket.  It is the responsibility of this * method to resize the table if appropriate. * * Subclass overrides this to alter the behavior of put method. */void addEntry(int hash, K key, V value, int bucketIndex) &#123;    if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123;        resize(2 * table.length);        hash = (null != key) ? hash(key) : 0;        bucketIndex = indexFor(hash, table.length);    &#125;    createEntry(hash, key, value, bucketIndex);&#125;\n新添加元素时，先看下有没有达到threshold &amp;&amp; bucketIndex元素不为null\n如果成立，那就需要resize，这是个耗性能的操作，所以在初始化时，一般计算好元素多少，给一个合适的初始容量\n按照上面的条件，一个合适的容量应该这样计算了\n我们有1000个元素new HashMap(1000), 但是理论上来讲new HashMap(1024)更合适，即使是1000，hashmap也自动会将其设置为1024。 但是new HashMap(1024)还不是更合适的，因为0.75*1000 &lt; 1000, 也就是说为了让0.75 * size &gt; 1000, 我们必须这样new HashMap(2048)才最合适，既考虑了&amp;的问题，也避免了resize的问题。 \n先看createEntry\nvoid createEntry(int hash, K key, V value, int bucketIndex) &#123;        Entry&lt;K,V&gt; e = table[bucketIndex];        table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e);        size++;    &#125;\n这个很简单，新建一个Entry指向bucketIndex，老元素e，被指向新元素的next。\n这儿也看出hashmap是使用的拉链法\n看Entry,就是一个链表，一个元素接着另一个元素\nstatic class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;        final K key;        V value;        Entry&lt;K,V&gt; next;        int hash;                Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123;            value = v;            next = n;            key = k;            hash = h;        &#125;\n\nresize方法耗性能的地方，重新散列，看看这个方法的实现\n//在put方法里,当容量达到threshold时，进行双倍的扩容。resize(2 * table.length);void resize(int newCapacity) &#123;        Entry[] oldTable = table;        int oldCapacity = oldTable.length;        if (oldCapacity == MAXIMUM_CAPACITY) &#123;            threshold = Integer.MAX_VALUE;            return;        &#125;        Entry[] newTable = new Entry[newCapacity];        transfer(newTable, initHashSeedAsNeeded(newCapacity));        table = newTable;        threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);    &#125;    /**     * Transfers all entries from current table to newTable.     */    void transfer(Entry[] newTable, boolean rehash) &#123;        int newCapacity = newTable.length;        for (Entry&lt;K,V&gt; e : table) &#123;            while(null != e) &#123;                Entry&lt;K,V&gt; next = e.next;                if (rehash) &#123;                    e.hash = null == e.key ? 0 : hash(e.key);                &#125;                int i = indexFor(e.hash, newCapacity);                e.next = newTable[i];                newTable[i] = e;                e = next;            &#125;        &#125;    &#125;\n如果容量已经达到MAX_VALUE,那就不扩容了，只能处理冲突\ntransfer(),这是核心方法，把以前的元素，按新的capacity，计算的hashCode，重新放置元素。\n这儿看到e.next&#x3D;newTable[i],明显使用的是链表头部插入法\nget方法public V get(Object key) &#123;        if (key == null)            return getForNullKey();        Entry&lt;K,V&gt; entry = getEntry(key);        return null == entry ? null : entry.getValue();    &#125;    final Entry&lt;K,V&gt; getEntry(Object key) &#123;        if (size == 0) &#123;            return null;        &#125;        int hash = (key == null) ? 0 : hash(key);        for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)];             e != null;             e = e.next) &#123;            Object k;            if (e.hash == hash &amp;&amp;                ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                return e;        &#125;        return null;    &#125;\nget很好理解了，跟算法一致，先hash找bucket，如果有冲突的元素，再使用equals来判定\nhashSeed/**     * A randomizing value associated with this instance that is applied to     * hash code of keys to make hash collisions harder to find. If 0 then     * alternative hashing is disabled.     */    transient int hashSeed = 0;    /**     * Initialize the hashing mask value. We defer initialization until we     * really need it.     */    final boolean initHashSeedAsNeeded(int capacity) &#123;        boolean currentAltHashing = hashSeed != 0;        boolean useAltHashing = sun.misc.VM.isBooted() &amp;&amp;                (capacity &gt;= Holder.ALTERNATIVE_HASHING_THRESHOLD);        boolean switching = currentAltHashing ^ useAltHashing;        if (switching) &#123;            hashSeed = useAltHashing                ? sun.misc.Hashing.randomHashSeed(this)                : 0;        &#125;        return switching;    &#125;\ninitHashSeedAsNeeded在inflateTable中被调用过，这个hashSeed到底有什么用？\nhashSeed就好像我们加密时使用的密钥，在StackOverfolw上是这样描述hashSeed的：\n\nThe seed parameter is a means for you to randomize the hash function. You should provide the same seed value for all calls to the hashing function in the same application of the hashing function. However, each invocation of your application (assuming it is creating a new hash table) can use a different seed, e.g., a random value.\n\n\nWhy is it provided?\n\n\nOne reason is that attackers may use the properties of a hash function to construct a denial of service attack. They could do this by providing strings to your hash function that all hash to the same value destroying the performance of your hash table. But if you use a different seed for each run of your program, the set of strings the attackers must use changes.\n\n虽然seed近似随机，但在同一个HashMap中必须保证每次的计算Hash值的时候使用的同一个seed，也就相当于保证我们在一个密码系统中加密时，使用同一个密钥。同时使用seed可以抵御攻击，因为每个应用的seed都会一样。\n对于安全方面的了解几乎是0，有机会再学习了。\nConcurrentModificationExceptionhashmap不是线程安全的\n private abstract class HashIterator&lt;E&gt; implements Iterator&lt;E&gt; &#123;        Entry&lt;K,V&gt; next;        // next entry to return        int expectedModCount;   // For fast-fail        int index;              // current slot        Entry&lt;K,V&gt; current;     // current entry                final Entry&lt;K,V&gt; nextEntry() &#123;            if (modCount != expectedModCount)                throw new ConcurrentModificationException();\n这个内部遍历类使用了Fail-Fast机制\n/**     * The number of times this HashMap has been structurally modified     * Structural modifications are those that change the number of mappings in     * the HashMap or otherwise modify its internal structure (e.g.,     * rehash).  This field is used to make iterators on Collection-views of     * the HashMap fail-fast.  (See ConcurrentModificationException).     */    transient int modCount;\nmodCount为HashMap的一个实例变量，并且被声明为volatile，表示任何线程都可以看到该变量被其它线程修改的结果\n（根据JVM内存模型的优化，每一个线程都会存一份自己的工作内存，此工作内存的内容与本地内存并非时时刻刻都同步，因此可能会出现线程间的修改不可见的问题） \n使用Iterator开始迭代时，会将modCount的赋值给expectedModCount，在迭代过程中，通过每次比较两者是否相等来判断HashMap是否在内部或被其它线程修改\n在并发条件下，还是要使用并发包下的ConcurrentHashmap，有时间也得写一写\n总结(1) 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。\n(2) 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。\n(3) HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。\n参考资料浅谈算法和数据结构: 十一 哈希表\n单链表—java实现\nHashMap的存取之美\n","categories":["java"],"tags":["hash"]},{"title":"IOC理解","url":"/blog/ioc-understanding.html","content":"\n成功就是简单道理的深刻理解与灵活运用\n\n前不久，阿里大牛虾总在群里抛出一个问题：“从深层次讲解一下如何理解IOC，IOC和DI是一回事吗？”\n这个问题真是让人平静而又不平静\n平静源于此问题就像问中国人怎么使用筷子，天天使用筷子，难道还不会使用筷子？\n但又不平静，你能写出一份详细的说明书，让一个不会使用筷子的人按此说明成功地使用上筷子吗？\n\n天天使用spring，是否还记得那些简单原理？现如今会写六种回字的你，还记得回的本意吗？\n\n那些曾经刻骨铭心的记忆,你有多久没有想起了\n\n\nIOC不管是平时交流，还是面试，当谈谈spring时，除了api使用，最主要还是要聊聊IOC\nIoc—Inversion of Control，即“控制反转”\n从语文的角度解析一下，如果“控制”当成一个动作，那就需要完善主语与宾语，也就是“谁”控制了“谁”；\n“反转”：没有反转是什么情况，what反转，why反转，how反转\n分两种情况讨论，1、没有IOC容器，2、有IOC容器\n没有IOC容器参与者回答“谁”控制了“谁”中的两个“谁”\n抽象讲：某个对象A控制了另一个某对象B\n宏观讲 某个对象A可能就是应用程序，比如读取或者修改一个文件，那么此处的文件也就是某对象B了\n微观讲，objectA 操作了 objectB，比如给objectB的属性赋值\n从由内向外的角度 由两个参与者：某一对象（任意的对象类），以及对象外的各种资源（需要的其它对象、或者是对象需要的文件资源等等）\n控制常规情况下的应用程序，如果要在A里面使用C，当然是直接去创建C的对象，也就是说，是在A类中主动去获取所需要的外部资源C\n\nA a = new AImpl(); C c = new CImpl(); a.setC(c);\n当前类控制了一切：主动实例化、获取依赖、主动装配\n这儿示例简单了点，一些项目会使用上Factory模式，让程序更面向接口，最小化变化，最大化地“开-闭”原则\n但不管如何，还是会面临一些问题：\n\n更换实现需要重新编译源代码\n依赖变更很难更换实现、难于测试\n耦合实例生产者和实例消费者\n\n有IOC容器引入IOC容器\n参与者除了对象与对象外的资源，增加了IOC容器\n控制引入IOC容器后，就不再是直接控制了，而是被动等待，等待IoC&#x2F;DI的容器获取一个C的实例，然后反向的注入到A类中\n\n此时，对象不再主动去new,而IoC容器来创建这些对象，即由Ioc容器来控制对象的创建；\n再来看“谁”控制了“谁”?\nIoC 容器控制了对象；控制什么？主要控制了外部资源获取（不只是对象包括比如文件等）\n反转A a = new AImpl(); C c = new CImpl(); a.setC(c);\n还是看这段代码，包含了 主动实例化、获取依赖，主动装配\n根据【控制】，IOC做到了主动实例化、获取依赖；而【反转】体现在了主动装配这一点\n传统应用程序是由我们自己在对象中主动控制去直接获取并set依赖对象，是为【正转】；\n而【反转】则是由容器来帮忙创建及注入依赖对象；\n为何是反转？\n因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转；哪些方面反转了？依赖对象的获取、装配被反转了\n\nIOC总结IoC很好的体现了面向对象设计法则之一—— 好莱坞法则：“别找我们，我们找你”；即由IoC容器帮对象找相应的依赖对象并注入，而不是由对象主动去找\n\n传统关系转变成\n\nIoC对编程带来的最大改变不是从代码上，而是从思想上，发生了“主从换位”的变化。应用程序原本是老大，要获取什么资源都是主动出击，但是在IoC思想中，应用程序就变成被动的了，被动的等待IoC容器来创建并注入它所需要的资源了\n这么小小的一个改变其实是编程思想的一个大进步，这样就有效的分离了对象和它所需要的外部资源，使得它们松散耦合，有利于功能复用，更重要的是使得程序的整个体系结构变得非常灵活\nDIDI—Dependency Injection，即“依赖注入”：组件之间依赖关系由容器在运行期决定，形象的说，即由容器动态的将某个依赖关系注入到组件之中。依赖注入的目的并非为软件系统带来更多功能，而是为了提升组件重用的频率，并为系统搭建一个灵活、可扩展的平台。\n通过依赖注入机制，我们只需要通过简单的配置，而无需任何代码就可指定目标需要的资源，完成自身的业务逻辑，而不需要关心具体的资源来自何处，由谁实现。　　\n理解DI的关键是：“谁依赖谁，为什么需要依赖，谁注入谁，注入了什么”\n那我们来深入分析一下：\n\n谁依赖于谁：当然是应用程序依赖于IoC容器；　　\n为什么需要依赖：应用程序需要IoC容器来提供对象需要的外部资源；　　\n谁注入谁：很明显是IoC容器注入应用程序某个对象，应用程序依赖的对象；　　\n注入了什么：就是注入某个对象所需要的外部资源（包括对象、资源、常量数据）\n\nIOC VS DIIoC和DI什么关系？\n貌似是个仁者见仁的问题，有人认为两者是同一个东西，也有人认为是不同的概念；\n摘抄一些见解\n\n\n根据上面的讲述，应该能看出来，依赖注入和控制反转是对同一件事情的不同描述，从某个方面讲，就是它们描述的角度不同。依赖注入是从应用程序的角度在描述，可以把依赖注入描述完整点：应用程序依赖容器创建并注入它所需要的外部资源；而控制反转是从容器的角度在描述，描述完整点：容器控制应用程序，由容器反向的向应用程序注入应用程序所需要的外部资源。\n\n\n\nDI仅是用一个单独的对象（装配器）来装配对象之间的依赖关系，一般有setter、构造、接口注入等，与IOC不是一回事，仅是IOC依赖管理层面的东西\n\n\n\nIOC是思想，DI是IOC的具体实现\n\n也可看看鼻祖Martin Fowler的表述\n\nAs a result I think we need a more specific name for this pattern. Inversion of Control is too generic a term, and thus people find it confusing. As a result with a lot of discussion with various IoC advocates we settled on the name Dependency Injection.\n\n参考资料Inversion of Control Containers and the Dependency Injection patternIOC是什么\n","tags":["IOC"]},{"title":"IO多路复用前世今生","url":"/blog/io-multiplexing-past-and-present-life.html","content":"之前总结了一篇文章《单服务器高性能》，主要整理了两方面的知识：\n一是socket以及IO常识\n二是单机高性能模式\n你会发现IO知识一般不会单独出现，常会与socket，linux底层相关知识结合出现，所以在学习IO时，总会有很多的背景知识，不然会很吃力。或者不明就理。\n这是为什么呢？\n与socket关联，应用角度看，是因为发生IO时，数据来源与目的地除了磁盘就是网络了，而网络必谈socket；其次从OS角度看，linux思想就是一切皆是文件，socket也是文件的一种。\n与linux关联，上面写了linux一切皆是文件，IO操作对象都是文件；其次IO操作得涉及内核，IO的一切优化都需要得到OS的支持。\n所以你会发现，谈到I&#x2F;O multiplexing、mmap、Zero-copy这些提升IO性能的技术时，都需要OS层面出手，否则很难有大的提升。\n其中I&#x2F;O multiplexing与Reactor经常被搞混，甚至被认为是同一种东西。\n我再尝试总结一下I&#x2F;O Multiplexing的前世今生以及与reactor的关联：\nI&#x2F;O multiplexingmultiplexing概念多用于通信领域，详细可看Multiplexing – Definition – Types of Multiplexing: FDM, WDM, TDM，截取两张图片表示multiplexing技术前后的对比：\n\n在没有multiplexing时，每次通信，一个通道上只能传输一个信号，浪费了带宽\n\n当有了multiplexing技术后，通过设备多路复用器multiplexer(MUX)，一个通道可以传输多个信号，带宽最大化利用。在接受端，通过信号分离器demultiplexer(DEMUX)，再把多个信号分离开。\n通过上面的两张图可以看出，multiplexing技术里面有两个设备比较关键，一是MUX负责多路复用,另一个是DEMUX负责多路分发。\n理解了multiplexing，再看看I&#x2F;O\n简要回顾一下：\n从最原始的BIO，PPC模式进化到TPC，通过线程池有效控制线程扩张，但线程上下文切换也带来了性能损耗依然不能小觑。关键是IO处理没有丝毫改进。\n\n从图中可以看出，之前block的依然block，之前system call的依然发生，对于成千上万的连接高并发，怎么达到高性能？\n怎么办呢？\n这一次还是kernal体现了大爱无私的胸怀，在提供了blocking read方法与non-blocking read方法后，又体贴地想出了两种方法\n1、不要每次都来问了，一次性打包问吧。把所有的system call整合在一起，一次性打包给system kernal,结合上面的multiplexing技术，I&#x2F;O multiplexing由此而来。\n2、不要总跑来问我了，有情况我通知你吧。对，这就是著名的Hollywood Principle\n根据这两个办法，打造出了最终的完美体epoll。当然在这个完美体前还有select、poll两个被丢弃的废品。至于这三者区别，可详看《单服务器高性能》。\n\nReactor pattern\nThe reactor design pattern is an event handling pattern for handling service requests delivered concurrently by one or more inputs. The service handler then demultiplexes the incoming requests and dispatches them synchronously to associated request handlers.\n\n更详细的介绍可看Reactor An Object Behavioral Pattern for Demultiplexing and Dispatching Handles for Synchronous Events\n看一下reactor pattern里面包含的部件：\n\n1.event:IO event like write, read, timeout and signal.\n2.Event Source (ES):file descriptor (fd) in linux and Socket or Handle in Windows. Program adds the event that it cares on the given event.\n3.event_demultiplexer (ED):select() and epoll() provided by the OS.  The program firstly add the event source (fd) and the related events to the ED. When event comes, ED eill notify that the events on one or more EVs are ready where program can process the events in nonblock way. The same ED way like select(), poll() and epoll() are used  in Libevent where they are encapsulated by eventop struct.\n4.event_handler_interface and event_handler_imp (EH):EH has a serial of interfaces and each interface refers to a different event.Reactor will invoke certain interface when some certain event fets ready. EH usually binds a valid ES.In libevent, it is event struct.\n5.reactor:It is the event management. It uses ED internally to add and remove event. When event is ready, invoke the callback function on the event. It is actually event_base struct in libevent.\n可以看到在reactor pattern中，有个reactor部件。而还有个部件event_demultiplexer是由多路复用技术支持。\n所以在谈到reactor时，是reactor模式，还是reactor部件？也没必要咬文嚼字了，反正他们是一家。\n不仅如此，还有一股编程思潮：响应式宣言里面也有reactor\n\n头晕，反正他们都是一家族的。\n总结一堆名词堆一起，看是又不是，是不是剪不断，理还乱。\n简单讲：\n结合I&#x2F;O与multiplexing，由此得来I&#x2F;O multiplexing。\nReactor模式中包含了reactor部件及依赖了多路复用技术。而多路复用技术的底层epoll又吸取了reactor思想。\n道生一，一生二。阴阳之道，存乎万物之间。\n","tags":["高性能","IO"]},{"title":"JDK8的map与flatmap区别","url":"/blog/the-difference-between-jdk8-map-and-flatmap.html","content":"\nmapmap() method -&gt; Data Transformation\nmap() takes Stream as input and return Stream\nStream map(Stream input){}\n&lt;R&gt; Stream&lt;R&gt; map(Function&lt;? super T, ? extends R&gt; mapper);\n\nIt’s mapper function produces single value for each input value.hence it is also called One-To-One mapping.\n\n这个方法比较好理解，把一个事物映射为另一个事物，是一对一的关系。\n在没有stream.map()时，就在使用apache和guava的类似api\napache中的ListUtils\npublic static &lt;E&gt; List&lt;E&gt; transformedList(final List&lt;E&gt; list,final Transformer&lt;? super E, ? extends E&gt; transformer) \n\nguava中的Lists\npublic static &lt;F, T&gt; List&lt;T&gt; transform(List&lt;F&gt; fromList, Function&lt;? super F, ? extends T&gt; function)\n\n\nflatMapflatMap() -&gt; map() + Flattering\nflatMap() takes Stream&lt;Stream&gt; as input and return Stream\nStream map(Stream&lt;Stream&gt; input){}\n&lt;R&gt; Stream&lt;R&gt; flatMap(Function&lt;? super T, ? extends Stream&lt;? extends R&gt;&gt; mapper);\n\nIt’s mapper function produces multiple value for each input value.hence it is also called One-To-Many mapping.\n\nflatteringflatMap()其实是两个方法的合并，map()好理解，主要是flattering。\n\nBefore Flattening: [[t,u], [v,w,x], [y,x]]\nAfter Flattening: [t,u,v,w,x,y,x]\n其实就是把两层数组打平了。\n实例在stackoverflow上找的一个示例：\nWhat’s the difference between map() and flatMap() methods in Java 8?\nflatMap helps to flatten a Collection&lt;Collection&gt; into a Collection. In the same way, it will also flatten an Optional&lt;Optional&gt; into Optional.\npublic class Parcel &#123;    String name;    List&lt;String&gt; items;    public Parcel(final String name, final String... items) &#123;        this.name = name;        this.items = Arrays.asList(items);    &#125;    public List&lt;String&gt; getItems() &#123;        return items;    &#125;    public static void main(final String[] args) &#123;        final Parcel amazon = new Parcel(&quot;amazon&quot;, &quot;Laptop&quot;, &quot;Phone&quot;);        final Parcel ebay = new Parcel(&quot;ebay&quot;, &quot;Mouse&quot;, &quot;Keyboard&quot;);        final List&lt;Parcel&gt; parcels = Arrays.asList(amazon, ebay);        System.out.println(&quot;-------- Without flatMap() ---------------------------&quot;);        final List&lt;List&lt;String&gt;&gt; mapReturn = parcels.stream()            .map(Parcel::getItems)            .collect(Collectors.toList());        System.out.println(&quot;\\t collect() returns: &quot; + mapReturn);        System.out.println(&quot;\\n-------- With flatMap() ------------------------------&quot;);        final List&lt;String&gt; flatMapReturn = parcels.stream()            .map(Parcel::getItems)            .flatMap(Collection::stream)            .collect(Collectors.toList());        System.out.println(&quot;\\t collect() returns: &quot; + flatMapReturn);    &#125;&#125;\n结果输出：\n-------- Without flatMap() ---------------------------\t collect() returns: [[Laptop, Phone], [Mouse, Keyboard]]-------- With flatMap() ------------------------------\t collect() returns: [Laptop, Phone, Mouse, Keyboard]\n\n\nAs you can see, with map() only:\n\nThe intermediate type is Stream&lt;List&gt;\nThe return type is List&lt;List&gt;\n\nand with flatMap():\n\nThe intermediate type is Stream\nThe return type is List\n\n参考flatMap() Method in Java 8\n\n","tags":["java"]},{"title":"Java并发的问题及应对办法","url":"/blog/problems-and-solutions-of-java-concurrency.html","content":"并发问题的源头并发？为啥需要并发呢？自然是为了性能，增强算力以及协调能力\n在现今计算机器体系中，涉及性能的主要有CPU、内存、IO三方面，而这三者的速度也是天壤之别，形象之讲，CPU天上一天，内存是地上一年，IO则要地上十年\n怎么应对：\n1、CPU增加了多级缓存，均衡与内存的速度差异，并且还从单核发展为多核增加算力\n2、操作系统增加线程，分时复用CPU，均衡CPU与IO的速度差异\n3、通过即时编译器重排序，处理器乱序执行，以及内存系统重排序优化指令执行次序，更好地利用缓存\n但这些措施并不是百利无害的，并发问题就是其中一害。\n1、缓存导致的可见性问题多核时代，每个核都有各自的L1，L2缓存，在各自缓存中修改的数据相互不可见。\n\n在《缓存是个面子工程》提到的硬件缓存，也带来了并发问题。\n\n2、线程切换带来的原子性问题这主要有些看似一行的代码，其实需要多条CPU指令才能完成\n如count+&#x3D;1，需要三条指令\n指令1：把变量count从内存加载到CPU的寄存器\n指令2：在寄存器中执行+1操作\n指令3：最后将结果写入内存\n当多线程时，线程切换时三条指令就会被错误执行，打破了原子性，导致逻辑的错误。\n3、编译优化带来的有序性问题编译器为了优化性能，有时改变了程序中语句的先后顺序。\npublic class Singleton &#123;  static Singleton instance;  static Singleton getInstance()&#123;    if (instance == null) &#123;      synchronized(Singleton.class) &#123;        if (instance == null)          instance = new Singleton();        &#125;    &#125;    return instance;  &#125;&#125;\nnew Singleton()这句话感觉是\n\n分配一块内存M\n在内存M上初始化Singleton对象\n然后M的地址赋值给instance变量\n\n实际执行路径却是：\n\n分配一块内存M\n将M的地址赋值给instance变量\n最后在内存M上初始化Singleton对象\n\nJMM如何解决上述的三大问题，JSR-133定义了内存模型JMM\n\nA memory model describes, given a program and an execution trace of that program, whether the execution trace is a legal execution of the program. For the Java programming language, the memory model works by examining each read in an execution trace and checking that the write observed by that read is valid according to certain rules.\n\n也就是说一个内存模型描述了一个给定的程序和和它的执行路径是否一个合法的执行路径。对于java序言来说，内存模型通过考察在程序执行路径中每一个读操作，根据特定的规则，检查写操作对应的读操作是否能是有效的。java内存模型只是定义了一个规范，具体的实现可以是根据实际情况自由实现的。但是实现要满足java内存模型定义的规范。\n内存模型的种类大致有两种：\nSequential Consistency Memory Model： 连续一致性模型。这个模型定义了程序执行的顺序和代码执行的顺序是一致的。也就是说 如果两个线程，一个线程T1对共享变量A进行写操作，另外一个线程T2对A进行读操作。如果线程T1在时间上先于T2执行，那么T2就可以看见T1修改之后的值。这个内存模型比较简单，也比较直观，比较符合现实世界的逻辑。但是这个模型定义比较严格，在多处理器并发执行程序的时候，会严重的影响程序的性能。因为每次对共享变量的修改都要立刻同步会主内存，不能把变量保存到处理器寄存器里面或者处理器缓存里面。导致频繁的读写内存影响性能。\n这种模型相当于禁用了缓存。如果再禁止编译器优化，就算是彻底解决上述问题了，但性能将受到严重影响。\nHappens-Before Memory Model： 先行发生模型。这个模型理解起来就比较困难。先介绍一个先行发生关系 （Happens-Before Relationship）　　如果有两个操作A和B存在A Happens-Before B，那么操作A对变量的修改对操作B来说是可见的。这个先行并不是代码执行时间上的先后关系，而是保证执行结果是顺序的。\nhappens-beforehappens-before 约束了编译器的优化行为，虽允许编译器优化，但是要求编译器优化后一定遵守 happens-before 规则。\nhappens-before规则：\n程序次序规则（program order rule）: 在一个线程内，先在前面的代码操作先行。准确的说控制流顺序而不是代码顺序。需要考虑分支，循环等结构。 \n管程锁定规则（monitor lock rule）：同一个资源锁，先unlock，之后才能lock。 \nVolatile变量规则（volatile variable rule）：一个变量被volatile修饰，多线程操作，先执行操作，再执行读操作。（同时写操作只能有一个） \n线程启动规则（Thread start rule）：Thread对象的start方法，先行发生于此线程的每一个方法。\n线程终止规则（Thread Termination rule)：该线程的所有方法，先行发生于该线程的终止检测方法。例如：可以通过Thread.join方法结束，Thread.isAlive()的返回值等手段检测到线程已经终止执行。 \n线程中断规则（Thread Interruption Rule）:  中断方法先行发生于，中断检测方法。中断方法interrupt()，中断检测interrupted()方法。\n对象终结规则（finalizer rule）:  一个对象的初始化完成（构造函数执行结束）先行发生于它的finalizer方法的开始。 \n传递性(Transitivity): 如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。\nas-if-serial在谈happens-befre常会提到as-if-serial\n即时编译器保证程序能够遵守as-if-serial属性。通俗地说，就是在单线程情况下，要给程序一个顺序执行的假象。也就是经过重排序的执行结果要与顺序执行的结果保持一致。\n而且，如果两个操作之间存在数据依赖时，编译器不能调整它们的顺序，否则将造成程序语义的改变。\npublic class AsIfSerialDemo &#123;    public static void main(String[] args) &#123;        int a = 10;//1        int b = 10;//2        int c = a+ b;//3    &#125;&#125;\n上面示例中：1和3之间存在数据依赖关系，同时2和3之间也存在数据依赖关系。因此在最终执行的指令序列中，3不能被重排序到1和2的前面（3排到1和2的前面，程序的结果将会被改变）。但1和2之间没有数据依赖关系，编译器和处理器可以重排序1和2之间的执行顺序。\nVS 时间先行对于happens-before先行发生，怎么理解，最常与“时间先后发生”搞混淆。\nhappens-before 关系是用来描述两个操作的内存可见性的。\n如果操作 X happens-before 操作 Y，那么 X 的结果对于 Y 可见。那么与“时间先后发生”顺序有什么区别？\n在《JSR-133: JavaTM Memory Model and Thread Specification》，happens-before是这样定义的：\n\nTwo actions can be ordered by a happens-before relationship.If one action happens-before another, then the first is visible to and ordered before the second.It should be stressed that a happens-before relationship between two actions does not imply thatthose actions must occur in that order in a Java platform implementation. The happens-beforerelation mostly stresses orderings between two actions that conflict with each other, and defineswhen data races take place. \n\n从定义中可以看出两点：\n\n1、the first is visible to and ordered before the second\n\n如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前\n\n2、does not imply that those actions must occur in that order in a Java platform implementation\n\n两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行\n\n由这两条可以得出，JMM是要求当有happens-before关系时，不仅要求了可见性，而且在时间上也得保证有序。然而在不改变语义的前提下，Java平台的实现可以自主决定。这也就表明了happens-before与时间先后没有更大的关联性。\nA happens-before B does not imply A happening before B.\nA happening before B does not imply A happens-before B.\n一个操作 “先行发生” 并不意味着这个操作必定是“时间上的先发生”\n// 以下操作在同一个线程中执行int i = 1;int j = 2;\n根据happens-before规则第一条，“int i &#x3D; 1” 的操作先行发生（Happens-before）于 “int j &#x3D; 2”，但在保证语义不改变的前提下，重排序了两条语句，那在时间上，“int j&#x3D;2”先执行了。\n在《The Happens-Before Relation》这篇文章中，作者还举了个示例：\nint A = 0;int B = 0;void foo()&#123;    A = B + 1;              // (1)    B = 1;                  // (2)&#125;\n虽然(1) happens-before (2),而且从上面的as-if-serial判断，(1) 得happen before (2) ,但作者观察并不是。\n\n从图上可看出，A被赋值为0，B被赋值为1，但 (1) 没被执行呢。\n关于这个问题，在stackoverflow happens-before  被讨论了。有人指出作者说得不对，而也有人给出解答：\nA and B are locations in memory. However the operation B+1 does not happen in memory, it happens in the CPU. Specifically, the author is describing these two operations.\nA &#x3D; B + 1 (1)\n\nA1 - The value in memory location B (0) is loaded into a CPU register\nA2 - The CPU register is incremented by 1\nA3 - The value in the CPU register (1) is written to memory location A\n\nB &#x3D; 1 (2)\n\nB1 - The value 1 is written to memory location B\n\nHappens-Before requires that the read of B (step A1) happens before the write of B (step B1). However, the rest of the operations have no interdependence and can be reordered without affecting the result. Any of these sequences will produce the same outcome\n\nA1, B1, A2, A3\nA1, A2, B1, A3\nA1, A2, A3, B1\n\n一个操作 “时间上的先发生” 也不能代表这个操作会是“先行发生”\nprivate int value = 0;// 线程 A 调用pubilc void setValue(int value)&#123;        this.value = value;&#125;// 线程 B 调用public int getValue()&#123;    return value;&#125;\n\n假设存在线程 A 和 B，线程 A 先（时间上的先后）调用了 setValue(1)，然后线程 B 调用了同一个对象的 getValue() ，那么线程 B 收到的返回值是什么? 0和1都有可能。因为两个操作之间没有happens-before关系。\nvolatilevolatile字段的happens-before关系指的是在两个不同线程中，【volatile的写操作】 happens-before之后【对同一字段的读操作】。这里有个关键字“之后”，指的是时间上的先后。也就是我这边写，你之后再读就一定能读得到我刚刚写的值。普通字段则没有这个保证。也就是上面的setValue()与getValue()示例问题\nint a=0;volatile int b=0;public void method1() &#123;  int r2 = a;  b = 1;&#125;public void method2() &#123;  int r1 = b;  a = 2;&#125;\n\n首先，b加了volatile之后，并不能保证b&#x3D;1一定先于r1&#x3D;b，而是保证r1&#x3D;b始终能够看到b的最新值。比如说b&#x3D;1;b&#x3D;2，之后在另一个CPU上执行r1&#x3D;b，那么r1会被赋值为2。如果先执行r1&#x3D;b，然后在另外一个CPU上执行b&#x3D;1和b&#x3D;2，那么r1将看到b&#x3D;1之前的值。\n在没有标记volatile的时候，同一线程中，r2&#x3D;a和b&#x3D;1存在happens before关系，但因为没有数据依赖可以重排列。一旦标记了volatile，即时编译器和CPU需要考虑到多线程happens-before关系，因此不能自由地重排序。\nvolatile与synchronized的区别，可以查看《volatile synchronized cas》\n总结本篇总结了Java并发问题的本质：可见性、原子性、有序性；以及应对这些问题，JMM中happens-before模型的规则。以及happens-before与happen before的区别。\n","tags":["并发"]},{"title":"JVM获取资源的途径和差别","url":"/blog/ways-and-differences-for-jvm-to-obtain-resources.html","content":"JVM加载配置资源文件有两种方式：\n1、ClassLoader#getResource\n2、Class#getResource\n两者之间的区别：ClassLoader并不关心当前类的包名路径，它永远以classpath为基点来定位资源。需要注意的是在用ClassLoader加载资源时，路径不要以”&#x2F;“开头，所有以”&#x2F;“开头的路径都返回null；\nClass.getResource如果资源名是绝对路径(以”&#x2F;“开头)，那么会以classpath为基准路径去加载资源，如果不以”&#x2F;“开头，那么以这个类的Class文件所在的路径为基准路径去加载资源\n从源代码层次分析一下，这个结论对不对？\nClassLoader#getResourcepublic InputStream getResourceAsStream(String name) &#123;        URL url = getResource(name);        try &#123;            return url != null ? url.openStream() : null;        &#125; catch (IOException e) &#123;            return null;        &#125;    &#125;\n\npublic URL getResource(String name) &#123;       URL url;       if (parent != null) &#123;           url = parent.getResource(name);       &#125; else &#123;           url = getBootstrapResource(name);       &#125;       if (url == null) &#123;           url = findResource(name);       &#125;       return url;   &#125;\n\n相对路径//classloader从根节点开始查找final URL resource = Thread.currentThread().getContextClassLoader().getResource(&quot;root.properties&quot;);System.err.println(resource);Assertions.assertNotNull(resource);//成功获取\n\n这样子是正常获取到资源\n绝对路径//以目录作对比，这样写，应该也没问题，但为什么返回是null呢？//并且很多资料都直接说 classloader加载资源时，不要以 / 开头，以 / 开头都会返回nullfinal URL resource1 = Thread.currentThread().getContextClassLoader().getResource(&quot;/root.properties&quot;);System.err.println(resource1);Assertions.assertNull(resource1);\n\n\n很多资料的结论classloader加载资源时，不要以 &#x2F; 开头，以 &#x2F; 开头都会返回null，是正确的。\n从debug中可以看出来为什么以&#x2F;开头，获取不到对应的资源。\n主要还是对根节点的理解不一样：\nclasscloader以根节点去查找，是以当前的classpath为起点；\n而以 &#x2F; 开头,就变成类似root下了，自然查找不到\n相对路径final URL resource2 = Thread.currentThread().getContextClassLoader().getResource(&quot;./root.properties&quot;);System.err.println(resource2);\n\n这样是可以成功查找。\n\nClass#getResoucepublic InputStream getResourceAsStream(String name) &#123;        name = resolveName(name);        ClassLoader cl = getClassLoader0();        if (cl==null) &#123;            // A system class.            return ClassLoader.getSystemResourceAsStream(name);        &#125;        return cl.getResourceAsStream(name);    &#125;\n\n看着Class#getResource，多加了一步resolveName，其实还是使用了Classloader#getResource方法\n其中resolveName()\nname不以’&#x2F;‘开头时，默认是从此类所在的包下取资源；\nname以’&#x2F;‘开头时，则会substring(1)，踢掉&#x2F;，绝对路径变相对数据再从ClassPath根下获取资源\nprivate String resolveName(String name) &#123;        if (name == null) &#123;            return name;        &#125;        if (!name.startsWith(&quot;/&quot;)) &#123;            Class&lt;?&gt; c = this;            while (c.isArray()) &#123;                c = c.getComponentType();            &#125;            String baseName = c.getName();            int index = baseName.lastIndexOf(&#x27;.&#x27;);            if (index != -1) &#123;                name = baseName.substring(0, index).replace(&#x27;.&#x27;, &#x27;/&#x27;)                    +&quot;/&quot;+name;            &#125;        &#125; else &#123;            name = name.substring(1);        &#125;        return name;    &#125;\n\n\n在与com.zhuxingsheng.lang.GetResourceTest同目录下面创建package.properties\n直接写文件名final URL resource = GetResourceTest.class.getResource(&quot;package.properties&quot;);System.err.println(resource);//获取资源正常\n\n根据debug信息，可以看出会从当前类目录去查找\n\n绝对路径final URL resource1 = getClass().getResource(&quot;/com/zhuxingsheng/lang/package.properties&quot;);System.err.println(resource1);//获取资源正常\n\n从resolveName方法，可知，写了绝对路径，会被substring(1),也就是手动拼接完事包路径，走了resolveName的第一个不以 &#x2F; 开头的分支路径。\n也就是classloader#getResource不要写绝对路径。\n完整相对路径final URL resource1 = getClass().getResource(&quot;com/zhuxingsheng/lang/package.properties&quot;);System.err.println(resource1);//获取失败\n\n从debug中可以看出，就是把完整的路径拼接了两次，路径变成了com&#x2F;zhuxingsheng&#x2F;lang&#x2F;com&#x2F;zhuxingsheng&#x2F;lang&#x2F;package.properties\n\n结论经过源代码的debug，上文的结论是正确的。\nClassLoader并不关心当前类的包名路径，它永远以classpath为基点来定位资源。需要注意的是在用ClassLoader加载资源时，路径不要以”&#x2F;“开头，所有以”&#x2F;“开头的路径都返回null；\nClass.getResource如果资源名是绝对路径(以”&#x2F;“开头)，那么会以classpath为基准路径去加载资源，如果不以”&#x2F;“开头，那么以这个类的Class文件所在的路径为基准路径去加载资源\n但在springboot中，自定义了classloader，打破了上述规则。下篇再看springboot的加载机制。\n","tags":["java","ClassLoader"]},{"title":"JIT优化之道","url":"/blog/jit-optimization.html","content":"碎碎念《JIT优化之道》是去年在公司的一次分享，对于公司组织分享我是赞同又不赞同，怎么讲呢？\n技术分享当然是好的，这是一个双赢，分享者教学相长，而收听者也能更快的了解进步。\n但以前在原先的公司也做过些类事情，但没有想象的好，大家对分享主题的探索也只限于在分享时间段内，过后很少有人，几乎没人去做进一步的探索。填鸭式的学习效果甚微。后来只涉及一些项目中使用到的知识点，让项目中人去发现项目中的一些亮点，盲区\n聪明人从旁人的错误中吸取教训,愚笨人则从自身的错误中吸取教训，有多少聪明人呢？不经历风雨又怎么见彩虹？\nJIT主要关注三个点\nJIT是什么\nJIT的原理\nJIT的意义\n\nJIT是什么JIT是just in time,即时编译器；使用该技术，能够加速java程序的执行速度\n\n编译器\nJava编译器总的来说分为\n\n前端编译器\nJIT（just in time compiler）编译器\nAOT（Ahead Of Time Compiler）编译器\n\n前端编译器： 将Java文件编译为class文件的编译器，目前主要有以下两个，                        Sun提供的Javac 和Eclipse JDT中的增量式编译器（ECJ）\nJIT编译器： 虚拟机后端运行期编译器，把字节码转换为机器码的过程。                         HotSpot Vm中提供的C1, C2编译器\nAOT编译器：直接把Java文件转换为本地机器码的过程\n解释器与编译器\n当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即执行。\n在程序运行后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码之后，可以获取更高的执行效率\n分层编译的策略TieredCompilation为了在程序启动响应速度与运行效率之间达到最佳平衡，HotSpot虚拟机还会逐渐启动分层编译的策略。分层编译根据编译器编译、优化的规模与耗时，划分出不同的编译层次，包括：\n\n第0层，程序解释执行，解释器不开启性能监控功能，可触发第1层编译。\n第1层，也称为C1编译，将字节码编译成本地代码，进行简单、可靠的优化，如有必要将加入性能监控的逻辑。\n第2层，也称为C2编译，也是将字节码编译为本地代码，但是会启动一下编译耗时较长的优化，甚至会根据性能监控信息进行一些不可靠的激进优化。\n\n实施分层编译后，Client Compiler和Server Compiler 将会同时工作，许多代码都可能会多次编译，C1获取更高的编译速度，用C2获取更好的编译质量，在解释时候的时候也无须再承担收集性能监控信息的任务。\nOracle JDK从JDK 6u25以后的版本支持了多层编译（-XX:+TieredCompilation）可以用jinfo -flag或-XX:+PrintFlagsFinal来确认是否打开JDK8是默认打开的\n\n图表描绘了纯解析、客户端、服务器端和混合编译的性能区别。X轴代码执行时间，Y轴代表性能\n和单纯的代码解析相比，使用客户端编译器可以提高大约5-10倍的执行性能，实际上提高了应用的性能。当然，收益的变化还是依赖于编译器性能如何，哪些优化生效了或者被实现了，还有就是对于目标执行平台来说应用程序设计的有多好。后者是Java开发人员从来不需要担心的。\n和客户端编译器相比，服务器端编译器通常能够提升可度量的30％－50％的代码效率。在大部分情况下，这性能的提高将平衡掉多余的资源开销。\n分层编译结合了两种编译器的优点。客户端编译产生了快速的启动时间和及时的优化，服务器端编译在执行周期的后期，可以提供更多的高级优化\nJIT开关\n3种执行方式，分别是解释执行、混合模式和编译执行，默认情况下处于混合模式中\n通过-Xint  -Xcomp改变执行方式\n\n通过代码也可以\njava.lang.Compiler.disable();java.lang.Compiler.enable();\n\n\npublic class Pi &#123;\tpublic static double calcPi() &#123;\t\tdouble re = 0;\t\tfor (int i = 1; i &lt; 100000; i++) &#123;\t\t\tre += ((i &amp; 1) == 0 ? -1 : 1) * 1.0 / (2 * i - 1);\t\t&#125;\t\treturn re * 4;\t&#125;\tpublic static void main(String[] args) &#123;\t\tlong b = System.currentTimeMillis();\t\tfor (int i = 0; i &lt; 100000; i++)\t\t\tcalcPi();\t\tlong e = System.currentTimeMillis();\t\tSystem.err.println(&quot;spend:&quot; + (e - b) + &quot;ms&quot;);\t&#125;&#125;mixed:spend:418msint:spend:2547mscomp:spend:416ms\n\njstat -compiler 显示VM实时编译的数量等信息。显示列名具体描述Compiled编译任务执行数量Failed编译任务执行失败数量Invalid编译任务执行失效数量Time编译任务消耗时间FailedType最后一个编译失败任务的类型FailedMethod最后一个编译失败任务所在的类及方法\njstat -compiler 55417Compiled Failed Invalid   Time   FailedType FailedMethod    6296      6       0    50.37          1  org/eclipse/jdt/internal/core/CompilationUnitStructureRequestor createTypeInfo\n\nJIT原理\n寻找热点代码在运行过程中，会被即时编译器编译的“热点代码”有两类，即：\n\n被多次调用的方法\n被多次执行的循环体（OSR On StackReplacement）\n\n判断是否是热点代码的行为成为热点探测：hot spotdetection,主要的热点探测方式主要有两种：\n\n基于采样的热点探测，JVM会周期性检查各个线程的栈顶，如果某个方法经常出现在栈顶，那就认定为热点方法。简单高效，精度不够。\n\n基于计数器的热点探测，统计方法执行次数。（HOTSPOT使用这种方式）\n\n\n计数器HOTSPOT有两个计数器：\n1、方法调用计数器\n2、回边计数器\n方法调用计数器\n方法调用计数器client默认1500次，server默认10000次，-XX:CompileThreshold\n方法调用计数器并不是统计方法调用绝对次数，而是一个相对执行频率，超过一定时间，如果方法调用次数不足以让它提交给编译器，则计数器就会被减少一半，这种现象称为热度衰减(Counter Decay)，进行热度衰减的动作是在垃圾回收时顺便进行的，而这段时间就被称为半衰周期（Counter Half Life Time）\n可用-XX:-UseCounterDecay来关闭热度衰减，用-XX:CounterHalfLifeTime来设置半衰时间。\n\n要不要关闭这个衰减？\nHotSpot VM的触发JIT的计数器的半衰（counter decaying）是一种很好的机制，保证只有真正热的代码才会被编译，而那种偶尔才被调用一次的方法则不会因为运行时间长而积累起虚假的热度。\n不建议关闭这个选项，除非它在具体案例中造成了问题。\nCounter decaying是伴随GC运行而执行的。过多的手动调用System.gc()倒是有可能会干扰了这个衰减，导致方法达不到触发JIT编译的热度。\n回边计数器\n回边计数器阈值计算公式\n（1）Client模式下方法调用计数器阈值（CompileThreshold）* OSR比率（OnStackReplacePercentage）&#x2F;100.其中OnStackReplacePercentage默认值为933，如果都取默认值，那Client模式虚拟机回边数的阈值为13995。\n（2）Server模式下方法调用计数器阈值（CompileThreshold）*（OSR比率（OnStackReplacePercentage）减去解释器监控比率（InterpreterProfilePercentage）的差值）&#x2F;100。\n其中OnStackReplacePercentage默认值为140，InterpreterProfilePercentage默认值为33，如果都取默认值，那Server模式虚拟机回边计数器的阈值为10700\n-XX:BackEdgeThreshold-XX:OnStackReplacePercentage\n\n与方法计数器不同，回边计数器没有计数热度衰减的过程，因此这个计数器统计的就是该方法循环执行的绝对次数\n学习JIT意义大方法 与 小方法？ java中一般建议一个方法不要写的过长，不方便维护和阅读是其中的一个原因，但是其真正性能的原因大家知道吗？\n我们知道，JVM一开始是以解释方式执行字节码的。当这段代码被执行的次数足够多以后，它会被动态优化并编译成机器码执行，执行速度会大大加快，这就是所谓的JIT编译。hotsopt源码中有一句\nif (DontCompileHugeMethods &amp;&amp; m-&gt;code_size() &gt; HugeMethodLimit) return false;\n当DontCompileHugeMethods&#x3D;true且代码长度大于HugeMethodLimit时，方法不会被编译\nDontCompileHugeMethods与HugeMethodLimit的值在globals.hpp中定义：\nproduct(bool, DontCompileHugeMethods, true,        &quot;don&#x27;t compile methods &gt; HugeMethodLimit&quot;)develop(intx, HugeMethodLimit,  8000,        &quot;don&#x27;t compile methods larger than this if +DontCompileHugeMethods&quot;)\n\n上面两个参数说明了Hotspot对字节码超过8000字节的大方法有JIT编译限制，这就是大方法不会被JIT编译的原因。由于使用的是product mode的JRE，\n我们只能尝试关闭DontCompileHugeMethods，即增加VM参数”-XX:-DontCompileHugeMethods”来强迫JVM编译大方法。\n但是不建议这么做，因为一旦CodeCache满了，HotSpot会停止所有后续的编译任务，虽然已编译的代码不受影响，但是后面的所有方法都会强制停留在纯解释模式。\n查看jit工作的参数-XX:-CITime 打印发费在JIT编译上的时间$ java -server -XX:+CITime Benchmark[...]Accumulated compiler times (for compiled methods only)------------------------------------------------  Total compilation time   :  0.178 s    Standard compilation   :  0.129 s, Average : 0.004    On stack replacement   :  0.049 s, Average : 0.024[...]\n\n-XX:+PrintCompilation 我们可以简单的输出一些关于从字节码转化成本地代码的编译过程$ java -server -XX:+PrintCompilation Benchmark  1       java.lang.String::hashCode (64 bytes)  2       java.lang.AbstractStringBuilder::stringSizeOfInt (21 bytes)  3       java.lang.Integer::getChars (131 bytes)  4       java.lang.Object::&lt;init&gt; (1 bytes)---   n   java.lang.System::arraycopy (static)  5       java.util.HashMap::indexFor (6 bytes)  6       java.lang.Math::min (11 bytes)  7       java.lang.String::getChars (66 bytes)  8       java.lang.AbstractStringBuilder::append (60 bytes)  9       java.lang.String::&lt;init&gt; (72 bytes) 10       java.util.Arrays::copyOfRange (63 bytes) 11       java.lang.StringBuilder::append (8 bytes) 12       java.lang.AbstractStringBuilder::&lt;init&gt; (12 bytes) 13       java.lang.StringBuilder::toString (17 bytes) 14       java.lang.StringBuilder::&lt;init&gt; (18 bytes) 15       java.lang.StringBuilder::append (8 bytes)[...] 29       java.util.regex.Matcher::reset (83 bytes) \n每当一个方法被编译，就输出一行-XX:+PrintCompilation。每行都包含顺序号（唯一的编译任务ID）和已编译方法的名称和大小。\n因此，顺序号1，代表编译String类中的hashCode方法到原生代码的信息。根据方法的类型和编译任务打印额外的信息。例如，本地的包装方法前方会有”n”参数，像上面的System::arraycopy一样。注意这样的方法不会包含顺序号和方法占用的大小，因为它不需要编译为本地代码。\n同样可以看到被重复编译的方法，例如StringBuilder::append顺序号为11和15。输出在顺序号29时停止 ，这表明在这个Java应用运行时总共需要编译29个方法。\n","tags":["jit","jvm"]},{"title":"Java异常处理","url":"/blog/java-exception-handling.html","content":"Java异常，本身知识体系很简单，但要设计好异常，却不是易事\nJava异常如何使用，尤其checked exception,好些语言（c#,python）都没有此类型异常，只有unchecked exception；对于java为什么有checked exception,是不是设计过渡，在java初期被讨论了很多回，以及如何使用异常也被讨论了很多次，最近我在落地DDD时，又思考到此问题，不得不再翻回这个老问题，翻阅《Effective java》、《J2EE设计开发编程指南》这些经典\n按普世标准，处理异常最佳实践有：\n\n【强制】异常不要用来做流程控制，条件控制。说明：异常设计的初衷是解决程序运行中的各种意外情况，且异常的处理效率比条件判断方式要低很多\n异常应该只用于异常的情况下：它们永远不应该用于正常的控制流，设计良好的API不应该强迫它的客户端为了正常的控制流而使用异常\n对可恢复情况使用受检异常，对编程错误使用运行时异常\n抛出与抽象相对应的异常\n每个方法抛出的异常都要有文档\n优先使用标准异常\n\n\n再来看看前人的论述：\n在使用UseCase来描述一个场景的时候，有一个主事件流和n个异常流。异常流可能发生在主事件流的过程，而try语句里面实现的是主事件流，而catch里面实现的是异常流，在这里Exception不代表程序出现了异常或者错误，Exception只是面向对象化的业务逻辑控制方法。如果没有明白这一点，那么我认为并没有真正明白应该怎么使用Java来正确的编程。\n而我自己写的程序，会自定义大量的Exception类，所有这些Exception类都不意味着程序出现了异常或者错误，只是代表非主事件流的发生的，用来进行那些分支流程的流程控制的。例如你往权限系统中增加一个用户，应该定义1个异常类，UserExistedException，抛出这个异常不代表你插入动作失败，只说明你碰到一个分支流程，留待后面的catch中来处理这个分支流程。传统的程序员会写一个if else来处理，而一个合格的OOP程序员应该有意识的使用try catch 方式来区分主事件流和n个分支流程的处理，通过try catch，而不是if else来从代码上把不同的事件流隔离开来进行分别的代码撰写\n很多人喜欢定义方法的返回类型为boolean型的，当方法正确执行，没有出错的时候返回true，而方法出现出现了问题，返回false。这在Java编程当中是大错而特错的！\n方法的返回值只意味着当你的方法调用要返回业务逻辑的处理结果的。如果业务逻辑不带处理结果，那么就是void的，不要使用返回值boolean来代表方法是否正确执行。\nboolean login(String username, String password);\n\n很多人喜欢用boolean返回，如果是true，就是login了，如果false就是没有登陆上。其实是错误的。还有的人定义返回值为int型的，例如如果正确返回就是0，如果用户找不到就是-1，如果密码不对，就是-2\nint login(String username, String password);\n\n然后在主程序里面写一个if else来判断不同的流程\nint logon = UserManager.login(xx,xx);;   if (logon ==0); &#123;  ...  &#125; else if (logon == 1); &#123;  ...  &#125; else if (logon ==2); &#123;  ..&#125;  \n\n这是面向过程的编程逻辑，不是面向对象的编程逻辑。\n应该这样来写：\nUser login(String username, String password); throws UserNotFoundException, PasswordNotMatchException; \n\n主程序这样写：\ntry &#123;    UserManager.login(xx,xx);;  ....   用户登陆以后的主事件流代码    &#125; catch (UserNotFoundException e); &#123;    ...    用户名称没有的事件处理，例如产生一个提示用户注册的页面    &#125; catch (PasswordNotMatchException e); &#123;    ....    密码不对的事件处理，例如forward到重新登陆的页面  &#125;  \n\n\n看到这个示例，似乎明显违背了最佳实践的第一条：不要用来流程控制\n如果这不是流程控制，那这种写法与流程控制有什么区别呢？再进一步，什么时候使用异常呢？\n什么时候使用异常在异常最佳实践中：异常只用于异常情况下！\n需要捕捉的异常也有两种，一种是自己的程序抛出的，一种是系统抛出的\n什么叫做程序抛出的异常，什么叫做系统抛出的异常，你能明确界定吗？FileNotFoundException你说算是系统异常呢？还是程序异常？站在某些程序员的角度，他会觉得是系统异常，不过像我喜欢看JDK源代码的人来说，我对Sun的程序什么情况下抛出FileNotFoundException很清楚，这些代码对我来说，和我自己写的代码能有什么不同吗？对我来说，FileNotFoundException就是程序异常。既然JDK可以抛出异常，凭什么我就不能抛出异常？\n站在底层程序员的角度来看，根本没有什么系统异常可言，否则的话，还不如不要定义任何异常得了，干脆就是函数调用返回值，你说为什么Sun不定义0，1，2这样的返回值，而是抛出异常呢？Java程序无非就是一堆class，JDK的class可以抛异常，我写的class为什么不能抛出？\n异常不异常的界定取决于你所关注的软件层面，例如你是应用软件开发人员，你关心的是业务流程，那么你就应该捕获业务层异常，你就应该定义业务层异常，向上抛出业务层异常。如果是底层程序员，你就应该定义和抛出底层异常。要不要抛出异常和抛出什么异常取决你站在什么软件层面了，离开这个前提，空谈异常不异常是没有意义的\n\n因为0,1,2这样的值表达的含义不够丰富，但是作为返回值，又不合理。————函数有它的本身的返回值。\n\n因此，返回一个异常，其实就是一个封装完好的，返回的对象。这个对象Type不是在函数名的前面说明，而是在一个更加特别的地方，函数的后面说明。这就是异常的本质————非正常的返回值。这个返回值，为什么不能用传统的方法处理呢？因为Object x&#x3D;method();表明它只能接受某一个特定的对象，如果出现Exception的对象，就会报错。因此需要catch来接手处理这样的返回值。\nchecked与unchecked选择对于何时抛出异常，上面的论述大致已经清楚，使用Exception的关键是，你站在什么样的角度来看这个问题，这也得看大家对异常写法的习惯，异常并不只是单单的异常，在OO中，异常也是方法返回值的一部分\nJava正统观点认为：已检查异常应该是标准用法，运行时异常表明编程错误，这也正如上面的例子，方法申明异常表明了有这些异常情况，那业务调用方需要考虑这些情况，但是检查异常引起了几个问题\n\n太多的代码：开发人员将会因为不得不捕捉他们无法合理地处理的已检查异常（属于“某个东西出了可怕错误”种类）并编写忽略（忍受）它们的代码而感到无力。\n难以读懂的代码：捕捉不能被正确地处理的异常并重新抛出它们没有执行一点有用的功能，反而会使查找实际做某件事的代码变得更困难\n异常的无休止封装：一个已检查异常要么必须被捕捉，要么必须在一个遇到它的那个方法的抛出子句中被声明。这时要么重新抛出数量不断增长的异常，或者说捕捉低级异常，要么重新抛出被封装在一个较高级的新异常中的它们\n易毁坏的方法签名\n已检查异常对接口不一定管用\n\n异常受检的本质并没有为程序员提供任何好处，它反而需要付出努力，还使程序更为复杂\n被一个方法单独抛出的受检异常，会给程序员带 来非常高的额外负担。如果这个方法还有其他的受检异常，它被调用的时候一定已经出现在一个try块中，所以这个异常只需要别外一个catch块\n非检查型异常的最大风险之一就是它并没有按照检查型异常采用的方式那样自我文档化。除非 API 的创建者明确地文档化将要抛出的异常，否则调用者没有办法知道在他们的代码中将要捕获的异常是什么\nRod Johnson采取了一种比eckel 稍正统的观点，因为Johnson认为已检查异常有一定用武之地，在一个异常相当于来自方法的一个可替代返回值得地方，这个异常无疑应该被检查，并且该语言能帮助实施这一点就再好不过了。但是觉得传统的java方法过分强调了已检查异常。\n\n使用Checked Exception还是UnChecked Exception的原则，我的看法是根据需求而定。\n如果你希望强制你的类调用者来处理异常，那么就用Checked Exception；如果你不希望强制你的类调用者来处理异常，就用UnChecked。\n那么究竟强制还是不强制，权衡的依据在于从业务系统的逻辑规则来考虑，如果业务规则定义了调用者应该处理，那么就必须Checked，如果业务规则没有定义，就应该用UnChecked。\n还是拿那个用户登陆的例子来说，可能产生的异常有：\nIOException (例如读取配置文件找不到)SQLException (例如连接数据库错误)ClassNotFoundException(找不到数据库驱动类)\nNoSuchUserExceptionPasswordNotMatchException\n以上3个异常是和业务逻辑无关的系统容错异常，所以应该转换为RuntimeException，不强制类调用者来处理；而下面两个异常是和业务逻辑相关的流程，从业务实现的角度来说，类调用者必须处理，所以要Checked，强迫调用者去处理。\n在这里将用户验证和密码验证转化为方法返回值是一个非常糟糕的设计，不但不能够有效的标示业务逻辑的各种流程，而且失去了强制类调用者去处理的安全保障。\n至于类调用者catch到NoSuchUserException和PasswordNotMatchException怎么处理，也要根据他自己具体的业务逻辑了。或者他有能力也应该处理，就自己处理掉了；或者他不关心这个异常，也不希望上面的类调用者关心，就转化为RuntimeException；或者他希望上面的类调用者处理，而不是自己处理，就转化为本层的异常继续往上抛出来。\n\nChecked Exception与UnChecked Exception：\n\n抛出Checked Exception，给直接客户施加一个约束，必须处理，但也是一种自由，客户可分门别类的处理不同异常；UnChecked Exception则给直接客户以自由，但也是一种欺瞒，因为客户不知道将要发生什么，所有的处理将是系统默认的处理（如打印堆栈到控制台，对开发者、用户都返回一样的内容，不管别人懂与不懂）。二者的选择其实是约束与自由的权衡。\n“对可恢复的情况使用已检查异常，对程序错误使用运行时异常。”而不是一咕脑的全抛出Checker Exception，这服务提供者是友好的\n所以，若不需要客户依据不同异常采取不同后续行为，那么抛出UnChecked Exception是友好的；但若客户需要根据不同异常类采取不同行动，抛出Checked Exception是友好的。\n\n对于checked exception转unchecked exception，大家都有共识，只是偏执于两方哪一方多些，在前期还是后期\nRod Johnson在spring的data access exception中就是个好示例，一是把异常细分化，更明确具体异常；二是把检查异常SQLException都转化为了unchecked exception\nErrorCode异常对代码和开发、维护及管理一个应用的人都有用是至关重要的\n对于开发、维护人异常消息串具有有限的价值：当这些消息串出现在日志文件中时，他们对解释问题可能是有帮助的，但它们将无法使调用代码正确地做出反应，并且不能依靠它们本身来把它们显示给用户。当不同的问题可能需要不同的动作时，相应的异常应该被建模为一个公用超类的独立子类。有时，该超类应该是抽象的。现在，调用代码将可自由地在相关的细节级别上捕捉异常\n已检查异常要比错误返回码（许多老式的语言中使用）好很多。迟早（或许不久），人们将不能检查一个错误返回值；\n使用编译程序来实施正确的错误处理时一件好事。同参数和返回值一样，这样的已检查异常对一个对象的api来说是整体的不可分部分\n用户应该通过在异常中包括错误代码来处理\nString getErrorCode();String getMessage();\n在spring早期代码中，就有ErrorCoded接口定义这两个方法，errorCode能够把为终端用户而计划的错误与为开发人员而计划的错误消息区分开。getMessage()用户记录日志，并且是面向开发人员\n\n","tags":["java"]},{"title":"Java异常实践","url":"/blog/java-exception-practice.html","content":"对于Java理论在《Java异常处理》中已经阐述了，看看理论如何指导落地\n现流行的文章SpringBoot如何优雅处理异常，落地的确方便，使用AOP统一处理异常，但只是处理了api层次的异常\n应用中抛出异常有两种方式：\n\n带有ErrorCode的异常\n明确类型的异常\n\n对于controller层，也是面向用户的，需要error code,所以采用第一种方式\n前端通过映射关系给出更好用户体验的提示语，也有很多项目都是controller层直接拼接出提示语，前端直接展示\n所以一般会定义一个接口ErrorCode\ninterface ErrorCode &#123;    String getErrorCode();    String getMessage();&#125;\n\n具体的实现可以通过enum\n@Getterenum ApiErrorCode implements ErrorCode &#123;        USER_NOT_FOUND(&quot;10000&quot;,&quot;用户不存在&quot;);        private String errorCode;    private String message;&#125;\n\n再定义一个统一异常\npublic class ApiException extends RuntimeException &#123;    public ApiException(ErrorCode errorCode) &#123;            &#125;&#125;\n在aop拦截时，直接拦截此异常就行\napi层次的异常可以这么处理，那业务层呢？很多时候都是缺失设计的，这也在上篇说过exception从语法层面看很简单，但要设计一个好的异常是很难的\n大多项目直接把api exception拿来当做business exception使用\n对于一个良好的业务接口，应该采用第二种方法：细致的异常\nUser login(String username, String password) throws UserNotFoundException, PasswordNotMatchException; \n\n已检查异常要比错误返回码（许多老式的语言中使用）好很多。迟早（或许不久），人们将不能检查一个错误返回值；使用编译程序来实施正确的错误处理是一件好事。同参数与返回值一样，这样的已检查异常对一个对象的API来说是整体的一个不可分割部分\n\n这样的接口更丰富，也更面向对象，可也给客户端带来的麻烦,缺点在上篇已经阐述\n\n对可恢复的情况使用已检查异常，对程序错误使用运行时异常\n\n在大多项目中，其实业务层抛出异常后，通常会“可恢复”吗？大多数情况也需要用户手工干预，系统无法自行恢复，比如UserNotFoundException, PasswordNotMatchException系统能怎么处理，无非还是得给用户重新输入用户名和密码\n在controller层去调用service方法，也只能如此处理\nResponse login(String username,String password) &#123;    try &#123;        userService.login(username,password);    &#125;catch(UserNotFoundException ue) &#123;        throw new ApiException(ApiErrorCode.USER_NOT_FOUND);    &#125;catch(PasswordNotMatchException pe)&#123;        throw new ApiException(ApiErrorCode.Password_Not_Match);    &#125;&#125;\n这样处理也就理论化了，带来了多少优点呢？这些缺点不正是checked exception被嘟囔的地方吗\n那我们把业务异常也定义为runtime exception,这样减少客户端压力，想处理就处理，不想处理，我们也可在拦截器中兜底\n不过抛出运行期异常，减少客户端的压力，但也带来了接口不明确的困惑\n\n非检查型异常的最大风险之一就是它并没有按照检查型异常采用的方式那样自我文档化。除非 API 的创建者明确地文档化将要抛出的异常，否则调用者没有办法知道在他们的代码中将要捕获的异常是什么\n\n总结起来，还是那句话，异常语法很简单，但设计好异常不易；现在技术快速发展，通过技术手段可以达到更大的便捷性，但不能只有技术手段而忽略设计，没有设计的代码称不上好代码，可以取舍，但不能全舍\n","tags":["java"]},{"title":"Kafka基础术语","url":"/blog/basic-terms-of-kafka.html","content":"一个简简单单的基础数据结构，却发展成了形形色色的消息队列中间件。世界就是如此奇妙。\n\n如上图，一个简单的队列数据结构，由生产者往里插入内容，由消费者从里面获取内容进行消费，就构建出一个简单的消息队列模型。\n消息模型有两种：\n1、点对点模型：也叫消息队列模型。多个消费者共同消费同一个队列，效率高\n2、发布&#x2F;订阅模型：发送方也称之为发布者(Publisher)，接受方称为订阅者(Subscriber)。与点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。\n\n一个简单的Kafka架构图：\n\n\n\n生产者：Producer向主题发布新消息的应用程序。\nBroker负责接收和处理客户端发送过来的请求，以及对消息进行持久化。一个Kafka集群由多个Broker组成。\n消费者：Consumer从主题订阅新消息的应用程序。\n消息队列一般有两种实现方式\n(1)Push(推模式) \n(2)Pull(拉模式)\n那么 Kafka Consumer 究竟采用哪种方式进行消费的呢?其实 Kafka Consumer 采用的是主动拉取 Broker数据进行消费的即 Pull 模式。这两种方式各有优劣，我们来分析一下：\n1)、为什么不采用Push模式?如果是选择 Push 模式最大缺点就是 Broker 不清楚 Consumer 的消费速度，且推送速率是 Broker 进行控制的， 这样很容易造成消息堆积，如果 Consumer 中执行的任务操作是比较耗时的，那么 Consumer 就会处理的很慢， 严重情况可能会导致系统 Crash。\n2)、为什么采用Pull模式?如果选择 Pull 模式，这时 Consumer 可以根据自己的情况和状态来拉取数据, 也可以进行延迟处理。但是 Pull 模式也有不足，Kafka 又是如何解决这一问题?如果 Kafka Broker 没有消息，这时每次 Consumer 拉取的都是空数据, 可能会一直循环返回空数据。 针对这个问题，Consumer 在每次调用 Poll() 消费数据的时候，顺带一个 timeout 参数，当返回空数据的时候，会在 Long Polling 中进行阻塞，等待 timeout 再去消费，直到数据到达。\n主题：Topic主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。\n分区：Partition一个有序不变的消息序列。每个主题下可以有多个分区。\n分区的主要原因，为了实现系统的高伸缩性(Scalability)。不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。\n分区策略：决定生产者将消息发送到哪个分区的算法。\n1、轮询策略，Round-robin策略，即顺序分配。\n2、随机策略，Randomness策略。所谓随机就是随意地将消息放置在做任意一个分区上。\n3、Key-ordering策略。\n消费者组：Consumer Group指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。\n为什么要引入消费者组？主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量(TPS)。\nKafka 仅仅使用 Consumer Group 这一种机制，却同时实现了传统消息引擎系统的两大模型：如果所有实例都属于同一个 Group，那么它实现的就是消息队列模型；如果所有实例分别属于不同的 Group，那么它实现的就是发布 &#x2F; 订阅模型。\nKafka Consumer Group 特点如下:\n1、 每个 Consumer Group 有一个或者多个 Consumer\n2、每个 Consumer Group 拥有一个公共且唯一的 Group ID\nspring.kafka.consumer.group-id\n\n3、Consumer Group 在消费 Topic 的时候，Topic 的每个 Partition 只能分配给组内的某个 Consumer，只要被任何 Consumer 消费一次, 那么这条数据就可以认为被当前 Consumer Group 消费成功\n最理想的情况是Consumer实例的数量应该等于该Group订阅主题的分区总数。例如：Consumer Group 订阅了 3个主题，分别是A、B、C，它们的分区数依次是1、2、3，那么通常情况下，为该Group 设置6个Consumer实例是比较理想的情形。\n如果设置小于或大于6的实例可以吗？当然可以，如果你有3个实例，那么平均下来每个实例大约消费2个分区（6&#x2F;3&#x3D;2）;如果你设置了9个实例，那么很遗憾，有3个实例（9-6&#x3D;3）将不会被分配任何分区，它们永远处于空闲状态\n副本机制(Replication)也称之为备份机制，通常是指分布式系统在多台网络互联的机器上保存有相同的数据拷贝。副本机制的好处：\n1、提供数据冗余。即使系统部分组件失效，系统依然能够继续运转，因而增加了整体可用性以及数据持久性。\n2、提供高伸缩性。支持横向扩展，能够通过增加机器的方式来提升读性能，进而提高读操作吞吐量。\n3、改善数据局部性。允许将数据放入与用户地埋位置相近的地方，从而降低系统延时。\nKafka副本，本质就是一个只能追加写消息的提交日志。根据Kafka副本机制的定义，同一个分区下的所有副本保存有相同的消息序列，这些副本分散保存在不同的Broker上，从而能够对抗部分Broker宕机带来的数据不可用。\n1、在Kakfa中，副本分成两类：领导者副本(Leader Replica)和追随者副本(Follower Replica)。每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。\n2、在Kafka中，追随者副本是不对外提供服务的。任何一个追随者副本都不能响应消费者和生产者的读写请求。所有的请求都必须由领导者副本来处理，或者说，所有读写请求都必须发往领导者副本所在的Broker,由该Broker负责处理。追随者副本不处理我客户端请求，它唯一的任务就是从领导者副本异步拉取消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。\n3、当领导者副本挂掉了，或者说领导者副本所在的Borker宕机时，Kafka依托于ZK提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。老Leader副本重启回来后，只能作为追随者副本加入到集群中。\n为什么Kafka的追随者副本没有任何作用，它既不能像MySQL那样帮助领导者副本“抗读”，也不能实现将某些副本放到离客户近的地方来改善数据局部性。\n1、方便实现“Read-your-writes”。当你使用生产者API向Kafka成功写入消息后，马上使用消费者API去读取刚才生产的消息。\n2、方便实现单调读“Monotonic Reads”。就是对于一个消费者用户而言，在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。\n重平衡：Rebalance消费者组内某个消费者实例持掉后，其他消费者实例自动重新分配订阅主题分区的过程。\nKafka 入门介绍\n","tags":["kafka"]},{"title":"GC及JVM参数","url":"/blog/gc-and-jvm-parameters.html","content":"前言这段时间懈怠了，罪过！\n最近看到有同事也开始用上了微信公众号写博客了，挺好的~给他们点赞，这博客我也不推广，默默的静静的，主要是担心自己坚持不了。以前写过时间事件日志现在也不写了；写过博客也不写了；月记也不写了。\n坚持平凡事就是伟大，本来计划一周一篇的，这次没有严格执行。懈怠了\n这个GC跟JVM内容太多了，理论性东西多些，少年时还能记个八九成，好久没弄，都忘记了。这次权当整理温习,再看看《深入理解JVM虚拟机》，找些过去写的博客挖点东西过来！\nGCJava GC（Garbage Collection，垃圾收集，垃圾回收）机制，是Java与C++&#x2F;C的主要区别之一，作为Java开发者，一般不需要专门编写内存回收和垃圾清理代码，对内存泄露和溢出的问题，也不需要像C程序员那样战战兢兢。这是因为在Java虚拟机中，存在自动内存管理和垃圾清扫机制。概括地说，该机制对虚拟机中的内存进行标记，并确定哪些内存需要回收，根据一定的回收策略，自动的回收内存，永不停息（Nerver Stop）的保证虚拟机中的内存空间，防止出现内存泄露和溢出问题。\n主要从这几个问题入手，就差不多了\n\nJava内存区域\n哪些内存需要回收？\n什么时候回收\n如何回收\n监控和优化GC\n\nJava内存区域\n\n程序计数器（Program Counter Register）\n\n程序计数器是一个比较小的内存区域，用于指示当前线程所执行的字节码执行到了第几行，可以理解为是当前线程的行号指示器。字节码解释器在工作时，会通过改变这个计数器的值来取下一条语句指令。每个程序计数器只用来记录一个线程的行号，所以它是线程私有（一个线程就有一个程序计数器）的。如果程序执行的是一个Java方法，则计数器记录的是正在执行的虚拟机字节码指令地址；如果正在执行的是一个本地（native，由C语言编写完成）方法，则计数器的值为Undefined，由于程序计数器只是记录当前指令地址，所以不存在内存溢出的情况，因此，程序计数器也是所有JVM内存区 域中唯一一个没有定义OutOfMemoryError的区域。\n\n虚拟机栈（JVM Stack）\n\n一个线程的每个方法在执行的同时，都会创建一个栈帧（Statck Frame），栈帧中存储的有局部变量表、操作站、动态链接、方法出口等，当方法被调用时，栈帧在JVM栈中入栈，当方法执行完成时，栈帧出栈。局部变量表中存储着方法的相关局部变量，包括各种基本数据类型，对象的引用，返回地址等。在局部变量表中，只有long和double类型会占用2个局部变量空间（Slot，对于32位机器，一个Slot就是32个bit），其它都是1个Slot。需要注意的是，局部变量表是在编译时就已经确定 好的，方法运行所需要分配的空间在栈帧中是完全确定的，在方法的生命周期内都不会改变。虚拟机栈中定义了两种异常，如果线程调用的栈深度大于虚拟机允许的最大深度，则抛出StatckOverFlowError（栈溢出）；不过多 数Java虚拟机都允许动态扩展虚拟机栈的大小(有少部分是固定长度的)，所以线程可以一直申请栈，知道内存不足，此时，会抛出 OutOfMemoryError（内存溢出）。每个线程对应着一个虚拟机栈，因此虚拟机栈也是线程私有的。\n\n本地方法栈（Native Method Statck）：\n\n本地方法栈在作用，运行机制，异常类型等方面都与虚拟机栈相同，唯一的区别是：虚拟机栈是执行Java方法的，而本地方法栈是用来执行native方法的，在很多虚拟机中（如Sun的JDK默认的HotSpot虚拟机），会将本地方法栈与虚拟机栈放在一起使用。本地方法栈也是线程私有的。\n\n堆区（Heap）\n\n堆区是理解Java GC机制最重要的区域，没有之一。在JVM所管理的内存中，堆区是最大的一块，堆区也是Java GC机制所管理的主要内存区域，堆区由所有线程共享，在虚拟机启动时创建。堆区的存在是为了存储对象实例，原则上讲，所有的对象都在堆区上分配内存（不过现代技术里，也不是这么绝对的，也有栈上直接分配的）。一般的，根据Java虚拟机规范规定，堆内存需要在逻辑上是连续的（在物理上不需要），在实现时，可以是固定大小的，也可以是可扩展的，目前主流的虚拟机都是可扩展的。如果在执行垃圾回收之后，仍没有足够的内存分配，也不能再扩展，将会抛出OutOfMemoryError:Java heap space异常。\n-Xms 参数设置最小值-Xmx 参数设置最大值 例：VM Args: -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError若-Xms=-Xmx,则可避免堆自动扩展。-XX:+HeapDumpOnOutOfMemoryError 可以让虚拟机在出现内存溢出是dump出当前的内存堆转储快照。\n\n\n方法区（Method Area）\n\n在Java虚拟机规范中，将方法区作为堆的一个逻辑部分来对待，但事实上，方法区并不是堆（Non-Heap）；另外，不少人的博客中，将Java GC的分代收集机制分为3个代：青年代，老年代，永久代，这些作者将方法区定义为“永久代”，这是因为，对于之前的HotSpot Java虚拟机的实现方式中，将分代收集的思想扩展到了方法区，并将方法区设计成了永久代。不过，除HotSpot之外的多数虚拟机，并不将方法区当做永久代，HotSpot本身，也计划取消永久代。方法区是各个线程共享的区域，用于存储已经被虚拟机加载的类信息（即加载类时需要加载的信息，包括版本、field、方法、接口等信息）、final常量、静态变量、编译器即时编译的代码等。方法区在物理上也不需要是连续的，可以选择固定大小或可扩展大小，并且方法区比堆还多了一个限制：可以选择是否执行垃圾收集。一般的，方法区上 执行的垃圾收集是很少的，这也是方法区被称为永久代的原因之一（HotSpot），但这也不代表着在方法区上完全没有垃圾收集，其上的垃圾收集主要是针对常量池的内存回收和对已加载类的卸载。在方法区上进行垃圾收集，条件苛刻而且相当困难，效果也不令人满意，所以一般不做太多考虑，可以留作以后进一步深入研究时使用。在方法区上定义了OutOfMemoryError:PermGen space异常，在内存不足时抛出。运行时常量池（Runtime Constant Pool）是方法区的一部分，用于存储编译期就生成的字面常量、符号引用、翻译出来的直接引用（符号引用就是编码是用字符串表示某个变量、接口的位置，直接引用就是根据符号引用翻译出来的地址，将在类链接阶段完成翻译）；运行时常量池除了存储编译期常量外，也可以存储在运行时间产生的常量（比如String类的intern()方法，作用是String维护了一个常量池，如果调用的字符“abc”已经在常量池中，则返回池中的字符串地址，否则，新建一个常量加入池中，并返回地址）。\n-XX:MaxPermSize 设置上限-XX:PermSize 设置最小值 例：VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M\n\n直接内存（Direct Memory）\n\n直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError异常出现，所以我们放到这里一起讲解。\nDirect Memory满了之后，系统不会自动回收这段内存； 而是要等Tenured Generation满触发GC时，Direct Memory才会被跟着回收。\n在JDK 1.4中新加入了NIO（New Input&#x2F;Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I&#x2F;O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。\n显然，本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，则肯定还是会受到本机总内存（包括RAM及SWAP区或者分页文件）的大小及处理器寻址空间的限制。服务器管理员配置虚拟机参数时，一般会根据实际内存设置-Xmx等参数信息，但经常会忽略掉直接内存，使得各个内存区域的总和大于物理内存限制（包括物理上的和操作系统级的限制），从而导致动态扩展时出现OutOfMemoryError异常。\n-XX:MaxDirectMemorySize 设置最大值，默认与java堆最大值一样。例 ：-XX:MaxDirectMemorySize=10M -Xmx20M\n\n\n哪些内存被回收根据运行时数据区域的各个部分，程序计数器、虚拟机栈、本地方法栈三个区域随着线程而生，随线程灭而灭。栈中的栈帧随着方法的进入和退出而进栈出栈。每个栈帧分配多少内存在类结构确定下来的时候就基本已经确定。所以这个三个区域内存回收时方法或者线程结束而回收的，不需要太多关注；而java堆和方法区则不一样，一个接口不同实现类，一个方法中不同的分支，在具体运行的时候才能确定创建那些对象，所以这部分内存是动态的，也是需要垃圾回收机制来回收处理的。\n\n堆内存\n\n判断堆内的对象是否可以回收，要判断这个对象实例是否确实没用，判断算法有两种：引用计数法和根搜索算法。\n\n引用计数法：就是给每个对象加一个计数器，如果有一个地方引用就加1，当引用失效就减1；当计数器为0，则认为对象是无用的。这种算法最大的问题在于不能解决相互引用的对象，如：A.b&#x3D;B;B.a&#x3D;A，在没有其他引用的情况下，应该回收；但按照引用计数法来计算，他们的引用都不为0，显然不能回收。\n\n根搜索算法：这个算法的思路是通过一系列名为“GC Roots”的对象作为起点，从这个节点向下搜索，搜索所经过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连(图论的不可达)时，则证明该对象不可用。\n\n\njava等一大部分商用语言是用根搜索算法来管理内存的，java中可以做为GC Roots的对象有如下几种：\n虚拟机栈（栈帧中的本地变量表）中的引用的对象；\n方法区中的类静态属性引用的对象；\n方法区中常量引用的对象；\n本地方法栈JNI(Native)的引用对象；\n无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象的引用链是否可达，判定对象是否存活都与“引用”有关。在JDK1.2以前，Java中的引用的定义很传统如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用。这种定义很纯粹，但是太过狭隘，一个对象在这种定义下只有被引用或者没有被引用两种状态，对于如何描述一些“食之无味，弃之可惜”的对象就显得无能为力。我们希望能描述这样一类对象：当内存空间还足够时，则能保留在内存之中；如果内存空间在进行垃圾收集后还是非常紧张，则可以抛弃这些对象。很多系统的缓存功能都符合这样的应用场景。\n在JDK 1.2之后，Java对引用的概念进行了扩充，将引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）4种，这4种引用强度依次逐渐减弱。\n\n强引用\n\n只要强引用还存在，垃圾收集器永远不会收掉被引用的对象\n\n软引用\n\n在系统将要发生内存异常之前，将会把这些对象列进回收范围之中进行第二次回收。\n\n弱引用\n\n被弱引用关联的对象只能生存道下一次垃圾收集发生之前。\n\n虚引用\n\n一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象的实例。\nfinalize()方法在Object类中\nprotected void finalize() throws Throwable &#123; &#125;\n注意下这个访问控制符是protected\nfinalize()在什么时候被调用?有三种情况\n\n所有对象被Garbage Collection时自动调用,比如运行System.gc()的时候.\n程序退出时为每个对象调用一次finalize方法。\n显式的调用finalize方法\n\n当一个对象不可到达时，并不是马上就被回收的。\n\n当对象没有覆盖finalize()方法，或者finalized()已经被JVM调用过，那就是没有必要执行finalzied();Finalizer线程执行它，但并不保证等待它执行结束，这主要是防止finalize()出现问题，导致Finalizer线程无限等待，整个内存回收系统崩溃\n具体的finalize流程：对象可由两种状态，涉及到两类状态空间，一是终结状态空间 F &#x3D; {unfinalized, finalizable, finalized}；二是可达状态空间 R &#x3D; {reachable, finalizer-reachable, unreachable}。各状态含义如下：unfinalized: 新建对象会先进入此状态，GC并未准备执行其finalize方法，因为该对象是可达的finalizable: 表示GC可对该对象执行finalize方法，GC已检测到该对象不可达。正如前面所述，GC通过F-Queue队列和一专用线程完成finalize的执行finalized: 表示GC已经对该对象执行过finalize方法reachable: 表示GC Roots引用可达finalizer-reachable(f-reachable)：表示不是reachable，但可通过某个finalizable对象可达unreachable：对象不可通过上面两种途径可达\n\n新建对象首先处于[reachable, unfinalized]状态(A)\n随着程序的运行，一些引用关系会消失，导致状态变迁，从reachable状态变迁到f-reachable(B, C, D)或unreachable(E, F)状态\n若JVM检测到处于unfinalized状态的对象变成f-reachable或unreachable，JVM会将其标记为finalizable状态(G,H)。若对象原处于[unreachable, unfinalized]状态，则同时将其标记为f-reachable(H)。\n在某个时刻，JVM取出某个finalizable对象，将其标记为finalized并在某个线程中执行其finalize方法。由于是在活动线程中引用了该对象，该对象将变迁到(reachable, finalized)状态(K或J)。该动作将影响某些其他对象从f-reachable状态重新回到reachable状态(L, M, N), 这就是对象重生\n处于finalizable状态的对象不能同时是unreahable的，由第4点可知，将对象finalizable对象标记为finalized时会由某个线程执行该对象的finalize方法，致使其变成reachable。这也是图中只有八个状态点的原因\n程序员手动调用finalize方法并不会影响到上述内部标记的变化，因此JVM只会至多调用finalize一次，即使该对象“复活”也是如此。程序员手动调用多少次不影响JVM的行为\n若JVM检测到finalized状态的对象变成unreachable，回收其内存(I)\n若对象并未覆盖finalize方法，JVM会进行优化，直接回收对象（O）\n\n注：System.runFinalizersOnExit()等方法可以使对象即使处于reachable状态，JVM仍对其执行finalize方法\n对finalize()的一句话概括：JVM能够保证一个对象在回收以前一定会调用一次它的finalize()方法。这句话中两个陷阱：回收以前一定和一次\n但有很多地方是讲，JVM不承诺这一定调用finalize()，这就是上面的陷阱造成的\n你永远不知道它什么时候被调用甚至会不会调用（因为有些对象是永远不会被回收的，或者被回收以前程序就结束了）,但如果他是有必要执行finalize()的，那在GC前一定调用一次且仅一次，如果在第一次GC时没有被回收，那以后再GC时，就不再调用finalize()\n\n方法区\n\n很多人认为方法区（或者HotSpot虚拟机中的永久代）是没有垃圾收集的，Java虚拟机规范中确实说过可以不要求虚拟机在方法区实现垃圾收集，而且在方法区进行垃圾收集的“性价比”一般比较低：在堆中，尤其是在新生代中，常规应用进行一次垃圾收集*++一般可以回收70%~95%的空间++，而永久代的垃圾收集效率远低于此。\n方法区回收主要有两部分：废弃的常量和无用的类。废弃的常量判断方法和堆中的对象类似，只要判断没有地方引用就可以回收。相比之下，判断一个类是否无用，条件就比较苛刻，需要同时满足下面3个条件才能算是“无用的类”：\n\n该类的所有实例都已经被回收，也就是java堆中不存在该类的任何实例；\n加载该类的ClassLoader已经被回收；\n该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。\n\n虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而不是和对象一样，不使用了就必然会回收。是否对类进行回收，\nHotSpot虚拟机提供了-Xnoclassgc参数进行控制，还可以使用-verbose:class-XX:+TraceClassLoading-XX:+TraceClassUnLoading查看类的加载和卸载信息。\n在大量使用反射、动态代理、CGLib等bytecode框架的场景，以及动态生成JSP和OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出\n如何回收选择合适的GC collector是JVM调优最重要的一项，前提是先了解回收算法\n“标记-清除”（Mark-Sweep）\n算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象\n主要缺点有两个\n\n一个是效率问题，标记和清除过程的效率都不高\n一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作\n\n“复制”（Copying）\n它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。\n只是这种算法的代价是将内存缩小为原来的一半，未免太高了一点\n现在的商业虚拟机都采用这种收集算法来回收新生代，IBM的专门研究表明，新生代中的对象98%是朝生夕死的，所以并不需要按照1∶1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中的一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地拷贝到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor的空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8∶1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存是会被“浪费”的。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。\n在对象存活率较高时就要执行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。\n-XX:SurvivorRatio=4设置年轻代中Eden区与Survivor区的大小比值。设置为4，则Eden区与两个Survivor区的比值为4:1:1，一个Survivor区占整个年轻代的1/6 \n\n\n为什么新生代有两个survivor?StackOverflow上面给出的解释是：\n\n\nThe reason for the HotSpot JVM’s two survivor spaces is to reduce the need to deal with fragmentation. New objects are allocated in eden space. All well and good. When that’s full, you need a GC, so kill stale objects and move live ones to a survivor space, where they can mature for a while before being promoted to the old generation. Still good so far. The next time we run out of eden space, though, we have a conundrum. The next GC comes along and clears out some space in both eden and our survivor space, but the spaces aren’t contiguous. So is it better to\n\nTry to fit the survivors from eden into the holes in the survivor space that were cleared by the GC?\nShift all the objects in the survivor space down to eliminate the fragmentation, and then move the survivors into it?\nJust say “screw it, we’re moving everything around anyway,” and copy all of the survivors from both spaces into a completely separate space–the second survivor space–thus leaving you with a clean eden and survivor space where you can repeat the sequence on the next GC?\n\n\n\nSun’s answer to the question is obvious.\n\n“标记-整理”（Mark-Compact）\n此算法结合了“标记-清除”和“复制”两个算法的优点。也是分两阶段，\n\n第一阶段从根节点开始标记所有被引用对象，\n第二阶段遍历整个堆，把清除未标记对象并且把存活对象“压缩”到堆的其中一块，按顺序排放。此算法避免了“标记-清除”的碎片问题，同时也避免了“复制”算法的空间问题。\n\n“分代收集”（Generational Collection）当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，这种算法并没有什么新的思想，只是根据对象的存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。\n\n\n新生代 GC（Minor GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快。\n\n老年代 GC（Major GC）：指发生在老年代的 GC，出现了 Major GC，经常会伴随至少一次的 Minor GC（但非绝对的，在 ParallelScavenge 收集器的收集策略里就有直接进行 Major GC 的策略选择过程） 。MajorGC 的速度一般会比 Minor GC 慢 10倍以上。虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在 Eden 出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1。对象在 Survivor 区中每熬过一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁）时，就会被晋升到老年代中。\n\n\n对象晋升老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。\n\n垃圾收集器\n按系统线程分\n注意并发（Concurrent）和并行（Parallel）的区别：\n\n并发是指用户线程与GC线程同时执行（不一定是并行，可能交替，但总体上是在同时执行的），不需要停顿用户线程（其实在CMS中用户线程还是需要停顿的，只是非常短，GC线程在另一个CPU上执行）；\n并行收集是指多个GC线程并行工作，但此时用户线程是暂停的；\n\n\n这个跟传统的并发并行概念不同并行是物理的，并发是逻辑的。并行是和串行对立。\n\nSerial收集器Serial是最基本、历史最悠久的垃圾收集器，使用复制算法，曾经是JDK1.3.1之前新生代唯一的垃圾收集器。目前也是ClientVM下 ServerVM 4核4GB以下机器的默认垃圾回收器。串行收集器并不是只能使用一个CPU进行收集，而是当JVM需要进行垃圾回收的时候，需要中断所有的用户线程，知道它回收结束为止，因此又号称“Stop The World” 的垃圾回收器。注意，JVM中文名称为java虚拟机，因此它就像一台虚拟的电脑一样在工作，而其中的每一个线程就被认为是JVM的一个处理器，因此大家看到图中的CPU0、CPU1实际为用户的线程，而不是真正机器的CPU，大家不要误解哦。\n串行回收方式适合低端机器，是Client模式下的默认收集器，对CPU和内存的消耗不高，适合用户交互比较少，后台任务较多的系统。\nSerial收集器默认新旧生代的回收器搭配为Serial+ SerialOld\n新生代、老年代使用串行回收；新生代复制算法、老年代标记-压缩\n在J2SE5.0上，在非server模式下，JVM自动选择串行收集器。也可以显示进行选择，在Java启动参数中增加： -XX:+UseSerialGC\n\nSerial Old收集器SerialOld是旧生代Client模式下的默认收集器，单线程执行，使用“标记-整理”算法在Server模式下，主要有两个用途：\n\n在JDK1.5之前版本中与新生代的Parallel Scavenge收集器搭配使用。\n作为年老代中使用CMS收集器的后备垃圾收集方案。\n\nParNew收集器ParNew收集器其实就是多线程版本的Serial收集器,\nStop The World\n他是多CPU模式下的首选回收器（该回收器在单CPU的环境下回收效率远远低于Serial收集器，所以一定要注意场景哦）\nServer模式下的默认收集器。\n新生代并行，老年代串行；新生代复制算法、老年代标记-压缩\n-XX:+UseParNewGC  ParNew收集器ParNew收集器默认开启和CPU数目相同的线程数-XX:ParallelGCThreads 限制线程数量\nParallel Scavenge收集器Parallel Scavenge收集器也是一个新生代垃圾收集器，同样使用复制算法，也是一个多线程的垃圾收集器,也称吞吐量优先的收集器\n所提到的吞吐量&#x3D;程序运行时间&#x2F;(JVM执行回收的时间+程序运行时间),假设程序运行了100分钟，JVM的垃圾回收占用1分钟，那么吞吐量就是99%。在当今网络告诉发达的今天，良好的响应速度是提升用户体验的一个重要指标，多核并行云计算的发展要求程序尽可能的使用CPU和内存资源，尽快的计算出最终结果，因此在交互不多的云端，比较适合使用该回收器。\n可以通过参数来打开自适应调节策略，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量；也可以通过参数控制GC的时间不大于多少毫秒或者比例\n新生代复制算法、老年代标记-压缩\n-XX:+UseParallelGC  使用Parallel收集器+ 老年代串行Parallel Scavenge收集器提供了两个参数用于精准控制吞吐量：a.-XX:MaxGCPauseMillis：控制最大垃圾收集停顿时间，是一个大于0的毫秒数。b.-XX:GCTimeRation：直接设置吞吐量大小，是一个大于0小于100的整数，也就是程序运行时间占总时间的比率，默认值是99，即垃圾收集运行最大1%（1/(1+99)）的垃圾收集时间-XX:+UseAdaptiveSizePolicy，这是个开关参数，打开之后就不需要手动指定新生代大小(-Xmn)、Eden与Survivor区的比例(-XX:SurvivorRation)、新生代晋升年老代对象年龄(-XX:PretenureSizeThreshold)等细节参数\n\nParallel OldParallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法。这个收集器是在JDK 1.6中才开始提供\n在JDK1.6之前，新生代使用ParallelScavenge收集器只能搭配年老代的Serial Old收集器，只能保证新生代的吞吐量优先，无法保证整体的吞吐量，Parallel Old正是为了在年老代同样提供吞吐量优先的垃圾收集器，如果系统对吞吐量要求比较高，可以优先考虑新生代Parallel Scavenge和年老代Parallel Old收集器的搭配策略\n参数控制： -XX:+UseParallelOldGC 使用Parallel收集器+ 老年代并行\n新生代Parallel Scavenge和年老代Parallel Old收集器搭配运行过程图：\nCMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B&#x2F;S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。\n由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行。老年代收集器（新生代使用ParNew）\n优点:并发收集、低停顿 \n缺点：产生大量空间碎片、并发阶段会降低吞吐量\n从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为4个步骤，包括： \n\n初始标记（CMS initial mark）\n\n并发标记（CMS concurrent mark）\n\n重新标记（CMS remark）\n\n并发清除（CMS concurrent sweep）\n\n\na.初始标记：只是标记一下GC Roots能直接关联的对象，速度很快，仍然需要暂停所有的工作线程。\nb.并发标记：进行GC Roots跟踪的过程，和用户线程一起工作，不需要暂停工作线程。\nc.重新标记：为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。\nd.并发清除：清除GC Roots不可达对象，和用户线程一起工作，不需要暂停工作线程。由于耗时最长的并发标记和并发清除过程中，垃圾收集线程可以和用户现在一起并发工作，所以总体上来看CMS收集器的内存回收和用户线程是一起并发地执行。\nCMS收集器工作过程：\n\n其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。\nCMS收集器有以下三个不足：\n\nCMS收集器对CPU资源非常敏感，其默认启动的收集线程数&#x3D;(CPU数量+3)&#x2F;4，在用户程序本来CPU负荷已经比较高的情况下，如果还要分出CPU资源用来运行垃圾收集器线程，会使得CPU负载加重。\n\nCMS无法处理浮动垃圾(Floating Garbage)，可能会导致Concurrent ModeFailure失败而导致另一次Full GC。由于CMS收集器和用户线程并发运行，因此在收集过程中不断有新的垃圾产生，这些垃圾出现在标记过程之后，CMS无法在本次收集中处理掉它们，只好等待下一次GC时再将其清理掉，这些垃圾就称为浮动垃圾。CMS垃圾收集器不能像其他垃圾收集器那样等待年老代机会完全被填满之后再进行收集，需要预留一部分空间供并发收集时的使用，可以通过参数-XX:CMSInitiatingOccupancyFraction来设置年老代空间达到多少的百分比时触发CMS进行垃圾收集，默认是68%。如果在CMS运行期间，预留的内存无法满足程序需要，就会出现一次ConcurrentMode Failure失败，此时虚拟机将启动预备方案，使用Serial Old收集器重新进行年老代垃圾回收。\n\nCMS收集器是基于标记-清除算法，因此不可避免会产生大量不连续的内存碎片，如果无法找到一块足够大的连续内存存放对象时，将会触发因此Full GC。CMS提供一个开关参数-XX:+UseCMSCompactAtFullCollection，用于指定在Full GC之后进行内存整理，内存整理会使得垃圾收集停顿时间变长，CMS提供了另外一个参数-XX:CMSFullGCsBeforeCompaction，用于设置在执行多少次不压缩的Full GC之后，跟着再来一次内存整理\n\n\n-XX:+UseConcMarkSweepGC  使用CMS收集器-XX:+ UseCMSCompactAtFullCollection Full GC后，进行一次碎片整理；整理过程是独占的，会引起停顿时间变长-XX:+CMSFullGCsBeforeCompaction  设置进行几次Full GC后，进行一次碎片整理-XX:ParallelCMSThreads  设定CMS的线程数量（一般情况约等于可用CPU数量）\n\nG1收集器G1可谓博采众家之长，力求到达一种完美。他吸取了增量收集优点，把整个堆划分为一个一个等大小的区域（region）。内存的回收和划分都以region为单位；同时，他也吸取了CMS的特点，把这个垃圾回收过程分为几个阶段，分散一个垃圾回收过程；而且，G1也认同分代垃圾回收的思想，认为不同对象的生命周期不同，可以采取不同收集方式，因此，它也支持分代的垃圾回收。为了达到对回收时间的可预计性，G1在扫描了region以后，对其中的活跃对象的大小进行排序，首先会收集那些活跃对象小的region，以便快速回收空间（要复制的活跃对象少了），因为活跃对象小，里面可以认为多数都是垃圾，所以这种方式被称为Garbage First（G1）的垃圾回收算法，即：垃圾优先的回收。\n\n与CMS收集器相比G1收集器有以下特点：\n\n空间整合，G1收集器采用标记整理算法，不会产生内存空间碎片。分配大对象时不会因为无法找到连续空间而提前触发下一次GC。\n\n可预测停顿，这是G1的另一大优势，降低停顿时间是G1和CMS的共同关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为N毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。\n\n\n收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔阂了，它们都是一部分（可以不连续）Region的集合。\nG1的新生代收集跟ParNew类似，当新生代占用达到一定比例的时候，开始出发收集。\n和CMS类似，G1收集器收集老年代对象会有短暂停顿。\n\n标记阶段，首先初始标记(Initial-Mark),这个阶段是停顿的(Stop the World Event)，并且会触发一次普通Mintor GC。对应GC log:GC pause (young) (inital-mark)\n\nRoot Region Scanning，程序运行过程中会回收survivor区(存活到老年代)，这一过程必须在young GC之前完成。\n\nConcurrent Marking，在整个堆中进行并发标记(和应用程序并发执行)，此过程可能被young GC中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，会计算每个区域的对象活性(区域中存活对象的比例)。\n\nRemark, 再标记，会有短暂停顿(STW)。再标记阶段是用来收集 并发标记阶段 产生新的垃圾(并发阶段和应用程序一同运行)；G1中采用了比CMS更快的初始快照算法:snapshot-at-the-beginning (SATB)。\n\nCopy&#x2F;Clean up，多线程清除失活对象，会有STW。G1将回收区域的存活对象拷贝到新区域，清除Remember Sets，并发清空回收区域并把它返回到空闲区域链表中。\n\n复制&#x2F;清除过程后。回收区域的活性对象已经被集中回收到深蓝色和深绿色区域。\n\n\n-XX:+UnlockExperimentalVMOptions -XX:+UseG1GC        #开启-XX:MaxGCPauseMillis =50                  #暂停时间目标-XX:GCPauseIntervalMillis =200          #暂停间隔目标-XX:+G1YoungGenSize=512m            #年轻代大小-XX:SurvivorRatio=6                            #幸存区比例\n\n\n什么时候回收Minor GC触发\nEden区域满了，或者新创建的对象大小 &gt; Eden所剩空间\nCMS设置了CMSScavengeBeforeRemark参数，这样在CMS的Remark之前会先做一次Minor GC来清理新生代，加速之后的Remark的速度。这样整体的stop-the world时间反而短\nFull GC的时候会先触发Minor GC\n\n啥时候会触发CMS GC？CMS不等于Full GC，很多人会认为CMS肯定会引发Minor GC。CMS是针对老年代的GC策略，原则上它不会去清理新生代，只有设置CMSScavengeBeforeRemark优化时，或者是concurrent mode failure的时候才会去做Minor GC\n1、旧生代或者持久代已经使用的空间达到设定的百分比时（CMSInitiatingOccupancyFraction这个设置old区，perm区也可以设置）；\n2、JVM自动触发(JVM的动态策略，也就是悲观策略)（基于之前GC的频率以及旧生代的增长趋势来评估决定什么时候开始执行），如果不希望JVM自行决定，可以通过-XX：UseCMSInitiatingOccupancyOnly&#x3D;true来制定；\n3、设置了 -XX：CMSClassUnloadingEnabled 这个则考虑Perm区；\n啥时候会触发Full GC？一、旧生代空间不足：java.lang.outOfMemoryError：java heap space；\n二、Perm空间满：java.lang.outOfMemoryError：PermGen space；\n三、CMS GC时出现promotion failed  和concurrent  mode failure（Concurrent mode failure发生的原因一般是CMS正在进行，但是由于old区内存不足，需要尽快回收old区里面的死的java对象，这个时候foreground gc需要被触发，停止所有的java线程，同时终止CMS，直接进行MSC。）；\n四、统计得到的minor GC晋升到旧生代的平均大小大于旧生代的剩余空间；\n五、主动触发Full GC（执行jmap -histo:live [pid]）来避免碎片问题；\n六、调用System.gc时，系统建议执行Full GC，但是不必然执行,-XX:+DisableExplicitGC 禁用System.gc()调用\nGC策略选择总结jvm有client和server两种模式，这两种模式的gc默认方式是不同的：\nclient模式下，新生代选择的是串行gc，旧生代选择的是串行gc\nserver模式下，新生代选择的是并行回收gc，旧生代选择的是并行gc\n一般来说我们系统应用选择有两种方式：吞吐量优先和暂停时间优先，对于吞吐量优先的采用server默认的并行gc方式，对于暂停时间优先的选用并发gc（CMS）方式。\n监控与调优GC日志-XX:+PrintGC 输出GC日志-XX:+PrintGCDetails 输出GC的详细日志-XX:+PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式）-XX:+PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）-XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息-Xloggc:../logs/gc.log 日志文件的输出路径-verbose.gc开关可显示GC的操作内容。打开它，可以显示最忙和最空闲收集行为发生的时间、收集前后的内存大小、收集需要的时间等\n\n-XX:+PrintGCTimeStamps和-XX:+PrintGCDateStamps\n使用-XX:+PrintGCTimeStamps可以将时间和日期也加到GC日志中。表示自JVM启动至今的时间戳会被添加到每一行中。例子如下：\n1 0.185: [GC 66048K-&gt;53077K(251392K), 0.0977580 secs]2 0.323: [GC 119125K-&gt;114661K(317440K), 0.1448850 secs]3 0.603: [GC 246757K-&gt;243133K(375296K), 0.2860800 secs]\n如果指定了-XX:+PrintGCDateStamps，每一行就添加上了绝对的日期和时间。\n1 2014-01-03T12:08:38.102-0100: [GC 66048K-&gt;53077K(251392K), 0.0959470 secs]2 2014-01-03T12:08:38.239-0100: [GC 119125K-&gt;114661K(317440K), 0.1421720 secs]3 2014-01-03T12:08:38.513-0100: [GC 246757K-&gt;243133K(375296K), 0.2761000 secs]\n如果需要也可以同时使用两个参数。推荐同时使用这两个参数，因为这样在关联不同来源的GC日志时很有帮助\n每一种收集器的日志形式都是由它们自身的实现所决定的，换而言之，每个收集器的日志格式都可以不一样。\n但虚拟机设计者为了方便用户阅读，将各个收集器的日志都维持一定的共性，\n例如以下两段典型的GC日志：\n33.125: [GC [DefNew: 3324K-&gt;152K(3712K), 0.0025925 secs] 3324K-&gt;152K(11904K), 0.0031680 secs]100.667: [Full GC [Tenured: 0K-&gt;210K(10240K), 0.0149142 secs] 4603K-&gt;210K(19456K), [Perm : 2999K-&gt;2999K(21248K)], 0.0150007 secs] [Times: user=0.01 sys=0.00, real=0.02 secs]\n最前面的数字“33.125：”和“100.667：”代表了GC发生的时间，这个数字的含义是从Java虚拟机启动以来经过的秒数。\nGC日志开头的“［GC”和“［Full GC”说明了这次垃圾收集的停顿类型，\n而不是用来区分新生代GC还是老年代GC的。\n如果有“Full”，说明这次GC是发生了Stop-The-World的，\n例如下面这段新生代收集器ParNew的日志也会出现“［Full GC”（这一般是因为出现了分配担保失败之类的问题，所以才导致STW）。\n如果是调用System.gc()方法所触发的收集，那么在这里将显示“［Full GC (System)”。\n[Full GC 283.736: [ParNew: 261599K-&gt;261599K(261952K), 0.0000288 secs] \n接下来的“［DefNew”、“［Tenured”、“［Perm”表示GC发生的区域，这里显示的区域名称与使用的GC收集器是密切相关的\n例如上面样例所使用的Serial收集器中的新生代名为“Default New Generation”，所以显示的是“［DefNew”。\n如果是ParNew收集器，新生代名称就会变为“［ParNew”，意为“Parallel New Generation”。\n如果采用Parallel Scavenge收集器，那它配套的新生代称为“PSYoungGen”，老年代和永久代同理，名称也是由收集器决定的。\n后面方括号内部的“3324K-&gt;152K(3712K)”含义是“GC前该内存区域已使用容量-&gt; GC后该内存区域已使用容量 (该内存区域总容量)”。\n而在方括号之外的“3324K-&gt;152K(11904K)”表示“GC前Java堆已使用容量 -&gt; GC后Java堆已使用容量 (Java堆总容量)”。\n再往后，“0.0025925 secs”表示该内存区域GC所占用的时间，单位是秒。\n有的收集器会给出更具体的时间数据\n如“［Times： user&#x3D;0.01 sys&#x3D;0.00， real&#x3D;0.02 secs］”，这里面的user、sys和real与Linux的time命令所输出的时间含义一致，分别代表用户态消耗的CPU时间、内核态消耗的CPU事件和操作从开始到结束所经过的墙钟时间（Wall Clock Time）。\nCPU时间与墙钟时间的区别是，墙钟时间包括各种非运算的等待耗时，例如等待磁盘I&#x2F;O、等待线程阻塞，而CPU时间不包括这些耗时，但当系统有多CPU或者多核的话，多线程操作会叠加这些CPU时间，所以读者看到user或sys时间超过real时间是完全正常的。\n分析工具可以使用一些离线的工具来对GC日志进行分析\n比如sun的gchisto( https://java.net/projects/gchisto)\ngcviewer（ https://github.com/chewiebug/GCViewer ），\n这些都是开源的工具，用户可以直接通过版本控制工具下载其源码，进行离线分析\n　　\nJVM参数HotSpot JVM 提供了三类参数。第一类包括了标准参数。顾名思义，标准参数中包括功能和输出的参数都是很稳定的，很可能在将来的JVM版本中不会改变。你可以用java命令（或者是用 java -help）检索出所有标准参数。我们在第一部分中已经见到过一些标准参数，例如：-server。\n第二类是X参数，非标准化的参数在将来的版本中可能会改变。所有的这类参数都以-X开始，并且可以用java -X来检索。注意，不能保证所有参数都可以被检索出来，其中就没有-Xcomp。\n第三类是包含XX参数（到目前为止最多的），它们同样不是标准的，甚至很长一段时间内不被列出来（最近，这种情况有改变 ，我们将在本系列的第三部分中讨论它们）。然而，在实际情况中X参数和XX参数并没有什么不同。X参数的功能是十分稳定的，然而很多XX参数仍在实验当中（主要是JVM的开发者用于debugging和调优JVM自身的实现）。值的一读的介绍非标准参数的文档 HotSpot JVM documentation，其中明确的指出XX参数不应该在不了解的情况下使用。这是真的，并且我认为这个建议同样适用于X参数（同样一些标准参数也是）。不管类别是什么，在使用参数之前应该先了解它可能产生的影响。用一句话来说明XX参数的语法。所有的XX参数都以”-XX:”开始，但是随后的语法不同，取决于参数的类型。\n\n对于布尔类型的参数，我们有”+”或”-“，然后才设置JVM选项的实际名称。例如，-XX:+用于激活选项，而-XX:-用于注销选项。\n对于需要非布尔值的参数，如string或者integer，我们先写参数的名称，后面加上”&#x3D;”，最后赋值。例如，  -XX:&#x3D;给赋值。\n\n-XX:+PrintFlagsFinal and -XX:+PrintFlagsInitial\n\n[Global flags]uintx AdaptivePermSizeWeight               = 20               &#123;product&#125;uintx AdaptiveSizeDecrementScaleFactor     = 4                &#123;product&#125;uintx AdaptiveSizeMajorGCDecayTimeScale    = 10               &#123;product&#125;uintx AdaptiveSizePausePolicy              = 0                &#123;product&#125;[...]uintx YoungGenerationSizeSupplementDecay   = 8                &#123;product&#125;uintx YoungPLABSize                        = 4096             &#123;product&#125; bool ZeroTLAB                             = false            &#123;product&#125; intx hashCode                             = 0                &#123;product&#125;\n表格的每一行包括五列，来表示一个XX参数。第一列表示参数的数据类型，第二列是名称，第四列为值，第五列是参数的类别。第三列”&#x3D;”表示第四列是参数的默认值，而”:&#x3D;” 表明了参数被用户或者JVM赋值了。\n-XX:+PrintCommandLineFlags\n这个参数让JVM打印出那些已经被用户或者JVM设置过的详细的XX参数的名称和值。\n换句话说，它列举出 -XX:+PrintFlagsFinal的结果中第三列有”:&#x3D;”的参数。\n以这种方式，我们可以用-XX:+PrintCommandLineFlags作为快捷方式来查看修改过的参数\n监控jvm使用自带工具就行，jstat,jmap,jstack\n\njstack主要用来查看某个Java进程内的线程堆栈信息\njmap用来查看堆内存使用状况，一般结合jhat使用\njstat利用JVM内建的指令对Java应用程序的资源和性能进行实时的命令行的监控，包括了对进程的classloader，compiler，gc情况\n\n优化\n选择合适的GC collector\n整个JVM heap的大小\nyoung generation在整个JVM heap中所占的比重\n\n参数实例public static void main(String[] args) throws InterruptedException&#123;       //通过allocateDirect分配128MB直接内存       ByteBuffer bb = ByteBuffer.allocateDirect(1024*1024*128);               TimeUnit.SECONDS.sleep(10);       System.out.println(&quot;ok&quot;);   &#125;\n测试用例1：设置JVM参数-Xmx100m，运行异常，因为如果没设置-XX:MaxDirectMemorySize，则默认与-Xmx参数值相同，分配128M直接内存超出限制范围\nException in thread &quot;main&quot; java.lang.OutOfMemoryError: Direct buffer memory    at java.nio.Bits.reserveMemory(Bits.java:658)    at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:123)    at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:306)    at com.stevex.app.nio.DirectByteBufferTest.main(DirectByteBufferTest.java:8)\n为了避免Perm区满引起的full gc，建议开启CMS回收Perm区选项：\n+CMSPermGenSweepingEnabled -XX:+CMSClassUnloadingEnabled\n默认CMS是在tenured generation沾满68%的时候开始进行CMS收集，如果你的年老代增长不是那么快，并且希望降低CMS次数的话，可以适当调高此值：\n-XX:CMSInitiatingOccupancyFraction&#x3D;80\n遇到两种fail引起full gc：\nPrommotion failed和Concurrent mode failed时：\npromotion failed是在进行Minor GC时，survivor space放不下、对象只能放入旧生代，而此时old gen 的碎片太多为进行过内存重组和压缩，无法提供一块较大的、连续的内存空间存放来自新生代对象\nPrommotion failed的日志输出大概是这样：\n42576.951: [ParNew (promotion failed): 320138K-&gt;320138K(353920K), 0.2365970 secs]42576.951: [CMS: 1139969K-&gt;1120688K( 166784K), 9.2214860 secs] 1458785K-&gt;1120688K(2520704K), 9.4584090 secs]\n因为解决这个问题的办法有两种完全相反的倾向：增大救助空间、增大年老代或者去掉救助空间。\n解决方法可以通过设置参数-XX:+UseCMSCompactAtFullCollection（打开对年老代的压缩）-XX:CMSFullGCsBeforeCompaction（设置运行多少次FULL GC以后对内存空间进行压缩、整理） \n直接关了servivor空间-XX:SurvivorRatio=65536 -XX:MaxTenuringThreshold=0\n\nconcurrent mode failure\n发生在当CMS已经在工作并处于concurrent阶段中，而Java堆的内存不够用需要做major GC（full GC）的时候。换句话说，old gen内存的消耗速度比CMS的收集速度要高，CMS收集器跟不上分配速度的时候会发生concurrent mode failure\nConcurrent mode failed的日志大概是这样的：\n(concurrent mode failure): 1228795K-&gt;1228598K(1228800K), 7.6748280 secs] 1911483K-&gt;1681165K(1911488K), [CMS Perm : 225407K-&gt;225394K(262144K)], 7.6751800 secs]\n避免这个现象的产生就是调小-XX:CMSInitiatingOccupancyFraction参数的值，让CMS更早更频繁的触发，降低年老代被沾满的可能。\nfull gc频繁说明old区很快满了。\n如果是一次full gc后，剩余对象不多。那么说明你eden区设置太小，导致短生命周期的对象进入了old区\n如果一次full gc后，old区回收率不大，那么说明old区太小\n已知虚拟机的一些参数设置如下： -Xms：1G； -Xmx：2G； -Xmn：500M； -XX:MaxPermSize：64M； -XX:+UseConcMarkSweepGC； -XX:SurvivorRatio=3； 求Eden区域的大小？\n\n分析这是网易2016年在线笔试题中的一道选择题。 先分析一下里面各个参数的含义： -Xms：1G ， 就是说初始堆大小为1G -Xmx：2G ， 就是说最大堆大小为2G -Xmn：500M ，就是说年轻代大小是500M（包括一个Eden和两个Survivor） -XX:MaxPermSize：64M ， 就是说设置持久代最大值为64M -XX:+UseConcMarkSweepGC ， 就是说使用使用CMS内存收集算法 -XX:SurvivorRatio=3 ， 就是说Eden区与Survivor区的大小比值为3：1：1题目中所问的Eden区的大小是指年轻代的大小，直接根据-Xmn：500M和-XX:SurvivorRatio=3可以直接计算得出解500M*(3/(3+1+1)) =500M*（3/5） =500M*0.6 =300M 所以Eden区域的大小为300M。\n\n-Xmn200m -server\njmap -heap pidHeap Configuration:   MinHeapFreeRatio         = 0   MaxHeapFreeRatio         = 100   MaxHeapSize              = 4282384384 (4084.0MB)   NewSize                  = 209715200 (200.0MB)   MaxNewSize               = 209715200 (200.0MB)   OldSize                  = 58720256 (56.0MB)   NewRatio                 = 2   SurvivorRatio            = 8   MetaspaceSize            = 21807104 (20.796875MB)   CompressedClassSpaceSize = 1073741824 (1024.0MB)   MaxMetaspaceSize         = 17592186044415 MB   G1HeapRegionSize         = 0 (0.0MB)Heap Usage:PS Young GenerationEden Space:   capacity = 92274688 (88.0MB)   used     = 37931936 (36.174713134765625MB)   free     = 54342752 (51.825286865234375MB)   41.107628562233664% usedFrom Space:   capacity = 58720256 (56.0MB)   used     = 20305320 (19.364662170410156MB)   free     = 38414936 (36.635337829589844MB)   34.57975387573242% usedTo Space:   capacity = 56623104 (54.0MB)   used     = 0 (0.0MB)   free     = 56623104 (54.0MB)   0.0% usedPS Old Generation   capacity = 176160768 (168.0MB)   used     = 65785064 (62.737525939941406MB)   free     = 110375704 (105.2624740600586MB)   37.34376544044132% used\n发现为什么from space与to space不对呢。应该是20M才对\n-server默认使用ParallelScavenge系的GCHotSpot VM里，ParallelScavenge系的GC（UseParallelGC / UseParallelOldGC）默认行为是SurvivorRatio如果不显式设置就没啥用。显式设置到跟默认值一样的值则会有效果因为ParallelScavenge系的GC最初设计就是默认打开AdaptiveSizePolicy的，它会自动、自适应的调整各种参数\n\n需要显示配置 -XX:SurvivorRatio=8\n\n参考资料http://yinwufeng.iteye.com/blog/2157787\nhttp://itindex.net/detail/47030-cms-gc-%E9%97%AE%E9%A2%98\nhttp://www.cnblogs.com/ityouknow/p/5614961.html\n","tags":["jvm","gc"]},{"title":"LSP之instanceof","url":"/blog/instanceof-lsp.html","content":"从年初就开始温习SOLID原则，原则看似很简单，有些其实就是一句话，但对照这些原则去观看自己的过往代码，还是很多违背这些原则的，诚然，没有完美的实践，但需要保持在走向完美的路上\n当然，如果你说天天在CRUD，从没有用到过这些原则，这就是另一个话题了\n最近就写了一段很臭的代码，反省一下\npublic AbstractInvoice(InvoiceCode invoiceCode, InvoiceNo invoiceNo, PaperDrewDate paperDrewDate, CheckCode checkCode) &#123;    this.invoiceCode = invoiceCode;    this.invoiceNo = invoiceNo;    this.paperDrewDate = paperDrewDate;    if (checkCode instanceof VerifyCheckCode) &#123;        this.checkCode = checkCode.toNormal();    &#125; else &#123;        this.checkCode = checkCode;    &#125;&#125;\n这段代码很简单，业务是发票，一张发票由基本的几个要素组成：发票代码、发票号码、开票时间、检验码、金额\n形象点，找个平常普通发票的票样\n\n其次，这是一个抽象类，构建时带有发票几票素，这些InvoiceCode,InvoiceNo,PaperDrewDate,CheckCode都是简单的Primitive Domain(不了解这个概念也没关系，下回分解；简单讲就是业务自包含的基本类型)\n完整的抽象类关系\n\n但代码里面用到了instanceof，当用到这个关键字，而且是在抽象实体时，基本上可以断定是抽象的层次不够，可能违背了LSP\nLSP原则很明了：子类可以随时替换父类；这儿用了instanceof，说明有不可替换的成份在\n再追看CheckCode的层次\n\n一个简单的校验码，为什么也要抽象成这样？\npublic abstract class CheckCode &#123;    protected String checkCode;    public CheckCode(String checkCode) &#123;        this.checkCode = checkCode;    &#125;        public CheckCode(int length, String checkCode, boolean isNumeric) &#123;    &#125;&#125;\n\n校验码有几种形式\n\n标准的20位长度的完整检验码\n后6位简短的检验码，发票做验真业务时使用\n区块链发票的检验码，5位长度，字母数字组合\n\n因为有三种形态，不同的长度就是不同的类型；验真时只需要简短检验码；查看完整信息时需要完整的检验码\n在发票接口中，也有相应的获取行为，也正因为有这种形为，需要在创建发票对象时，把VerifyCheckCode转换成NormalCheckCode\npublic interface Invoice &#123;    public CheckCode getCheckCode();        public String getVerifyCheckCode();\n\n这儿有个疑问，为什么不在构建发票前，把verifyCheckCode转成normalCheckCode，而不是到Invoice的构建内部再转化，那也就没有instanceof的事\n\n但再细想，对于发票来讲，其实只有一个checkCode属性，没有VerifyCheckCode，那只是在请求验真时的一种形态，所以在发票对象中，不应该有verifyCheckCode属性\n所以Invoice对象应该是这样\npublic interface Invoice &#123;    public CheckCode getCheckCode();&#125;public AbstractInvoice(InvoiceCode invoiceCode, InvoiceNo invoiceNo, PaperDrewDate paperDrewDate, CheckCode checkCode) &#123;        this.invoiceCode = invoiceCode;        this.invoiceNo = invoiceNo;        this.paperDrewDate = paperDrewDate;        this.checkCode = checkCode;&#125;\n\n对于primitive domain,CheckCode自包含中应该带有verifyCheckCode\n\n每一种CheckCode都有各自不同的行为\n\n一般通过instanceof判断子类型时，都有不满足LSP的嫌疑；在这个场景中也差不多，但抓住了这一点，重新思考一下，类层次与结构行为可以设计得更合理\n"},{"title":"Marketing Warfare","url":"/blog/marketing-warfare.html","content":"\n之前这本书翻译为《营销战》，现在又翻译成《商战》了\n结合当前商业动态，此书可能会回答你心中的一些问题\n\n为什么哈罗单车融资成功了，可ofo压金都成了问题？为什么在阿里绝对的市场占有率之机，拼多多诞生了并还在持续增长？当年的当当图书，京东快递如何抢占了客户真的是打江山容易，守江山难吗？战略与战术到底哪一个更重要？\n\n商业即战争战争属于商业竞争的范畴，同样也是人类利益和活动的冲突\n商业需要新理念明确清晰的定义是重要的开始，定义就是角度，也见深度\n\n商业活动必须满足消费者的需要和需求\n人类通过交换过程满足需要和需求的活动\n引导商品和服务从生产者流向消费者的一系列经济活动\n通过预测顾客或客户需求，并引导满足需求的商品和服务从生产者流向顾客或客户，从而实现组织目标的各种活动\n确定客户需求、根据组织生产能力将需求概念化、将概念同组织的适当能力相联系、根据先前确定的客户需求，使随后的生产概念化、将此概念同客户相联系\n\n兵力原则基本原则：兵力优势。无论何时，都应该首先尽力做到这一点\n用兵之法，十则围之，五则攻之，倍则战之，敌则能分之，少则能逃之，不若则能避之。故小敌之坚，大敌之擒也\n兵力原则是最基本的战争原则，其本质就是以多打少：大鱼吃小鱼，大公司击败小公司\n战地性质商战在心智中打响，它无时无刻不存在于你自己和潜在顾客的心智中。\n心智即战场，一个复杂且难以理解的阵地\n战略形式\n防御战原则\n只有市场领导者才能打防御战\n\n最佳的防御就是勇于自我攻击\n\n强大进攻必须及时封杀\n\n\n进攻战领导者应进行防御战，而非攻击战\n进攻战适用于行业第二或第三的公司，公司要足够强大才能向领导者发起持续进攻\n原则\n领导者的强势地位是主要的考虑因素\n找到领导者强势中的弱势，并聚而攻之\n尽可能在狭长地带发起攻击\n\n侧翼战侧翼战是最具有创新性的战略形式\n原则\n最佳的侧翼战是在无争地带展开\n\n战术奇袭是作战计划中最重要的一环\n\n追击与进攻同等重要\n\n\n游击战敌进我退，敌驻我拢，敌疲我打，敌退我追\n原则\n找到一块小得足以守得住的阵地\n\n无论多么成功，都不能效仿领导者\n\n一旦有变，随时准备撤退\n\n\nVS侧翼战\n\n\n\n侧翼战\n游击战\n\n\n\n1、\n深思熟虑，创意\n同样想法应用细分市场\n\n\n2、\n近距离领导者\n远离领导者\n\n\n3、\n夺取蚕食领导者市场份额\n区域市场\n\n\n战略与战术“战术驱动战略”，这是战争研究得出的最重要思想之一。\n战略服从战术就像形式服从内容一样，战略应该服从战术。战术结果的取得，是战略的最终目标和唯一目的。\n伟大的战略目标是使一切工作在一定的战术层面上顺利进行，而不是其他什么目的\n巴顿说：“人们不应该先制订计划，然后让形势适应计划，而应该让计划适应当前的形势。我认为，胜败取决于最高指挥部是否拥有这种能力。”\n总结可以尝试性的给开篇的问题给个答案，不一定对，毕竟不是专业人士，也非局中之人\n当年共享单车红遍南北，貌似市场被ofo，魔拜一统天下；而一些品牌却玩起了游击战，突袭攫取他们放弃的三四线城市，并快速追击，以致当领导者出现疲态时，主动进攻，一举进入了一线城市\n一个品牌无法支撑两个不同的概念。低价劳斯莱斯会损害其高价的定位，而且很多时候，低价产品无法热销，因为没有人愿意购买廉价的劳斯莱斯。\n所以阿里有了淘宝，也要搞天猫；但不可能一统所以市场，拼多多抓住了被忽略，或者说是阿里主动放弃的领地，提出社交电商，打了一个漂亮的侧翼战\n淘宝火及一时，可为什么选择京东购物？淘宝品种很全，但物流不够快，京东发现了客户痛点，找到了淘宝领导者强势中的弱势，以“隔日达”为口号，快速占领了用户心智\n战略重要，还是战术重要的呢？ 好似道与术的取舍一样。人们总认为道更重要。与IT行业的架构一样\n但康威定律如是说：设计系统的组织，其产生的设计等同于组织之内、组织之间的沟通结构。也就是架构偏向于组织结构，如果架构异于组织结构，那可能再完美的架构也无法落地。无法落地的架构是好架构吗？\n一个伟大的战略必须要以当前环境的战术能力为前提，不能实现，能算是好战略吗？\n","categories":["读书"],"tags":["读书"]},{"title":"SOLID之LSP","url":"/blog/lsp-of-solid.html","content":"里氏代换原则 LSP，Liskov Substitution Principle\n\n子类型必须能够替换掉它们的基类型\n\n\n若对每个类型S的对象O1，都存在一个类型T的对象O2，使得在所有针对T编写的程序P中，用O1替换O2后，程序P行为功能不变，则S是T的子类型\n\nLSP是继承关系设计基本原则，也是使OCP成为可能的主要原则之一。正是子类型的可替换性才使得使用基类类型的模块在无需修改的情况下就可以扩展，对于LSP的违反常常会导致以明显违反OCP的方式使用运行时类型辨别(RTTI),这种方式常常是使用一个显式的if语句或才if&#x2F;else链去确定一个对象的类型\n假设一个函数f，它的参数为指向某个基类B的指针或者引用。同样假设B的某个派生类D，如果把D对象作为B类型传递给f，会导致f出现错误的行为。那么D就违反了LSP。显然，D对于f来说是脆弱的。\nf的编写者会想去对D进行一些测试，以便于在把D的对象传递给f时，可以使f具有正确的行为。这个测试违反了OCP，因为此时f对于B的所有派生类都不再是封闭的\nIS-A“IS-A”是严格的分类学意义上的定义，意思是一个类是另一个类的“一种”\n我们经常说继承是IS-A关系，也就是如果一个新类型的对象被认为和一个已有类的对象之间满足IS-A关系，那么这个新对象的类应该从这个已用对象的类派生\n从一般意义上讲，一个正方形就是一个矩形。因此，把Sequare类视为从Rectangle类派生是合乎逻辑的\nvoid f(Rectangle r) &#123;    r.setWidth(5);    r.setHeight(4);    assert(r.Area() == 20)&#125;\n此时，如果传入的是Sequare对象，那这个函数f不能正确处理，也就是Squauare不能替换Rectangle，也就违反了LSP，意味着LSP与通常的数学法则和生活常识有不可混淆的区别\n在OOD中IS-A关系是就行为方式而言，而不是属性，这也就是面向接口编程；派生类的行为方式和输出不能违反基类已经确立的任何限制。基类的用户不应该被派生类的输出扰乱\n简单判断就是“可替换性”，子类是否能替换父类并保持原有行为不变\nLSP与架构LSP从诞生开始，也就差不多这些内容，主要是指导如何使用继承关系的一种方法。随着时间推移，在更宏观上，LSP逐渐演变成了一种更广泛的、指导接口与其实现方式的设计原则\n可以是java风格的接口，具有多个实现类：甚至可以是几个服务响应同一个rest接口，用户都依赖于一种接口，并且都期待实现该接口的类之间能具有可替换性\n一旦违背了可替换性，该系统架构就不得不为此增添大量复杂的应对机制\n","tags":["SOLID"]},{"title":"SOLID之DIP","url":"/blog/dip-of-solid.html","content":"依赖反转原则 DIP, Dependency inversion principle\n\n\n高层模块不应该依赖于低层模块。二者都应该依赖于抽象\n抽象不应该依赖于细节。细节应该依赖于抽象\n\n\n高低层首先理解一下什么高层和低层\n高层高层包含了一个应用程序中的重要策略选择和业务模型\n也就是业务逻辑是高层\n低层相对于高层，低层包括框架、数据库、消息队列等其它系统部分\n\n这也符合我们的预期，不管数据库，还是框架改变时，不应该影响到业务逻辑；也就是说业务逻辑不应该依赖于具体实现技术细节\n反转反转想起了IOC，之前总结了一篇《IOC理解》\nDIP里面指的反转是什么？\n\n这是一个典型的调用树例子，main函数调用了一些高层函数，这些高层函数又调用了一些中层函数，中层函数继续调用低层函数。源代码层面的依赖不可避免地要跟随程序的控制流\n这造成了程序耦合性特别的高，若程序需要改变实现方式，那就是灾难，也违反了OCP\n也导致了在软件架构上别无选择。系统行为决定了控制流，而控制流则决定了源代码依赖关系\n\n有这么多的问题，怎么办呢？ 反转\n\n反转依赖方向\n\n如何达到呢？利用面向对象的多态特性，这是面向对象编程的好处，也是面向对象的核心本质，无论面向怎么样的源代码级别的依赖关系，都可以将其反转\n\n控制流是从高层到低层，但低层模块与接口抽象类的方向正好相反\n面向对象编程就是以多态为手段来对源代码中的依赖关系进行控制能力\n架构师可以完全采用面向对象系统中所有源代码依赖关系，而不再受到系统控制流的限制。不管哪个模块调用或者被调用，架构师都可以随意更改源代码依赖关系\n\n业务逻辑控制用户界面与数据库，但源代码依赖关系相反，这样业务逻辑模块的源代码不需要引入用户界面和数据库两个模块，于是业务逻辑组件就可以独立于用户界面和数据库独立部署，不会对业务逻辑产生任何影响\n反转：控制流方向与源代码依赖关系方向相反，源代码依赖方向永远是控制流方向的反转\n分层延伸一下DIP，探讨一下分层架构\n架构模式有很多种，分层、六边形等等，分层架构是运用最为广泛的架构模式\n为什么要分层虽然分层架构很流行，尤其常用的MVC，但为什么需要分层呢？\n对系统的结构分层，把系统中相关联的部分被集中放在一个独立的层内，分而治之，这正好是SRP，每一层只能有一个引起他变化的原因\n如何分层呢？变化原因可以有多个维度\n一、基于关注点,如MVC，其上面向用户的体验与交互，中间面向应用与业务逻辑，其下面向各种外部资源与设备\n二、基于变化，针对不同变化原因确定层次边界，如数据库结构的修改自然会影响到基础设施的数据模型以及领域层的领域模型，但当我们仅修改数据库访问实现时，就不应该影响到领域层\n不管以何种原因将软件切割成不同的层，至少有一层是只包含该软件的业务逻辑的，而用户接口、系统接口则属于其他层\n\n\n源码中的依赖关系必须只指向同心圆的内层，即由低层机制指向高层策略\n\nEntities业务实体：封装了整个系统的关键业务逻辑，一个业务实体既可以是一个带有方法的对象，也可以是一组数据结构和函数集合。\n如果我们写的不是一个大型系统，而是一个单一应用的话，那么我们的业务实体就是该应用的业务对象。这些对象封装了该应用中最通用、最高层的业务逻辑\n而分层也不必为经典的三层架构又或是DDD的四层的固有思维，而是将分层视为关注点分离的水平抽象层次的体现。层太少可能导致关注点不够分离，导致系统的结构不合理；层太多则引入太多的间接而增加不必要的开支\n层协作在固有认知中，分层架构的依赖都是自顶向下传递的\n比如：Controller依赖Service，Service依赖Dao;如此控制流决定了源代码的依赖关系，也就是没有反转，是违背DIP的\n从DIP定义，为什么要依赖抽象呢？除了能反转从而解耦，还有别的原因吗？\n我们每次修改接口时，一定会去修改实现；但修改实现时不一定修改接口；也就是抽象比实现稳定，抽象层相对是个稳定的层次；抓住不变的，控制住变化的，是我们的目标，优秀工程师就得多花时间在设计接口上，减少未来对其改动，争取在不修改接口的情况下增加新功能\n其实除了自顶向下的请求也有自底向上的通信：通知，观察者模式，在上层定义Observer接口，提供update()方法供下层在感知状态发生变更时高用\n层与层之间的协作，就得借助DIP，打破高层依赖低层的固有思维，从解除耦合的角度探索层之间可能的协作关系，再配合IOC，具体依赖关系由IOC框架实现，更好地解除了高层对低层的依赖\n实践\n在代码中多使用抽象接口，尽量避免使用那些多变的具体实现类\n不要在具体实现类上创建子类\n不要override包含具体实现的函数\n应避免在代码中写入与任何具体实现相关的名字，或者是其它容易变动的事物的名字\n\n","tags":["SOLID"]},{"title":"SOLID之LOD","url":"/blog/lod-of-solid.html","content":"迪米特法则 Law of Demeter\nLOD\n最早出现于 1987年，由美国东北大学的伊恩·霍兰德（Ian Holland）提出。也叫做“最少知识原则”。\n\n\nEach unit should have only limited knowledge about other units: only units “closely” related to the current unit. Or: Each unit should only talk to its friends; Don’t talk to strangers.\n\n\n\n\n高内聚低耦合我们设计的目标就是高内聚低耦合，是否高内聚关键在于封装性\n看段代码：\nString name = book.getAuthor().getName();\n可以推断出这行代码是获得一部作品作者的名字。\n正常都能写出这段代码，因为在同一模块下大多数代码都是同一个人写的，所以Book和Author两个类都清楚里面的细节。但如果是不同人写的呢？至少得问下别人，作者名字在哪个类？或者翻阅类中实现细节。\n从接口设计角度，外部只能知道Book对象，而Book中关联的对象细节是不需要知道的，这正是封装性的体现，降低认知负载。\n而这也正好违背了LOD原则。\n不该有直接依赖关系的类之间，不要有依赖；\n有依赖关系的类之间，尽量只依赖必要的接口。\n迪米特法则是希望减少类之间的耦合，让类越独立越好。LOD功效正是指导我们能设计出高内聚、\n所以上面的代码得改动一下Book类\nclass Book &#123;   public String getAuthorName()&#123;        return author.getName();   &#125;&#125;\n\n谁是朋友？既然LOD指出只跟自己的朋友交流，那得搞清楚谁是朋友？\n对于一个类C，它拥有的一个方法称为M。方法M发送信息的目标对象必须为：\n\nM方法的参数对象，还有对自身的引用（被方法M创建的实例对象、被方法M调用的方法生成的实例对象、全局对象）。\n类C的实例对象。\n\n把上面的情况拆解开：\n\n本身(this,self)\n方法M的参数对象(parameter)\n类C内实例变量引用的对象(instance variable)\n被方法M创建的对象 或 方法M调用的方法创建的对象\n如果实例变量是集合，集合中的对象(collection,aggregration)\n\n示例在正统的SOLID原则中，都不包含LOD原则，但它确实能很好地指导我们如何封装，达到高内聚的目标。\n下面看两个常见到的问题作为示例，进一步理解这个原则。\n流式API上面提到的代码\nString name = book.getAuthor().getName();\n开始没有意识到违背LOD，但至少会有null情况，所以会改成\nif(book != null) &#123;    Author author = book.getAuthor();    if(author != null) &#123;        name = author.getName();    &#125;&#125;\n如果有好几层,就会嵌套很多层。\n但从JDK8之后，有了Optional，代码就变成了\nname = Optional.ofNullable(book).map(Book::getAuthor).map(Author::getName);\n\n虽然这样子很简洁地解决了null的问题，但是不是一样违背LOD呢？\n延伸一下，是不是链式调用都违反了LOD，毕竟形式上的确很像，一个连接符接着一个连接符。\nReport report = new ReportBuilder()  .withBorder(1)  .withBorderColor(Color.black)  .withMargin(3)  .withTitle(&quot;Law of Demeter Report&quot;)  .build();\n\n如我们常见的builder方式，每次返回的都是self。根据“谁是朋友”的定义是允许的。这是简单的示例，但像上面的Optional呢？\n每次Optional.map之后，其实并不是最初的Optional对象了，Stream也一样，每次返回的都是一个新的Stream对象。\n怎么解释这种问题呢？这个问题其实有很多人提出疑问，大概有这么几种回答：\n1、Stream shows that you are using it as intended by the Java language designers\n2、any standard library objects should be exempt from the Law of Demeter\n3、All these laws&#x2F;principles are rarely absolute and more guidelines than dogmas. In this case it might be about balancing LoD vs. KISS.\n所以结论是什么呢？\n我想重要的还是共识，团队内的共识。就像在JDK7~JDK8的过渡期，团队中有先行者引入了stream新特性，很多成员看得头大，制定了团队公约，不要使用stream。但现在fluent interface已经很亲民了，自然团队对stream有更高的认同，有了共识，谁还会抵制它。\nRESTful API再扩展一下，看到很长的RESTful风格的url，这是不是也有违背LOD原则的嫌疑？\n在RESTful API场景下，实体只有客户端和API提供者，API内部的实现细节也被API层屏蔽了，所以并不会违背LOD原则。\n总结LOD原则指导我们更好地封装，达到内聚性目标。但通过fluent interface，也认识到任何原则都是指导性，不可教条。考虑原则的同时，还得考虑ROI，而且还得与其它原则权衡，达到最适合的设计。\n参考资料The Genius of the Law of Demeter\nLOD原则的高明之处\n","tags":["SOLID"]},{"title":"SOLID之ISP","url":"/blog/solid-isp.html","content":"接口隔离原则，ISP，Interface Segregation Principle\n用于处理胖接口（fat interface）所带来的问题。如果类的接口定义暴露了过多的行为，则说明这个类的接口定义内聚程度不够好\n第一种定义: Clients should not beforced to depend upon interfaces that they don’t use.\n客户端不应该依赖它不需用的接口\n第二种定义：The dependency of oneclass to another one should depend on the smallest possible interface。\n类间的依赖关系应该建立在最小的接口上\n\nISP还是比较简单的，通过行为分离，达到高内聚效果\n不遵循ISP\n类A依赖接口I中的方法1、方法2、方法3，类B是对类A依赖的实现。类C依赖接口I中的方法1、方法4、方法5，类D是对类C依赖的实现。\n对于类B和类D来说，虽然他们都存在着用不到的方法（也就是图中红色字体标记的方法），但由于实现了接口I，所以也必须要实现这些用不到的方法\n显然接口I是个胖接口，客户端依赖了他不需要用的接口方法\n遵循ISP\n将原有的接口I拆分为三个接口，类A不需要用到“方法4”和“方法5”，就可以选择不依赖接口I3\n实例\n设计一个门接口，它包含了一款自动门所需要的功能，开关，自动关闭等。\n但是并不是每个门都有自动关闭的功能，所以timeOut超时这个方法放在该接口中，就会导致所有实现这个接口的子类都会默认的继承了这个方法，哪怕子类中不对这个方法做处理。\n\n把接口拆分成2个，拆分成Door和TimeClient，2个接口，这样Door就只保持原有的基本功能，而timeOut超时的方法则放到TimeClient接口中，这样就可以解决上述中接口臃肿的问题\nVS SRP很多人会觉的接口隔离原则跟之前的单一职责原则很相似，其实不然\n其一，单一职责原则原注重的是职责；而接口隔离原则注重对接口依赖的隔离。\n其二，单一职责原则主要是约束类，其次才是接口和方法，它针对的是程序中的实现和细节；而接口隔离原则主要约束接口接口，主要针对抽象，针对程序整体框架的构建\n\n在单一职责原则中，一个接口可能有多个方法，提供给多种不同的调用者所调用，但是它们始终完成同一种功能，因此它们符合单一职责原则，却不符合接口隔离原则，因为这个接口存在着多种角色，因此可以拆分成更多的子接口，以供不同的调用者所调用。\n比如说，项目中我们通常有一个Web服务管理的类，接口定义中，我们可能会将所有模块的数据调用方法都在接口中进行定义，因为它们都完成的是同一种功能：和服务器进行数据交互；但是对于具体的业务功能模块来说，其他模块的数据调用方法它们从来不会使用，因此不符合接口隔离原则\n架构在一般情况下，任何层次的软件设计如果依赖于不需要的东西，都会是有害。\n从源代码层次来说，这亲的依赖关系会导致不必要的重新编译和重新部署\n对更高层次的软件架构设计来说，问题也类似\n\n如果D中包含了F不需要的功能，那么这些功能同样也会是S不需要的。对D中这些功能的修改会导致F需要被重新部署，后者又会导致S的重新部署。\n更糟糕的是，D中一个无关功能的错误也可能会导致F和S运行出错\nTIPS采用接口隔离原则对接口进行约束时，要注意以下几点：\n\n接口尽量小，但是要有限度。对接口进行细化可以提高程序设计灵活性是不挣的事实，但是如果过小，则会造成接口数量过多，使设计复杂化。所以一定要适度。\n为依赖接口的类定制服务，只暴露给调用的类它需要的方法，它不需要的方法则隐藏起来。只有专注地为一个模块提供定制服务，才能建立最小的依赖关系。\n提高内聚，减少对外交互。使接口用最少的方法去完成最多的事情。\n\n运用接口隔离原则，一定要适度，接口设计的过大或过小都不好。设计接口的时候，只有多花些时间去思考和筹划，才能准确地实践这一原则\nReference《整洁架构之道》\nInterface Segregation Principle(ISP)–接口隔离原则\n","tags":["SOLID"]},{"title":"SOLID之OCP","url":"/blog/ocp-of-solid.html","content":"开闭原则 OCP Open-Closed Principle\n\n设计良好的计算机软件应该易于扩展，同时抗拒修改\n\n换句话说，一个良好的计算机系统应该在不需要修改的前提下就可以轻易被扩展\n遵循开闭原则设计出的模块具有两个特征：\n\n“对于扩展是开放的”，当应用的需求改变时，我们可以对模块进行扩展，使其具有满足那些改变的新行为\n“对于更改是封装的”，对模块进行扩展时，不必改动原有的代码\n\n其实这也是研究软件架构的根本目的。如果对原始需求的小小延伸就需要对原有的软件系统进行大幅修改，那么这个系统的架构设计显示是失败的\n一个好的软件架构设计师会努力将旧代码的修改需求量降至最小，甚至为0\n这原则看着很矛盾，需要扩展，但却又不要修改；那么如何实现这个原则呢？\n抽象，面向接口编程\n模块可以操作一个抽象体。由于模块依赖于一个固定的抽象体，所以它对于更改可以是关闭的。同时，通过从这个抽象体派生，也可以扩展此模块的行为\nclient,server都是具体类，client使用server\n\n如果client想使用另一个server对象，那么需要修改client中使用server的地方\n显然这样违反了OCP\n\n在新的设计中，添加了ClientInterface接口，此接口是一个拥有抽象成员函数的抽象类。Client类使用这个抽象类。如果我们希望client对象使用不同的server，只需要从clientinterface类派生一个新类，client无需任何修改\ninterface ClientInterface&#123;    public void Message();    //Other functions&#125; class Server:ClientInterface&#123;    public void Message();&#125; class Client &#123;   ClientInterface ci;   public void GetMessage()   &#123;       ci.Message();   &#125;   public void Client(ClientInterface paramCi)   &#123;       ci=paramCi;   &#125;&#125; //那么在主函数(或主控端)则public static void Main()&#123;   ClientInterface ci = new Server();   //在上面如果有新的Server类只要替换Server()就行了．   Client client = new Client(ci);   client.GetMessage();&#125;\n\n\nOCP设计类与模块时的重要原则，但是在架构层面，这项原则意义更重大。\n在设计时，可以先将满足不同需求的代码分组(SRP),然后再来调整这些分组之间的依赖关系(DIP)\nIOC是不是也有OCP的味道\nOCP算是面向对象设计的核心所在。遵循这个原则可以带来面向对象技术的巨大好处(灵活性，可重用性以及可维护性)\n然而，并不是说只要使用一种面向对象语言就得遵循这个原则。对于应用程序中每个部分都肆意地进行抽象同样不是一个好主意。正确的做法是，开发人员应该仅仅对程序中呈现出频繁变化的那些部分进行抽象，拒绝不成熟的抽象和抽象本身一样重要\n在一个复杂的软件中为什么会建议“尽量”不要违背OCP？\n最核心的原因就是一个现有逻辑的变更可能会影响一些原有的代码，导致一些无法预见的影响。这个风险只能通过完整的单元测试覆盖来保障，但在实际开发中很难保障单测的覆盖率。OCP的原则能尽可能的规避这种风险，当新的行为只能通过新的字段&#x2F;方法来实现时，老代码的行为自然不会变\n\nCommon Closure Principle（CCP）共同封闭原则\nCCP延伸了开闭原则（OCP）的“关闭”概念，当因为某个原因需要修改时，把需要修改的范围限制在一个最小范围内的包里\n一个包中所有的类应该对同一种类型的变化关闭。一个变化影响一个包，便影响了包中所有的类。一个更简短的说法是：一起修改的类，应该组合在一起（同一个包里）。如果必须修改应用程序里的代码，我们希望所有的修改都发生在一个包里（修改关闭），而不是遍布在很多包里。CCP原则就是把因为某个同样的原因而需要修改的所有类组合进一个包里。如果2个类从物理上或者从概念上联系得非常紧密，它们通常一起发生改变，那么它们应该属于同一个包。\nCCP还是解决分布式单体可怕的反模式的法宝\n在现流行的微服务架构中，按业务能力和子域以及SRP和CCP进行分解是将应用程序分解为服务的好方法\n","tags":["SOLID"]},{"title":"SOLID之SRP","url":"/blog/srp-of-solid.html","content":"单一职责原则  SRP，single responsibility principle\nSRP是所有原则中最简单的之一，也是最难正确运用的之一，也是我们日常中最常用的一个\n不管是编码，重构，甚至当下流行的微服务中\n在很多团队的规范中，都会听到一条编码规范：一个方法不要超过x行代码\n作为一群自命不凡的程序员，为什么在规范中却有如此一条格调不对称规范\n主要问题就在于思维对SRP的缺失\n\n微服务这个术语的一个问题是会将你的关注点错误地聚集在“微”上。它暗示服务应该非常小。很多团队在实施时，也是往小了去考虑，偏移了核心目标\n微服务的目标是将精心设计的服务定义为能够由小团队开发的服务，并且交付时间最短，与其它团队协作最小。\n理论上，团队可能只负责单一服务，因此服务绝对不是微小的\n单一从个人理解可以分为狭义与广义\n狭义： \n狭义只是从面向底层实现细节的设计原则\n\n一个类而言，应该仅有一个引起它变化的原因\n\n在日常中，在编写方法或者重构方法，也是以这个为原则，即确保一个函数只完成一个功能。\n在将大方法重构成小方法时经常会用到这个原则\n广义：\n相对狭义，适用的范围相对大些，不再是一个类，一个方法，亦或是一个原因\n\n任何一个软件模块都应该只对某一类行为者负责\n\n“软件模块”不再只是一个类，可以是一组紧密相关的函数和数据结构,甚至一个独立应用服务\n职责什么是职责？如果一个类承担多于一个职责，那么引起它变化的原因就会有多个\n在SRP中，职责定义为“变化的原因”，如果你能够想到多于一个的动机去改变一个类，那么这个类就具有多于一个的职责\n因此对于职责的定义需要结合具体业务，有时从感性上理解一个类的多个方法应该拆分，但如果应用程序的变化方式总是导致这几个职责同时变化，那么就不需要分离\n","tags":["SOLID"]},{"title":"Spring的Lazy与SmartInitializingSingleton","url":"/blog/springs-lazy-and-smartinitializingsingleton.html","content":"最近在工作中使用一个消息队列组件。发现当系统没有完全启动成功时，就开始消费消息了，出现所依赖资源初始化工作还没有完成，造成消费失败的情况。\n通过源码跟踪，发现组件开始消费是在InitializingBean#afterPropertiesSet中触发的。\n怎么处理呢？\n首先，InitializingBean#afterPropertiesSet是在Bean初始化完成后调用的。\n而现状是想在所有资源都被初始化完成后，再开始执行。\n第一种方案：SmartInitializingSingletonspring中提供了所有Bean初始化完成后再调用的机制。实现SmartInitializingSingleton\nSmartInitializingSingleton 与 InitializingBean两者有很大的区别：\n1，SmartInitializingSingleton只作用于单例bean，InitializingBean无此要求。但他们都不能用于懒加载的bean。\n2，SmartInitializingSingleton是在所有单例Bean都初始化完成后调用的，InitializingBean是每个bean初始化完成后就会调用。\n但因为是第三方组件，也不想修改源码，所以此路不通。\n第二种方案：想到了@Lazy把触发的Bean设置成@Lazy，再所有资源初始化完成后，进行主动加载。激活具体的消息消费行为。\n行动分两步：\n1、在具体消费消息的Bean上增加注解@Lazy\n2、spring启动完成后，再主动加载此Bean\n此时，又涉及到了spring的初始化过程\nspring提供了很多启动各个阶段的触发点\n包括ApplicationRunner、CommandLineRunner以及各种事件：\n\nApplicationContextInitializedEvent : triggered after ApplicationContext is prepared and ApplicationContextInitializers are called but before bean definitions are loaded\n\n\nApplicationPreparedEvent : triggered after bean definitions are loaded\n\n\nApplicationStartedEvent : triggered after context has been refreshed but before command-line and application runners are called\n\n\nApplicationReadyEvent : triggered after any application and command-line runners are called\n\n\nApplicationFailedEvent : triggered if there is an exception on startup\n\n结合spring初始化过程，写一个小示例，验证一下bean初始化与这些事件的先后顺序\n创建一个Bean\npublic class InitFirst implements InitializingBean, SmartInitializingSingleton &#123;    public InitFirst() &#123;        System.out.println(&quot;InitFirst construct method&quot;);    &#125;    public void init() &#123;        System.out.println(&quot;InitFirst init method&quot;);    &#125;    @PostConstruct    public void postConstruct() &#123;        System.out.println(&quot;InitFirst @PostConstruct&quot;);    &#125;    @Override    public void afterPropertiesSet() throws Exception &#123;        System.out.println(&quot;InitFirst afterPropertiesSet()&quot;);    &#125;    @Override    public void afterSingletonsInstantiated() &#123;        System.out.println(&quot;InitFirst afterSingletonsInstantiated()&quot;);    &#125;&#125;\n\n实现一下BeanPostProcessor\n@Componentpublic class InitBeanPostProcessor implements BeanPostProcessor &#123;    @Override    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123;        if (bean instanceof InitFirst || bean instanceof InitSecond) &#123;            System.out.println(&quot;postProcessBeforeInitialization:&quot; + beanName);        &#125;        return bean;    &#125;    @Override    @Nullable    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123;        if (bean instanceof InitFirst || bean instanceof InitSecond) &#123;            System.out.println(&quot;postProcessAfterInitialization:&quot; + beanName);        &#125;        return bean;    &#125;&#125;\n\n监听一下各种Event\n@Componentpublic class InitListener &#123;    @EventListener(ApplicationPreparedEvent.class)    public void preparedEvent() &#123;        System.out.println(&quot;Yaaah, ApplicationPreparedEvent&quot;);    &#125;    @EventListener(ApplicationStartedEvent.class)    public void startedEvent() &#123;        System.out.println(&quot;Yaaah, ApplicationStartedEvent&quot;);    &#125;    @EventListener(ApplicationReadyEvent.class)    public void runAfterStartup() &#123;        System.out.println(&quot;Yaaah, ApplicationReadyEvent&quot;);    &#125;&#125;\n\n最后执行的结果：\nInitFirst construct methodpostProcessBeforeInitialization:initFirstInitFirst @PostConstructInitFirst afterPropertiesSet()InitFirst init methodpostProcessAfterInitialization:initFirstInitSecond construct methodpostProcessBeforeInitialization:initSecondInitSecond @PostConstructInitSecond afterPropertiesSet()InitSecond init methodpostProcessAfterInitialization:initSecondInitFirst afterSingletonsInstantiated()InitSecond afterSingletonsInstantiated()Yaaah, ApplicationPreparedEventYaaah, ApplicationStartedEventApplicationRunnerCommandLineRunnerYaaah, ApplicationReadyEvent\n\n整个初始化的顺序：\nconstruct -&gt; postProcessBeforeInitialization -&gt; @PostConstruct -&gt; InitializingBean#afterPropertiesSet -&gt; init-method -&gt; postProcessAfterInitialization -&gt; ApplicationPreparedEvent -&gt; ApplicationStartedEvent -&gt;  ApplicationRunner&#x2F;CommandLineRunner -&gt; ApplicationReadyEvent\nApplicationRunner与CommandLineRunner谁先执行？\n在都没有标注order的情况下，ApplicationRunner 的优先级要高于CommandLineRunner\n在方案二执行时，发现了Spring延迟加载Lazy没有生效的情况，后来追查到是xxl-job的bug。在遍历任务时，加载了所有的bean，包含了Lazy的Bean。在最近的xxl-job 2.4版本中进行了修复：\n\nhttps://github.com/xuxueli/xxl-job/pull/3155/commits/b4835d40f18084e9facb9ec0d41993fdc885aca8\n参考资料Run method on Spring Boot startup\n","tags":["spring"]},{"title":"The clean coder 读书笔记","url":"/blog/the-clean-coder-reading-notes.html","content":"\n这本书不厚，但都是干货。\n在前言中，就写了本书的目的：\n\n\n什么是软件专业人士\n软件专业人士如何行事\n软件专业人士如何处理冲突，应对很紧的工期，如何和不讲道理的管理人员打交道\n软件专业人士何时应该说”不”？怎么说？\n软件专业人士如何应对压力？\n\n\n这些问题，也正是一名软件开发人员需要去了解的问题。\n\n所谓专业人士：就是能对自己犯下错误负责的人，哪怕那些错误实际上在所难免\n\n专业人士有哪些特性呢？\n\n不担当，比如代码测试的全覆盖\n不随便承诺\n不会阻止别人修改自己的代码\n满足雇主的需求\n需要专门训练提升自己的技能\n\n摘录一些干货，再对比一下当下的开发环境，那是相当贴切\n\n为什么大多数开发人员不敢不断修改他的代码呢？因为他们害怕会改坏代码！为什么会有这样的担心呢？因为他们没有做过测试\n\n这个对于现在的开发环境太真实了，在一个项目上线后，其实在开发中后期，就已经出现这样的情况\n\n一个方法，代码很乱，逻辑看着有点不通，出于对代码整洁的追求，重构起来，结果发布之后，出现了bug，原先功能已经不能正常运作了，而这个bug，得等很多才会被发现，因为这个功不在本期开发版本计划中，过了测试期了\n一个方法里面有行代码，看似无用，删除了吧，结果又出了一个隐形的bug\n\n正是以上问题，所以项目中的人越来越不敢动代码，不能删，不能改，只能加，有新需求，就只能加点代码，只要能正常工作，就不要管别的代码了，管了就得挂。\n这就是完全没有测试的问题。\n\n要用这些自动化单元测试去测多少代码呢？还要说吗？全部！全部都要测\n\n这一种方法，就是TDD，来规避这个问题。\n作者是TDD的践行者\n\n如果连所有代码是否都可以正常运行都不知道，还算什么专业人士？\n\n如果说多年前，很多人对TDD有疑问，当然现在还是有人有疑问，有疑问的原因，就是你还没有践行TDD。\n对于TDD：\n\n\n此事已有定论\n争论已经结束\nGOTO是有害的\nTDD确实可行\n\n\n有此人事先写代码，事后再写测试，这种方法相对于TDD来讲呢？\n\n如果很仔细地来看，也许后写测试还可以达到较高的覆盖率真。但是事后写的测试只是一种防守。而先行编写的测试则是进攻，事后编写测试的作者已经受制于已有代码，他已经知道问题是如何解决的。与采用测试先行的方式编写的测试代码比起来，后写的测试在深度和捕获错误的灵敏度方面要逊色很多\n\n一个开发方法，业界已经得到普遍认可，但国内有多少公司实施了？至少我所经历的公司都没有。聪明的开发者们宁可在出了问题花大量的精力去一步步调试，也不愿花一点点的时间去写单元测试，执行TDD。\n曾经在读云风博客时，发现一段有共鸣的话\n\n反感围绕着调试的开发方式，也是不断的在测试，试错，纠正的循环中奔波，好的程序员应该努力的在编写的过程中，在头脑中排错，在预感到坏味道时，就赶紧重写，而坏味道就是代码陷入了复杂度太高的境地，无法一眼看潜在的问题。对付复杂度最好的武器是简化代码\n\n\n在遇到bug时，应该仔细浏览代码，设想各种出错的可能。而不是将错误代码运行起来，查看运行中的状态变化\n\n这段话中不赞成的解决问题方式，其实是很多开发人员普遍具备的。\n作者在对编码也有相似的体会\n\n我发现，要精熟掌握每项技艺，关键都是要具备“信心”和“出错感知”能力。\n\n我想作者的“出错感知” 与 云风的“预感到坏味道” 是一样的\n作者给了一套了编码规则与原则\n\n做好准备\n\n快速响应，做出第一版本\n深入需求分析\n插件式，低耦合\n可读性，可维护性\n\n当感到疲劳，焦虑的时候，千万不要写代码\n\n流态区\n避免进入流态区\n\n\n\n这种意识状态并非真的极为高效，也绝非毫无错误。这其实只是一种“浅层冥想”状态，在这种状态下，为了追求所谓的速度，理性思考的能力会下降\n\n其实这不是我第一次听到的建议，不要进入流态区，只是一种精神酸爽，对于实质工作没有意义，因为进入了这种状态会出现只见树木不见森林，当时流线性的写出代码，事后经常会发现偏离了方向，不得不重写。\n\n中断\n作者给出了两种方法\n\n\n\n\n结对编程，让搭档维护住中断的上下文\nTDD，失败的测试能帮你维护住编码进度的上下文\n\n\n\n阻塞\n当情绪低落，焦虑，恐惧时，最好的方法：找一个搭档结对编程\n\n\n作者是一个TDD以及结对编程的提倡与践行人，在书可你可以看到很多次作者对这两种方法的推荐，可惜国内很少！\n书中有两个章节与近期订阅的李笑来老师文章有重合\n\n练习\n\n\n任何事情，只要想做得快，都离不开练习。两个武者搏斗，每个人都必须能够迅速识别出对方的意图，并且百分之一秒内正确应对。在搏斗中，你不可能有充足的时间来研究架势，思考如何应对，这时候你只能依靠身体的反应。实际上，真正做出反应的是你的身体，大脑是在更高级的层面上思考\n\n也就是李笑来老师提的刻意练习，如果程序员不去刻意练习，写各种demo,那么我想水平永远是hello world的水平了\n\n注意力\n注意力是稀缺的资源，它类似魔力点数，如果你用光了自己的注意力点数，必须花一个小时或更多的时间都不需要注意的事情，来补充它。\n\n\n\n 这是时间管理时提到的，李笑来也讲，注意力是你最宝贵的财富\n\n时间在本质上不属于你，你只能试着与它做朋友，让它为你所用。你的注意力才是你所拥有最重要、最宝贵的资源。你可以自己作主，要把它放在“成长”上。\n\n","categories":["读书"],"tags":["读书"]},{"title":"SOLID总结","url":"/blog/solid-summary.html","content":"之前已经把SOLID的每人原则都阐述过一遍，此篇主要是从全局角度复述一下SOLID，对于细节概念再做少许补充\nSOLID原则的历史已经很悠久，早在20世纪80年代末期，都已经开始逐渐成型了\n通常来讲，想构建一个好的软件系统，应该从写整洁的代码开始做起。毕竟如果建筑的砖头质量不佳，那么架构所能起到的作用也会很有限。反之亦然，如果建筑的架构设计不佳，那么其所用砖头质量再好也没用\nSOLID原则的主要作用就是告诉我们如何将数据和函数组织成为类，以及如何将这些类链接起来成为程序，类似于指导我们如何将砖块彻成墙与房间\n对照几张前辈们画的图，看图说话\n\n这张图把SOLID的整体关系描述清楚了，不再是把各个原则单独看待\n单一职责是所有设计原则的基础，开闭原则是设计的终极目标。\n里氏替换原则强调的是子类替换父类后程序运行时的正确性，它用来帮助实现开闭原则。\n而接口隔离原则用来帮助实现里氏替换原则，同时它也体现了单一职责。\n依赖倒置原则是过程式编程与OO编程的分水岭，同时它也被用来指导接口隔离原则\n\n这些原则每个单独看都是简单的，但他们却是优秀代码的指导思想，不得不常读，常思；犹如设计模式，很多时候你感觉懂了，不过只是懂了介绍模式的示例，并没有真正理解模式\n反观这些原则，道理类似\n如SRP：是公认最容易理解的原则，却是被违反得最多的设计原则之一；再比如ISP，看着简单，更小和更具体的瘦接口比庞大臃肿的胖接口好，很多时候都没有明白接口的定义\n在实现编写代码时，只要是service都会加上一个 service interface，但想想，从项目开启到后期维护，几乎没有一个 service interface 有一个以上的实现，那为什么要加个接口呢？美其名曰面向接口编程，其实是人云亦云，让自己也让别人看着是那么一回事而已\n面向接口编程所指的“接口”并非Java语言中的interface类型，而是指面向调用者对外暴露的接口，代表一种交互与协作，是对信息的隐藏和封装，而不是具体的interface类型。即使是普通的java方法仍然满足隐藏细节的原则，如果是public的，就可以认为该方法是“面向接口设计”中的接口，也就是说：不要针对实现细节编程，而是针对接口编程\n接口之所以存在，是为了解耦。开发者常常有一个错误的认知，以为是实现类需要接口。其实是消费者需要接口，实现类只是提供服务，因此应该由消费者（客户端）来定义接口。理解了这一点，才能正确地站在消费者的角度定义Role interface，而不是从实现类中提取Header Interface。\n对于Role interface 与 header interface , Martin Fowler给出了定义：\n\nA role interface is defined by looking at a specific interaction between suppliers and consumers. A supplier component will usually implement several role interfaces, one for each of these patterns of interaction. This contrasts to a HeaderInterface, where the supplier will only have a single interface\n\n如果你先定义了一个类，然后因为你需要定义接口对其抽象，然后就简单地将这个类的所有公有方法都提取到抽象的接口中，这样设计的接口，被Martin Fowler称为Header Interface,这种接口也正是胖接口的来源，而 Role interface 才是能达到瘦接口目标\n想起一位投资前辈说的话，成功就是对简单道理的深刻理解和灵活运用；我们很多时候有种无力感，为什么这么简单的道理都做不好，落地不了呢？其实是没有深刻理解而自以为懂了\n\n\nKent Beck对软件设计的定义：软件设计是为了在让软件在长期范围内容易应对变化\n为了软件更容易应对变化，就需要符合软件的道：高内聚低耦合\n单一职责和开放封闭，更多的在强调类划分时的高内聚；而里氏替换，依赖倒置，接口隔离则更多的强调类与类之间协作接口（即API）定义的低耦合,单独应用SOLID的某一个原则并不能让收益最大化。应该把它作为一个整体来理解和应用，从而更好地指导软件设计。\n这个同心圆的原图本来是：\n\n要实现道就得遵循正交设计四原则：\n\n消除重复\n分离关注点\n缩小依赖范围\n向稳定的方向依赖\n\n「正交设计」的理论、原则、及其方法论出自前ThoughtWorks软件大师「袁英杰」先生。这一块对我来讲很新颖，消化之后再总结\n\n\n这幅图揭示了模块化设计的全部：首先将一个低内聚的模块首先拆分为多个高内聚的模块；然后再考虑这多个模块之间的API设计，以降低这些高内聚的软件单元之间的耦合度。\n除了内聚与耦合之外，上面这幅图还揭示了另外一种关系：正交。具备正交关系的两个模块，可以做到一方的变化不会影响另外一方的变化。换句话说，双方各自独自变化，互不影响。\n而这幅图的右侧，正是我们模块化的目标。它描述了永恒的三方关系：客户，API，实现，以及它们之间的关系。这个三方关系图清晰的指出了我们应该关注的内聚性，耦合性，以及正交性都发生在何处\n总结：\n软件的复杂性已经是世界性难题，但最原始的道是相当简单的，就是要高内聚低耦合，在追求道的过程中，前人总结出了很多原则，这些原则相互协作、相互碰撞，我们需要平衡，取舍，这考验架构师的功力，也要求架构师对这些基本概念有深刻理解\n参考：\n《正交设计，OO 与 SOLID》\n你真的了解SOLID吗？\nRoleInterface\n","tags":["SOLID"]},{"title":"ThreadLocal解析","url":"/blog/threadlocal-parsing.html","content":"前言最近对于职业规划做了些思考，时间不等人，时机不等人；又是金三银四的好时机，今天当面试官虐人，明天被面试被人虐，相互伤害，爱恨情仇，一切都是缘分。\n一份简历，一两张A4纸，就要体现出一个人的真实水平，没点功力，还真是难。\n技术人都比较实在，不明白之前，感觉很高深，有难点，学了之后必有进步；但在搞过之后，发现不过如此，感觉都是理所当然，简单如是，不好意思跟人讲研究了什么，实在是太简单；\n正因为有如此思维，所以在写简历时无处下笔，感觉没什么优势可写，毫无亮点。要么就是简单写写项目经历，要么对着招聘简介看看，摘抄一些了\n不管怎么写，还是要写出自己的特长，把自己拿手的写出来，少不可怕，只要写出来的不被面试官难倒，就算成功。\n当然也不能为了体现多面手，乱写，熟悉XX，精通OO，了解MM，掌握GG；到面试时，被问得打脸就不好了。\n面试时态度端正也很重要，正面回答问题，有时其实对问题答案掌握不好，回避问题甚至绕弯弯，当然这还是看度的，不可绕太多，行家一出手就知有没有，诚恳点，知道多少说多少，知之为知之。\n\n面试官，我当得也不好，层次不清，岗位定位不清，有时为了招些优秀的，会问些不合岗位的问题，问得过难；\n还是要好好挖掘候选人简历，毕竟简历是展现的第一窗口，技术人书写能力差，不能很好的推销自己，所以还是要从简历中挖掘亮点，有时很精通，但写出来的很笼统，需要面试官去发现亮点了\nThreadLocal的意义这个类，好早就有了，JDK1.2就出现了。有时也会用一用，但他的作用是什么，很难表达了，难以表达，不能形成文字，说明了解的深度不够。\n\nThreadLocal为解决多线程程序的并发问题提供了一种新的思路；\nThreadLocal的目的是为了解决多线程访问资源时的共享问题。\n\n这基本上搜索到的threadlocal文章开头都是这样写的。\n然，谎言说多了就成了真理。\n但在JDK文档里面\n\n该类提供了线程局部 (thread-local)变量。这些变量不同于它们的普通对应物，因为访问某个变量（通过其 get 或 set 方法）的每个线程都有自己的局部变量，它独立于变量的初始化副本。ThreadLocal 实例通常是类中的 private static 字段，它们希望将状态与某一个线程（例如，用户 ID 或事务 ID）相关联。\n\nThreadLocal的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。\nThreadLocal和多线程并发没有什么关系。ThreadLocal模式是为了解决单线程内的跨类跨方法调用的\n\nThreadLocal不是用来解决对象共享访问问题的，而是为了处理在多线程环境中，某个方法处理一个业务，需要递归依赖其他方法时，而要在这些方法中共享参数的问题。\n例如有方法a()，在该方法中调用了方法b()，而在b方法中又调用了方法c()，即a–&gt;b—&gt;c，如果a，b，c都需要使用用户对象，那么我们常用做法就是a(User user)–&gt;b(User user)—c(User user)。\n但是如果使用ThreadLocal我们就可以用另外一种方式解决：  在某个接口中定义一个静态的ThreadLocal 对象，  例如 public static ThreadLocal  threadLocal&#x3D;new ThreadLocal ();  然后让a，b，c方法所在的类假设是类A，类B，类C都实现1中的接口  在调用a时，使用A.threadLocal.set(user) 把user对象放入ThreadLocal环境  这样我们在方法a，方法b，方法c可以在不用传参数的前提下，在方法体中使用threadLocal.get()方法就可以得到user对象。\n上面的类A，类B ，类C就可以分别对应我们做web开发时的 web层的Action—&gt;业务逻辑层的Service–&gt;数据访问层的DAO，当我们要在这三层中共享参数时，那么我们就可以使用ThreadLocal 了。\n\n在使用hibernate中常见的方法\npublic class HibernateUtil &#123;    private static Log log = LogFactory.getLog(HibernateUtil.class);    private static final SessionFactory sessionFactory;     //定义SessionFactory     static &#123;        try &#123;            // 通过默认配置文件hibernate.cfg.xml创建SessionFactory            sessionFactory = new Configuration().configure().buildSessionFactory();        &#125; catch (Throwable ex) &#123;            log.error(&quot;初始化SessionFactory失败！&quot;, ex);            throw new ExceptionInInitializerError(ex);        &#125;    &#125;    //创建线程局部变量session，用来保存Hibernate的Session    public static final ThreadLocal session = new ThreadLocal();     /**     * 获取当前线程中的Session     * @return Session     * @throws HibernateException     */    public static Session currentSession() throws HibernateException &#123;        Session s = (Session) session.get();        // 如果Session还没有打开，则新开一个Session        if (s == null) &#123;            s = sessionFactory.openSession();            session.set(s);         //将新开的Session保存到线程局部变量中        &#125;        return s;    &#125;     public static void closeSession() throws HibernateException &#123;        //获取线程局部变量，并强制转换为Session类型        Session s = (Session) session.get();        session.set(null);        if (s != null)            s.close();    &#125;&#125;\n\nThreadlocal源码这个类有以下方法：\n\nget()：返回当前线程拷贝的局部线程变量的值。\ninitialValue()：返回当前线程赋予局部线程变量的初始值。\nremove()：移除当前线程赋予局部线程变量的值。\nset(T value)：为当前线程拷贝的局部线程变量设置一个特定的值。\n\nget()方法public T get() &#123;        Thread t = Thread.currentThread();        ThreadLocalMap map = getMap(t);        if (map != null) &#123;            ThreadLocalMap.Entry e = map.getEntry(this);            if (e != null)                return (T)e.value;        &#125;        return setInitialValue();    &#125;\n根据当前线程，拿到ThreadLocalMap，通过当前threadloal对象取到value.\nprivate T setInitialValue() &#123;        T value = initialValue();        Thread t = Thread.currentThread();        ThreadLocalMap map = getMap(t);        if (map != null)            map.set(this, value);        else            createMap(t, value);        return value;&#125;    ThreadLocalMap getMap(Thread t) &#123;        return t.threadLocals;&#125;    void createMap(Thread t, T firstValue) &#123;        t.threadLocals = new ThreadLocalMap(this, firstValue);    &#125;\nThread.java 里面\nThreadLocalMap是Thread的属性\n/* ThreadLocal values pertaining to this thread. This map is maintained     * by the ThreadLocal class. */    ThreadLocal.ThreadLocalMap threadLocals = null;\n\n\n这个还跟之前的理解不太一样，以为是以当前threadId为key,取到值\n数据结构是这样的：\nthreadlocal&lt;threadId,value&gt;\n事实上结构是这样的：\nthread &lt;-&gt; threadlocalmap&lt;threadlocal,value&gt;\n每个Thread维护一个ThreadLocalMap映射表，这个映射表的key是ThreadLocal实例本身，value是真正需要存储的Object。\n\n这样设计的主要有以下几点优势：\n\n这样设计之后每个Map的Entry数量变小了：之前是Thread的数量，现在是ThreadLocal的数量，能提高性能，据说性能的提升不是一点两点\n当 Thread销毁之后对应的ThreadLocalMap也就随之销毁了，能减少内存使用量。\n\n\n内存泄露有些人认为在使用此类时，容易出现OOM\n\n\n如上图，ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用引用他，那么系统gc的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：\nThread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value\n永远无法回收，造成内存泄露。\n\n进一步分析一下ThreadlocalMap\n/**     * ThreadLocalMap is a customized hash map suitable only for     * maintaining thread local values. No operations are exported     * outside of the ThreadLocal class. The class is package private to     * allow declaration of fields in class Thread.  To help deal with     * very large and long-lived usages, the hash table entries use     * WeakReferences for keys. However, since reference queues are not     * used, stale entries are guaranteed to be removed only when     * the table starts running out of space.     */    static class ThreadLocalMap &#123;\n根据注释和代码，发现ThreadLocalMap并没有使用HashMap，而是重新实现了一个map，里面放的Entry\n/**         * The entries in this hash map extend WeakReference, using         * its main ref field as the key (which is always a         * ThreadLocal object).  Note that null keys (i.e. entry.get()         * == null) mean that the key is no longer referenced, so the         * entry can be expunged from table.  Such entries are referred to         * as &quot;stale entries&quot; in the code that follows.         */        static class Entry extends WeakReference&lt;ThreadLocal&gt; &#123;            /** The value associated with this ThreadLocal. */            Object value;            Entry(ThreadLocal k, Object v) &#123;                super(k);                value = v;            &#125;        &#125;\n\n/**         * Construct a new map initially containing (firstKey, firstValue).         * ThreadLocalMaps are constructed lazily, so we only create         * one when we have at least one entry to put in it.         */        ThreadLocalMap(ThreadLocal firstKey, Object firstValue) &#123;            //默认16长度            table = new Entry[INITIAL_CAPACITY];            //hashcode取模，得到坑位            int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);            table[i] = new Entry(firstKey, firstValue);            size = 1;            setThreshold(INITIAL_CAPACITY);        &#125;        /**         * Set the resize threshold to maintain at worst a 2/3 load factor.         */        private void setThreshold(int len) &#123;            threshold = len * 2 / 3;        &#125;        private void set(ThreadLocal key, Object value) &#123;\t\t\t// We don&#x27;t use a fast path as with get() because it is at\t\t\t// least as common to use set() to create new entries as\t\t\t// it is to replace existing ones, in which case, a fast\t\t\t// path would fail more often than not.\t\t\tEntry[] tab = table;\t\t\tint len = tab.length;\t\t\tint i = key.threadLocalHashCode &amp; (len - 1);\t\t\tfor (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123;\t\t\t\tThreadLocal k = e.get();\t\t\t\tif (k == key) &#123;\t\t\t\t\te.value = value;\t\t\t\t\treturn;\t\t\t\t&#125;\t\t\t\t//key在gc时，会被回收，变成null\t\t\t\tif (k == null) &#123;\t\t\t\t\treplaceStaleEntry(key, value, i);\t\t\t\t\treturn;\t\t\t\t&#125;\t\t\t&#125;\t\t\ttab[i] = new Entry(key, value);\t\t\tint sz = ++size;\t\t\tif (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)\t\t\t\trehash();\t\t&#125;private void replaceStaleEntry(ThreadLocal key, Object value, int staleSlot) &#123;\t\t\tEntry[] tab = table;\t\t\tint len = tab.length;\t\t\tEntry e;\t\t\t// Back up to check for prior stale entry in current run.\t\t\t// We clean out whole runs at a time to avoid continual\t\t\t// incremental rehashing due to garbage collector freeing\t\t\t// up refs in bunches (i.e., whenever the collector runs).\t\t\tint slotToExpunge = staleSlot;                        //替换掉之前有key=null的\t\t\tfor (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len))\t\t\t\tif (e.get() == null)\t\t\t\t\tslotToExpunge = i;\t\t\t// Find either the key or trailing null slot of run, whichever\t\t\t// occurs first\t\t\tfor (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123;\t\t\t\tThreadLocal k = e.get();\t\t\t\t// If we find key, then we need to swap it\t\t\t\t// with the stale entry to maintain hash table order.\t\t\t\t// The newly stale slot, or any other stale slot\t\t\t\t// encountered above it, can then be sent to expungeStaleEntry\t\t\t\t// to remove or rehash all of the other entries in run.\t\t\t\tif (k == key) &#123;\t\t\t\t\te.value = value;\t\t\t\t\ttab[i] = tab[staleSlot];\t\t\t\t\ttab[staleSlot] = e;\t\t\t\t\t// Start expunge at preceding stale entry if it exists\t\t\t\t\tif (slotToExpunge == staleSlot)\t\t\t\t\t\tslotToExpunge = i;\t\t\t\t\tcleanSomeSlots(expungeStaleEntry(slotToExpunge), len);\t\t\t\t\treturn;\t\t\t\t&#125;\t\t\t\t// If we didn&#x27;t find stale entry on backward scan, the\t\t\t\t// first stale entry seen while scanning for key is the\t\t\t\t// first still present in the run.\t\t\t\tif (k == null &amp;&amp; slotToExpunge == staleSlot)\t\t\t\t\tslotToExpunge = i;\t\t\t&#125;\t\t\t// If key not found, put new entry in stale slot\t\t\ttab[staleSlot].value = null;\t\t\ttab[staleSlot] = new Entry(key, value);\t\t\t// If there are any other stale entries in run, expunge them\t\t\tif (slotToExpunge != staleSlot)\t\t\t\tcleanSomeSlots(expungeStaleEntry(slotToExpunge), len);\t\t&#125;\n\n在这个过程中遇到的key为null的Entry都会被擦除，那么Entry内的value也就没有强引用链，自然会被回收。将key为null的这些Entry都删除，防止内存泄露。\n\n\n但是光这样还是不够的，上面的设计思路依赖一个前提条件：要调用ThreadLocalMap的getEntry函数或者set函数。这当然是不可能任何情况都成立的，所以很多情况下需要使用者手动调用ThreadLocal的remove函数，手动删除不再需要的ThreadLocal，防止内存泄露。所以JDK建议将ThreadLocal变量定义成private static的，这样的话ThreadLocal的生命周期就更长，由于一直存在ThreadLocal的强引用，所以ThreadLocal也就不会被回收，也就能保证任何时候都能根据ThreadLocal的弱引用访问到Entry的value值，然后remove它，防止内存泄露\n\n为什么使用弱引用\nTo help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys.为了应对非常大和长时间的用途，哈希表使用弱引用的 key\n\n\nkey 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。\nkey 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除\n\n比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。\n因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。\n总结ThreadLocal的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。\n\n不是为了解决多线程共享同步之类的作用\n\nThreadLocal变量定义成private static,不要定义成局部变量\n\n\n参考资料http://www.iteye.com/topic/617368\nhttp://qifuguang.me/2015/09/02/[Java%E5%B9%B6%E5%8F%91%E5%8C%85%E5%AD%A6%E4%B9%A0%E4%B8%83]%E8%A7%A3%E5%AF%86ThreadLocal/\n","tags":["ThreadLocal"]},{"title":"httpRequest中重复读取inputstream注意事项","url":"/blog/precautions-for-repeatedly-reading-inputstream-in-httprequest.html","content":"在Filter中获取请求体，就得解析一次request的inputStream。\n而在tomcat的设计中，request的inputStream只能读取一次，读取完一次后，虽然inputStream还在那，也不会变成空，但里面的内容已经被没有了。\n解决方案很简单，就是继承HttpServletRequestWrapper，缓存request中流的内容。\n比如实现一个类:ServletRequestReadWrapper\n整个类的结构是这样的：\n\n然而世事总不那么一帆风顺。\n当请求头Content-Type值为 multipart&#x2F;form-data 时，情况就出现了问题。在https://www.zhihu.com/question/434950674 这个回答中有说明。\n在使用multipart&#x2F;form-data上传文件时，controller类似这样的\n@PostMappingpublic void upload(MultipartFile file) throws IOException &#123;&#125;\n\n想要得到一个MultipartFile类型的内容，原理与其他类型一样，spring从request中获得流内容，并反射创建MultipartFile。\n但相对于普通类型，Multipart并没有从request.getInputstream中获取内容，而是从另一个方法getParts里面获取，但getParts返回的内容也是解析的request.getInputStream中的内容。\n\n是不是有点奇怪，为什么在wrapper里面已经缓存了inputstream内容，为什么到了右下解再去getInputStream时，却没有了呢？\ntomcat的request类结构是一个装饰器模式\n\nrequestWrapper中的getInputStream其实还得来源于真实的Request对象。而在整个处理过程的末端，获取inputStream，并不是从requestWrapper中获取的，而是从真实的Request对象中获取。此时流内容已经被读取过，自然就读取不到了。\n再回味下主要的源码，HttpServletRequestWrapper中getParts()\n@Overridepublic Collection&lt;Part&gt; getParts() throws IOException, ServletException &#123;    return this._getHttpServletRequest().getParts(); &#125;private HttpServletRequest _getHttpServletRequest() &#123;    return (HttpServletRequest) super.getRequest();&#125;\n\n到了RquestFacade的getParts()\n@Overridepublic Collection&lt;Part&gt; getParts() throws IllegalStateException,        IOException, ServletException &#123;    return request.getParts();&#125;\n\n再到Request的getParts()\npublic Collection&lt;Part&gt; getParts() throws IOException, IllegalStateException,            ServletException &#123;        parseParts(true);&#125;private void parseParts(boolean explicit) &#123;...//解析流中文件内容，upload.parseRequest中会调用request.getInputStream//而传入的request，并不requestWrapper，而是真实的Request本身//而此时Request中的流已经被读取过了，所以解析出的文件内容为空//controller中的file变成了nullList&lt;FileItem&gt; items = upload.parseRequest(new ServletRequestContext(this));...&#125;\n\n\n到此，原理已经讲清楚了。怎么解决呢？\n1、在Wrapper中，非multipart缓存inputstream，是multipart时，则缓存parts\npublic ServletRequestReadWrapper(final HttpServletRequest request) throws IOException, ServletException &#123;    super(request);    if (HttpUtils.isMultipartContent(request)) &#123;        parts = request.getParts();    &#125; else &#123;        final ServletInputStream is = request.getInputStream();        if (null != is) &#123;            final ByteArrayOutputStream os = new ByteArrayOutputStream();            this.bodyLength = ByteStreams.copy(is, os);            this.body = os.toByteArray();        &#125;    &#125;&#125;\n\n2、放弃multipart的消息体。\n得到消息体的内容，有时只是为了记录日志，像文件上传，其实得到的消息体也没啥好记录的，所以放弃记录mulipart类型消息体。\n"},{"title":"motan入门","url":"/blog/introduction-to-motan.html","content":"motan weibo的RPC框架，Motan是一套高性能、易于使用的分布式远程服务调用(RPC)框架\n这次在项目中引入了此框架。\n在使用中学习。研读下源码。记录下使用学习过程。\nRPC原理\n什么是Stub？\nStub是一段代码，用来转换RPC过程中传递的参数。处理内容包括不同OS之间的大小端问题。另外，Client端一般叫Stub，Server端一般叫Skeleton。\n生产方式：1）手动生成，比较麻烦；2）自动生成，使用IDL（InterfaceDescriptionLanguate），定义C&#x2F;S的接口。\n交互机制标准：一般采用IDL，生成IDL的工具 RPCGEN（）。\n为什么引入motan引入它，主要是因为它能满足项目需求；\n\n它比较牛，支撑了整个weibo\n集成了spring,基本无侵入\n具有集群功能，支持zookeeper\n\n还有别的优点了，官方文档写得很漂亮，但这几点已经足以吸引我\nmotan demo直接官方示例吧，也可以\nfork me\n我会在阅读源码的过程中，加上注释\n","categories":["源码解读"],"tags":["motan"]},{"title":"code review","url":"/blog/code-review.html","content":"也不知code review是从哪年开始流行的，我的职场经历从刚开始完全没有到1对1，再到团队式review\n一、Review Meeting\n优点： \n\n团队内新技术&#x2F;新观点的交流Meeting、项目开发思路、解决方案讨论，偏头脑风暴式；\n各类项目都适合进行；\n\n缺点： \n\n依赖于主持者（项目owner）的素质、时间成本高（为会议上所有人时间的总和）；\n集体评审的代码行数有限；\n\n二、Single Review\n优点： \n\n更偏重与具体的代码评审，人员分散参与，评审代码行数有保证；\n时间自由，reviewer什么时候进行评审时间可自控；\n\n缺点： \n\n依赖reviewer的技术水平，代码提交合并前强审核，只适用于重要项目或核心模块；\n\nwhy为什么需要code review，其实在任何行业，基本都是大厂带给整个行为最佳实践，code review就是其中一种实践\n\nThe biggest thing that makes Google’s code so good is simple: Code Review.\n\n\nAt Google, no code, for any product, for any project, gets checked in until it gets a positive review.\n\ncode review的好处可以罗列出很多很多，设计、结构、编码方方面面\n\n代码有这几种级别：1）可编译，2）可运行，3）可测试，4）可读，5）可维护，6）可重用。通过自动化测试的代码只能达到第3）级，而通过Code Review的代码少会在第4）级甚至更高\n\n\nCode Review主要是让你的代码可以更好的组织起来，有更易读，有更高的维护性，同时可以达到知识共享，找到bug只是其中的副产品\n\n以我个人经验看，code review更多是技术及业务知识的分享，甚至可以相互结合，理论分享与code的结合\n比如check list与最佳实践结合\nhowcode review有点类似TDD，但强于TDD，这儿的强于不是说功能性，而在于落地层面，只要大家坐一起，指点江山，就可以完成了，当然效果另说\n怎么更好地落地code review呢？或者说code review需要review些什么？code?\n每个团队都有各自的情况，所以并不是随便拿一份review check list对照就做好，至少侧重点不同\n比如人家团队人员素质普遍高一些，那人家的checklist可能就少了些基础知识点；团队职责不同，checklist也可能会相应不同，基础架构的checklist肯定跟业务线的不一样，各个不同业务线的也不同，需要根据团队情况制定合适的checklist\n极端情况，团队中无人能识别好代码，每次都是流水帐式看代码，那团队人员得流动一下了\n如何code review，结合why谈谈一些点\n\n不要挑毛病这就是上面的图中显示的，尤其团队式review，一群坐在下面的人\n\n命名不太好啦\n空格太多了\n方法太长了\n编码没格式化啊\n这循环用lambda一行解决问题\n实现的不是产品要的\n这设计有问题啊\n\n对1~4点，这些纯粹是浪费时间，一个团队的时间是宝贵的，来review这些，极大的浪费\n因此需要明确两点：\n\nCode review 不应该承担发现代码错误的职责\nCode review 不应该成为保证代码风格和编码标准的手段\n\n【管理工具化、工具流程化】指导方针，这儿可以引入checkstyle工具，让团队统一code sytle,新人加入团队时的培训指南中，并加入到CI中，检查失败直接构建失败\n再引入sonar识别常见质量问题和安全问题，这样提高code review的质量\n第5点：这也很典型，从code review层面讲，这也不应该是code review的职责，但从知识分享角度讲，这的确是，怎么办呢？使用流还是经典的for循环最好，如果团队成员对同一段代码有不同的意见，那么开发人员应该如何进行修改，结束审阅，并将代码推送到生产中？\n解决这个问题最好能有一套最佳实践标准，明确什么情况使用流式，什么情况使用传统方式，其实这很难，真这样搞最佳实践会成为一本谁也学不完的手册，那只能说“这要看情况”，未尝不可，但需要有前提，团队中需要有一名裁决者来决定最终方案，而不能陷入长时间的争论\n好比service能不能跨业务调用dao，这也是无对错，需要是的团队的一致性和最初的决策方案，不必每次code review时无休争论\n6~7两点，这是最坑的，浪费了开发时间，也对代码作者造成极大打击，为什么到此时才发现，所以需要在开始前就得对功能设计和架构设计进行review，不能只看结果，得看起始与过程\n保证正确性这是code review的前提条件，如上述的6、7两点，不应该出现，一个优秀的工程师需要能够独当一面，能够在系统角度实现局部的良好设计，通过合理的测试方法论验证结果。能够用合理的数据结构、算法实现功能\n在技术驱动的团队里，即使需求很紧急，对于关键的功能，核心成员也会耐心地审视架构设计和实现方案，如何控制熵，如何用更合理的方式实现，如何考虑到未来的变化。技术驱动的团队里，应该持续进行对设计的调整和代码的微小重构与改良，时刻在整个系统的设计和表现（performance）角度审视自己的工作。这也是“系统思考”的核心。大部分的代码的熵增大难以控制，并不是因为没有好的架构，而是因为迭代中忽略了系统性的思考和审视，而是用局部的解决方案解决问题，在反复迭代后，复杂度过高导致控制熵变得异常困难。这是code review比较难解决的\n分享从上面所述，code review虽然能发现代码中的一些错误，但不应该是他的核心价值。正好在《DDD总结》中所述，“降低代码复杂度”是所有方法实践论的终极目标。降低复杂度、易于扩展是我们的目标。那么code review也应该是为实现这个目标的手段，因此code review需要去review设计的合理性（如实现方法，数据结构，设计模式，扩展性考虑等），是否存在大量重复代码等\n如何达到这些呢？需要发挥团队力量，三个臭皮匠顶过一个诸葛亮，代码终究是需要人去看的，通过与他人的交流，去寻求最佳实践，交流前提就是去分享自我，包括设计思想和实现路径\n小到与一个人分享，也就是一对一code reivew，这样让review的开发人员了解代码的设计和实现，即能得到别人的指导，又能传递自我，并且能互为backup,方便后期维护，减少项目风险\n大到与团队分享，产生技术氛围，让好的知识、设计在团队中分享，实现整体团队的成长和整体效益最大化\n也鉴于要去把代码与人分享，就更容易让大家写出更具可读性的代码，提高可维护性，随便也让别人发现除功能逻辑外的一些技术逻辑：比如数据库连接是否忘记关闭，线程池是否正确使用等等，也加强了checklist的广度和深度\nwhen什么时候code review，大多数时候都是在上线前才做这件事，但理论最佳时间应该在提测前，以防测试完成后，又要对代码做变动\n在实践时，可以拿出专门时间进行，以错开迭代发布的紧张期\n\n除了上述的方法论，team leader还要在如何更好地code review，让团队更有意愿地参与上花心思，让团队成为一个学习型组织，有工程师文化的组织\n"},{"title":"motan客户端","url":"/blog/motan-client.html","content":"RPC的本质方法调用对于程序员来讲是再正常不过的事了，object.method()，RPC的使用也一样，但底层对这一过程又切分开，有client和server两端，也就是调用者与实现者\n因为他们不再在同一进程中，需要通过网络跨JVM实现这一调用过程\n在java中的实现手法：动态代理+socket通信；这就是个套路，上层怎么封装实现，但底层就是这样，概莫能外\n请求过程motan的调用实现先画个简单的序列图，理清一下调用过程\nmotan与spring的结合，后面再写了，spring的扩展也很简单。\n基于对RPC本质的认识，可以先找到InvocationHandler的实现类RefererInvocationHandler\n这个接口就一个方法\npublic Object invoke(Object proxy, Method method, Object[] args)        throws Throwable;\n在这个方法里面就是去构造socket传输的request对象，request主要就是方法的签名信息与参数，传输到server端，去执行对应的实现方法\npublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;        if(isLocalMethod(method))&#123;            if(&quot;toString&quot;.equals(method.getName()))&#123;                return clustersToString();            &#125;            throw new MotanServiceException(&quot;can not invoke local method:&quot; + method.getName());        &#125;        DefaultRequest request = new DefaultRequest();        request.setRequestId(RequestIdGenerator.getRequestId());        request.setArguments(args);        request.setMethodName(method.getName());        request.setParamtersDesc(ReflectUtil.getMethodParamDesc(method));        request.setInterfaceName(clz.getName());        request.setAttachment(URLParamType.requestIdFromClient.getName(), String.valueOf(RequestIdGenerator.getRequestIdFromClient()));        // 当 referer配置多个protocol的时候，比如A,B,C，        // 那么正常情况下只会使用A，如果A被开关降级，那么就会使用B，B也被降级，那么会使用C        for (Cluster&lt;T&gt; cluster : clusters) &#123;            String protocolSwitcher = MotanConstants.PROTOCOL_SWITCHER_PREFIX + cluster.getUrl().getProtocol();            Switcher switcher = switcherService.getSwitcher(protocolSwitcher);            if (switcher != null &amp;&amp; !switcher.isOn()) &#123;                continue;            &#125;            request.setAttachment(URLParamType.version.getName(), cluster.getUrl().getVersion());            request.setAttachment(URLParamType.clientGroup.getName(), cluster.getUrl().getGroup());            // 带上client的application和module            request.setAttachment(URLParamType.application.getName(), ApplicationInfo.getApplication(cluster.getUrl()).getApplication());            request.setAttachment(URLParamType.module.getName(), ApplicationInfo.getApplication(cluster.getUrl()).getModule());            Response response = null;            boolean throwException =                    Boolean.parseBoolean(cluster.getUrl().getParameter(URLParamType.throwException.getName(),                            URLParamType.throwException.getValue()));            try &#123;                //真正执行                response = cluster.call(request);                return response.getValue();            &#125;\ninvoke交给了Cluster.call，而Cluster又给了HAStragy.call，HA策略通过loadbalance选择负载均衡策略得到Referer\nCluster是什么在InvocationHandler里面,调用了Cluster的call方法，从代码上看，它的本质就是Referer的集合，并且提供了HA服务以及负载均衡。而Referer是提供服务的一个抽象\nHA与LoadBalance\nHAHA策略，就提供了两种，\nfail-fastfail-fast很简单，调用失败就抛异常；\nfail-overfail-over相对fail-fast多了重试次数，如果失败，就重试一个referer\nLoadBalance这倒提供了不少\nRound-Robin这个很简单，一个一个往下轮询就行了，但需要记住上一次的位置\nrandom随机\nLeast Load这个motan实现有点意思\n\n由于Referer List可能很多，比如上百台，如果每次都要从这上百个Referer或者最低并发的几个，性能有些损耗，因此 random.nextInt(list.size())获取一个起始的index，然后获取最多不超过MAX_REFERER_COUNT的 状态是isAvailable的referer进行判断activeCount.\n\nlocalFirst\n本地服务优先获取策略：对referers根据ip顺序查找本地服务，多存在多个本地服务，获取Active最小的本地服务进行服务。当不存在本地服务，但是存在远程RPC服务，则根据ActivWeight获取远程RPC服务;当两者都存在，所有本地服务都应优先于远程服务，本地RPC服务与远程RPC服务内部则根据ActiveWeight进行\n\nNettyClient上层不管怎么选择服务，最后都需要传输层去传输，nettyclient就是传输作用。\n在DefaultRpcReferer中创建了一个nettyClient。向server发送远程调用\nprivate Response request(Request request, boolean async) throws TransportException &#123;\t\tChannel channel = null;\t\tResponse response = null;\t\ttry &#123;\t\t\t// return channel or throw exception(timeout or connection_fail)\t\t\tchannel = borrowObject();\t\t\tif (channel == null) &#123;\t\t\t\tLoggerUtil.error(&quot;NettyClient borrowObject null: url=&quot; + url.getUri() + &quot; &quot;\t\t\t\t\t\t+ MotanFrameworkUtil.toString(request));\t\t\t\treturn null;\t\t\t&#125;\t\t\t// async request\t\t\tresponse = channel.request(request);\t\t\t// return channel to pool\t\t\treturnObject(channel);\n使用了common-pool连接池\n在这儿是委托给了nettychannel.request()，nettyclient与nettychannel是什么关系呢？client有server地址,channel就是这个地址连接的通道。在nettychannel中\npublic Response request(Request request) throws TransportException &#123;\t    int timeout = nettyClient.getUrl().getMethodParameter(request.getMethodName(), request.getParamtersDesc(),\t            URLParamType.requestTimeout.getName(), URLParamType.requestTimeout.getIntValue());\t\tif (timeout &lt;= 0) &#123;               throw new MotanFrameworkException(&quot;NettyClient init Error: timeout(&quot; + timeout + &quot;) &lt;= 0 is forbid.&quot;,                       MotanErrorMsgConstant.FRAMEWORK_INIT_ERROR);           &#125;\t\tNettyResponseFuture response = new NettyResponseFuture(request, timeout, this.nettyClient);\t\tthis.nettyClient.registerCallback(request.getRequestId(), response);\t\tChannelFuture writeFuture = this.channel.write(request);\t\tboolean result = writeFuture.awaitUninterruptibly(timeout, TimeUnit.MILLISECONDS);\t\tif (result &amp;&amp; writeFuture.isSuccess()) &#123;\t\t\tresponse.addListener(new FutureListener() &#123;\t\t\t\t@Override\t\t\t\tpublic void operationComplete(Future future) throws Exception &#123;\t\t\t\t\tif (future.isSuccess() || (future.isDone() &amp;&amp; ExceptionUtil.isBizException(future.getException()))) &#123;\t\t\t\t\t\t// 成功的调用 \t\t\t\t\t\tnettyClient.resetErrorCount();\t\t\t\t\t&#125; else &#123;\t\t\t\t\t\t// 失败的调用 \t\t\t\t\t\tnettyClient.incrErrorCount();\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;);\t\t\treturn response;\t\t&#125;\n\n\n到此，整个请求过程已经完成。\n返回处理调用完成之后，总得得到结果才行\nmotan返回过程在上面nettychannel.request方法，会返回一个response，NettyResponseFuture这个类名就说明了一切，使用了Future模式。\n在返回response时，构造真实response\nprivate Response asyncResponse(Response response, boolean async) &#123;\t\tif (async || !(response instanceof NettyResponseFuture)) &#123;\t\t\treturn response;\t\t&#125;\t\treturn new DefaultResponse(response);\t&#125;\t\n真实response里面，使用futureresponse去取值\npublic DefaultResponse(Response response) &#123;        this.value = response.getValue();        this.exception = response.getException();        this.requestId = response.getRequestId();        this.processTime = response.getProcessTime();        this.timeout = response.getTimeout();    &#125;\n\n在futureresponse里面：\npublic Object getValue() &#123;\t\tsynchronized (lock) &#123;\t\t\tif (!isDoing()) &#123;\t\t\t\treturn getValueOrThrowable();\t\t\t&#125;\t\t\tif (timeout &lt;= 0) &#123;\t\t\t\ttry &#123;\t\t\t\t\tlock.wait();\t\t\t\t&#125; catch (Exception e) &#123;\t\t\t\t\tcancel(new MotanServiceException(&quot;NettyResponseFuture getValue InterruptedException : &quot;\t\t\t\t\t\t\t+ MotanFrameworkUtil.toString(request) + &quot; cost=&quot;\t\t\t\t\t\t\t+ (System.currentTimeMillis() - createTime), e));\t\t\t\t&#125;\t\t\t\t// don&#x27;t need to notifylisteners, because onSuccess or\t\t\t\t// onFailure or cancel method already call notifylisteners\t\t\t\treturn getValueOrThrowable();\t\t\t&#125; else &#123;\t\t\t\tlong waitTime = timeout - (System.currentTimeMillis() - createTime);\t\t\t\tif (waitTime &gt; 0) &#123;\t\t\t\t\tfor (;;) &#123;\t\t\t\t\t\ttry &#123;\t\t\t\t\t\t\tlock.wait(waitTime);\t\t\t\t\t\t&#125; catch (InterruptedException e) &#123;\t\t\t\t\t\t&#125;\t\t\t\t\t\tif (!isDoing()) &#123;\t\t\t\t\t\t\tbreak;\t\t\t\t\t\t&#125; else &#123;\t\t\t\t\t\t\twaitTime = timeout - (System.currentTimeMillis() - createTime);\t\t\t\t\t\t\tif (waitTime &lt;= 0) &#123;\t\t\t\t\t\t\t\tbreak;\t\t\t\t\t\t\t&#125;\t\t\t\t\t\t&#125;\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t\tif (isDoing()) &#123;\t\t\t\t\ttimeoutSoCancel();\t\t\t\t&#125;\t\t\t&#125;\t\t\treturn getValueOrThrowable();\t\t&#125;\t&#125;\n没有使用java.util.concurrent包中Condition,CountDownLatch之类的工具类，而是使用原始的wait,notify组合\n在NettyClient中,得到返回对象后，对responsefuter进行赋值\npipeline.addLast(&quot;handler&quot;, new NettyChannelHandler(NettyClient.this, new MessageHandler() &#123;\t\t\t\t\t@Override\t\t\t\t\tpublic Object handle(Channel channel, Object message) &#123;\t\t\t\t\t    //得到返回对象\t\t\t\t\t\tResponse response = (Response) message;                        //得到对应request的future\t\t\t\t\t\tNettyResponseFuture responseFuture = NettyClient.this.removeCallback(response.getRequestId());\t\t\t\t\t\tif (responseFuture == null) &#123;\t\t\t\t\t\t\tLoggerUtil.warn(\t\t\t\t\t\t\t\t\t&quot;NettyClient has response from server, but resonseFuture not exist,  requestId=&#123;&#125;&quot;,\t\t\t\t\t\t\t\t\tresponse.getRequestId());\t\t\t\t\t\t\treturn null;\t\t\t\t\t\t&#125;\t\t\t\t\t\tif (response.getException() != null) &#123;\t\t\t\t\t\t\tresponseFuture.onFailure(response);\t\t\t\t\t\t&#125; else &#123;\t\t\t\t\t\t\tresponseFuture.onSuccess(response);\t\t\t\t\t\t&#125;\t\t\t\t\t\treturn null;\t\t\t\t\t&#125;\t\t\t\t&#125;));\n\nresponseFuture的onsuccess方法,进行赋值并notify\npublic void onSuccess(Response response) &#123;\t\tthis.result = response.getValue();\t\tthis.processTime = response.getProcessTime();\t\tdone();\t&#125;private boolean done() &#123;\t\tsynchronized (lock) &#123;\t\t\tif (!isDoing()) &#123;\t\t\t\treturn false;\t\t\t&#125;\t\t\tstate = FutureState.DONE;\t\t\tlock.notifyAll();\t\t&#125;\t\tnotifyListeners();\t\treturn true;\t&#125;\n\n\n总结到此，客户端部分已经完成，主要就是两方面\n\n调用请求\n返回处理\n\n还有一些问题：\n\n客户端怎么服务发现的？\n服务降低怎么处理的？\n\n","categories":["源码解读"],"tags":["motan"]},{"title":"motan扩展机制","url":"/blog/motan-extension-mechanism.html","content":"motan第二篇,本来想写motan的rpc调用过程的，但项目中的需求需要对motan进行扩展，所以就先记录下\n引导在写一个框架或者在项目中提供一些底层服务时，都会有这种情况，会有一些默认的实现，但你知道这些默认实现只是很满足很基本的自身需求，开发人员可能会扩展，想自定义一个实现\n处理方式\n\n提供一个设置实现类的setter，开发者在初始化时调用一下\n提供配置入口，给个key,配置上自定义类名\n类似slf4j一样，提供桥接类\n\nSPImotan使用了spi的方式\nSPI(Service Provider Interface),服务提供接口；也是一种服务发现机制\n系统里抽象的各个模块，往往有很多不同的实现方案，比如日志模块的方案，xml解析模块、jdbc模块的方案等。面向的对象的设计里，我们一般推荐模块之间基于接口编程，模块之间不对实现类进行硬编码。一旦代码里涉及具体的实现类，就违反了可拔插的原则，如果需要替换一种实现，就需要修改代码。为了实现在模块装配的时候能不在程序里动态指明，这就需要一种服务发现机制。java spi就是提供这样的一个机制：为某个接口寻找服务实现的机制。有点类似IOC的思想，就是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要。\n\n在JDK6之前，你可能会自己定义一种服务提供的约定，在JDK6之后，java也提供了标准约定\n扩展者在jar包的META-INF/services/目录下放置与接口同名的文本文件 内容为接口实现类名，多个实现类名用换行符分隔\njava.util.ServiceLoader类来实现从配置文件中加载子类或者接口的实现类\nSPI与API的区别What is the difference between Service Provider Interface (SPI) and Application Programming Interface (API)?More specifically, for Java libraries, what makes them an API and/or SPI?the API is the description of classes/interfaces/methods/... that you call and use to achieve a goalthe SPI is the description of classes/interfaces/methods/... that you extend and implement to achieve a goalPut differently, the API tells you what a specific class/method does for you and the SPI tells you what you must do to conform.Sometimes SPI and API overlap. For example in JDBC the Driver class is part of the SPI: If you simply want to use JDBC, you don&#x27;t need to use it directly, but everyone who implements a JDBC driver must implement that class.The Connection interface on the other hand is both SPI and API: You use it routinely when you use a JDBC driver and it needs to be implemented by the developer of the JDBC driver。        \n\nJDK spi使用jdk自带的ServiceLoader写一个示例：\n一个接口\npublic interface Spi &#123;    public void provide();&#125;\n\n一个实现类\npublic class DefaultSpi implements Spi&#123;    @Override    public void provide() &#123;        System.out.println(&quot;默认spi实现&quot;);    &#125;&#125;\n\n入口类\n/** * 一个spi的demo * */public class SpiDemoMain&#123;    public static void main( String[] args )    &#123;        ServiceLoader&lt;Spi&gt; spiServiceLoader = ServiceLoader.load(Spi.class);        Iterator&lt;Spi&gt; spiIterator = spiServiceLoader.iterator();        while ( spiIterator.hasNext()) &#123;            spiIterator.next().provide();        &#125;    &#125;&#125;\n\n在META-INF文件夹里面新建个services文件夹，在services文件夹里面新建一个com.jjk.spi.Spi文件\n完整的代码可从https://github.com/zhuxingsheng/spidemo下载\nServiceLoader源码解析原理很简单，一个类实现这个SPI机制\n它的本质，也就是从某个地方加载服务实现类，文件名是服务接口名\n定义存放文件的地方\nprivate static final String PREFIX = &quot;META-INF/services/&quot;;\n\n类内部使用了延迟加载LazyIterator，在使用到了实现类时，才去实例化。\nprivate S nextService() &#123;            if (!hasNextService())                throw new NoSuchElementException();            String cn = nextName;            nextName = null;            Class&lt;?&gt; c = null;            try &#123;                                c = Class.forName(cn, false, loader);            &#125; catch (ClassNotFoundException x) &#123;                fail(service,                     &quot;Provider &quot; + cn + &quot; not found&quot;);            &#125;            if (!service.isAssignableFrom(c)) &#123;                fail(service,                     &quot;Provider &quot; + cn  + &quot; not a subtype&quot;);            &#125;            try &#123;            // 调用next方法时，才实例化                S p = service.cast(c.newInstance());                providers.put(cn, p);                return p;            &#125; catch (Throwable x) &#123;                fail(service,                     &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;,                     x);            &#125;            throw new Error();          // This cannot happen        &#125;\n\nmotan spimotan的spi，跟java spi差不多，但做了一些加强\n先看官方文档\n\n\n实现SPI扩展点接口\n\n\n\n\n实现类增加注解@Spi(scope &#x3D; Scope.SINGLETON)  &#x2F;&#x2F;扩展加载形式，单例或多例@SpiMeta(name &#x3D; “motan”)  &#x2F;&#x2F;name表示扩展点的名称，根据name加载对应扩展@Activation(sequence &#x3D; 100) &#x2F;&#x2F;同类型扩展生效顺序，部分扩展点支持。非必填增加SPI实现声明 ${classpath}&#x2F;MATA-INF&#x2F;services&#x2F;${SPI interface fullname}文件中添加对应SPI接口实现类全名。 可参照motan-core模块&#x2F;MATA-INF&#x2F;services&#x2F;下的配置\n\n\n主要类就是com.weibo.api.motan.core.extension.ExtensionLoader代码在https://github.com/zhuxingsheng/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/core/extension/ExtensionLoader.java#L100-99其实代码很简单，不需要额外的解读，都能看明白\n还有几个注解类\n@Spi  指定类生命周期\n@SpiMeta 给类一个别名，方便配置时使用\n","categories":["源码解读"],"tags":["motan"]},{"title":"motan服务端","url":"/blog/motan-server.html","content":"前引新年回来上班，记录下服务端的处理过程，就当热个身\n服务端的处理也有套路，不管上层怎么玩，最后还得是通过反射得到Method对象，再调用invoke()\n根据这张序列图，可以把服务端分为两部分\n\nNettyServer前面的算一部分，搭基础构建Exporter对象\nnettyserver后面的算一部分，找到对应method，invoke,通过网络返回\n\n构建Exporter对象结合spring其实在《motan客户端》时有提过，但没有深究；spring扩展自定义xml是个很老的技术了spring扩展xml文档\n\nspring通过XML解析程序将其解析为DOM树，通过NamespaceHandler指定对应的Namespace的BeanDefinitionParser将其转换成BeanDefinition。再通过Spring自身的功能对BeanDefinition实例化对象。\n\n\n在期间，Spring还会加载两项资料：\n\nMETA-INF&#x2F;spring.handlers\n\n\n\n指定NamespaceHandler(实现org.springframework.beans.factory.xml.NamespaceHandler)接口，或使用org.springframework.beans.factory.xml.NamespaceHandlerSupport的子类。2. META-INF&#x2F;spring.schemas \n\n\n在解析XML文件时将XSD重定向到本地文件，避免在解析XML文件时需要上网下载XSD文件。通过现实org.xml.sax.EntityResolver接口来实现该功能。\n\nConfigHandler解析完xml后，服务器通过ServiceConfigBean来监听spring容器加载完成。\n@Override    public void onApplicationEvent(ContextRefreshedEvent event) &#123;        if (!getExported().get()) &#123;            export();        &#125;    &#125;\n调用export()，构建Exporter；\npublic synchronized void export() &#123;        if (exported.get()) &#123;            LoggerUtil.warn(String.format(&quot;%s has already been expoted, so ignore the export request!&quot;, interfaceClass.getName()));            return;        &#125;        checkInterfaceAndMethods(interfaceClass, methods);        List&lt;URL&gt; registryUrls = loadRegistryUrls();        if (registryUrls == null || registryUrls.size() == 0) &#123;            throw new IllegalStateException(&quot;Should set registry config for service:&quot; + interfaceClass.getName());        &#125;        Map&lt;String, Integer&gt; protocolPorts = getProtocolAndPort();        for (ProtocolConfig protocolConfig : protocols) &#123;            Integer port = protocolPorts.get(protocolConfig.getId());            if (port == null) &#123;                throw new MotanServiceException(String.format(&quot;Unknow port in service:%s, protocol:%s&quot;, interfaceClass.getName(),                        protocolConfig.getId()));            &#125;            doExport(protocolConfig, port, registryUrls);        &#125;        afterExport();    &#125;\n这个方法主要就做了两件事\n\nloadRegistryUrls()，根据motan:registry,生成URL对象。URL也算是整个框架的核心，一个url包含了配置中的所有内容。就像一个领域对象一样。\n\n如果使用的是zookeeper，对就的URL就是：zookeeper:&#x2F;&#x2F;127.0.0.1:2181&#x2F;com.weibo.api.motan.registry.RegistryService?group&#x3D;default_rpc\n这是注册中心的URL\n而服务URL是以参数为embed为key包含在里面，里面包含了所有的服务参数\nmotan:&#x2F;&#x2F;127.0.0.1:8002&#x2F;com.share.rpc.service.DEMOService?module&#x3D;match-rpc&amp;loadbalance&#x3D;activeWeight&amp;nodeType&#x3D;service&amp;accessLog&#x3D;true&amp;minWorkerThread&#x3D;2&amp;protocol&#x3D;motan&amp;isDefault&#x3D;true&amp;maxWorkerThread&#x3D;10&amp;refreshTimestamp&#x3D;1486448597095&amp;id&#x3D;com.weibo.api.motan.config.springsupport.ServiceConfigBean&amp;export&#x3D;protocolMatch:8002&amp;requestTimeout&#x3D;60000&amp;group&#x3D;match-rpc&amp;\n\ndoExport()\n\nConfigHandler configHandler = ExtensionLoader.getExtensionLoader(ConfigHandler.class).getExtension(MotanConstants.DEFAULT_VALUE); exporters.add(configHandler.export(interfaceClass, ref, urls));\n到这儿就是委托给ConfigHandler处理了。\n默认的实现类：SimpleConfigHandler\n这个类里面有两个重要的方法：\n@Override    public &lt;T&gt; T refer(Class&lt;T&gt; interfaceClass, List&lt;Cluster&lt;T&gt;&gt; clusters, String proxyType) &#123;        ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getExtension(proxyType);        return proxyFactory.getProxy(interfaceClass, new RefererInvocationHandler&lt;T&gt;(interfaceClass, clusters));    &#125;    @Override    public &lt;T&gt; Exporter&lt;T&gt; export(Class&lt;T&gt; interfaceClass, T ref, List&lt;URL&gt; registryUrls) &#123;        String serviceStr = StringTools.urlDecode(registryUrls.get(0).getParameter(URLParamType.embed.getName()));        URL serviceUrl = URL.valueOf(serviceStr);        // export service        // 利用protocol decorator来增加filter特性        String protocolName = serviceUrl.getParameter(URLParamType.protocol.getName(), URLParamType.protocol.getValue());        Protocol protocol = new ProtocolFilterDecorator(ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(protocolName));        Provider&lt;T&gt; provider = new DefaultProvider&lt;T&gt;(ref, serviceUrl, interfaceClass);        Exporter&lt;T&gt; exporter = protocol.export(provider, serviceUrl);        // register service        register(registryUrls, serviceUrl);        return exporter;    &#125;\nrefer()就是RefererConfig配置完后的调用的方法，就看到了客户端的核心类RefererInvocationHandler\nexport()就是服务端使用的方法了。\n构造provider\npublic interface Provider&lt;T&gt; extends Caller&lt;T&gt; &#123;    Class&lt;T&gt; getInterface();&#125;\n其实就是外面服务类的代理类,里面就一个服务类的引用。在初始化时，把所有的方法全部缓存\nprivate void initMethodMap(Class&lt;T&gt; clz) &#123;        Method[] methods = clz.getMethods();        for (Method method : methods) &#123;            String methodDesc = ReflectUtil.getMethodDesc(method);            methodMap.put(methodDesc, method);        &#125;    &#125;\nProtocol的export就是启动一个netty server，提供对外服务。\nregister 注册服务按上面export()，先启动一个netty server，服务一切就绪后，再向注册中心进行注册了。\nprivate void register(List&lt;URL&gt; registryUrls, URL serviceUrl) &#123;        for (URL url : registryUrls) &#123;            // 根据check参数的设置，register失败可能会抛异常，上层应该知晓            RegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getExtension(url.getProtocol());            if (registryFactory == null) &#123;                throw new MotanFrameworkException(new MotanErrorMsg(500, MotanErrorMsgConstant.FRAMEWORK_REGISTER_ERROR_CODE,                        &quot;register error! Could not find extension for registry protocol:&quot; + url.getProtocol()                                + &quot;, make sure registry module for &quot; + url.getProtocol() + &quot; is in classpath!&quot;));            &#125;            Registry registry = registryFactory.getRegistry(url);            registry.register(serviceUrl);        &#125;    &#125;\n根据注册协议选择注册中心RegistryFacotry有三种：1. direct 2.local 3.zookeeper\n对应的registry也是这三种\n在zookeeperregistry里面，\nprotected void doRegister(URL url) &#123;        try &#123;            serverLock.lock();            // 防止旧节点未正常注销            removeNode(url, ZkNodeType.AVAILABLE_SERVER);            removeNode(url, ZkNodeType.UNAVAILABLE_SERVER);            createNode(url, ZkNodeType.UNAVAILABLE_SERVER);        &#125; catch (Throwable e) &#123;            throw new MotanFrameworkException(String.format(&quot;Failed to register %s to zookeeper(%s), cause: %s&quot;, url, getUrl(), e.getMessage()), e);        &#125; finally &#123;            serverLock.unlock();        &#125;    &#125;\n这儿注册后，这个服务还是unavailable，需要调用MotanSwitcherUtil.setSwitcherValue(MotanConstants.REGISTRY_HEARTBEAT_SWITCHER, true);才能变成available\nNettyServer一样的套路，有一个默认ChannelHandler，其实什么事都不干，只是包装一下自定义Handler\nfinal NettyChannelHandler handler = new NettyChannelHandler(NettyServer.this, messageHandler,\t\t\t\tstandardThreadExecutor);\t\tbootstrap.setPipelineFactory(new ChannelPipelineFactory() &#123;\t\t\t// FrameDecoder非线程安全，每个连接一个 Pipeline\t\t\tpublic ChannelPipeline getPipeline() &#123;\t\t\t\tChannelPipeline pipeline = Channels.pipeline();\t\t\t\tpipeline.addLast(&quot;channel_manage&quot;, channelManage);\t\t\t\tpipeline.addLast(&quot;decoder&quot;, new NettyDecoder(codec, NettyServer.this, maxContentLength));\t\t\t\tpipeline.addLast(&quot;encoder&quot;, new NettyEncoder(codec, NettyServer.this));\t\t\t\tpipeline.addLast(&quot;handler&quot;, handler);\t\t\t\treturn pipeline;\t\t\t&#125;\t\t&#125;);\n\n这儿有个有意思的MessageHandler:ProviderProtectedMessageRouter从名字看，有保护功能\n\n\n如果接口只有一个方法，那么直接return true \n如果接口有多个方法，那么如果单个method超过 maxThread &#x2F; 2 &amp;&amp; totalCount &gt;  (maxThread * 3 &#x2F; 4)，那么return false;\n如果接口有多个方法(4个)，同时总的请求数超过 maxThread * 3 &#x2F; 4，同时该method的请求数超过 maxThead * 1 &#x2F; 4， 那么return false\n其他场景return true\n\n\nprotected boolean isAllowRequest(int requestCounter, int totalCounter, int maxThread, Request request) &#123;        if (methodCounter.get() == 1) &#123;            return true;        &#125;        // 该方法第一次请求，直接return true        if (requestCounter == 1) &#123;            return true;        &#125;        // 不简单判断 requsetCount &gt; (maxThread / 2) ，因为假如有2或者3个method对外提供，        // 但是只有一个接口很大调用量，而其他接口很空闲，那么这个时候允许单个method的极限到 maxThread * 3 / 4        if (requestCounter &gt; (maxThread / 2) &amp;&amp; totalCounter &gt; (maxThread * 3 / 4)) &#123;            return false;        &#125;        // 如果总体线程数超过 maxThread * 3 / 4个，并且对外的method比较多，那么意味着这个时候整体压力比较大，        // 那么这个时候如果单method超过 maxThread * 1 / 4，那么reject        return !(methodCounter.get() &gt;= 4 &amp;&amp; totalCounter &gt; (maxThread * 3 / 4) &amp;&amp; requestCounter &gt; (maxThread * 1 / 4));    &#125;\n\n拒绝的结果就是放一个异常：\nprivate Response reject(String method, int requestCounter, int totalCounter, int maxThread) &#123;        DefaultResponse response = new DefaultResponse();        MotanServiceException exception =                new MotanServiceException(&quot;ThreadProtectedRequestRouter reject request: request_counter=&quot; + requestCounter                        + &quot; total_counter=&quot; + totalCounter + &quot; max_thread=&quot; + maxThread, MotanErrorMsgConstant.SERVICE_REJECT);        exception.setStackTrace(new StackTraceElement[0]);        response.setException(exception);        LoggerUtil.error(&quot;ThreadProtectedRequestRouter reject request: request_method=&quot; + method + &quot; request_counter=&quot; + requestCounter                + &quot; =&quot; + totalCounter + &quot; max_thread=&quot; + maxThread);        return response;    &#125;\n\notherRpcContextprivate static final ThreadLocal&lt;RpcContext&gt; localContext = new ThreadLocal&lt;RpcContext&gt;() &#123;        protected RpcContext initialValue() &#123;            return new RpcContext();        &#125;    &#125;;    public static RpcContext getContext() &#123;        return localContext.get();    &#125;\n这个ThreadLocal尽然还可以设置默认初始值，以前尽然没用过\n总结服务端相对客户端还是很简单的。\n没有ha,loadbalance，就是原生netty就把请求处理完了。\n","categories":["源码解读"],"tags":["motan"]},{"title":"socket与IO高性能","url":"/blog/socket-and-io-high-performance.html","content":"最近看到篇好文章《IO多路复用》，记得早期学习时，也去探索过select、poll、epoll的区别，但后来也是没有及时记录总结，也忘记了，学习似乎就是在记忆与忘记中徘徊，最后在心中留下的火种，是熄灭还是燎原就看记忆与忘记间的博弈\nsocket与io一对兄弟，有socket地方必然有io，io数据也大多来源于socket，回顾这两方面的知识点，大致梳理一下\nsocketSocket是应用层与TCP&#x2F;IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP&#x2F;IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议\n除了TCP协议（三次握手、四次挥手）知识点外，再就是各阶段与java api对应的方法\n\n三次握手关联到两个方法：服务端的listen()与客户端的connect()\n两个方法的共通点：TCP三次握手都不是他们本身完成的，握手都是内核完成的，他们只是通知内核，让内核自动完成三次握手连接\n不同点：connect()是阻塞的，listen()是非阻塞的\n三次握手的过程细节：\n\n\n第一次握手：客户端发送 SYN 报文，并进入 SYN_SENT 状态，等待服务器的确认；\n第二次握手：服务器收到 SYN 报文，需要给客户端发送 ACK 确认报文，同时服务器也要向客户端发送一个 SYN 报文，所以也就是向客户端发送 SYN + ACK 报文，此时服务器进入 SYN_RCVD 状态；\n第三次握手：客户端收到 SYN + ACK 报文，向服务器发送确认包，客户端进入ESTABLISHED 状态。待服务器收到客户端发送的 ACK 包也会进入ESTABLISHED 状态，完成三次握手\n\nioIO中常听到的就是同步阻塞IO，同步非阻塞IO，异步非阻塞IO；也就是同步、异步、阻塞、非阻塞四个词组合体，可从名字上看就不大对，既然同步，应该都是阻塞，怎么会有同步非阻塞？不知道哪位先贤的学习总结却流传深远\n还有些把non-blocking IO与NIO都混淆了\n对于IO模型，最正统的应该来自Richard Stevens的“UNIX® Network Programming Volume 1, Third Edition: The Sockets Networking ”，6.2节“I&#x2F;O Models”\n\nBlocking I&#x2F;O\nNon-Blocking I&#x2F;O\nI&#x2F;O Multiplexing\nAsynchronous I&#x2F;O\n\n在理解这四种常见模型前，先简单说下linux的机制，可以更方便理解IO，在《堆外内存》中提到linux的处理IO流程以及Zero-Copy技术，算是IO模型更深入的知识点\n应用程序发起的一次IO操作实际包含两个阶段：\n\n1.IO调用阶段：应用程序进程向内核发起系统调用\n2.IO执行阶段：内核执行IO操作并返回\n2.1. 准备数据阶段：内核等待I&#x2F;O设备准备好数据\n2.2. 拷贝数据阶段：将数据从内核缓冲区拷贝到用户空间缓冲区\n\n\n\n对于阻塞与非阻塞，讲的是用户进程&#x2F;线程与内核之间的切换；当内核数据没有准备好时，用户进程就得挂起\n对于同步与异步，重点在于执行结果是否一起返回,IO就是指read,send是否及时获取到结果\n大致分析一下，同步异步、阻塞非阻塞的两两组合其实是把宏观与微观进行了穿插，从应该程序角度获取结果是同步或异步，而IO内部再细分了阻塞与非阻塞\n由上文所述：IO操作分两个阶段 1、等待数据准备好(读到内核缓存) ，2、将数据从内核读到用户空间(进程空间)。 一般来说1花费的时间远远大于2。 1上阻塞2上也阻塞的是同步阻塞IO； 1上非阻塞2阻塞的是同步非阻塞IO，NIO，Reactor就是这种模型； 1上非阻塞2上非阻塞是异步非阻塞IO，AIO，Proactor就是这种模型。\n同步阻塞IO（Blocking IO）因为用户态被阻塞，等待内核数据的完成，所以需要同步等待结果\n\n同步非阻塞IO（Non-blocking IO）用户态与内核不再阻塞了，但需要不停地轮询获取结果，浪费CPU，这方式还不如BIO来得痛快\n\nIO多路复用Reactor模式,意为事件反应，操作系统的回调&#x2F;通知可以理解为一个事件，当事件发生时，进程&#x2F;线程对该事件作出反应。Reactor模式也称作Dispatcher模式，即I&#x2F;O多路复用统一监听事件，收到事件后分配（Dispatch）给某个进程&#x2F;线程\n\n对于IO多路复用，里面再有的细节就是一个优化过程，select,poll,epoll\n\nAIOProactor模式,Reactor可理解为“来了事件我通知你，你来处理”，而Proactor是“来了事件我处理，处理完了我通知你”。这里“我”是指操作系统，“你”就是用户进程&#x2F;线程\n\n四种模型对比\n对于IO模型的优化进程，一是操作系统的支持，减少系统调用，用户态与内核的切换；二是机制的变换，从命令式到响应性的转变\n\n高性能架构只温习Socket&#x2F;IO知识太无趣了，我们要温故知新，升华一下，从架构角度谈一谈\n从常规服务处理业务流程讲：request -&gt; process -&gt; response\n\n站在架构师的角度，当然需要特别关注高性能架构的设计。高性能架构设计主要集中在两方面：\n\n尽量提升单服务器的性能，将单服务器的性能发挥到极致。\n如果单服务器无法支撑性能，设计服务器集群方案。\n\n除了以上两点，最终系统能否实现高性能，还和具体的实现及编码相关。但架构设计是高性能的基础，如果架构设计没有做到高性能，则后面的具体实现和编码能提升的空间是有限的。形象地说，架构设计决定了系统性能的上限，实现细节决定了系统性能的下限。\n单服务器高性能的关键之一就是服务器采取的并发模型，并发模型有如下两个关键设计点：\n\n服务器如何管理连接\n服务器如何处理请求\n\n以上两个设计点最终都和操作系统的 I&#x2F;O 模型及进程模型相关。\n\nI&#x2F;O 模型：阻塞、非阻塞、同步、异步\n进程模型：单进程、多进程、多线程\n\n传统模式PPC&amp;TPCPPC，即Process Per Connection，为每个连接都创建一个进程去处理。此模式实现简单，适合服务器连接不多的场景，如数据库服务器\nTPC，即Thread Per Connection，为每个连接都创建一个线程去处理。线程创建消耗少，线程间通信简单\n这两种都是传统的并发模式，使用于常量连接的场景，如数据库（常量连接海量请求），企业内部（常量连接常量请求）\n至于是进程还是线程，大多与语言特性相关，Java语言由于JVM是一个进程，管理线程方便，故多使用线程，如Netty。C语言进程和线程均可使用，如Nginx使用进程，Memcached使用线程。\n不同并发模式的选择，还要考察三个指标，分别是响应时间（RT），并发数（Concurrency），吞吐量（TPS）。三者关系，吞吐量&#x3D;并发数&#x2F;平均响应时间。不同类型的系统，对这三个指标的要求不一样。\n三高系统，比如秒杀、即时通信，不能使用\n三低系统，比如ToB系统，运营类、管理类系统，一般可以使用\n高吞吐系统，如果是内存计算为主的，一般可以使用，如果是网络IO为主的，一般不能使用。\nReactor&amp;Proactor对于传统方式，显示只能适合常量连接常量请求，不能适应互联网场景\n如双十一场景下的海量连接海量请求；门户网站的海量连接常量请求；\n引入线程池也是一种手段，但也不能根本解决，如常量连接海量请求的中间件场景，线程虽然轻量但也有得消耗资源，终有上限\nReactor，意为事件反应，操作系统的回调&#x2F;通知可以理解为一个事件，当事件发生时，进程&#x2F;线程对该事件作出反应。Reactor模式也称作Dispatcher模式，即I&#x2F;O多路复用统一监听事件，收到事件后分配（Dispatch）给某个进程&#x2F;线程。\n可以看到，I&#x2F;O多路复用技术是Reactor的核心，本质是将I&#x2F;O操作给剥离出具体的业务进程&#x2F;线程，从而能够进行统一管理，使用select&#x2F;epoll去同步管理I&#x2F;O连接。\nReactor模式的核心分为Reactor和处理资源池。Reactor负责监听和分配事件，池负责处理事件\n如何高性能呢？就得IO多路复用，配合上进程、线程组合，就有：\n\n单Reactor 单进程 &#x2F; 线程\n单Reactor 多线程\n多Reactor 单进程 &#x2F; 线程(此实现方案相比“单 Reactor单进程”方案，既复杂又没有性能优势，所以很少实际应用)\n多Reactor 多进程 &#x2F; 线程\n\n单Reactor单线程\n在这种模式中，Reactor、Acceptor和Handler都运行在一个线程中\n单 Reactor 单进程的模式优点就是很简单，没有进程间通信，没有进程竞争，全部都在同一个进程内完成。\n但其缺点也是非常明显，具体表现有：\n\n只有一个进程，无法发挥多核 CPU 的性能；只能采取部署多个系统来利用多核 CPU，但这样会带来运维复杂度，本来只要维护一个系统，用这种方式需要在一台机器上维护多套系统。\nHandler 在处理某个连接上的业务时，整个进程无法处理其他连接的事件，很容易导致性能瓶颈\n\n因此，单 Reactor 单进程的方案在实践中应用场景不多，只适用于业务处理非常快速的场景，目前比较著名的开源软件中使用单 Reactor 单进程的是 Redis\n在redis中如果value比较大，redis的QPS会下降得很厉害，有时一个大key就可以拖垮\n现在redis6.0版本后，已经变成多线程模型，对于大value的删除性能就提高了\n单Reactor多线程\n在这种模式中，Reactor和Acceptor运行在同一个线程，而Handler只有在读和写阶段与Reactor和Acceptor运行在同一个线程，读写之间对数据的处理会被Reactor分发到线程池中\n单Reator多线程方案能够充分利用多核多 CPU的处理能力，但同时也存在下面的问题：\n\n多线程数据共享和访问比较复杂。例如，子线程完成业务处理后，要把结果传递给主线程的 Reactor 进行发送，这里涉及共享数据的互斥和保护机制。以 Java 的 NIO 为例，Selector 是线程安全的，但是通过 Selector.selectKeys() 返回的键的集合是非线程安全的，对 selected keys 的处理必须单线程处理或者采取同步措施进行保护。\nReactor 承担所有事件的监听和响应，只在主线程中运行，瞬间高并发时会成为性能瓶颈\n\n多Reactor多线程为了解决单 Reactor 多线程的问题，最直观的方法就是将单Reactor改为多Reactor\n\n目前著名的开源系统 Nginx 采用的是多Reactor多进程，采用多Reactor多线程的实现有 Memcache 和 Netty\n使用5W根因分析法(它又叫 5Why 分析法或者丰田五问法,具体是重复问五次“为什么”)检查一下对这块知识的学习程度\n\n问题 1：为什么 Netty 网络处理性能高？\n\n\n答：因为 Netty 采用了 Reactor 模式 \n\n\n问题 2：为什么用了 Reactor 模式性能就高？\n\n\n答：因为 Reactor 模式是基于 IO 多路复用的事件驱动模式。 \n\n\n问题 3：为什么 IO 多路复用性能高？\n\n\n答：因为 IO 多路复用既不会像阻塞 IO 那样没有数据的时候挂起工作线程，也不需要像非阻塞 IO 那样轮询判断是否有数据。 \n\n\n问题 4：为什么 IO 多路复用既不需要挂起工作线程，也不需要轮询？\n\n\n答：因为 IO 多路复用可以在一个监控线程里面监控很多的连接，没有 IO 操作的时候只要挂起监控线程；只要其中有连接可以进行 IO 操作的时候，操作系统就会唤起监控线程进行处理。 \n\n\n问题 5：那还是会挂起监控线程啊，为什么这样做就性能高呢？\n\n\n答：首先，如果采取阻塞工作线程的方式，对于 Web 这样的系统，并发的连接可能几万十几万，如果每个连接开一个线程的话，系统性能支撑不了；而如果用线程池的话，因为线程被阻塞的时候是不能用来处理其他连接，会出现等待线程的问题。其次，线上单个系统的工作线程数配置可以达到几百上千，这样数量的线程频繁切换会有性能问题，而单个监控线程切换的性能影响可以忽略不计。第三，工作线程没有 IO 操作的时候可以做其他事情，能够大大提升系统的整体性能。\n\nReference五种IO模型透彻分析\nIO模型\nScalable IO in Java\n《从零开始学架构》\n","tags":["IO","Reactor","socket"]},{"title":"springboot2.6.x与swagger3兼容问题追踪","url":"/blog/spring-boot-2.6.-x-and-swagger-3-compatibility-issue-tracking.html","content":"最近项目中使用了高版本的springboot-2.6.4，以及swagger3\n&lt;dependency&gt;    &lt;groupId&gt;io.springfox&lt;/groupId&gt;    &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt;    &lt;version&gt;3.0.0&lt;/version&gt;&lt;/dependency&gt;\n\n结果启动应用程序失败，报错：\nFailed to start bean &#x27;documentationPluginsBootstrapper&#x27;; nested exception is java.lang.NullPointerException\n\n这个问题，网上资料不少，主要原因是因为springboot2.6.x后，把pathMatcher默认值修改了，springfox年久失修，与springboot出现了兼容性问题。\n找到一个Spring Boot下的Issue：https://github.com/spring-projects/spring-boot/issues/28794，但这个issue已经关闭了，目前这个问题的主要讨论在springfox，具体issue是这个：https://github.com/springfox/springfox/issues/3462\n主要项目中还需要使用springboot-actuator,所以简单的修改一下配置spring.mvc.pathmatch.matching-strategy&#x3D;ant-path-matcher还不行。可参考：Spring Boot 2.6.x 集成swagger3.0.0报错解决方案，Swagger is not working with Spring Boot 2.6.X\n在此问题追踪过程中，第一个就是原先的Ant方式与当前的PathPattern有什么区别：\nAntPathMatcher vs PathPattern诞生时间AntPathMatcher是一个早在2003年(Spring的第一个版本)就已存在的路径匹配器，\n而PathPattern是Spring 5新增的，旨在用于替换掉较为“古老”的AntPathMatcher。\n性能PathPattern性能比AntPathMatcher优秀。\n理论上pattern越复杂，PathPattern的优势越明显\n功能1、PathPattern只适用于web环境，AntPathMatcher可用于非web环境。\n2、PathPattern去掉了Ant字样，但保持了很好的向下兼容性。\n3、除了不支持将 ** 写在path中间之外（以消除歧义），其它的匹配规则从行为上均保持和AntPathMatcher一致\n4、并且还新增了强大的{*pathVariable}的支持\n@Testpublic void test() &#123;    System.out.println(&quot;=======&#123;*pathVariable&#125;语法======&quot;);    PathPattern pattern = PathPatternParser.defaultInstance.parse(&quot;/api/com/zhuxingsheng/&#123;*pathVariable&#125;&quot;);    // 提取匹配到的的变量值    System.out.println(&quot;是否匹配：&quot; + pattern.matches(PathContainer.parsePath(&quot;/api/com/zhuxingsheng/a/b/c&quot;)));    PathPattern.PathMatchInfo pathMatchInfo = pattern.matchAndExtract(PathContainer.parsePath(&quot;/api/com/zhuxingsheng/a/b/c&quot;));    System.out.println(&quot;匹配到的值情况：&quot; + pathMatchInfo.getUriVariables());&#125;=======&#123;*pathVariable&#125;语法======是否匹配：true匹配到的值情况：&#123;pathVariable=/a/b/c&#125;\n在没有PathPattern之前，虽然也可以通过&#x2F;**来匹配成功，但却无法得到匹配到的值，现在可以了！\n5、整体上可认为后者兼容了前者的功能\n具体介绍可查看：《Spring5新宠PathPattern，AntPathMatcher：那我走？》\n在源码中也有详细说明：\norg.springframework.web.util.pattern.PathPattern? matches one character* matches zero or more characters within a path segment** matches zero or more path segments until the end of the path&#123;spring&#125; matches a path segment and captures it as a variable named &quot;spring&quot;&#123;spring:[a-z]+&#125; matches the regexp [a-z]+ as a path variable named &quot;spring&quot;&#123;*spring&#125; matches zero or more path segments until the end of the path and captures it as a variable named &quot;spring&quot;Note: In contrast to org.springframework.util.AntPathMatcher,** is supported only at the end of a pattern. For example /pages/&#123;**&#125; is valid but /pages/&#123;**&#125;/details is not. The same applies also to the capturing variant &#123;*spring&#125;. The aim is to eliminate ambiguity when comparing patterns for specificity\n\n在springboot 2.6后，Spring MVC处理程序映射匹配请求路径的默认策略已从AntPathMatcher更改为PathPatternParser\nActuator端点现在也使用基于 PathPattern 的 URL 匹配。需要注意的是，Actuator端点的路径匹配策略无法通过配置属性进行配置。\n如果需要将默认切换回 AntPathMatcher，可以将 spring.mvc.pathmatch.matching-strategy 设置为 ant-path-matcher\nspring.mvc.pathmatch.matching-strategy=ant-path-matcher\n\nspringboot2.6.X与swagger3兼容为什么改变了下pathmatch方式，就会影响到swagger，没想明白，毕竟swagger的路径，PathPattern也是可以正常解析的。\ndebug了下代码：\n不配置spring.mvc.pathmatch.matching-strategy\n应用在启动时，会自动设置PatternPaser\n\n可以看到默认值就是PATH_PATTERN_PARSER，也正是springboot2.6后的默认方式：\n\n不配置时spring.mvc.pathmatch.matching-strategy，pathPatterns是被赋值的：\n\nspringfox.documentation.spring.web.WebMvcRequestHandler#getPatternsCondition时，就是null。\n\n这样也就出现了文章开头的兼容问题。\n在配置ant-path-matcher后，RequestMappingInfo中的pathPatterns和patterns的赋值变化，pathPatterns是无值，patterns是有值。\nspring.mvc.pathmatch.matching-strategy=ant-path-matcher\n\n\n解决方案解决springboot2.6和swagger冲突的问题这篇文章算是列举方案比较全的。\n如果只是通过BeanProcessor修改了HandleMapping，但不修改pathmatch，会访问不了swagger，会出现以下错误：\no.s.web.servlet.PageNotFound             : No mapping for GET /webjars/js/chunk-vendors.90e8ba20.jso.s.web.servlet.PageNotFound             : No mapping for GET /webjars/js/chunk-735c675c.be4e3cfe.jso.s.web.servlet.PageNotFound             : No mapping for GET /webjars/css/app.f802fc13.css\n可以追加一下swagger资源的映射，最终出的方案：https://www.jianshu.com/p/1ea987c75073；\n在整合actuator时，SpringBoot 2.6.* 整合springfox 3.0报错中也指出了，并且解释了原理。但没有理解作者表达的springfox.documentation.spring.web.WebMvcRequestHandler#getPatternsCondition时为null的过滤掉。\n代码里面反而是把为null的提取出来了呀。\nspringdoc既然swagger3.0更新不及时，就不用再纠结，直接使用springdoc也是很好的方案。\n使用springdoc来替换swagger3.0，《从springfox迁移到springdoc》\n总结虽然解决了问题，但原理尚需追踪。不如用springdoc来得简单些。\n","tags":["spring"]},{"title":"springboot之ClassLoader","url":"/blog/classloader-of-springboot.html","content":"上篇《ClassLoader#getResource与Class#getResource的差别》了解原生java获取资源方式以及方式之间的区别。\n这篇介绍一下springboot的加载方式。\n要想调试springboot加载方式，不能直接在idea中运行主程序，要使用真实场景下的java -jar方式运行，需要做两件事：\n1、需要打包springboot应用程序\n2、在IDEA中用java -jar springboot.jar来运行才能debug\nspringboot使用maven plugin打包成可运行的jar文件\n&lt;plugin&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&lt;/plugin&gt;\n\nSpringBoot打出的jar包，可以直接通过解压的方式查看内部的构造。一般情况下有三个目录。\n\nBOOT-INF：这个文件夹下有两个文件夹classes用来存放用户类，也就是原始jar.original里的类；还有一个是lib，就是这个原始jar.original引用的依赖。\nMETA-INF：这里是通过java -jar启动的入口信息，记录了入口类的位置等信息。\norg:Springboot loader的代码，通过它来启动。\n\n\nMANIFEST.MF文件的内容：\nManifest-Version: 1.0Implementation-Title: springboot-testImplementation-Version: 1.0-SNAPSHOTStart-Class: com.zhuxingsheng.AppSpring-Boot-Classes: BOOT-INF/classes/Spring-Boot-Lib: BOOT-INF/lib/Build-Jdk-Spec: 1.8Spring-Boot-Version: 2.2.1.RELEASECreated-By: Maven Jar Plugin 3.2.0Main-Class: org.springframework.boot.loader.JarLauncher\n\n里面有两个重要的参数:\nMain-Class: org.springframework.boot.loader.JarLauncherStart-Class: com.zhuxingsheng.App\n\nMain-Class：记录了java -jar的启动入口，当使用该命令启动时就会调用这个入口类的main方法，显然可以看出，Springboot转移了启动的入口，不是应用自身的com.zhuxingsheng.App入口类。\nStart-Class：应用自身的com.zhuxingsheng.App入口类，当内嵌的jar包加载完成之后，会使用LaunchedURLClassLoader线程加载类来加载这个用户编写的入口类。\n在IDEA中正常启动应用程序，整个类加载体系与直接使用java -jar springboot.jar是不一样的，想要在IDEA里面debug springboot应用程序\n先引入loader依赖：\n&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-loader&lt;/artifactId&gt;    &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/dependency&gt;\n\n再对应用程序通过maven package打包成jar\n再在IDEA中设置：\n\n并指定Path to JAR.\n启动之后，先进入JarLauncher：\n\ndebug进入后，会使用springboot自定义的LaunchedURLClassLoader加载应用程序，LaunchedURLClassLoader类体系：\n\n加载资源的过程如在《Classloader加载资源的方式》中提到的一样。\n与之前的做个小实验，但这次做点小变动，在依赖的jar中也放一个META-INF&#x2F;app.properties文件。\n并在工程本身的resources里面也放一个META-INF&#x2F;app.properties\n此时系统中有两个META-INF&#x2F;app.properties，通过下面的四种情况来加载资源文件，会获取到哪一个文件？\n//第一种场景 final URL resource = Thread.currentThread().getContextClassLoader().getResource(&quot;/META-INF/app.properties&quot;);//第二种场景 final URL resource = Thread.currentThread().getContextClassLoader().getResource(&quot;META-INF/app.properties&quot;); //第三种场景final URL resource1 = App.class.getResource(&quot;/META-INF/app.properties&quot;);        //第四种场景final URL resource1 = App.class.getResource(&quot;META-INF/app.properties&quot;);\n\n第一种 ClassLoader绝对路径按《Classloader加载资源的方式》结论，应该会返回null。\n然而实事并非无此：\n这不得不提到在URLClassPath里面有两个内部Loader：\n\nFileLoader 是加载文件夹中的文件\nJarLoader 是加载jar中的文件\n在《Classloader加载资源的方式》中的结论是基于FileLoader加载的，而现在的方式是使用JarLoader。\n使用ClassLoader.getResource时，都是基于根节点查找，这点是没错的，只是根节点是BOOT-INF下的lib和classes：\n\n去加载每一个jar中的文件，判断是不是存在：\n\n可以看出，因为根节点不同，所以文件没有加载到，项目根目录里面的META-INF&#x2F;app.properties，是在整体工程根目录的META-INF&#x2F;app.properties中。\n此时，找到的文件目录是在：\n\njar:file:&#x2F;Users&#x2F;zhuxingsheng&#x2F;workspace&#x2F;springboot-demo&#x2F;springboot-test&#x2F;target&#x2F;app.jar!&#x2F;BOOT-INF&#x2F;lib&#x2F;general-tool-utils-1.1.0-SNAPSHOT.jar!&#x2F;META-INF&#x2F;app.properties\n\n\n第二种 ClassLoader 相对路径\n\n可以看出使用的是AppClassLoader，加载的路径为\n\njar:file:&#x2F;Users&#x2F;zhuxingsheng&#x2F;workspace&#x2F;springboot-demo&#x2F;springboot-test&#x2F;target&#x2F;app.jar!&#x2F;META-INF&#x2F;app.properties\n\n可以看出 相对路径 与绝对路径的区别，以及与FileLoader的区别：\n1、绝对路径是LaunchedURLClassLoader从classpath根节点查找；相对路径是AppClassLoader从当前jar为根目录查找\n2、FileLoader绝对路径是:file:&#x2F;META-INF&#x2F;app.properties,而JarLoader的绝对路径则不同了，会带上整个classpath\n第三种 Class 绝对路径由《Classloader加载资源的方式》知道，这种方式与第二种场景效果一致：\n//第二种场景 final URL resource = Thread.currentThread().getContextClassLoader().getResource(&quot;META-INF/app.properties&quot;);\n\n路径地址在：\n\njar:file:&#x2F;Users&#x2F;zhuxingsheng&#x2F;workspace&#x2F;springboot-demo&#x2F;springboot-test&#x2F;target&#x2F;app.jar!&#x2F;META-INF&#x2F;app.properties\n\n第三种 Class 相对路径类似于：\nfinal URL resource = Thread.currentThread().getContextClassLoader().getResource(&quot;com/zhuxingsheng/META-INF/app.properties&quot;);\n\n总结此篇一是介绍了怎么在IDEA中debug出运行java -jar springboot.jar的效果。二是介绍springboot类加载机制，以及绝对路径与相对路径的区别。\n当依赖jar包中有与工程目录下有同路径同名资源文件时，为了不必要的冲突，在classloader#getResource时，不要使用绝对路径。\n如在apollo的源码中：\n\n也会特意使用substring处理掉绝对路径。保证加载资源的正确性。\n","tags":["ClassLoader","springboot"]},{"title":"threadlocal再温习","url":"/blog/threadlocal-review.html","content":"早时总结过《ThreadLocal解析》、《FastThreadLocal解析》\n最近看些资料时，又注意到这个类，不尽想再重温下，很多知识点，之前已经总结了，此篇主要有两个问题：\n1、弱引用的意义\n2、如何防key冲突\n弱引用ThreadLocal底层使用的ThreadLocalMap一直在进化中，早在JDK1.3时代还是使用的普通的HashMap，后来才改写成ThreadLocalMap\n这个ThreadLocalMap有两个特殊之处，一是使用了线性探索法，详情见《Hashmap源码解析》；二是key使用了弱引用\n/** * ThreadLocalMap is a customized hash map suitable only for * maintaining thread local values. No operations are exported * outside of the ThreadLocal class. The class is package private to * allow declaration of fields in class Thread.  To help deal with * very large and long-lived usages, the hash table entries use * WeakReferences for keys. However, since reference queues are not * used, stale entries are guaranteed to be removed only when * the table starts running out of space. */static class ThreadLocalMap&#123;&#125;\n\n从注释可以看出作者为什么使用弱引用，为了处理大对象和长周期对象，在GC时可以主动回收\n一直感觉这儿的弱引用设计是个鸡肋\n在实际使用中，还是会出现内存泄漏，何必使用弱引用呢？\n在ThreadLocal的类注释中\nThis class provides thread-local variables.  These variables differ from * their normal counterparts in that each thread that accesses one (via its * &#123;@code get&#125; or &#123;@code set&#125; method) has its own, independently initialized * copy of the variable.  &#123;@code ThreadLocal&#125; instances are typically private * static fields in classes that wish to associate state with a thread (e.g., * a user ID or Transaction ID).\n建议使用static修饰\n阿里规范也有此建议：\n\n【参考】ThreadLocal 对象使用 static 修饰，ThreadLocal 无法解决共享对象的更新问题。 说明:这个变量是针对一个线程内所有操作共享的，所以设置为静态变量，所有此类实例共享此静态变量， 也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象(只要是这个线程内定义的)都可 以操控这个变量。\n\n在 stackflow上点赞比较多的回答：\n\nBecause if it were an instance level field, then it would actually be “Per Thread - Per Instance”, not just a guaranteed “Per Thread.” That isn’t normally the semantic you’re looking for.\n\n\nUsually it’s holding something like objects that are scoped to a User Conversation, Web Request, etc. You don’t want them also sub-scoped to the instance of the class.One web request &#x3D;&gt; one Persistence session.Not one web request &#x3D;&gt; one persistence session per object.\n\n结合实际项目中都是使用线程池的，所以线程基本也是常驻内存的，根据建议使用static修饰，根本没有被回收的机会，虽是弱引用，但一直被强引用\n所以何必呢，还让这个点成为一个常备的面试题，同是程序员，非得难为自己人呢！\n\n上面的结论其实还是从大多数人的思维方式思考的，就是提到ThreadLocal都会与线程联系上，在线程的背景里讨论ThreadLocal\n但从类注释上看，它是个变量：This class provides thread-local variables，所以还是从变量角度考虑\n从变量范围讲，有类变量，局部变量，那ThreadLocal就是线程范围内的变量\n\n根据变量的作用域，可以将变量分为全局变量，局部变量。简单的说，类里面定义的变量是全局变量，函数里面定义的变量是局部变量。\n\n\n还有一种作用域是线程作用域，线程一般是跨越几个函数的。为了在几个函数之间共用一个变量，所以才出现：线程变量，这种变量在Java中就是ThreadLocal变量。\n\n\n全局变量，范围很大；局部变量，范围很小。无论是大还是小，其实都是定死的。而线程变量，调用几个函数，则决定了它的作用域有多大。\n\n\nThreadLocal是跨函数的，虽然全局变量也是跨函数的，但是跨所有的函数，而且不是动态的。\n\n\nThreadLocal是跨函数的，但是跨哪些函数呢，由线程来定，更灵活\n\npublic class ThreadLocalDemo&#123;\tpublic static void main(String[] args)\t&#123;\t\tThreadLocal&lt;Integer&gt; count = new ThreadLocal&lt;Integer&gt;();\t\t//使用count\t\tcount.set(10);\t\t// count不再被使用，可以进行内存回收\t\tSystem.out.println(&quot;&quot;);\t&#125;&#125;\n这个示例中，count要不要被回收\n\n我想，此时JDK的作者也是左右为难，从眼见为实的角度来说，变量不用了就应该进行回收，实现内存的自动回收，这是Java给人最大的特点。\n\n\n但是，此时不能回收count，因为它与10绑定到了一块，而且只能通过count才能读写10。最后JDK作者耍了一个小聪明，用弱引用包装了count，没有干脆利索的进行内存回收，而是拖拖拉拉的进行回收，反正，最后实现了变量不用就回收的基本原则，与Java的传统思想一脉相承\n\n\n到此，应该是知道为什么作者要设计为弱引用了，按建议使用ThreadLocal,修饰为static,就不是为了防内存泄漏，而只是为了达到java变量不使用就回收的基本原则，只是在线程范围时，只能曲线救国了\n防碰撞在hash数据结构中，最重要的一点就是如何更好地设计，尽量避免key的冲突\n普通的hashmap使用的是拉链法，把长度设置成2的N次方，还有负载因子\nThreadLocalMap使用的线程探索法，作者使用了哪些奇技淫巧\nmap的长度/** * The initial capacity -- MUST be a power of two. */private static final int INITIAL_CAPACITY = 16;\nThreadLocalMap没有设置容量的方法，一般情况下，也不会实例化那么多ThreadLocal实例\n必须是2的N次方，这个特性在HashMap中一样，就不解释了，详情见《Hashmap源码解析》\n负载因子在hashmap中，默认负载因子为了0.75，在ThreadLocal中呢？\n/** * Set the resize threshold to maintain at worst a 2/3 load factor. */private void setThreshold(int len) &#123;    threshold = len * 2 / 3;&#125;\n\n看出负载因子为2&#x2F;3\n但threadlocalmap还有特别的地方，就是弱引用，key可能变成null，所以在get,set都会清理key为null的Entry\ntab[i] = new Entry(key, value);int sz = ++size;if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)    rehash();\n\n再看rehash();\n/** * Re-pack and/or re-size the table. First scan the entire * table removing stale entries. If this doesn&#x27;t sufficiently * shrink the size of the table, double the table size. */private void rehash() &#123;    expungeStaleEntries();    // Use lower threshold for doubling to avoid hysteresis    if (size &gt;= threshold - threshold / 4)        resize();&#125;\nrehash方法并不是直接就rehash了，会先清理过期元素，再判断size&gt;&#x3D; threshold-threshold&#x2F;4\nthreshold&#x3D;len * 2 &#x2F; 3\nthreshold-threshold&#x2F;4&#x3D;len * 2 &#x2F; 3-(len * 2 &#x2F; 3)&#x2F;4&#x3D; len&#x2F;2\n所以最终是在清理过期元素后，元素数量超过len&#x2F;2时，就会正式扩容两倍\n0x61c88647hash函数的设计是hash类数据结构的一个重点，空间与时间的平衡是关键\n/** * ThreadLocals rely on per-thread linear-probe hash maps attached * to each thread (Thread.threadLocals and * inheritableThreadLocals).  The ThreadLocal objects act as keys, * searched via threadLocalHashCode.  This is a custom hash code * (useful only within ThreadLocalMaps) that eliminates collisions * in the common case where consecutively constructed ThreadLocals * are used by the same threads, while remaining well-behaved in * less common cases. */private final int threadLocalHashCode = nextHashCode();/** * The next hash code to be given out. Updated atomically. Starts at * zero. */private static AtomicInteger nextHashCode =    new AtomicInteger();/** * The difference between successively generated hash codes - turns * implicit sequential thread-local IDs into near-optimally spread * multiplicative hash values for power-of-two-sized tables. */private static final int HASH_INCREMENT = 0x61c88647;/** * Returns the next hash code. */private static int nextHashCode() &#123;    return nextHashCode.getAndAdd(HASH_INCREMENT);&#125;\n每当创建ThreadLocal实例时这个值都会累加 0x61c88647\n\n0x61c88647转化成十进制：2654435769为32位无符号整数的黄金分割值，而-1640531527就是32位带符号整数的黄金分割值\n当容量为2的N次方，并且使用上这个魔法值后，元素经过散列算法后恰好填充满了整个容器，也就是实现了完美散列\n对于这个数字由来，我也大致搜索了些资料，这已经超出作为一名码农的能力范围，只能反思数学老师讲的：不是数学用不上，而是你没有用上的能力\n环形/** * Increment i modulo len. */private static int nextIndex(int i, int len) &#123;    return ((i + 1 &lt; len) ? i + 1 : 0);&#125;/** * Decrement i modulo len. */private static int prevIndex(int i, int len) &#123;    return ((i - 1 &gt;= 0) ? i - 1 : len - 1);&#125;\n\n在寻找下一个位置时，虽然threadlocalmap是线性探索，但逻辑上使用环形结构，这个与防冲突关系不大，但也是个知识点，一并罗列下\n参考一针见血 ThreadLocal\nWhy 0x61c88647?\nThreadLocal源码——黄金分割数的使用\n","tags":["ThreadLocal"]},{"title":"traceId在filter还是interceptor中处理","url":"/blog/whether-traceid-is-processed-in-filter-or-interceptor.html","content":"traceId在链路监控中是很重要的组成部分，在实际项目中，traceId处理可以在filter中处理，也可以在interceptor中处理。\n本文重点说明下他们的区别是什么？以及spring对fitler的增强。\n1、filter与interceptor的执行顺序\n2、spring的OncePerRequestFilter\n执行顺序注册了两个fitler和一个interceptor\n@Overridepublic void addInterceptors(InterceptorRegistry registry) &#123;    registry.addInterceptor(new SelfInterceptor());&#125;@Beanpublic FilterRegistrationBean registerSecondFilter() &#123;    FilterRegistrationBean&lt;SecondFilter&gt; registration = new FilterRegistrationBean&lt;&gt;();    registration.setFilter(new SecondFilter());    registration.addUrlPatterns(&quot;/*&quot;);    registration.setName(&quot;SecondFilter&quot;);    registration.setOrder(Ordered.HIGHEST_PRECEDENCE + 1);    return registration;&#125;@Beanpublic FilterRegistrationBean registerTraceIdFilter() &#123;    FilterRegistrationBean&lt;TraceIdFilter&gt; registration = new FilterRegistrationBean&lt;&gt;();    registration.setFilter(new TraceIdFilter());    registration.addUrlPatterns(&quot;/*&quot;);    registration.setName(&quot;traceIdFilter&quot;);    registration.setOrder(Ordered.HIGHEST_PRECEDENCE);    return registration;&#125;\n\n\n\n1、Filter：与Spring 无关，基于Servlet， 可以获取request 和 response，但是具体处理方法及相关参数获取不到；\n2、Interceptor：与Spring相关，可以获取request 和 response 以及具体处理方法，但是获取不到具体方法参数的值；\n3、Aspect： 与Spring相关，不可获取request和response ， 可以获取具体方法及具体方法参数的值；\nOncePerRequestFilter\nFilter base class that aims to guarantee a single execution per request dispatch, on any servlet container. It provides a doFilterInternal method with HttpServletRequest and HttpServletResponse arguments.\n\n\nAs of Servlet 3.0, a filter may be invoked as part of a REQUEST or ASYNC dispatches that occur in separate threads. A filter can be configured in web.xml whether it should be involved in async dispatches. However, in some cases servlet containers assume different default configuration. Therefore sub-classes can override the method shouldNotFilterAsyncDispatch() to declare statically if they should indeed be invoked, once, during both types of dispatches in order to provide thread initialization, logging, security, and so on. This mechanism complements and does not replace the need to configure a filter in web.xml with dispatcher types.\n\n简单的说就是去适配了不同的web容器，以及对异步请求，也只过滤一次的需求。另外打个比方：如：servlet2.3与servlet2.4也有一定差异：\n\n在servlet2.3中，Filter会经过一切请求，包括服务器内部使用的forward转发请求和&lt;%@ include file&#x3D;”&#x2F;login.jsp”%&gt;的情况\n\n\nservlet2.4中的Filter默认情况下只过滤外部提交的请求，forward和include这些内部转发都不会被过滤，\n\n\n因此此处我有个建议：我们若是在Spring环境下使用Filter的话，个人建议继承OncePerRequestFilter吧，而不是直接实现Filter接口。这是一个比较稳妥的选择\n\nWays to add Servlet Filters in Spring Boot\n","tags":["链路追踪"]},{"title":"volatile synchronized  cas","url":"/blog/volatile-synchronized--cas.html","content":"之前写了《熔断》，以及其中使用的《计数器算法》；本来是要接着再写不通过定时器清理计数环的计数器算法，看了下我司亿级网关的计数器，百行的代码，但却是满满bug。不得穿插一下并发的基础知识\n处理并发，最基本的元件就这三样\n\nsynchronized 这个关键字不必讲，从开始多线程，它就进入你的视线\nvolatile 在jdk5之后大放异彩\ncas 在J.U.C中大量使用，他与volatile组合是J.U.C的基石\n\nJMM谈到多线程，不得不说的JMM，这儿只做简单阐述\n在jsr-133中是这么定义的\n\nA memory model describes, given a program and an execution trace of that program,whether the execution trace is a legal execution of the program. For the Java programming language,the memory model works by examining each read in an execution trace and checking that the write observed by that read is valid according to certain rules.\n\n也就是说一个内存模型描述了一个给定的程序和和它的执行路径是否一个合法的执行路径。对于java序言来说，内存模型通过考察在程序执行路径中每一个读操作，根据特定的规则，检查写操作对应的读操作是否能是有效的。java内存模型只是定义了一个规范，具体的实现可以是根据实际情况自由实现的。但是实现要满足java内存模型定义的规范。\n从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读&#x2F;写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java内存模型的抽象示意图如下：\n\nvolatile由于java的内存模型中有工作内存和主内存之分，所以可能会有两种问题：\n（1）线程可能在工作内存中更改变量的值，而没有及时写回到主内存，其他线程从主内存读取的数据仍然是老数据\n（2）线程在工作内存中更改了变量的值，写回主内存了，但是其他线程之前也读取了这个变量的值，这样其他线程的工作内存中，此变量的值没有被及时更新。\n为了解决这个问题，可以使用同步机制，也可以把变量声明为volatile，\nJMM:对volatile字段的写入操作happens-before于每一个后续的同一个字段的读操作\n如何理解呢？\n（1）每次对变量的修改，都会引起处理器缓存（工作内存）写回到主内存。\n（2）一个工作内存回写到主内存会导致其他线程的处理器缓存（工作内存）无效。\n基于以上两点，如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。\nvolatile原子性Java内存模型要求lock, unlock, read, load, assign, use, write这个8个操作都具有原子性，但是同时又对64位的数据类型(long&amp;double)给了一个相对宽松的规定，就是允许虚拟机将没有被volatile参数修饰的64位数据类型的读写划分为两次32位的操作来进行，即允许虚拟机将load, store, read, write这个4个操作实现为非原子的。\n当线程把主存中的long&#x2F;double类型的值读到线程内存中时，可能是两次32位值的写操作，显而易见，如果几个线程同时操作，那么就可能会出现高低2个32位值出错的情况发生。\njava虚拟机规范（jvm spec）中，规定了声明为volatile的long和double变量的get和set操作是原子的\n\nWrites and reads of volatile long and double values are always atomic.Writes to and reads of references are always atomic, regardless of whether they are implemented as 32-bit or 64-bit values.\n\n关于volatile变量的使用建议：多线程环境下需要共享的变量采用volatile声明；如果使用了同步块或者是常量，则没有必要使用volatile。\n当然，需要注意的是，这儿的原子性，与i++不是一个概念\n前者是单个变量写，后者是复合操作\nvolatile实现volatile是如何做到可见性的呢？\n来段代码看下，定义两个变量\nprivate int i;private volatile int j;\n\n通过java -verbos XX.class 查看一下生成的编译码\n\n发现唯一的区别就在于volatile多了ACC_VOLATILE标识\n通过查看JVM源码，可以看到如下代码\n\n这就是大名鼎鼎的“内存屏障”的抽象\n内存屏障内存屏障Memory Barriers：是一组处理器指令，用于实现对内存操作的顺序限制。\nMemory barrier 能够让 CPU 或编译器在内存访问上有序。一个 Memory barrier 之前的内存访问操作必定先于其之后的完成。\n内存屏障有两个能力：\n\n阻止屏障两边的指令重排序\n强制把写缓冲区&#x2F;高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效\n\nMemory barrier 分类：\n\n编译器 barrier\nCPU Memory barrier\n\n内存屏障列表：\n\nJMM针对编译器制定的volatile重排序规则表：\n举例来说，第三行最后一个单元格的意思是：在程序顺序中，当第一个操作为普通变量的读或写时，如果第二个操作为volatile写，则编译器不能重排序这两个操作。\n从上表我们可以看出：\n当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后\n当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前\n当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。\nvolatile的内存语义的（JVM）实现策略：\n\n在每个volatile写操作前，会插入一个StoreStore屏障；\n在每个volatile写操作后，会插入一个storeload屏障；\n在每个volatile读操作后，插入一个LoadLoad，一个LoadStore屏障\n\n上图中的StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。\n这里比较有意思的是volatile写后面的StoreLoad屏障。这个屏障的作用是避免volatile写与后面可能有的volatile读&#x2F;写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面，是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）。为了保证能正确实现volatile的内存语义，JMM在这里采取了保守策略：在每个volatile写的后面或在每个volatile读的前面插入一个StoreLoad屏障。从整体执行效率的角度考虑，JMM选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：一个写线程写volatile变量，多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时，选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里我们可以看到JMM在实现上的一个特点：首先确保正确性，然后再去追求执行效率。\n\n上图中的LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。\n重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：\n\n编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。\n指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。\n内存系统的重排序。由于处理器使用缓存和读&#x2F;写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。从java源代码到最终实际执行的指令序列，会分别经历下面三种重排序：\n\n\n上述的1属于编译器重排序，2和3属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel称之为memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。\n比如现在有一段代码如下：\na = 1; //代码1b = 1; //代码2\n编译器和处理为了提高并行度，可以将代码1和2调整顺序，即先执行代码2和代码1\n但是若是其他情况：\na = 1; //代码3b = a; //代码4\n这种情况因为代码3和4存在数据依赖，存在hanpens-before关系，处理器和编译器会遵守 as-if-serial原则，不会调整顺序。\nas-if-serial原则：不管怎么重排序，单线程程序的执行结果不能发生改变。编译器、Runtime和处理器也是如此。这个语义相当于把单线程保护起来了，所以即使编译器和处理器对指令序列进行了重排序，我们也会认为程序指令并没有发生重排序\nhanpens-before：指前一个操作对后一个操作可见，并不是前一个操作必须在后一个操作之前执行。\n当存在控制依赖时，编译器和处理器会采取猜测执行机制来提高并行度，如下代码：\na = 1;flag = true ;if(flag)&#123; //代码5    a * = 2; //代码6&#125;\n代码5和6不存在数据依赖，可能会重排，处理器和编译器会先将代码6的执行结果放在缓冲区，等执行代码5之后，将缓冲区的结果直接赋值给a\n从JSR-133开始，volatile写-读建立的happens before关系\nclass VolatileExample &#123;    int a = 0;    volatile boolean flag = false;     public void writer() &#123;        a = 1;                   //1        flag = true;               //2    &#125;     public void reader() &#123;        if (flag) &#123;                //3            int i =  a;           //4            ……        &#125;    &#125;&#125;\n假设线程A执行writer()方法之后，线程B执行reader()方法。根据happens before规则，这个过程建立的happens before 关系可以分为两类：·     根据程序次序规则，1 happens before 2; 3 happens before 4。·     根据volatile规则，2 happens before 3。·     根据happens before 的传递性规则，1 happens before 4。上述happens before 关系的图形化表现形式如下：\n\n在上图中，每一个箭头链接的两个节点，代表了一个happens before 关系。黑色箭头表示程序顺序规则；橙色箭头表示volatile规则；蓝色箭头表示组合这些规则后提供的happens before保证。\n这里A线程写一个volatile变量后，B线程读同一个volatile变量。A线程在写volatile变量之前所有可见的共享变量，在B线程读同一个volatile变量后，将立即变得对B线程可见。\n在JSR-133之前的旧Java内存模型中，虽然不允许volatile变量之间重排序，但旧的Java内存模型允许volatile变量与普通变量之间重排序。在旧的内存模型中，VolatileExample示例程序可能被重排序成下列时序来执行：\n\n在旧的内存模型中，当1和2之间没有数据依赖关系时，1和2之间就可能被重排序（3和4类似）。其结果就是：读线程B执行4时，不一定能看到写线程A在执行1时对共享变量的修改。\n因此在旧的内存模型中 ，volatile的写-读没有监视器的释放-获取具有的内存语义。\n为了提供一种比监视器锁更轻量级的线程之间通信的机制，JSR-133专家组决定增强\nvolatile的内存语义：严格限制编译器和处理器对volatile变量与普通变量的重排序，确保volatile的写-读和监视器的释放-获取一样，具有相同的内存语义。\n从编译器重排序规则和处理器内存屏障插入策略来看，只要volatile变量与普通变量之间的重排序可能会破坏volatile 的内存语意，这种重排序就会被编译器重排序规则和处理器内存屏障插入策略禁止。\n由于volatile仅仅保证对单个volatile变量的读&#x2F;写具有原子性，而监视器锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性。在功能上，监视器锁比volatile更强大；在可伸缩性和执行性能上，volatile更有优势。如果读者想在程序中用volatile代替监视器锁，请一定谨慎。\nvolatile示例还是不太明白，直接跑段代码，区别一下flag带与不带volatile修饰的情况，就很明显了\npublic class TestVolatile &#123;    public static void main(String[] args) &#123;        ThreadDemo td = new ThreadDemo();        new Thread(td).start();        while(true)&#123;            if(td.getFlag())&#123;                System.out.println(&quot;主线程flag:&quot; + td.getFlag());                break;            &#125;        &#125;    &#125;&#125;class ThreadDemo implements Runnable&#123;    //共享变量    private volatile   boolean  flag = false;    public boolean getFlag() &#123;        return flag;    &#125;    public void setFlag(boolean flag) &#123;        this.flag = flag;    &#125;    @Override    public void run() &#123;        try &#123;            Thread.sleep(200);        &#125; catch (Exception e) &#123;        &#125;        flag = true;        System.out.println(&quot;其他线程flag=&quot; + getFlag());    &#125;&#125;\n\nsynchronized在多线程并发编程中Synchronized一直是元老级角色，很多人都会称呼它为重量级锁\nJava SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率\n\npublic class SynchronizedTest &#123;    public synchronized void test1()&#123;    &#125;    public void test2()&#123;        synchronized (this)&#123;        &#125;    &#125;&#125;\n能过javap -v 查看编译后的代码：\n\n\n从反编译的结果来看，方法的同步并没有通过指令monitorenter和monitorexit来完成（理论上其实也可以通过这两条指令来实现），不过相对于普通方法，其常量池中多了ACC_SYNCHRONIZED标示符。JVM就是根据该标示符来实现方法的同步的：当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。 其实本质上没有区别，只是方法的同步是一种隐式的方式来实现，无需通过字节码来完成。\n关于这两条指令的作用，我们直接参考JVM规范中描述：\nmonitorenter\n\nEach object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows:• If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor.• If the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count.• If another thread already owns the monitor associated with objectref, the thread blocks until the monitor’s entry count is zero, then tries again to gain ownership.\n\n这段话的大概意思为：\n每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：\n1、如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。\n2、如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1.\n3.如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。\nmonitorexit：\n\nThe thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref.The thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero, the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so.\n\n这段话的大概意思为：\n执行monitorexit的线程必须是objectref所对应的monitor的所有者。\n指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个 monitor 的所有权。 \n通过这两段描述，我们应该能很清楚的看出Synchronized的实现原理，Synchronized的语义底层是通过一个monitor的对象来完成，其实wait&#x2F;notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait&#x2F;notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。\nclass SynchronizedExample &#123;int a = 0;boolean flag = false; public synchronized void writer() &#123;    a = 1;    flag = true;&#125; public synchronized void reader() &#123;    if (flag) &#123;        int i = a;        ……    &#125;&#125;&#125;\n上面示例代码中，假设A线程执行writer()方法后，B线程执行reader()方法。这是一个正确同步的多线程程序。\n\ncasJava在JDK1.5之前都是靠 synchronized关键字保证同步的，这种通过使用一致的锁定协议来协调对共享状态的访问，可以确保无论哪个线程持有共享变量的锁，都采用独占的方式来访问这些变量。这就是一种独占锁，独占锁其实就是一种悲观锁，所以可以说 synchronized 是悲观锁。\n悲观锁机制存在以下问题：　　\n\n在多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调度延时，引起性能问题。\n一个线程持有锁会导致其它所有需要此锁的线程挂起。\n如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能风险。\n\n对比于悲观锁的这些问题，另一个更加有效的锁就是乐观锁。\n其实乐观锁就是：每次不加锁而是假设没有并发冲突而去完成某项操作，如果因为并发冲突失败就重试，直到成功为止。\nCAS是项乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。\nCAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前值。）CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”这其实和乐观锁的冲突检查+数据更新的原理是一样的。\npublic final boolean compareAndSet(int expect, int update) &#123;       return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125;\n\nunsafe.compareAndSwapInt(this, valueOffset, expect, update);类似：if (this == expect) &#123;       this = update        return true;&#125;  else &#123;       return false;&#125;\n\nCAS原理CAS通过调用JNI的代码实现的。JNI:Java Native Interface为JAVA本地调用，允许java调用其他语言。\n而compareAndSwapInt就是借助C来调用CPU底层指令实现的。\n下面是sun.misc.Unsafe类的compareAndSwapInt()方法的源代码：\npublic final native boolean compareAndSwapInt(Object o, long offset,                                              int expected,                                              int x);\n\n可以看到这是个本地方法调用。这个本地方法在openjdk中依次调用的c++代码为：unsafe.cpp，atomic.cpp和atomicwindowsx86.inline.hpp。这个本地方法的最终实现在openjdk的如下位置：openjdk-7-fcs-src-b147-27jun2011\\openjdk\\hotspot\\src\\oscpu\\windowsx86\\vm\\ atomicwindowsx86.inline.hpp（对应于windows操作系统，X86处理器）。下面是对应于intel x86处理器的源代码的片段：\n// Adding a lock prefix to an instruction on MP machine// VC++ doesn&#x27;t like the lock prefix to be on a single line// so we can&#x27;t insert a label after the lock prefix.// By emitting a lock prefix, we can define a label after it.#define LOCK_IF_MP(mp) __asm cmp mp, 0  \\                       __asm je L0      \\                       __asm _emit 0xF0 \\                       __asm L0:inline jint     Atomic::cmpxchg    (jint     exchange_value, volatile jint*     dest, jint     compare_value) &#123;  // alternative for InterlockedCompareExchange  int mp = os::is_MP();  __asm &#123;    mov edx, dest    mov ecx, exchange_value    mov eax, compare_value    LOCK_IF_MP(mp)    cmpxchg dword ptr [edx], ecx  &#125;&#125;\n如上面源代码所示，程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（lock cmpxchg）。反之，如果程序是在单处理器上运行，就省略lock前缀（单处理器自身会维护单处理器内的顺序一致性，不需要lock前缀提供的内存屏障效果）。\nintel的手册对lock前缀的说明如下：\n\n确保对内存的读-改-写操作原子执行。在Pentium及Pentium之前的处理器中，带有lock前缀的指令在执行期间会锁住总线，使得其他处理器暂时无法通过总线访问内存。很显然，这会带来昂贵的开销。从Pentium 4，Intel Xeon及P6处理器开始，intel在原有总线锁的基础上做了一个很有意义的优化：如果要访问的内存区域（area of memory）在lock前缀指令执行期间已经在处理器内部的缓存中被锁定（即包含该内存区域的缓存行当前处于独占或以修改状态），并且该内存区域被完全包含在单个缓存行（cache line）中，那么处理器将直接执行该指令。由于在指令执行期间该缓存行会一直被锁定，其它处理器无法读&#x2F;写该指令要访问的内存区域，因此能保证指令执行的原子性。这个操作过程叫做缓存锁定（cache locking），缓存锁定将大大降低lock前缀指令的执行开销，但是当多处理器之间的竞争程度很高或者指令访问的内存地址未对齐时，仍然会锁住总线。\n禁止该指令与之前和之后的读和写指令重排序。\n把写缓冲区中的所有数据刷新到内存中。\n\nCAS缺点 CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。ABA问题，循环时间长开销大和只能保证一个共享变量的原子操作\n\nABA问题。因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。\n循环时间长开销大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。\n只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j&#x3D;a，合并一下ij&#x3D;2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。\n\nconcurrent包的实现由于java的CAS同时具有 volatile 读和volatile写的内存语义，因此Java线程之间的通信现在有了下面四种方式：\n\nA线程写volatile变量，随后B线程读这个volatile变量。\nA线程写volatile变量，随后B线程用CAS更新这个volatile变量。\nA线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。\nA线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。\n\nJava的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读-改-写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读-改-写操作的原子指令）。同时，volatile变量的读&#x2F;写和CAS可以实现线程之间的通信。把这些特性整合在一起，就形成了整个concurrent包得以实现的基石。如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式：\n\n首先，声明共享变量为volatile；\n然后，使用CAS的原子条件更新来实现线程之间的同步；\n同时，配合以volatile的读&#x2F;写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。\n\nvolatile vs synchronized1.volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取；synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。2.volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的。3.volatile仅能实现变量的修改可见性，不能保证原子性（线程A修改了变量还没结束时,另外的线程B可以看到已修改的值,而且可以修改这个变量,而不用等待A释放锁,因为Volatile 变量没上锁）；而synchronized则可以保证变量的修改可见性和原子性。4.volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞和上下文切换。5.volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。\n6.在使用volatile关键字时要慎重，并不是只要简单类型变量使用volatile修饰，对这个变量的所有操作都是原子操作。当变量的值由自身决定时，如n&#x3D;n+1、n++ 等，volatile关键字将失效。只有当变量的值和自身无关时对该变量的操作才是原子级别的，如n &#x3D; m + 1，这个就是原级别的。所以在使用volatile关键时一定要谨慎，如果自己没有把握，可以使用synchronized来代替volatile。\n7.“锁是昂贵的”，谨慎使用锁机制。\n参考资料Java Language Specification \nvolatile的底层源码分析\nvolatile\n内存屏障（Memory barrier）\n深入理解Java内存模型（四）——volatile\n","categories":["java"],"tags":["volatile","cas"]},{"title":"zookeeper-paxos","url":"/blog/zookeeper-paxos.html","content":"在《常识五配置中心》文章中，少了一节关于zookeeper内容，现在补全\n此篇也作为《从Paxos到zookeeper分布式一致性原理与实践》的读书笔记\n\n这本书很早就出版了，现在才知道，惭愧。好书总是发现的晚，Better late than never！\nIT界日异月新，如果你还没有使用过ZK，那也可以跳过了，虽然现在大多数互联网架构都使用，但它也是个古老物件了。随着CoreOS和Kubernetes等项目在开源社区日益火热，etcd已是跃然而上，我司新一代配置中心架构也开始使用etcd代替zk\n但功不唐捐，还是要努力抓住它的尾巴，回味一下错失的年华\n问题提出分布式系统对于数据的复制需求一般都来自于以下两个原因\n\n为了增加系统的可用性，以防止单点故障引起的系统不可用。\n提高系统的整体性能，通过负载均衡技术，能够让分布在不同地方的数据副本都能够为用户提供服务。\n\n数据复制在可用性和性能方面给分布式系统带来的巨大好处是不言而喻的，然而数据复制所带来的一致性挑战，也是每一个系统研发人员不得不面对的。\n一致性\n强一致性\n弱一致性\n会话一致性\n用户一致性\n\n\n最终一致性\n\n分布式架构通过消息传递进行通信和协调的系统\n\n分布性\n对等性\n并发性\n缺乏全局时钟\n故障总是会发生\n\n问题通信异常网络是不可靠的\n网络分区俗称“脑裂”\n三态成功，失败，超时\n节点故障每个节点随时都有可能发生故障\nACID &amp;&amp; CAP &amp;&amp; BASE\nACID这个集中式架构中，数据库就能保证\nACID是Atomic（原子性）、Consistency（一致性）、Isolation（隔离性）和Durability（持久性）的英文缩写。\n原子性：指整个数据库事务是不可分割的工作单位。只有使据库中所有的操作执行成功，才算整个事务成功；事务中任何一个SQL语句执行失败，那么已经执行成功的SQL语句也必须撤销，数据库状态应该退回到执行事务前的状态。\n一致性：指数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。例如对银行转帐事务，不管事务成功还是失败，应该保证事务结束后ACCOUNTS表中Tom和Jack的存款总额为2000元。\n隔离性：指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看到中间状态的数据。\n持久性：指的是只要事务成功结束，它对数据库所做的更新就必须永久保存下来。即使发生系统崩溃，重新启动数据库系统后，数据库还能恢复到事务成功结束时的状态。\nCAPCAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼\n\n一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）\n可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）\n分区容错性（P）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。\n\n设想一下，当一个分布式系统发生了部分隔离：\n\n节点被分隔到了两个区域：写入区域（1）的数据无法复制到区域（2），而访问区域（2）的请求也不能被转发到区域（1）。\n这时候，如果让左边的写入成功——优先保证可用性，则访问区域（2）的请求读不到最新一致的数据，违反了一致性。\n反之，如果让写入失败（阻塞），或者彻底阻止外部请求访问区域（2）——则保证了数据一致性，但是损失了可用性。\n因此，要同时保证一致性和可用性，区域（1）和区域（2）必须能够互相通讯。\nBASE, 最终一致性这个理论由 Basically Available, Soft state, Eventual consistency 组成。核心的概念是 Eventual consistency ——最终一致性。它局部的放弃了 CAP 理论中的“完全”一致性，提供了更好的可用性和分区容忍度。\nBasically Available基本可用, 或者说部分可用。由于分布式系统的节点故障是常见的，业务必须接受这种不可用，并且做出选择：是访问另一个节点忍受数据的临时不一致，还是等待节点恢复并忍受业务上的部分不可用。\nSoft state把所有节点的数据 (数据 &#x3D; 状态) 都看作是缓存（Cache）。适当的调整业务，使业务可以忍受数据的临时不一致，并保证这种不一致是无害的，可以被最终用户理解。\nEventual consistency放弃在任何时刻、从任何节点都能读到完全一致的数据。允许数据的临时不一致，并通过异步复制、重试和合并消除数据的临时不一致。\n注意 在分布式系统中，写入和读取可能发生在不同的节点上。最终一致带来的问题是，业务在写入后立即读取，很可能读不到刚刚写入的数据\n在实际工程实践中，最终一致性存在以下五类主要变种。\n\n因果一致性（Causal consistency）因果一致性是指，如果进程A在更新完某个数据项后通知了进程B，那么进程B之后对该数据项的访问都应该能够获取到进程A更新后的最新值，并且如果进程B要对该数据项进行更新操作的话，务必基于进程A更新后的最新值，即不能发生丢失更新情况。与此同时，与进程A无因果关系的进程C的数据访问则没有这样的限制。\n读己之所写（Read your writes）读己之所写是指，进程A更新一个数据项之后，它自己总是能够访问到更新过的最新值，而不会看到旧值。也就是说，对于单个数据获取者来说，其读取到的数据，一定不会比自己上次写入的值旧。因此，读己之所写也可以看作是一种特殊的因果一致性。\n会话一致性（Session consistency）会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现“读己之所写”的一致性，也就是说，执行更能操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。\n单调读一致性（Monotonic read consistency）单调读一致性是指如果一个进程从系统中读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。\n单调写一致性（Monotonic write consistency）单调写一致性是指，一个系统需要能够保证来自同一个进程的写操作被顺序地执行。\n\n一致性协议2PC&amp;&amp;3PC2PC&#x2F;3PC全称:Two&#x2F;Three Phase Commit,中文名叫叫两阶段&#x2F;三阶段提交；为了使基于分布式系统架构下的所有节点在进行事务处理的过程中能够ACID特性而设计的一种算法，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交\n2PC第一阶段：提交事务阶段(投票阶段)\n\n事务询问：协调者会问所有的参与者结点，是否可以执行提交操作\n执行事务：各个参与者执行事务操作 如：资源上锁，将Undo和Redo信息记入事务日志中\n参与者向协调者反馈事务询问的响应：如果参与者成功执行了事务操作，反馈给协调者Yes响应，否则No响应\n\n第二阶段：执行事务提交(执行阶段)\n假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务提交\n\n发送提交请求：协调者向参与者发送Commit请求\n事务提交：参与者接受到Commit请求后，会正式执行事务提交操作，并在完成提交之后释放事务资源\n反馈事务提交结果：参与者在完成事务提交之后，向协调者发送Ack消息\n完成事务：协调者接受到所有参与者反馈的Ack消息后，完成事务\n\n假如任何一个参与者向协调者反馈了No响应，或者在等待超时之后，协调者尚无接收到所有参与者的反馈信息，那么就会中断事务\n\n发送回滚请求：协调者向参与者发送Rollback请求\n事务回滚：参与者利用Undo信息来执行事务回滚，并释放事务资源\n反馈事务回滚结果：参与者在完成事务回滚之后，向协调者发送Ack消息\n中断事务：协调者接收到所有参与者反馈的Ack消息之后，中断事务\n\n网上看来的西方教堂结婚一个桥段很好的描述了2PC协议：1.牧师分别问新郎和新娘：你是否愿意……不管生老病死……（投票阶段）2.当新郎和新娘都回答愿意后（锁定一生的资源），牧师就会说：我宣布你们……（执行阶段）\n优缺点\n二阶段提交协议的优点：原理简单，实现方便。\n二阶段提交协议的缺点：同步阻塞、单点问题、脑裂、太过保守\n\n同步阻塞二阶段提交协议存在的最明显也是最大的一个问题就是同步阻塞，这会极大地限制分布式系统的性能。在二阶段提交的执行过程中，所有参与该事务操作的逻辑都处于阻塞状态，也就是说，各个参与者在等待其他参与者响应的过程中，将无法进行其他任何操作。\n单点问题协调者的角色在整个二阶段提交协议中起到了非常重要的作用。一旦协调者出现问题，那么整个二阶段提交流程将无法运转，更为严重的是，如果协调者是在阶段二中出现问题的话，那么其他参与者将会一直处于锁定事务资源的状态中，而无法继续完成事务操作。\n数据不一致在二阶段提交协议的阶段二，即执行事务提交的时候，当协调者向所有的参与者发送Commit请求之后，发生了局部网络异常或者是协调者在尚未发送完Commit请求之前自身发生了崩溃，导致最终只有部分参与者收到了Commit请求。于是，这部分收到了Commit请求的参与者就会进行事务的提交，而其他没有收到Commit请求的参与者则无法进行事务提交，于是整个分布式系统便出现了数据不一致性现象。\n太过保守如果在协调者指示参与者进行事务提交询问的过程中，参与者出现故障而导致协调者始终无法获取到所有参与者的响应信息的话，这时协调者只能依靠其自身的超时机制来判断是否需要中断事务，这样的策略显得比较保守。换句话说，二阶段提交协议没有设计较为完善的容错机制，任意一个节点的失败都会导致整个事务的失败。\n在异步环境(asynchronous)并且没有节点宕机(fail-stop)的模型下，2PC可以满足全认同、值合法、可结束，是解决一致性问题的一种协议。但如果再加上节点宕机(fail-recover)的考虑，2PC是否还能解决一致性问题呢？\ncoordinator如果在发起提议后宕机，那么participant将进入阻塞(block)状态、一直等待coordinator回应以完成该次决议。这时需要另一角色把系统从不可结束的状态中带出来，我们把新增的这一角色叫协调者备份(coordinator watchdog)。coordinator宕机一定时间后，watchdog接替原coordinator工作，通过问询(query) 各participant的状态，决定阶段2是提交还是中止。这也要求 coordinator&#x2F;participant 记录(logging)历史状态，以备coordinator宕机后watchdog对participant查询、coordinator宕机恢复后重新找回状态。\n从coordinator接收到一次事务请求、发起提议到事务完成，经过2PC协议后增加了2次RTT(propose+commit)，带来的时延(latency)增加相对较少。\n3PC3PC是2PC的改进版本，将2PC的第一阶段：提交事务阶段一分为二，形成了CanCommit、PreCommit和doCommit三个阶段组成的事务处理协议\n在2PC中一个participant的状态只有它自己和coordinator知晓，假如coordinator提议后自身宕机，在watchdog启用前一个participant又宕机，其他participant就会进入既不能回滚、又不能强制commit的阻塞状态，直到participant宕机恢复。这引出两个疑问：\n\n能不能去掉阻塞，使系统可以在commit&#x2F;abort前回滚(rollback)到决议发起前的初始状态\n当次决议中，participant间能不能相互知道对方的状态，又或者participant间根本不依赖对方的状态\n\n具体看一张流程图\n\n阶段一：CanCommit\n\n事务询问。协调者向所有的参与者发送一个包含事务内容的canCommit请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应。\n各参与者向协调者反馈事务询问的响应。参与者在接收到来自协调者的canCommit请求后，正常情况下，如果其自身认为可以顺利执行事务，那么会反馈Yes响应，并进入预备状态，否则反馈No响应。\n\n阶段二：PreCommit\n在阶段二中，协调者会根据各参与者的反馈情况来决定是否可以进行事务的PreCommit操作，正常情况下，包含两种可能。\n\n执行事务预提交\n\n假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务预提交。\n\n发送预提交请求。协调者向所有参与者节点发出preCommit的请求，并进入Prepared阶段。\n事务预提交。参与者接收到preCommit请求后，会执行事务操作，并将Undo和Redo信息记录到事务日志中。\n各参与者向协调者反馈事务执行的响应。如果参与者成功执行了事务操作，那么就会反馈给协调者Ack响应，同时等待最终的指令：提交（commit）或中止（abort）。\n\n\n中断事务假如任何一个参与者向协调者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。\n\n\n发送中断请求。协调者向所有参与者节点发出abort请求。\n中断事务。无论是收到来自协调者的abort请求，或者是在等待协调者请求过程中出现超时，参与者都会中断事务。\n\n阶段三：doCommit\n该阶段将进行真正的事务提交，会存在以下两种可能的情况。\n\n执行提交\n\n\n发送提交请求。进入这一阶段，假设协调者处于正常工作状态，并且它接收到了来自所有参与者的Ack响应，那么它将从“预提交”状态转换到“提交”状态，并向所有的参与者发送doCommit请求。\n事务提交。参与者接收到doCommit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源。\n反馈事务提交结果。参与者在完成事务提交之后，向协调者发送Ack消息。\n完成事务。协调者接收到所有参与者反馈的Ack消息后，完成事务。\n\n\n中断事务进入这一阶段，假设协调者处于正常工作状态，并且有任意一个参与者向协调者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。\n\n\n发送中断请求。协调者向所有的参与者节点发送abort请求。\n事务回滚。参与者接收到abort请求后，会利用其在阶段二中记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源。\n反馈事务回滚结果。参与者在完成事务回滚之后，向协调者发送Ack消息。\n中断事务。协调者接收到所有参与者反馈的Ack消息后，中断事务。\n\n需要注意的是，一旦进入阶段三，可能会存在以下两种故障。\n\n协调者出现问题\n协调者和参与者之间的网络出现故障。\n\n无论出现哪种情况，最终都会导致参与者无法及时接收到来自协调者的doCommit或是abort请求，针对这样的异常情况，参与者都会在等待超时之后，继续进行事务提交。\n优缺点三阶段提交协议的优点：\n相较于二阶段提交协议，三阶段提交协议最大的优点就是降低了参与者的阻塞范围，并且能够在出现单点故障后继续达成一致。\n三阶段提交协议的缺点：\n三阶段提交协议在去除阻塞的同时也引入了新的问题，那就是在参与者接收到preCommit消息后，如果网络出现分区，此时协调者所在的节点和参与者无法进行正常的网络通信，在这种情况下，该参与者依然会进行事务的提交，这必然出现数据的不一致性。\ncoordinator接收完participant的反馈(vote)之后，进入阶段2，给各个participant发送准备提交(prepare to commit)指令。participant接到准备提交指令后可以锁资源，但要求相关操作必须可回滚。coordinator接收完确认(ACK)后进入阶段3、进行commit&#x2F;abort，3PC的阶段3与2PC的阶段2无异。协调者备份(coordinator watchdog)、状态记录(logging)同样应用在3PC。\nparticipant如果在不同阶段宕机，我们来看看3PC如何应对：\n\n阶段1: coordinator或watchdog未收到宕机participant的vote，直接中止事务；宕机的participant恢复后，读取logging发现未发出赞成vote，自行中止该次事务\n阶段2: coordinator未收到宕机participant的precommit ACK，但因为之前已经收到了宕机participant的赞成反馈(不然也不会进入到阶段2)，coordinator进行commit；watchdog可以通过问询其他participant获得这些信息，过程同理；宕机的participant恢复后发现收到precommit或已经发出赞成vote，则自行commit该次事务\n阶段3: 即便coordinator或watchdog未收到宕机participant的commit ACK，也结束该次事务；宕机的participant恢复后发现收到commit或者precommit，也将自行commit该次事务\n\n因为有了准备提交(prepare to commit)阶段，3PC的事务处理延时也增加了1个RTT，变为3个RTT(propose+precommit+commit)，但是它防止participant宕机后整个系统进入阻塞态，增强了系统的可用性，对一些现实业务场景是非常值得的。\npaxos2PC:同步阻塞、单点问题、脑裂、太过保守\n3PC:主要解决的单点故障问题，并减少阻塞,但依然存在数据不一致以及太过保守问题\n2PC协议用于保证属于多个数据分片上的操作的原子性。这些数据分片可能分布在不同的服务器上，2PC协议保证多台服务器上的操作要么全部成功，要么全部失败。\nPaxos协议用于保证同一个数据分片的多个副本之间的数据一致性。\nPaxos算法要解决的问题就是如何在可能发生几起宕机或网络异常的分布式系统中，快速且正确地在集群内部对某个数据的值达成一致，并且保证不论发生以上任何异常，都不会破坏整个系统的一致性\n复制策略很多资料介绍paxos时，很学术，上来就是提案者，接受者~ 我也是云里雾里，只能不明觉历。\n罗列一些问题：\n一致性是什么？以前怎么处理一致性问题？\n没有paxos时，以前的解决方案有哪些问题？\npaxos怎么演变而来？\npaxos怎么解决问题的？\n理论背景的缺失，让人难以理解！\n看到了可靠分布式系统基础 Paxos 的直观解释，感觉有点明白了。引用一下！\n对于一致性，现在一些方案大都是走复制模式，如主从及进化的主从\n主从异步复制如Mysql的binlog复制\n\n主接到写请求\n主写入本磁盘\n主应答‘OK’\n主复制数据到从库\n\n如果磁盘在复制前损坏： 数据丢失\n\n主从同步复制\n主接到写请求\n主复制日志到从库\n从库这时可能阻塞\n客户端一直等待应答OK，直到所有从库返回\n\n一个失联节点造成整个系统不可用\n主从半同步复制\n主接到写请求\n主复制日志到从库\n从库可能阻塞\n如果1&lt;&#x3D;x&lt;&#x3D;n个从库返回OK,刚返回客户端OK\n\n高可靠、高可用、可能任何从库都不完整\n多数派写\n客户端写入W &gt;&#x3D;N&#x2F;2+1个节点，不需要主\n多数派读：W+R&gt;N;R&gt;&#x3D;N&#x2F;2+1\n容忍最多(N-1)&#x2F;2个节点损坏\n最后1次覆盖先前写入\n所有写入操作需要有1个全局顺序:时间戳\n\n一致性:最终一致性事务性:非原子更新、脏读、更新丢失问题\n多数派读写的不足一个假想存储服务\n\n一个有3个存储节点的存储服务集群\n使用多数派读写策略\n“i”的每次更新对应有多个版本i1,i2,i3…\n这个存储系统支持3个命令 get读最新的i,set 设置下个版本i的值为n,inc 对i加n\n\n命令实现：\n“set” → 直接对应多数派写.\n“inc” → (最简单的事务型操作):\n\n通过多数派读，读取最新的 “i”: i1\nLet i2 &#x3D; i1 + n\nset i2\n\n\n并发问题\n我们期待最终X可以读到i3&#x3D;5, 这需要Y能知道X已经写入了i2。如何实现这个机制？\n在X和Y的2次“inc”操作后，为了得到正确的i3：整个系统里对i的某个版本(i2)，只能有1次成功写入.\n推广为:在存储系统中，一个值(1个变量的1个版本)在被认为确定(客户端接到OK)之后，就不允许被修改().\n如何定义“被确定的”?\n如何避免修改“被确定的”值\n如何确定一个值方案：每次写入一个值前，先运行一次多数派读，来确认是否这个值（可能）已经被写过了\n\n但是，X和Y可能同时以为还没有值被写入过，然后同时开始写\n\n方案改进:让存储节点记住谁最后1次做过“写前读取”，并拒绝之前其他的“写前读取”的写入操作\n\npaxospaxos就是以上的解决方案\n\n将所有节点都写入同一个值，且被写入后不再更改。\n\n两个操作\n\nProposal Value：提议的值；\nProposal Number：提议编号，可理解为提议版本号，要求不能冲突；\n\n三个角色\n\nProposer：提议发起者。Proposer 可以有多个，Proposer 提出议案（value）。所谓 value，可以是任何操作，比如“设置某个变量的值为value”。不同的 Proposer 可以提出不同的 value，例如某个Proposer 提议“将变量 X 设置为 1”，另一个 Proposer 提议“将变量 X 设置为 2”，但对同一轮 Paxos过程，最多只有一个 value 被批准。\nAcceptor：提议接受者；Acceptor 有 N 个，Proposer 提出的 value 必须获得超过半数(N&#x2F;2+1)的 Acceptor批准后才能通过。Acceptor 之间完全对等独立。\nLearner：提议学习者。上面提到只要超过半数accpetor通过即可获得通过，那么learner角色的目的就是把通过的确定性取值同步给其他未确定的Acceptor。\n\n协议过程\n\nproposer将发起提案（value）给所有accpetor，超过半数accpetor获得批准后，proposer将提案写入accpetor内，最终所有accpetor获得一致性的确定性取值，且后续不允许再修改。\n\n协议分为两大阶段，每个阶段又分为A&#x2F;B两小步骤：\n\n准备阶段（占坑阶段）\n第一阶段A：Proposer选择一个提议编号n，向所有的Acceptor广播Prepare（n）请求。\n第一阶段B：Acceptor接收到Prepare（n）请求，若提议编号n比之前接收的Prepare请求都要大，则承诺将不会接收提议编号比n小(&lt;&#x3D;)的提议，并且带上之前Accept的提议中编号小于n(&lt;)的最大的提议，否则不予理会。\n\n\n接受阶段（提交阶段）\n第二阶段A：整个协议最为关键的点：Proposer得到了Acceptor响应\n如果未超过半数accpetor响应，直接转为提议失败；\n如果超过多数Acceptor的承诺，又分为不同情况：\n\n\n如果所有Acceptor都未接收过值（都为null），那么向所有的Acceptor发起自己的值和提议编号n，记住，一定是所有Acceptor都没接受过值；\n如果有部分Acceptor接收过值，那么从所有接受过的值中选择对应的提议编号最大的作为提议的值，提议编号仍然为n。但此时Proposer就不能提议自己的值，只能信任Acceptor通过的值，维护一但获得确定性取值就不能更改原则；\n\n\n第二阶段B：Acceptor接收到提议后，如果该提议版本号不等于自身保存记录的版本号（第一阶段记录的），不接受该请求，相等则写入本地。\n\n\n\n整个paxos协议过程看似复杂难懂，但只要把握和理解这两点就基本理解了paxos的精髓：\n\n理解第一阶段accpetor的处理流程：如果本地已经写入了，不再接受和同意后面的所有请求，并返回本地写入的值；如果本地未写入，则本地记录该请求的版本号，并不再接受其他版本号的请求，简单来说只信任最后一次提交的版本号的请求，使其他版本号写入失效；\n理解第二阶段proposer的处理流程：未超过半数accpetor响应，提议失败；超过半数的accpetor值都为空才提交自身要写入的值，否则选择非空值里版本号最大的值提交，最大的区别在于是提交的值是自身的还是使用以前提交的。\n\n\n简单讲，在prepare阶段，以编号大的为准；在accept阶段以值为准\n\n参考资料漫谈事务与分布式事务（3）- 分布式困境\n分布式系统理论基础 - 一致性、2PC和3PC\n可靠分布式系统基础 Paxos 的直观解释\n如何浅显易懂地解说 Paxos 的算法\nPaxos算法的理解\n以两军问题为背景来演绎Basic Paxos\nBasic Paxos算法\n","categories":["读书"],"tags":["读书","zookeeper"]},{"title":"zookeeper知识结构","url":"/blog/zookeeper-knowledge-structure.html","content":"之前写过关于zookeeper的一篇文章《zookeeper-paxos》，paxos太难理解了，当时理解了，但现在又忘记了，机械学习果然是不行的\n虽然曾经有一篇文章讲阿里不使用zk做服务发现，但大多数公司的分布式架构中基本都能看到zk的身影，而且他躲在里面，你可能看不到他，感受不到他的存在\n对于架构体系中的这样一位选手，了解，学习，研究是相当有必要的\nZK是什么ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby 一个开源的实现\nZooKeeper 是集群的管理者，监视着集群中各节点的状态，根据节点提交的反馈进行下 一步合理的操作。最终，将简单易用的接口和功能稳定，性能高效的系统提供给用户\n\nzooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services\n\n这大概描述了Zookeeper的作用，配置管理，名字服务，提供分布式同步以及集群管理\n为什么需要ZK知道了zk的定义，其实跟不知道差不多，还是要追根溯源，看看zk今世因缘，存在的意义\nzk的历史很多地方都有介绍，这儿就不赘述了\n相对历史，更想知道为什么需要zk？\n以前经历的系统，都是使用redis做为服务中心了，不管使用single redis,还是redis cluster，能胜任架构需求，全局命名服务、订阅发布监听服务列表、分布式锁足矣\n一度怀疑zk的价值，也阻碍了进一步学习的热情，但存在即合理\n设计 ZooKeeper 的目的是为了减轻分布式应用程序所承担的协调任务\n还是从ZK的定义追溯它的作用\n配置管理在我们的应用中除了代码外，还有一些就是各种配置。比如数据库连接等\n一般我们都是使用配置文件的方式，在代码中引入这些配置文件。但是当我们只有一种配置，只有一台服务器，并且不经常修改的时候，使用配置文件是一个很好的做法，但是如果我们配置非常多，有很多服务器都需要这个配置，而且还可能是动态的话使用配置文件就不是个好主意了。\n这个时候往往需要寻找一种集中管理配置的方法，我们在这个集中的地方修改了配置，所有对这个配置感兴趣的都可以获得变更。比如我们可以把配置放在数据库里，然后所有需要配置的服务都去这个数据库读取配置\n但是，因为很多服务的正常运行都非常依赖这个配置，所以需要这个集中提供配置服务的服务具备很高的可靠性。\n一般我们可以用一个集群来提供这个配置服务，但是用集群提升可靠性，那如何保证配置在集群中的一致性呢？ 这个时候就需要使用一种实现了一致性协议的服务了。Zookeeper就是这种服务，它使用Zab这种一致性协议来提供一致性\n名字服务比如为了通过网络访问一个系统，我们得知道对方的IP地址，但是IP地址对人非常不友好，这个时候我们就需要使用域名来访问。\n但是计算机是不能是别域名的。\n怎么办呢？\n如果我们每台机器里都备有一份域名到IP地址的映射，这个倒是能解决一部分问题，但是如果域名对应的IP发生变化了又该怎么办呢？于是我们有了DNS这个东西。\n我们只需要访问一个大家熟知的(known)的点，它就会告诉你这个域名对应的IP是什么。\n在我们的应用中也会存在很多这类问题，特别是在我们的服务特别多的时候，如果我们在本地保存服务的地址的时候将非常不方便，但是如果我们只需要访问一个大家都熟知的访问点，这里提供统一的入口，那么维护起来将方便得多了\n分布式锁比如在一个分布式环境中，为了提高可靠性，我们的集群的每台服务器上都部署着同样的服务\n但是，一件事情如果集群中的每个服务器都进行的话，那相互之间就要协调，编程起来将非常复杂。而如果我们只让一个服务进行操作，那又存在单点。通常还有一种做法就是使用分布式锁，在某个时刻只让一个服务去干活，当这台服务出问题的时候锁释放，立即fail over到另外的服务\n这在很多分布式系统中都是这么做，这种设计有一个更好听的名字叫Leader Election(leader选举)。比如HBase的Master就是采用这种机制。但要注意的是分布式锁跟同一个进程的锁还是有区别的，所以使用的时候要比同一个进程里的锁更谨慎的使用\n这儿其实说了两个作用\n\n传统意义的锁，如《剖析分布式锁》，保护对共享资料操作\nmaster选举，像JOB，为了高可用，会有多台服务器部署同一套JOB程序，但在运行时，只有一台服务器真正执行业务，此时，需要选择一台服务器，如果这台机器挂了，别的机器需要顶替上来\n\n集群管理在分布式的集群中，经常会由于各种原因，比如硬件故障，软件故障，网络问题，有些节点会进进出出。有新的节点加入进来，也有老的节点退出集群。这个时候，集群中其他机器需要感知到这种变化，然后根据这种变化做出对应的决策\n比如我们是一个分布式存储系统，有一个中央控制节点负责存储的分配，当有新的存储进来的时候我们要根据现在集群目前的状态来分配存储节点\n这个时候我们就需要动态感知到集群目前的状态，这也就是注册中心\nCAP分布式系统在设计时，都会考虑一下CAP，在现有理论下，CAP是不能同时满足的，所以需要根据业务场景选择合适的设计要求\nCAP定义在《zookeeper-paxos》中有详细说明\n\nZooKeeper是个CP（一致性+分区容错性）的，即任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性；但是它不能保证每次服务请求的可用性。也就是在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。\nZooKeeper是分布式协调服务，它的职责是保证数据在其管辖下的所有服务之间保持同步、一致；所以就不难理解为什么ZooKeeper被设计成CP而不是AP特性的了\n而且， 作为ZooKeeper的核心实现算法Zab，就是解决了分布式系统下数据如何在多个服务之间保持同步问题的\n特点\n顺序一致性：从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。\n原子性：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。\n单一系统映像：无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。\n可靠性：一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。\n\nznode在谈到分布式的时候，我们通常说的“节点”是指组成集群的每一台机器然而，在 ZooKeeper 中，“节点”分为两类：\n\n第一类同样是指构成集群的机器，我们称之为机器节点。\n第二类则是指数据模型中的数据单元，我们称之为数据节点一ZNode\n\n与Linux文件系统不同的是，Linux文件系统有目录和文件的区别，而Zookeeper的数据节点称为ZNode，ZNode是Zookeeper中数据的最小单元，每个ZNode都可以保存数据，同时还可以挂载子节点，因此构成了一个层次化的命名空间，称为树\n\n\n每一个znode默认能够存储1MB的数据（对于记录状态性质的数据来说，够了）\n\n可以使用zkCli命令，登录到zookeeper上，并通过ls、create、delete、sync等命令操作这些znode节点\n\n\nznode除了名称、数据以外，还有一套属性：zxid\nZooKeeper状态的每一次改变, 都对应着一个递增的Transaction id, 该id称为zxid. 由于zxid的递增性质, 如果zxid1小于zxid2, 那么zxid1肯定先于zxid2发生\n创建任意节点, 或者更新任意节点的数据, 或者删除任意节点, 都会导致Zookeeper状态发生改变, 从而导致zxid的值增加\n\n此外，znode还有操作权限。如果我们把以上几类属性细化，又可以得到以下属性的细节：\n\nczxid：创建节点的事务的zxid\nmzxid：对znode最近修改的zxid\nctime：以距离时间原点(epoch)的毫秒数表示的znode创建时间\nmtime：以距离时间原点(epoch)的毫秒数表示的znode最近修改时间\nversion：znode数据的修改次数\ncversion：znode子节点修改次数\naversion：znode的ACL修改次数\nephemeralOwner：如果znode是临时节点，则指示节点所有者的会话ID；如果不是临时节点，则为零。\ndataLength：znode数据长度。\nnumChildren：znode子节点个数。\n\nznode是由客户端创建的，它和创建它的客户端的内在联系，决定了它的存在性：\n\nPERSISTENT-持久化节点：创建这个节点的客户端在与zookeeper服务的连接断开后，这个节点也不会被删除（除非您使用API强制删除）。\nPERSISTENT_SEQUENTIAL-持久化顺序编号节点：当客户端请求创建这个节点A后，zookeeper会根据parent-znode的zxid状态，为这个A节点编写一个全目录唯一的编号（这个编号只会一直增长）。当客户端与zookeeper服务的连接断开后，这个节点也不会被删除。\nEPHEMERAL-临时目录节点：创建这个节点的客户端在与zookeeper服务的连接断开后，这个节点（还有涉及到的子节点）就会被删除。\nEPHEMERAL_SEQUENTIAL-临时顺序编号目录节点：当客户端请求创建这个节点A后，zookeeper会根据parent-znode的zxid状态，为这个A节点编写一个全目录唯一的编号（这个编号只会一直增长）。当创建这个节点的客户端与zookeeper服务的连接断开后，这个节点被删除。\n\n另外，无论是EPHEMERAL还是EPHEMERAL_SEQUENTIAL节点类型，在zookeeper的client异常终止后，节点也会被删除。\n服务的四种状态服务器具有四种状态，分别是LOOKING,FOLLOWING,LEADING,OBSERVING \n\nLOOKING寻找leader状态当前服务器处于该状态时，它会认为当前集群中没有leader，因此需要进入leader选举状态\nFOLLOWING跟随者状态表示当前服务器的角色是Follower角色 \nLEADING领导者状态表示当前服务器是Leader \nOBSERVING观察者状态表示当前服务器角色是Observer\n\n\n角色最典型集群模式：Master&#x2F;Slave 模式（主备模式）\n在这种模式中，通常 Master 服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务\nzookeeper都是集群形式部署的，而zk服务又分为不同角色来执行不同的任务,ZooKeeper中没有选择传统的 Master&#x2F;Slave 概念\n而是引入了Leader、Follower 和 Observer 三种角色\n\n在区分zk服务器角色之前，需要解释几个概念： \n\n事务请求在zk中，那些会改变服务器状态的请求称为事务请求（创建节点、更新数据、删除节点、创建会话等等） \n非事务请求从zk读取数据但是不对状态进行任何修改的请求称为非事务请求\n\n领导者Leader\n事务请求的唯一调度和处理者，保证集群事务处理的顺序性； \t\n集群内部各服务器的调度者\n只有一个\n\n跟随者（Follower）\n处理客户端非事务请求，转发事务请求给Leader服务器 \t\n参与事务请求Proposal的投票\n参与Leader选举的投票\n\n观察者（Observer):\nFollower 和 Observer 唯一的区别在于 Observer 机器不参与 Leader 的选举过程\n也不参与写操作的“过半写成功”策略，因此 Observer \n机器可以在不影响写性能的情况下提升集群的读性能\n\n数据流\n\n在Client向Follwer发出一个写的请求\nFollwer把请求发送给Leader\nLeader接收到以后开始发起投票并通知Follwer进行投票\nFollwer把投票结果发送给Leader\nLeader将结果汇总后如果需要写入，则开始写入同时把写入操作通知给Leader，然后commit;\nFollwer把请求结果返回给Client\n\nleader选举选举(election)是分布式系统实践中常见的问题，通过打破节点间的对等关系，选得的leader(或叫master、coordinator)有助于实现事务原子性、提升决议效率\n为什么需要选举集群本身有很多种类，如tomcat集群，集群里面每一台机器是对等的，所以其自身不存在leader之说\n另外一类，如fastDfs，其依赖于独特的HASH算法，建立文件名和路径之间的映射关系，写操作都是通过namenode分发到各台datanode之上，算法保证了文件名的独一无二，也不存在leader的说法\n还有memcache集群，集群里面的机器之间彼此无心跳，通过一致性hash尽可能将key值的存储分散化，降低单一memcahe服务器down机的影响。\n还有一类是主从复制，主节点负责写，从节点负责读，提高读的性能。从节点定期通过心跳与主节点沟通，一旦主节点挂掉了，从节点马上接手主节点的任务\n对于分布式应用，难以避免出现网络的抖动。比如，主节点暂时失去响应，如瞬时负载过高，网络拥塞或者其他原因导致主节点暂时失去响应，超过响应超时时间，这个时候从节点启动，承担起leader的职责，但是原先的主节点又恢复了服务。这个时候，如果没有选举机制（不能仅仅自己宣告自己是leader，还要广而告之，让其他服务器或者客户端知道自己是leader），有可能会存在两个leader节点，导致集群发生混乱\n上图示例一下此类场景\n\n主节点出现问题，那就是单点故障\n\n传统方式是采用一个备用节点，这个备用节点定期给当前主节点发送ping包，主节点收到ping包以后向备用节点发送回复Ack，当备用节点收到回复的时候就会认为当前主节点还活着，让他继续提供服务\n\n当主节点挂了，这时候备用节点收不到回复了，然后他就认为主节点挂了接替他成为主节点如下图\n\n但是这种方式就是有一个隐患，就是网络问题，来看一网络问题会造成什么后果，如下图\n\n也就是说我们的主节点的并没有挂，只是在回复的时候网络发生故障，这样我们的备用节点同样收不到回复，就会认为主节点挂了，然后备用节点将他的Master实例启动起来，\n这样我们的分布式系统当中就有了两个主节点也就是—双Master，\n出现Master以后我们的从节点就会将它所做的事一部分汇报给了主节点，一部分汇报给了从节点，这样服务就全乱了\n选举场景在哪些场景下需要进行leader选举\n\n服务器初始化启动\n服务器运行期间无法和Leader保持连接\n\n初始化时若进行Leader选举，则至少需要两台机器，这里选取3台机器组成的服务器集群为例。在集群初始化阶段，当有一台服务器Server1启动时，其单独无法进行和完成Leader选举，当第二台服务器Server2启动时，此时两台机器可以相互通信，每台机器都试图找到Leader，于是进入Leader选举过程。选举过程如下\n\n1.每个Server发出一个投票。由于是初始情况，Server1和Server2都会将自己作为Leader服务器来进行投票，每次投票会包含所推举的服务器的myid和ZXID，使用(myid, ZXID)来表示，此时Server1的投票为(1, 0)，Server2的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。\n2.接受来自各个服务器的投票。集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自LOOKING状态的服务器\n3.处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投票进行PK，PK规则如下\n3.1.优先检查ZXID。ZXID比较大的服务器优先作为Leader\n3.2.如果ZXID相同，那么就比较myid。myid较大的服务器作为Leader服务器\n\n\n\n对于Server1而言，它的投票是(1, 0)，接收Server2的投票为(2, 0)，首先会比较两者的ZXID，均为0，再比较myid，此时Server2的myid最大，于是更新自己的投票为(2, 0)，然后重新投票，对于Server2而言，其无须更新自己的投票，只是再次向集群中所有机器发出上一次投票信息即可。\n\n4.统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于Server1、Server2而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出了Leader。\n5.改变服务器状态。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING。\n\nLeader挂掉在Zookeeper运行期间，Leader与非Leader服务器各司其职，即便当有非Leader服务器宕机或新加入，此时也不会影响Leader，但是一旦Leader服务器挂了，那么整个集群将暂停对外服务，进入新一轮Leader选举，其过程和启动时期的Leader选举过程基本一致。假设正在运行的有Server1、Server2、Server3三台服务器，当前Leader是Server2，若某一时刻Leader挂了，此时便开始Leader选举。选举过程如下\n\n1.变更状态。Leader挂后，余下的非Observer服务器都会讲自己的服务器状态变更为LOOKING，然后开始进入Leader选举过程\n2.每个Server会发出一个投票。在运行期间，每个服务器上的ZXID可能不同，此时假定Server1的ZXID为123，Server3的ZXID为122；在第一轮投票中，Server1和Server3都会投自己，产生投票(1, 123)，(3, 122)，然后各自将投票发送给集群中所有机器。\n3.接收来自各个服务器的投票。与启动时过程相同。\n4.处理投票。与启动时过程相同，此时，Server1将会成为Leader。\n5.统计投票。与启动时过程相同。\n6.改变服务器的状态。与启动时过程相同\n\n过程\n理想状态\n\n在第一轮中，按照“我最牛逼，我怕谁”的原则，每个节点都推荐它自己为集群的leader节点\n按照我们假设的理想条件，节点S1首先收到了S2发送来的推荐者“2”，节点S1发现“2”要比它之前推荐的“1”（也就是它自己）牛。根据谁牛推荐谁的原则，“S1”清空自己的票箱，重新选举“2”（注意，此时“S1”的新票箱中已经有两票选举“2”了，一票是它自己，另外一票是”S2”，并且所有节点都是Looking状态）\n同样的事情发生在“S2”身上：”S2”收到了”S3”发过来的推荐信息，发现“3”这个被推举者比之前自己推举的“2”要牛，于是也清空自己的票箱，发起一轮新的投票，此时“S2”选举“3”。依次类推”S3”、”S4”\n这里要注意S5这个节点，在第一轮接受到了来源于“S1”——“S4”的推举者（一定注意，每一次接受信息，都会广播一次“我坚持推举的人”），发现“还是推荐的5最牛”，于是“我继续推举S5吧”\n以上这个过程在整个理想的网络环境上一直持续。到了第四轮，“S1”收到了“S2”发送来的推举者“5”，发现“5”要比当前“S1”推荐的“4”要牛。所以“S1”清空了自己的票箱，重新推举“5”（发送给其他所有节点）\n关键的第五轮来了，我们再重复一下，经过之前的选举，现在“S2”——“S5”都已经推举“5”为Leader了，而且都处于第四轮。这时他们收到了”S1”发来的新的“第五轮”投票，于是都和之前一样，做相同的一件事：清空自己的票箱，重新向其他所有节点广播自己的第五轮投票“5”\n于是，节点X，收到了大于N &#x2F; 2 +１的选举“5”的投票，且都是第五轮投票。这样每个节点就都知道了自己的角色。，选举结束。所有将成为Follower状态的节点，向将要成为Leader的节点发起最后一次“工作是否正常”的询问。得到肯定的ack后，整个集群的工作状态就确认了\n\n非理想状态过程中出现了宕机、网络延迟、网络物理层断开等情况\n\n在第三轮的选举过程后，“S1”,“S2”两个节点就断开了，他们的投票信息根本没有发送出去\n\n“S3”收到了“S4”,“S5”发来的投票信息，这时“S3”的票箱处于第3轮，并且发现了占大多数的投票结果：大家选举“S5”为Leader节点\n同样的事情也发生在“S4”身上。这样“S3”,“S4”两个节点率先知道了投票结果，在最后一次询问Leader节点是否能正常工作，并得到了肯定的ACK之后，“S3”,“S4”两个节点变成了Follower状态\n之后，无论“S3”,“S4”两个节点收到了任何节点的投票信息，都直接向源节点反馈投票结果，不会再进行投票了。\n在投票完成后，“S1”,“S2”重新连入后，虽然他们发起了投票，但是不会再收到投票反馈了。直接根据“S3”或者“S4”发来的结果状态，变成Follower状态\n\n总结此篇zookeeper的基础内容基本都包含了\n了解这些基本已经入门\n下一篇学习其中最核心的zab协议，理解原子性广播概念，以及zab的实现过程\n参考资料面试问题，请说明zookeeper的选举机制\nzookeeper选举机制\nZookeeper的Leader选举\n","tags":["zookeeper"]},{"title":"zookeeper知识结构2-zab协议","url":"/blog/zookeeper-knowledge-structure-2-zab-protocol.html","content":"通过《zookeeper知识结构1》了解了zookeeper是什么？为什么使用zookeeper? 以及zookeeper内部数据结构，选举机制\nzab定义ZAB全称ZooKeeper Atomic Broadcast protocol\nZooKeeper原子广播协议，实现了主备模式下的系统架构，保持集群中各个副本之间的数据同步(数据最新，一致性)\n\n原子广播在具体深入zab之前，先搞明白原子广播\n原子性好理解，不管是事务的ACID，还是多线程中，都有这个概念；广播也好理解，像系统中常引入消息队列进行消息广播\n但两者合在一起，有点犯晕了，广播怎么需要原子性？哪部分操作不可分割呢？\n\n所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的,也就是说,要么整个集群所有机器都成功应用了某一个事务, 要么就都没应用.\n\n按照上面的解释，原子性体现在所有机器事务一致性,要么都接受广播，要么都不接受；为了更深入理解，从头开始深入一下这个机制的大致流程\n在分布式中，这个机制有很多具体实现，比如2PC,3PC，paxos等等\n副本在这个机制介绍前，需要先介绍下分布式中的副本(Replication)\n副本简直是处理故障恢复的的万能钥匙\n数据副本的收益：\n\n提升系统可用性，需要挂更多的节点才会导致数据丢失\n提升系统性能，多个副本可以同时处理或者交给更快的机器处理\n\n分布式系统采用副本可以获得可扩展性，高性能，可用性，容错性\n\n害怕数据不可用，采用副本吧，多副本能确保数据由于故障丢失的概率大大降低；\n计算太慢，采用副本吧，将计算散布到多台机器上；\nI&#x2F;O太慢，采用副本吧，将数据cache到local机器上，可以极大的提升吞吐\n\n正常多副本，可以从任何副本请求数据\n\n数据同步为了多个副本上的数据同步，一般会加一个dispatche,client请求到dispatche上，dispatche会对请求进行排序，并按同样的顺序分发到各个副本，保持各副本数据一致\n\n此时，dispatche成了系统中的单点，不具备高可用，所以会部署多个dispatch\n\n每个dispatche相互通信，并且每个dispatche都可以分发到各个副本；此时就会出现上图中的并发更新一致性问题，类似于《深入浅出事务》中的第二类更新丢失\n在并发操作时，应用本身对于数据的先后都是可以接受的，但在各个副本中的数据必须保持一致，也就是下图中的结果都是可以的\n\n也就是讲，各个dispatche得以相同的顺序进行更新副本\n顺序同步解决并发更新不一致问题，思路就是对请求操作进行排序，按顺序执行\n\n数据更新的过程如下：\n\n客户发送操作请求到任意一个节点的分发器上\n分发器接收到请求后，将请求广播到其他节点上的分发器，并且这些分发器之间会对所有的并发请求进行排序。最终每个节点的分发器上都会有一份完全一样的请求列表。这个功能通常称作原子广播（Atomic Broadcast） 或者 全局排序广播（Total Order Broadcast)\n分发器将列表中的操作请求按照顺序送给本节点的数据副本\n\n在这个模型中，原子广播的逻辑和业务逻辑是分开的。这么做的好处是非常明显的，业务逻辑的实现不再受分布式需求的限制，原子广播的逻辑则不需要考虑业务逻辑的具体需求。独立的原子广播的逻辑可以被重用到很多的分布式的应用上\n原型根据上面的推导，得出一个最简单的原型\n\ndispatche增加一个队列，也可以把它设计成日志文件（顺序追加的文件）或者管道等等，当有请求时，会按顺序存储到队列，但这个队列中的每个位置只能存储一次数据，存储后不能进行更改\n请求操作\n\n收到客户端的数据存储请求后，选择一个存储位置。发送数据储存指令给其他的分发器，同时将数据存储到自己的存储队列中\n当收到其他分发器发送的存储指令后，将数据存储到自己的存储队列。如果该位置已经存储了数据，则返回失败\n\n\n数据存储指令的内容:[存储位置，数据]\n存储位置的选择:选择最小的空存储位\n\n并发更新\n当两个client分别发到不同到dispatche上请求，两个dispatche相互同步时，出现了不一致，违背了各个队列的每个位置只能存储一次元素，不能更改的原则\n锁对于并发问题，首先想到就是加锁，对于分布式系统怎么加锁呢？\n2PC提供了好的思路\n\n借鉴一下2pc，加锁过程如下：\n第一步：加锁\n\n\n接受到请求，选择本地队列位置，并加锁\n发送加锁指令到别的dispatche2，dipatche2进行相同位置加锁，并回返lock ack\n\n\n加锁指令：[位置]\n\n第二步：更新\n\n\n收到所有dispatche都返回lock ack\n数据写入队列位置上，并发送存储指令给所有disptache\ndispatche收到存储指令，把数据写入队列相应位置\n\n死锁并发考虑的两个问题：安全性与活跃性\n\ndispatche1与dispatche2分别接收到请求，在第一步加锁时，先给自己队列加锁，再发送加锁指令给其它dispatche\n此时，就出现死锁：如dispathe1对自身队列位置1加锁，再发送指令给disptache2的队列位置1加锁，但disptache2的队列位置1被自己锁住了，反之disptache1队列位置1也一样，此时双方进入死锁，永远阻塞\n优先级锁有一种策略，就是给锁增加一个优化级\n\n每个锁请求都有一个优先级，优先级高的锁请求可以撤销优先级低的锁。\n如果一个存储指令的锁被撤销了，就不能被执行\n\n\n如图所示，两个dispatche分别接收到请求，p1 p2是各自锁的优先级，p1高于p2\n\ndispatch1接收请求后，自己队列加锁；收到dispatch2的加锁请求，但p2优先级低于p1，所以被阻塞\ndispatche2自身加锁后，收到dispatche1的加锁请求，由于p1高于p2，dispatche2撤销p2操作，p1成功加锁\ndispatche1成功在所有dispatche上加锁\n\n优先级：\n\n有先后次序,优先级不能相等\n不可重复\n\n比如以dispatche的id作为优先级值，dispatcheId是不同的，也能区分优先级，但这样会出现不平衡，以id大的优先级高，那永远id为大的优先获取锁，加锁成功处理请求\n为了更好的均衡各个客户的请求处理，可以采用下面的优先级定义：[数值，dispatcheID]\n数值可以由各个dispatche指定，比如所有disptache都原子累加，这样可以保证每个dispathe的均衡，当数值相等时，再比较dispatcheId\n节点故障故障可能发生在每个阶段，一是加锁阶段，二是数据更新阶段；再细节大概有三种情况：\n\n加锁成功，但没有写入数据\n部分节点写入了数据\n故障dispatche已经写入数据，但没有同步到别的dispatche\n\n加锁成功，没有写入数据这个很好解决，通过优先级锁，另的节点发起一个更高优先级操作就可以覆盖先前的记录\n部分节点写入数据解决这个问题，需要加强一下更新操作，之前的更新操作，发送存储指令给各个节点，就结束了\n现在不单单发送指令，还需要再广播\n也就是节点接受到存储指令，如果节点已经有数据写入，则与数据一起返回；这样当所有节点返回加锁成功后，检查是否有数据返回，如果有数据返回，则将数据放入存储指令，发送给所有节点\n没有同步别的dispatche需要增加一个“预存储队列”，预写入机制\n当dispatche1发生故障时，其它的dispatche的预存储队列中已经存入了数据。其它节点接管dispatche1时，会先重发预存储队列中的数据到所有dispatche\n预写入过程可以保证：如果数据被写入了任意的存储队列，那么所有节点的预存储队列都有这个数据\n多数派上面的广播机制中，加锁以及预写入都需要所有节点返回成功。如果任意一个节点有故障都会失败。在复杂网络环境下，整个系统很脆弱，不能高可用\n因此可以改进为半数以上节点成功回复就可以\n大多数派机制下，会带来一些更复杂的中间状态，整个过程：\n\n发送加锁指令\n收到加锁指令后，检查指定存储位置是否已经加锁，如没有，则返回加锁成功；如被加锁，则比较锁优先级，如果优先级更高，就撤销原有锁，重新加锁返回成功；如果已经预写入数据，则将数据一并返回\n当超过半数节点返回加锁成功后，检查是否有数据返回。如果有数据返回，则将优先级最高的数据存入预存储指令。如果没有数据返回，则将自己的数据写入预存储指令。发送预存储指令给所有dispatche,并写入自己的预存储队列\n收到预存储指令，将数据写入预存储队列。如果预存储锁被撤销，则返回失败\n当超过半数返回预存储成功，刚发送存储指令给所有dispatche，并写入自己的存储队列\n当收到存储队列，将数据写入自己存储队列中\n\nZAB详细有了上面的原型，理解其它的具体协议就会轻松很多，在具体实现时，都会看到原型中的概念\nZAB协议是为分布式协调服务 Zookeeper 专门设计的一种支持 崩溃恢复 和 原子广播 协议\nZAB协议定义了选举（election）、发现（discovery）、同步（sync）、广播(Broadcast)四个阶段\n\n原型抽象根据上面的原型，结合zk的源码，梳理一下源码中对应原型的抽象\n投票对象这个对象对应着原型中的存储指令，优先级加锁指令\npublic Vote(long id, long zxid) &#123;    this.id = id;    this.zxid = zxid;    this.electionEpoch = -1;    this.peerEpoch = -1;    this.state = ServerState.LOOKING;&#125;\nid：被推举的Leader的SID\nzxid：被推举的Leader事务ID\n\n为了保证事务的顺序一致性，zookeeper 采用了递增的事 务 id 号（zxid）来标识事务。\n所有的提议（proposal）都在被提出的时候加上了 zxid。\n实现中 zxid 是一个 64 位的数字\n它高32 位是 epoch（ZAB 协议通过 epoch 编号来区分 Leader 周期变化的策略）用来标识 leader关系是否改变，每次一个 leader 被选出来，它都会有一个新的epoch&#x3D;（原来的 epoch+1），标识当前属于那个 leader 的统治时期。\n低 32 位用于递增计数\n可以想象为中国古代的年号，例如万历十五年，万历是epoch，十五年是id\nelectionEpoch：逻辑时钟，用来判断多个投票是否在同一轮选举周期中，该值在服务端是一个自增序列，每次进入新一轮的投票后，都会对该值进行加1操作\npeerEpoch：被推举的Leader的epoch\nelectionEpoch和peerEpoch的区别在于，electionEpoch记录的选举的轮次，而peerEpoch则指的是当前leader的任期\nstate：当前服务器的状态\nFastLeaderElectionzk默认的选举算法，为什么需要选举可以参照《zookeeper知识结构1》\n术语\n外部投票：特指其他服务器发来的投票。\n内部投票：服务器自身当前的投票。\n选举轮次：Zookeeper服务器Leader选举的轮次，即logicalclock\nPK：对内部投票和外部投票进行对比来确定是否需要变更内部投票\n\n\nelectionEpoch和logicalclock的区别在于，electionEpoch指的是发出server的logicalclock，而logicalclock则指的是当前Server所处的选举的轮次\n\n\n队列\nsendqueue：选票发送队列，用于保存待发送的选票。\nrecvqueue：选票接收队列，用于保存接收到的外部投票。\nWorkerReceiver：选票接收器。其会不断地从QuorumCnxManager中获取其他服务器发来的选举消息，并将其转换成一个选票，然后保存到recvqueue中，在选票接收过程中，如果发现该外部选票的选举轮次小于当前服务器的，那么忽略该外部投票，同时立即发送自己的内部投票。\nWorkerSender：选票发送器，不断地从sendqueue中获取待发送的选票，并将其传递到底层QuorumCnxManager中\n\nQuorumCnxManagerClientCnxn是ZooKeeper客户端中用于处理网络I&#x2F;O的一个管理器\n在Leader选举的过程中也有类似的角色，那就是QuorumCnxManager——每台服务器启动的时候都会启动一个QuorumCnxManager，负责各台服务器之间的底层Leader选举过程中的网络通信\nQuorumCnxManager这个类内部维护了一系列的队列，用于保存接收到的、待发送的消息，以及消息的发送器。\n除接收队列以外，这里提到的所有队列都有一个共同点——按SID分组形成队列集合，我们以发送队列为例来说明这个分组的概念。\n假设集群中除自身外还有4台机器，那么当前服务器就会为这4台服务器分别创建一个发送队列，互不干扰。\n\nqueueSendMap：消息发送队列，用于保存那些待发送的消息。queueSendMap是一个Map，按照SID进行分组，分别为集群中的每台机器分配了一个单独队列，从而保证各台机器之间的消息发送互不影响。\nsenderWorkerMap：发送器集合。每个SendWorker消息发送器，都对应一台远程ZooKeeper服务器，负责消息的发送。同样，在sendWorkerMap中，也按照SID进行了分组。\nlastMessageSent：最近发送过的消息。在这个集合中，为每个SID保留最近发送过的一个消息\n\n\n在SendWorker的具体实现中，有一个细节需要我们注意一下：一旦ZooKeeper发现针对当前远程服务器的消息发送队列为空，那么这个时候就需要从lastMessageSent中取出一个最近发送过的消息来进行再次发送。这个细节的处理主要为了解决这样一类分布式问题：接收方在消息接收前，或者是在接收到消息后服务器挂掉了，导致消息尚未被正确处理。那么如此重复发送是否会导致其他问题呢？当然，这里可以放心的一点是，ZooKeeper能够保证接收方在处理消息的时候，会对重复消息进行正确的处理\n\nlastMessageSent接近原型中的预存储队列\n选票过程\n\n1.自增选举轮次。Zookeeper规定所有有效的投票都必须在同一轮次中，在开始新一轮投票时，会首先对logicalclock进行自增操作。\n2.初始化选票。在开始进行新一轮投票之前，每个服务器都会初始化自身的选票，并且在初始化阶段，每台服务器都会将自己推举为Leader\n3.发送初始化选票。完成选票的初始化后，服务器就会发起第一次投票。Zookeeper会将刚刚初始化好的选票放入sendqueue中，由发送器WorkerSender负责发送出去。\n4.接收外部投票。每台服务器会不断地从recvqueue队列中获取外部选票。如果服务器发现无法获取到任何外部投票，那么就会立即确认自己是否和集群中其他服务器保持着有效的连接，如果没有连接，则马上建立连接，如果已经建立了连接，则再次发送自己当前的内部投票\n5.判断选举轮次。在发送完初始化选票之后，接着开始处理外部投票。在处理外部投票时，会根据选举轮次来进行不同的处理。\n5.1.外部投票的选举轮次大于内部投票。若服务器自身的选举轮次落后于该外部投票对应服务器的选举轮次，那么就会立即更新自己的选举轮次(logicalclock)，并且清空所有已经收到的投票，然后使用初始化的投票来进行PK以确定是否变更内部投票。最终再将内部投票发送出去。\n5.2.外部投票的选举轮次小于内部投票。若服务器接收的外选票的选举轮次落后于自身的选举轮次，那么Zookeeper就会直接忽略该外部投票，不做任何处理，并返回步骤4。\n5.3.外部投票的选举轮次等于内部投票。此时可以开始进行选票PK\n\n\n6.选票PK。在进行选票PK时，符合任意一个条件就需要变更投票\n6.1.若外部投票中推举的Leader服务器的选举轮次大于内部投票，那么需要变更投票。\n6.2.若选举轮次一致，那么就对比两者的ZXID，若外部投票的ZXID大，那么需要变更投票。\n6.3.若两者的ZXID一致，那么就对比两者的SID，若外部投票的SID大，那么就需要变更投票。\n\n\n7.变更投票。经过PK后，若确定了外部投票优于内部投票，那么就变更投票，即使用外部投票的选票信息来覆盖内部投票，变更完成后，再次将这个变更后的内部投票发送出去。\n8.选票归档。无论是否变更了投票，都会将刚刚收到的那份外部投票放入选票集合recvset中进行归档。recvset用于记录当前服务器在本轮次的Leader选举中收到的所有外部投票（按照服务队的SID区别，如{(1, vote1), (2, vote2)…}）。\n9.统计投票。完成选票归档后，就可以开始统计投票，统计投票是为了统计集群中是否已经有过半的服务器认可了当前的内部投票，如果确定已经有过半服务器认可了该投票，则终止投票。否则返回步骤4\n10.更新服务器状态。若已经确定可以终止投票，那么就开始更新服务器状态，服务器首选判断当前被过半服务器认可的投票所对应的Leader服务器是否是自己，若是自己，则将自己的服务器状态更新为LEADING，若不是，则根据具体情况来确定自己是FOLLOWING或是OBSERVING。\n\n以上10个步骤就是FastLeaderElection的核心，其中步骤4-9会经过几轮循环，直到有Leader选举产生。\n总结通过对原子广播原型的理解，更容易理解zab，对于paxos也一样\n当然zab还有很多的细节，还能再深入，挖出很多知识点。但只看理论终归有些空洞，下一篇实践一下，详述zk版本分布式锁\n参考资料Leader选举\n分布式系统\n由浅入深理解Paxos协议\n","tags":["zookeeper"]},{"title":"zookeeper知识结构3-分布式锁","url":"/blog/zookeeper-knowledge-structure-3-distributed-lock.html","content":"zk相关文章已经有了三篇《zookeeper-paxos》、《zookeeper知识结构》、《zookeeper知识结构2-zab协议》\n但都没有到具体到应用，此篇弥补一下\n\ntalk is cheap,show me the code\n\nclient如何使用zk\n除了zk提供原生客户端，还有能过编程方式\nzkclizkcli原生操作指令比较简单\nzkcli    连接默认zookeeper服务器zkcli -server ip:port    连接指定的zookeeper服务器create -s -e path data [acl]    创建节点，-s表示顺序，-e表示临时，默认是持久节点，acl缺省表示不做任何权限限制ls path [watch]    显示path下的节点，不递归显示,watch注册监听，命令行可忽视ls2 path    显示当前节点下的节点和当前节点的属性信息get path [watch]    获取path的属性信息和数据内容set path data [version]    更新path的数据内容，version是做类似cas的功能的对应dataversion，命令行可忽略delete path [version]    删除节点，不能递归删除，只能删除叶子节点setacl path acl    设置节点acl,例子(scheme:id:password=:perm)-(digest:example:sha-1(base64(pwd))=:cdrwa) create delete read write admingetacl path    获取path节点的aclstat path    查看path的属性信息quit 退出zkcli\n\nZkClient VS Curator这两个常用的开源组件\n相对zkclient,Curator已经成为Apache的顶级项目,不仅解决了非常底层的细节开发工作，包括连接重连、反复注册Watcher和NodeExistsException异常等,还提供了Zookeeper各种应用场景（Recipe，如共享锁服务、Master选举机制和分布式计算器等）的抽象封装\n所以推荐使用curator\n应用主要介绍两种常见情景，一是分布式锁，二是master选举\n分布式锁为什么zk能实现分布式锁？\n像redis原理是通过全局key是否存，而zk则是通过其特定的数据结构来实现：利用节点名称的唯一性\n\nZooKeeper抽象出来的节点结构是一个和unix文件系统类似的小型的树状的目录结构。ZooKeeper机制规定：同一个目录下只能有一个唯一的文件名。例如：我们在Zookeeper目录&#x2F;jjk目录下创建，两个客户端创建一个名为Lock节点，只有一个能够成功\n\n思路一：持久节点利用名称唯一性，加锁操作时，只需要所有客户端一起创建&#x2F;lock节点，只有一个创建成功，成功者获得锁。解锁时，只需删除&#x2F;lock节点，其余客户端再次进入竞争创建节点，直到所有客户端都获得锁\n代码片段尝试加锁\n/** * 尝试加锁,直接创建节点，如果节点创建失败，说明加锁失败 * @param lockName * @return */public boolean tryLock(String lockName) &#123;    try &#123;        //创建节点        String path = cf.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT).forPath(getLockPath(lockName), lockName.getBytes());       logger.info(Thread.currentThread().getName()+ &quot;try lock  success ,path:&quot;+path+&quot; tid:&quot;+Thread.currentThread().getName());        return true;    &#125;catch (KeeperException.NodeExistsException e) &#123;       logger.info(&quot;try lock fail,&quot;+&quot; tid:&quot;+Thread.currentThread().getName());    &#125;catch (Exception ex) &#123;        ex.printStackTrace();    &#125;    return false;&#125;\n\n尝试加锁失败后，阻塞等待\n/** * 尝试加锁失败后，阻塞等待 * @param lockName * @throws Exception */public void waitForLock(String lockName) throws Exception &#123;    //监听子节点    PathChildrenCache pathChildrenCache = new PathChildrenCache(cf, LOCK_PATH, false);    pathChildrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);    pathChildrenCache.getListenable().addListener(new PathChildrenCacheListener() &#123;        @Override        public void childEvent(CuratorFramework client, PathChildrenCacheEvent event) throws Exception &#123;            switch (event.getType()) &#123;                case CHILD_REMOVED:                    logger.info(&quot;path:&quot; + event.getData().getPath() + &quot; has removed,start to lock:&#123;&#125;&quot;,Thread.currentThread().getName());                    countDownLatch.countDown();                    break;                default:                    //logger.info(&quot; has changeed,&#123;&#125;,start to lock:&#123;&#125;&quot;,event.getType(),Thread.currentThread().getName());                    break;            &#125;        &#125;    &#125;);    boolean hasLock = false;    while(!hasLock) &#123;        Stat stat = cf.checkExists().forPath(getLockPath(lockName));        //节点存在,此处与unlock非原子操作，如果在checkExists返回true时刻，成功unlock,那此端无限等待        if (stat == null) &#123;            logger.info(&quot;waitForLock not exists:&#123;&#125;&quot;, Thread.currentThread().getName());           hasLock = tryLock(lockName);           if(hasLock) &#123;               logger.info(&quot;waitForLock get lock :&#123;&#125;&quot;, Thread.currentThread().getName());               break;           &#125;        &#125; else &#123;            logger.info(&quot;waitForLock exists:&#123;&#125;&quot;, Thread.currentThread().getName());            countDownLatch.await();        &#125;    &#125;&#125;\n\n解锁\npublic boolean unlock(String lockName) throws Exception &#123;        logger.info(&quot;start unlock:&quot; + lockName + &quot; tid:&quot; + Thread.currentThread().getName());        cf.delete().forPath(getLockPath(lockName));        logger.info(&quot;end unlock:&quot; + lockName + &quot; tid:&quot; + Thread.currentThread().getName());    return true;&#125;\n\n这个方案比较简单，但会出现两个问题：\n\n“惊群效应”，所有客户端都是监听这个节点变化，当一端释放锁时，别的端都会抢占\n如果加锁成功的client突然崩溃，那么锁无法正常释放，全局进入死锁状态\n\n思路二：临时有序节点为了应对上面的问题，可以使用临时有序节点：EPHEMERAL_SEQUENTIAL，之前的篇章中说明了临时节点特点，在client与zk断开连接时，临时节点会自动删除\n加锁算法：\n\n客户端调用create()方法创建名为“&#x2F;lock”的节点，需要注意的是，这里节点的创建类型需要设置为EPHEMERAL_SEQUENTIAL\n客户端调用getChildren(“lock”)方法来获取所有已经创建的子节点，同时在这个节点上注册上子节点变更通知的Watcher\n客户端获取到所有子节点path之后，如果发现自己在步骤1中创建的节点是所有节点中序号最小的，那么就认为这个客户端获得了锁\n如果在步骤3中发现自己并非是所有子节点中最小的，说明自己还没有获取到锁，就开始等待，直到下次子节点变更通知的时候，再进行子节点的获取，判断是否获取锁\n\n解锁算法：\n\n删除自己创建的那个子节点\n\n\n代码片段尝试加锁失败后，阻塞等待\npublic void waitForLock(String lockName) throws Exception &#123;    logger.info(&quot;waitForLock &#123;&#125;:&#123;&#125;&quot;,beforeNode, Thread.currentThread().getName());    boolean hasLock = false;    while(!hasLock) &#123;       //是不是最小节点        boolean isMin = isMinNode();        if (isMin) &#123;//是 则成功获取锁            logger.info(&quot;waitForLock getLock:&#123;&#125;&quot;, Thread.currentThread().getName());            break;        &#125; else &#123;            try &#123;                cf.getData().usingWatcher(new Watcher() &#123;                    @Override                    public void process(WatchedEvent event) &#123;                        switch (event.getType()) &#123;                            case NodeDeleted:                                logger.info(&quot;path:&quot; + event.getPath() + &quot; has removed,before:&#123;&#125;,start to lock:&#123;&#125;&quot;, beforeNode, Thread.currentThread().getName());                                countDownLatch.countDown();                                break;                        &#125;                    &#125;                &#125;).forPath(beforeNode);                logger.info(&quot;waitForLock waiting:&#123;&#125;&quot;, Thread.currentThread().getName());                countDownLatch.await();                logger.info(&quot;开始抢占:&#123;&#125;,&#123;&#125;&quot;, Thread.currentThread().getName(), currentNode);            &#125;catch (KeeperException.NoNodeException e)&#123;                logger.info(&quot;waitForLock has delete:&#123;&#125;,&#123;&#125;&quot;,beforeNode, Thread.currentThread().getName());            &#125;        &#125;    &#125;&#125;\n\n这个方案解决了思路一中的问题\n\n只监听当前节点的上一个节点，这样就解决了“惊群”现象\n临时节点，当连接断开后，就会自动删除，不会出现过期时间问题\n\n完美了吗？再回看《剖析分布式锁》。zk实现方式完美了吗？\n显然示例中没有达到好锁的标准，更完善的实现可以看看curator中的InterProcessLock\n单机此锁高可用了吗？对比一下Redis，哪种方案更完美？\n\n客户端1发生GC停顿的时候，zookeeper检测不到心跳，也是有可能出现多个客户端同时操作共享资源的情形\nredis的最新set指令,zk的临时节点两个性质都是一样的，解决了因过期时间问题引起的死锁\n有了“续命丸”方案，在单机情况下，redis更完美些，至少不会出现zk临时节点因session超时提前删除问题\n集群在集群下呢？ 线上环境，为了高可用不大会使用单点\n如redis的cluster，哨兵模式;但由于Redis的主从复制（replication）是异步的，这可能会出现在数据同步过程中，master宕机，slave来不及同步数据就被选为master，从而数据丢失\n\n客户端1从Master获取了锁\nMaster宕机了，存储锁的key还没有来得及同步到Slave上\nSlave升级为Master\n客户端2从新的Master获取到了对应同一个资源的锁\n\nRedLock算法为了应对这个情形， redis的作者antirez提出了RedLock算法，步骤如下(该流程出自官方文档)，假设我们有N个master节点(官方文档里将N设置成5，其实大等于3就行)\n\n获取当前时间（单位是毫秒）\n轮流用相同的key和随机值在N个节点上请求锁，在这一步里，客户端在每个master上请求锁时，会有一个和总的锁释放时间相比小的多的超时时间。比如如果锁自动释放时间是10秒钟，那每个节点锁请求的超时时间可能是5-50毫秒的范围，这个可以防止一个客户端在某个宕掉的master节点上阻塞过长时间，如果一个master节点不可用了，我们应该尽快尝试下一个master节点\n客户端计算第二步中获取锁所花的时间，只有当客户端在大多数master节点上成功获取了锁（在这里是3个），而且总共消耗的时间不超过锁释放时间，这个锁就认为是获取成功了\n如果锁获取成功了，那现在锁自动释放时间就是最初的锁释放时间减去之前获取锁所消耗的时间\n如果锁获取失败了，不管是因为获取成功的锁不超过一半（N&#x2F;2+1)还是因为总消耗时间超过了锁释放时间，客户端都会到每个master节点上释放锁，即便是那些他认为没有获取成功的锁\n\n缺陷\n比如一下场景，两个客户端client 1和client 2，5个redis节点nodes (A, B, C, D and E)。\n\nclient 1从A、B、C成功获取锁，从D、E获取锁网络超时\n节点C的时钟不准确(如时钟跳跃)，导致锁快速超时(算法第4点)\nclient 2从C、D、E成功获取锁，从A、B获取锁网络超时\n这样client 1和client 2都获得了锁\n\n对于步骤2，还有一种情况，比如节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了；节点C重启后，client2从C、D、E成功获取锁\n对于这两种情况，redis作者antirez给出了两种人为补偿措施\n\n一时钟问题，不允许人员修改时间\n二节点重启，提出延迟重启的概念，即一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，等待的时间大于锁的有效时间。采用这种方式，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响\n\n\nRedlock的问题，最关键的一点在于Redlock需要客户端去保证写入的一致性，后端5个节点完全独立，所有的客户端都得操作这5个节点。如果5个节点有一个leader，客户端只要从leader获取锁，其他节点能同步leader的数据，这样，分区、超时、冲突等问题都不会存在。所以为了保证分布式锁的正确性，我觉得使用强一致性的分布式协调服务能更好的解决问题\n\n而强一致问题，zk可以完成，zk是个CP系统，zk内部机制就保证了各数据的一致性\n分布式锁到此，对分布式锁的实现可以总结一下\nzookeeper可靠性比redis强太多，只是效率低了点，如果并发量不是特别大，追求可靠性，首选zookeeper\n为了效率，则首选redis实现\n总结除了分布式锁，还有一个常用场景:master选举。在curator中也有相应封装：LeaderSelector；具体实现可以自行阅读源码\n参考资料基于zookeeper的分布式锁\n《Is Redlock safe?》\n《How to do distributed locking》\ncurator使用说明\n分布式锁实现抉择\n聊一聊分布式锁的设计\n","tags":["zookeeper"]},{"title":"《软技能》笔记之职业与学习","url":"/blog/career-and-learning-of-soft-skills-notes.html","content":"之前看的《原则》，有没有感觉作者的原则都对，但实际操作又感觉假大空呢？\n\n《软技能-代码之外的生存技能》这本书可以算是《原则》的实践指南，作者对每一个建议都是事无巨细地指导方案，虽然此书对任何职业都有指导意义，但由于作者程序员的身份，让此书对程序员的实际指导更具体明确\n呐喊这是此前github上很火的评论，我称之为程序员的呐喊\n\n人人都推崇要活到老，学到老。但当真正身陷这个快速变更的行业里，有时难免出现焦躁，疲惫感\n如何应对职业生涯，制定好职业规划，是此行业从业者们必须时时反省的话题\n软技能\n作者从七个方面阐述他的思想，这一篇记录下职业与学习两方面\n职业\n作者阐述了在职业中可能遇到的各种问题，面面俱到\n心态不想当将军的士兵不是好士兵\n把自己看成老板，不要安逸于一名职员\n把自己当做一个软件企业，把雇主当做企业的一个客户，你应当能够提供某种产品或者服务\n目标《原则》中人生五步中的第一步就是确定目标，大多数人没有目标，但更大的问题是不知道如何确定目标\n人际交往talk is cheap ,show me the code\n程序员特殊崇尚这句话，喜欢静静的写代码！但实事上每个职业工作都是与人打交道\ncode is cheap , show me the answer\n面试最快捷的方式让面试官不见其人先闻其声\n让面试官对你怀有好感\n学习\n教育就是当一个人把在学校所学全部忘光之后剩下的东西 –爱因斯坦\n\n\n教育的首要目标，并不在于“知”而在于“行”  –赫伯特 斯宾塞\n\n三要素为了能够掌握一门技术，我需要了解以下三个要点\n\n如何开始 ——要想开始使用自己所学的，我需要掌握哪些基本知识？ \n学科范围 ——我现在学的东西有多宏大？我应该怎么做？在开始阶段，我不需要了解每个细节，但是如果我能对该学科的轮廓有大致的了解，那么将来我就能发现更多细节。 \n基础知识 ——不止在开始阶段，要想使用一项特定的技术，我需要了解基本的用户案例和最常见的问题，也需要知道自己学的哪20%就能满足80%的日常应用\n\n学习十步法\n从第一步到第六步：这些步骤只用作一次！\n第一步：了解全局通常完成这一步我们可以使用网络搜索来完成大量的研究。在这一阶段我们只需要对要学习的东西有一个大概的了解即可。\n第二步 ：确定范围现在我们在对我们要学习的东西有一定的了解的情况下，接下来就要集中精力去明确自己到底想要学习什么？在任何项目中，明确项目范围是至关重要的，唯有这样才能了解项目的全局，做好相应的准备工作。\n而在这样的一个过程中，我们都很容易犯一个错误就是试图解决太大的问题而把自己搞得不堪重负，因此，我们要明确自己的学习范围。为此我们需要运用在第一步中所获得信息来让自己的关注点落脚在更小也可控制的范围内。\n但在此过程中，我们可能会受到诱惑，为了学习该主题下不同的主题，我们可能会扩张自己的学习范围导致自己不够聚焦，所以请务必的抵制这个有诱惑，尽可能的保持专注，一次只能学习一样东西。我们可以稍后再回头学习别的领域的分支。\n最后，请一定注意：明确学习范围的时候要考虑的时间因素，你的学习范围务必大小适当，既能够符合你的学习理由，又能符合你的时间限制。\n第三步：定义目标在我们全力以赴之前，明确“成功”的含义极为重要。如果不知道成功是什么样子，很难找准目标，也很难知道自己什么时候已经真正达到目标。所以在当你知道自己的目标是什么的时候，你就可以更轻松的使用倒推方式，明确实现目标所需要的步骤。\n这一步的目标是形成一份简明清晰的陈述，勾勒出你勤奋学习后的成功图景。但是一定要确保其中包含的的具体成功标准，从而能让你用来充分评估自己是否已经达成学习目标。\n好的目标应该是具体的，无二义性的，不要对自己想要完成的任务进行含糊不清的描述。\n你想从自己的学习经历中获取什么决定了你的成功标准是什么。请确保你能借此在学习结束后评估自己是否达成目标。好的成功标准也能让你向着既定目标不断前进。\n第四步：寻找资源要尝试收集到多种多样的资源来帮助你学习，而不是只读一本关于这一主题的书。资源是多种多样的，不局限于书籍。现在随着网络的广泛应用，你几乎可以针对自己感兴趣的人和主题找到大量的资源。\n在这一不中，你要尽可能多的寻找自己所选择的相关资料，而且此时你无需考虑这些资源的质量。在你寻找过后，你要对你找到的这些资源进行过滤，去伪存真。\n如果你不想因为单一来源的信息而产生偏见，那你就尽可能的去获取各种各样的信息吧。\n第五步：创建学习计划好的技术书都遵循着这样的规律：打好基础，做好铺垫，然后逐个展开每一章的论述。对于大多数学科而言，学习是一个自然的过程。从A开始，前进到B，然后到达Z。这个顺序对你掌握随机的碎片化知识价值不大。你需要找出在最短时间内从A到Z的正确路径，并且到达沿途的重要地标。\n在这一步，你需要创建自己的学习路径。把它看作自己写作时候打大纲。\n打造自己的学习计划，一个好方法就是借鉴吸取他人的方法，我们这时候可以翻看自己在第四步找来的资料，看看他们是如何学习这个主题的，如果很多不同的作者都把内容分解为相同的模块和顺序，你不妨可以去试一试，效仿他们去做一个自己的学习计划。\n第六步：筛选资源现在，我们知道自己要学习什么，按照什么样的方式去学习，那么是时候决定要使用哪些资源来完成自己的学习任务。现在时候对这些资源进行筛选，挑选最有价值记的几项来帮至自己实现目标。\n在这一步中，把我们在第四步中收集的全部资料浏览一遍，找出哪些内容能够覆盖自己的学习计划。\n一旦完成了这一步，我们就可以准备进到学习计划中的第一个模块了！\n但在我们实现自己的目标之前，我们还需要为每个模块重复第7步到第10步。\n第七步到第十步：循环往复（学习——实践——掌握——教授）\n第七步： 开始学习，浅尝辄止在这一步中，我们的目标是获得足够多的与所学主题相关的信息，从让能让我们开始学习，并在下一步中动手操作。\n这一步的关键在于过犹不及。我们通常会很容易的就失去自控力，开始消化计划学习中列出的所有资源。但是你会发现，如果你能经受住这样的诱惑，你会取得更大的成就。你要专注于掌握自己所需的、能再下一步动手操作的的最小量的知识。\n第八步：动手操作，边学边玩这一步既有趣又可怕。说它有趣是因为你真的是在玩耍，说它可怕是因为这一步完全没有边际。在一部没有任何规则，你可以做任何你想做的事情，如何更好地实施这一步，完全由你来决定。\n大多数人会尝试通过读书或者观看视频来掌握某个主题，他们会提前吸收很多信息，然后再付诸实践。这一方法的问题在于，在他们读书或者看视频的时候，他们并不知道哪些内容是重点。他们只是在因循他们设计好的学习路径。\n现在，我们无需提前了解全部内容，你要做的首要的一件事情就是亲自操作和亲身体验。采用这种方法，你通过探索和时间学习。在操作的过程中，你的大脑自然地产生各种各样的问题：它是如何工作的？如果我这么做，它会发生什么？我该如何解决这个问题？这些问题引导着你走向真正重要的方向。当你回过头来寻找问题答案的时候，不只是这些问题迎刃而解，而且你记得的东西比你学习的东西要多得多，因为你所学到的都是对你很重要的东西。\n在这一步中，不要担心结果，勇敢探索吧。\n第九步：全面掌握，学以致用好奇心是学习特别是自学的重要组成部分。这一步的目标就是让你找会好奇寻驱动的学习。在第八步中，你通过动手操作发现了一些尚未找到的答案的问题。现在时候来回答这些问题了，在这一步中，你要利用先前收集到的所有资料，进行深入学习。\n为了有效利用自己选择的材料，为上一步产生的问题寻找答案，阅读文字、观看视频、与他们交流都是必要的手段。这能让你沉浸在学习材料中，尽可能地汲取知识。\n不要害怕回头再去操作，付出更多，因为这不仅能让你找到问题的答案，也能让你学到新的东西。给自己足够多的时间去深入理解自己的主题，你可以阅读，可以实验，可以观察，也可以操作。\n不过请记住，你依然没有必要把收集到的所有资料全部仔细看看一遍。你只需要阅读或者观看与当前所学有关的部分。\n 最后请不要忘了，你在第三步中定义的成功标准。试着把自己正在学习的内容与最终目标关联起来。你掌握的每个模块，都应该以某种方式推动你向着终极目标前行。\n第十步：乐为人师，融会贯通如果你真的想深入地掌握一门学问，想对这门学问做到融会贯通，那么你必须要做到”好为人师“。除此之外，别无他法。\n在现实中，你只需要超前别人一步，就可以成为他们的老师。有时候，比学生超前太多的专家反而不能得心应手的教，因为他们无法与学生产生共鸣。他们忘记了初学者是什么样子，很容易专注于他们认为简单的细节。\n在这一步中，我们要要求自己走出自己的舒适区，将自己学到的知识教给别人。要想确定你确实掌握了某些知识，这是唯一的办法；同时在我们将自己所学到的东西介绍给别人时，这也是查缺补漏的好办法。\n你可以通过很多方式将自己所学交给他们。你可以写博客，也可以制作视频。你也可以跟自己的舍友，基友，爱人以及朋友探讨，将自己所学解释给他们。\n重点在于，你要花时间将自己学到的东西从大脑提取出来，以别人能理解的方式组织起来。在经历这整个过程之后，你会发现，有很多你以为自己明白了的知识点，其实并没有摸透。于是你将会将那些以前自己没太明白的东西联系起来，并且简化自己大脑中已有的信息，将它们浓缩并经常复习。\n后续这篇只记录了职业与学习两部分，后续还有程序员更需要关注的营销部分\n","tags":["读书"]},{"title":"《软技能》笔记之营销与生产力","url":"/blog/marketing-and-productivity-of-soft-skills-notes.html","content":"\n《软技能-代码之外的生存技能》这本书可以算是《原则》的实践指南，作者对每一个建议都是事无巨细地指导方案，虽然此书对任何职业都有指导意义，但由于作者程序员的身份，让此书对程序员的实际指导更具体明确\n之前《软技能笔记之职业与学习》写了职业与学习，这一篇写营销与生产力；作者的做法有些真是自己实践的，莫名喜感\n营销酒香也怕巷子深，尤其追求实干的程序员是得掌握一些自我营销知识\n\n\n营销就是一场争夺人们注意力的竞赛\n\n凡人听到营销都会皱眉头，名声实在是不怎么样。但实事上营销追求的是“实现价值在先，要求回报在后”\n价值在先自我营销的正确方式就是为他人提供价值，学习如何控制好自己要传达的信息，塑造好自己的形象，扩展信息送达的人群\n营销并不能确保你一定成功，但是它却是你可控的重要元素\n基本机制：要想让人们追随你、倾听你、你就要带给他们价值：为他们的问题提供答案，甚至是给他们带去欢乐\n正视自我我不是专家，没什么可营销的 ———— 其实很多人都喜欢向只比自己稍微优秀一点点的人学习，因为这些人才是可望而又可及的\n一直谈论自己并试图证明自己价值连城。然而，你会发现，能解决他人的问题，真正能够帮到他人，你更容易获得成功。\n营销手段\n创建品牌：品牌即承诺，承诺按照你预期的方式交付你所预期的价值\n打造博客：最大秘诀有且仅有一个————持之以恒，持之以恒地坚持写作，坚持不懈地产生高品质的内容。感觉没什么可写，提前头脑风暴出各种不同的想法，每当有新想法时，添加到主题列表中\n演讲\n著书立说\n\n思维障碍看起来像个傻瓜这种想法，我也有，比如我不太敢主动分享自己的文章，感觉写得傻，蠢。好在我没有不行动，还在坚持写\n\n在我的职业生涯中，我一共错失了9000多次投篮，输掉了近300场比赛。我本来有26次绝杀的机会却投球不进。我失败了一次又一次。 这就是我能够成功的原因     ————迈克尔 乔丹\n\n生产力这是一个快速变化的世界，时间飞逝，人难免焦虑，很多人会去看很多关于时间管理方面的书籍，但时间真的能管理吗？\n如何让自己成为一台性能卓越、品质出众的超级高效机器\n这一章节，有些地方给了新的认知，有些我自己也在践行，效果不错，值得一试\n制定计划这不用再重复，没有方向的油轮，是永远到达不了目的地的\n可以从季度计划、月计划、周计划、日计划，让自己知道在前进，在向目标靠近\n番茄工作法我没有实践过这个方式，但对于程序员来讲，看一段源码，分析一个bug，几个小时的专注其实没什么问题，有时真是废寝忘食。\n所以我对此方法也不屑，但作者的看法，带给我启发\n\n番茄工作法只有被当作估算和评估工作的工具时，才能发挥它的真正威力\n\n\n制订任务列表全凭主观臆断，每天能够专注完成的工作量才是最重要的\n\n其实作者的意思就是要对自己的专注能力进行量化。量化是很重要的，大多数都是感觉，比如感觉自己很专注的工作，但真正专注了多久呢？上班8小时，专注了几个小时？一周专注工作几个小时？平均每个月能专注多久，这些是需要量化的。\n无论是制订目标，还是改进目标，都需要量化，数据说话。就好比性能优化，不能凭感觉，而得给出具体数据。\n我很认同作者的这个提法，所以现在也在尝试看自己一天能专注几个番茄时间\n定额工作法制订一些固定周期内的工作\n比如：\n\n每周跑3次\n每周一篇博客\n每天学习一个算法\n\n\n实现定额制后，我发现自己的工作成果比以往多了很多。最大好处在于，长期坚持这么做，我就能随着时间的推移度量并标记自己的进度。可以确切知道自己在给定的一段时间内能够完成的工作量。\n\n承诺是“定额工作法”的核心这其实很明显，太多人是只会制订计划，但从不执行，所以这是对自己的一份承诺\n可以帮助克服意志力薄弱的问题，通过预先设定好的必须要遵循的过程，消除需要做出决策的部分\n为什么这种工作法有效呢？\n\n以缓慢但稳定的节奏工作，要优于快速但缺乏持久和坚持的工作方式\n\n这个方法，其实我就在使用，比如我自己制定每月至少写一篇读书笔记、一篇技术学习\n开始很难做到，但会时时提醒自己，要去读书，对学习的技术，要做整理。\n这样坚持一段时间后，现在我算是超额完成，现在每月要写四篇文章，两篇关于读书的，两篇关于技术的\n这样也正好呼应了营销部分的打造一个好博客，坚持写作，一个月四篇，一年就有48篇。其实看看一年量化，这数字也太少了，但要完成还真不容易\n有了对自己的承诺，会强迫自己去兑现\n保持激情是人就会疲惫，新鲜感会消退，产生倦怠\n想起李笑来的一句话，任何事，前期都不要用力过猛，越猛后期就越乏力\n\n赛跑比的是谁耐力更长久，而不是看谁冲刺更有力\n\n所以生产力的真正秘诀在于：长期坚持做一些小事\n\n延伸阅读：\n《软技能笔记之职业与学习》\n《原则》读书笔记\n","tags":["读书"]},{"title":"一致性哈希","url":"/blog/consistent-hashing-.html","content":"背景图片分库存储时，每一张图片都可以定位到特定的服务器\n\nhash上图中，假设我们查找的是”a.png”，由于有4台服务器（排除从库），因此公式为hash(a.png) % 4 &#x3D; 2 ，可知定位到了第2号服务器，这样的话就不会遍历所有的服务器，大大提升了性能！\n一切都运行正常，再考虑如下的两种情况；\n\n一个 cache 服务器 m down 掉了（在实际应用中必须要考虑这种情况），这样所有映射到 cache m 的对象都会失效，怎么办，需要把 cache m 从 cache 中移除，这时候 cache 是 N-1 台，映射公式变成了 hash(object)%(N-1) ；\n由于访问加重，需要添加 cache ，这时候 cache 是 N+1 台，映射公式变成了 hash(object)%(N+1) ；\n\n1 和 2 意味着什么？\n这意味着突然之间几乎所有cache 都失效了。缓存雪崩，这是一场灾难\n一致性hash有什么方法可以改变这个状况呢，这就是 consistent hashing\n比如有{N0, N1, N2}三个节点，陆续有多个资源要分配到这三个节点上，如何尽可能均匀的分配到这些节点上\n算法一致性哈希算法的思路为：先构造出一个长度为2^32 整数环，根据N0-3的节点名称的hash值（分布为[0,2^32 -1]）放到这个环上\n\n整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32 -1，也就是说0点左侧的第一个点代表2^32 -1， 0和2^32 -1在零点中方向重合，我们把这个由2^32个点组成的圆环称为Hash环\n下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设四台服务器使用ip地址哈希后在环空间的位置如下：\n\n接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器！\n例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下： \n\n根据一致性Hash算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上\n容错性如果一个节点宕机了，会引起系统故障吗？\n\n如上图，Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响\n扩展性如果在系统中增加一台服务器Node X\n\n此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X ！一般的，在一致性Hash算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响\n综上所述，一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。\n数据倾斜一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，其环分布如下： \n\n此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上\n然而，这又会造成一个“雪崩”的情况，即A节点由于承担了B节点的数据，所以A节点的负载会变高，A节点很容易也宕机，这样依次下去，这样造成整个集群都挂了\n虚拟节点\n计算机的任何问题都可以通过增加一个虚拟层来解决\n\n解决上述数据倾斜问题，也可能通过使用虚拟层的手段：将每台物理缓存服务器虚拟为一组虚拟缓存服务器，将虚拟服务器的hash值放置在hash环上，Key在环上先找到虚拟服务器节点，再得到物理服务器的信息\n例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点： \n\n同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题\n那么在实践中，一台物理服务器虚拟为多少个虚拟服务器节点合适呢？太多会影响性能，太少又会导致负载不均衡，一般说来，经验值是150，当然根据集群规模和负载均衡的精度需求，这个值应该根据具体情况具体对待\n实现判定哈希算法好坏的四个定义：\n\n平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件\n单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区\n分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性\n负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷\n\n在具体实现时，主要考虑点选择适合的数据结构构造hash环\n此数据结构的特点：插入与删除性能、快速找到特定元素的下一位\n常见算法结构可以有回顾：\n《一篇解决排序算法》\n《树结构概述》\n从时间复杂度方面选择，使用平衡二叉树数据结构，可以使得查找的时间复杂度降低为O(logN)\n使用java，以TreeMap为例，TreeMap本身还提供了一个tailMap(K fromKey)方法，支持从红黑树中查找比fromKey大的值的集合，但并不需要遍历整个数据结构\nimport java.util.Collection;import java.util.SortedMap;import java.util.TreeMap;public class ConsistentHash&lt;T&gt; &#123; private final HashFunction hashFunction; private final int numberOfReplicas; private final SortedMap&lt;Integer, T&gt; circle = new TreeMap&lt;Integer, T&gt;(); public ConsistentHash(HashFunction hashFunction, int numberOfReplicas,     Collection&lt;T&gt; nodes) &#123;   this.hashFunction = hashFunction;   this.numberOfReplicas = numberOfReplicas;   for (T node : nodes) &#123;     add(node);   &#125; &#125; public void add(T node) &#123;   for (int i = 0; i &lt; numberOfReplicas; i++) &#123;     circle.put(hashFunction.hash(node.toString() + i), node);   &#125; &#125; public void remove(T node) &#123;   for (int i = 0; i &lt; numberOfReplicas; i++) &#123;     circle.remove(hashFunction.hash(node.toString() + i));   &#125; &#125; public T get(Object key) &#123;   if (circle.isEmpty()) &#123;     return null;   &#125;   int hash = hashFunction.hash(key);   if (!circle.containsKey(hash)) &#123;     SortedMap&lt;Integer, T&gt; tailMap = circle.tailMap(hash);     hash = tailMap.isEmpty() ? circle.firstKey() : tailMap.firstKey();   &#125;   return circle.get(hash); &#125;&#125;\n\ndubbo实现理解完理论，再扒一下工业级产品的运用，dubbo负载均衡策略之一ConsistentHashLoadBalance\nprivate final TreeMap&lt;Long, Invoker&lt;T&gt;&gt; virtualInvokers;ConsistentHashSelector(List&lt;Invoker&lt;T&gt;&gt; invokers, String methodName, int identityHashCode) &#123;    this.virtualInvokers = new TreeMap&lt;Long, Invoker&lt;T&gt;&gt;();    this.identityHashCode = identityHashCode;    URL url = invokers.get(0).getUrl();    this.replicaNumber = url.getMethodParameter(methodName, &quot;hash.nodes&quot;, 160);    String[] index = Constants.COMMA_SPLIT_PATTERN.split(url.getMethodParameter(methodName, &quot;hash.arguments&quot;, &quot;0&quot;));    argumentIndex = new int[index.length];    for (int i = 0; i &lt; index.length; i++) &#123;        argumentIndex[i] = Integer.parseInt(index[i]);    &#125;    for (Invoker&lt;T&gt; invoker : invokers) &#123;        String address = invoker.getUrl().getAddress();        for (int i = 0; i &lt; replicaNumber / 4; i++) &#123;            byte[] digest = md5(address + i);            for (int h = 0; h &lt; 4; h++) &#123;                long m = hash(digest, h);                virtualInvokers.put(m, invoker);            &#125;        &#125;    &#125;&#125;\n\n整体思想是一样的，虚拟节点+TreeMap,但实现得更精致，使用MD5加密KEY，更加平衡性，整体的思路解释：\n//对所有节点，生成nCopies个虚拟结点  for(Node node : nodes) &#123;      //每四个虚拟结点为一组，为什么这样？下面会说到      for(int i=0; i&lt;nCopies / 4; i++) &#123;          //getKeyForNode方法为这组虚拟结点得到惟一名称          byte[] digest=HashAlgorithm.computeMd5(getKeyForNode(node, i));      /** Md5是一个16字节长度的数组，将16字节的数组每四个字节一组，分别对应一个虚拟结点，这就是为什么上面把虚拟结点四个划分一组的原因*/          for(int h=0;h&lt;4;h++) &#123;            //对于每四个字节，组成一个long值数值，做为这个虚拟节点的在环中的惟一key          //结果转换为long类，这是因为生成的结果是一个32位数，若用int保存可能会产生负数。而一致性hash生成的逻辑环其hashCode的范围是在 0 - MAX_VALUE之间。因此为正整数，所以这里要强制转换为long类型，避免出现负数。            Long k = ((long)(digest[3+h*4]&amp;0xFF) &lt;&lt; 24)                  | ((long)(digest[2+h*4]&amp;0xFF) &lt;&lt; 16)                  | ((long)(digest[1+h*4]&amp;0xFF) &lt;&lt; 8)                  | (digest[h*4]&amp;0xFF);              allNodes.put(k, node);          &#125;      &#125;  &#125;\n\n总结QA\n为什么hash一致性的数据空间范围是2^32次方？\n\n这个问题有两种答案，一是技术限制、一是实际场景：\n\n因为，java中int的最大值是2^31-1最小值是-2^31,2^32刚好是无符号整形的最大值\n因为一致性hash算法是来做服务器的负载均衡，而服务器的IP地址是32位，所以是2^32-1次方的数值空间\n\n\n进一步追尾基础，为什么java中int的最大值是2^31-1最小值是-2^31？\n\n因为，int的最大值最小值范围设定是因为一个int占4个字节，一个字节占8位，二进制中刚好是32位\n根据算法特性，一致性hash是最好的选择吗？\n下一篇介绍另一种实现google maglev hashing算法\n参考资料《大型网站技术架构》\n对一致性Hash算法，Java代码实现的深入研究\n为什么hash环是32位\n"},{"title":"一份JVM参数","url":"/blog/a-copy-of-jvm-parameters.html","content":"想写个一份百万QPS系统的JVM参数，感觉太标题党了，虽然这的确是，但还是朴实点；\nJVM参数调优是性能重器，安全第一，不可乱用，更不能因为网上推荐文章(此篇)而随便用\n之前关于JVM的几篇文章《是否需要主动GC》、《JIT优化》、《GC及JVM参数》；\n这些都涉及到JVM参数,然道理懂不少，还是配置不好参数；调优的确是个费劲的事。这儿直接给一份参数，可以直接拿来主义，当然也有些参数需要配合硬件及应用环境，斟酌使用，一切以实战为准\n其实有很多现成的，如elasticsearch、cassandra、VIP\njvm参数总体分两种：标准参数(以-开始)与非标准参数;\n非标准参数又分了两种：不太标准(以-X开始)与特别不标准(以-XX开始)\n参数列表就标准到非标准一一进行说明\n标准参数顾名思义，标准参数中包括功能和输出的参数都是很稳定的，很可能在将来的JVM版本中不会改变。你可以用java命令（或者是用 java -help）检索出所有标准参数\n-server\n这个参数涉及分层编译策略，简单讲，就是把更多的代码更早地编译成本地代码\n-D\n应用附加配置参数，通过System.getProperty读取\n-Djava.security.egd&#x3D;file:&#x2F;dev&#x2F;.&#x2F;urandom \n-Djava.net.preferIPv4Stack&#x3D;true \n-Djava.awt.headless&#x3D;true \n-Dspring.profiles.active&#x3D;dev\n非标准参数非标准化的参数在将来的版本中可能会改变\n在实际情况中X参数和XX参数并没有什么不同。X参数的功能是十分稳定的，然而很多XX参数仍在实验当中（主要是JVM的开发者用于debugging和调优JVM自身的实现）\nX参数-Xms2048m\n-Xmx2048m\n-Xmn2048m\n-Xss512K\n这几个老面孔，设置堆大小\nXms和Xmx设置一样，可以减轻伸缩堆大小带来的压力;Xmn新年代大小\nXss规定了每个线程堆栈的大小。一般情况下256K是足够了； 如果线程数较多，函数的递归较少，线程栈内存可以调小节约内存，默认1M\n-Xloggc\n-Xloggc:&#x2F;dev&#x2F;shm&#x2F;gc.log\n有人担心写GC日志会影响性能，但测试下来实在没什么影响，GC问题是Java里最常见的问题，没日志怎么行。\n后来又发现如果遇上高IO的情况，GC时操作系统正在flush pageCache 到磁盘，也可能导致GC log文件被锁住，从而让GC结束不了。所以把它指向了&#x2F;dev&#x2F;shm 这种内存中文件系统，避免这种停顿，详见Eliminating Large JVM GC Pauses Caused by Background IO Traffic\n\nXX参数XX参数 虽然是最不稳定参数，但使用的最多，好神奇，很多特殊的性能调优都需要用到\n\n对于布尔类型的参数，我们有”+”或”-“，然后才设置JVM选项的实际名称。例如，-XX:+用于激活选项，而-XX:-用于注销选项\n对于需要非布尔值的参数，如string或者integer，我们先写参数的名称，后面加上”&#x3D;”，最后赋值。例如， -XX:&#x3D;给赋值\n\n在使用此类参数时，可以使用两个命令先确认一下JVM默认值，防止JVM变动，最好还是明确设置\n-XX:+PrintFlagsInitial表示打印出所有XX选项的默认值-XX:+PrintFlagsFinal表示打印出XX选项在运行程序时生效的值\n\n这些参数从功能大体分类一下\n\n空间大小，类似-X参数，但这些空间各个JVM可能不同实现，如PermSize\n监控类，帮助确定问题Trouble shooting Options\n优化类，调优性能\nGC策略类\n\n内存类-XX:PermSize&#x3D;512m -XX:MaxPermSize&#x3D;512m\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=200m; support was removed in 8.0Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256m; support was removed in 8.0\n在JDK8之后，永久代向元空间的转换，配置项变成了\n-XX:MetaspaceSize&#x3D;200m -XX:MaxMetaspaceSize&#x3D;256m\n为什么需要这样转换？\n\n1、字符串存在永久代中，容易出现性能问题和内存溢出。2、类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。3、永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。4、Oracle 可能会将HotSpot 与 JRockit 合二为一。\n\n-XX:MaxDirectMemorySize&#x3D;2048m\n堆外内存的最大值，默认为Heap区总内存减去一个Survivor区的大小；像使用netty之类框架，用得多些。\n在DirectByteBuffer中，首先向Bits类申请额度，Bits类有一个全局的 totalCapacity变量，记录着全部DirectByteBuffer的总大小，每次申请，都先看看是否超限 – 堆外内存的限额默认与堆内内存(由-XMX 设定)相仿，可用 -XX:MaxDirectMemorySize 重新设定。\n如果已经超限，会主动执行Sytem.gc()，期待能主动回收一点堆外内存。然后休眠一百毫秒，看看totalCapacity降下来没有，如果内存还是不足，就抛出大家最头痛的OOM异常；详细可见《堆外内存》\n-XX:ReservedCodeCacheSize&#x3D;240M\nJIT编译后二进制代码的存放区，满了之后就不再编译，对性能影响很大。JDK7默认不开多层编译48M，开了96M，而JDK8默认开多层编译240M。可以在JMX里看看CodeCache的大小，JDK7下的48M一般够了，也可以把它设大点，反正内存多\n-XX:NewRatio&#x3D;1\n这个参数，与-Xmn or (-XX:NewSize and -XX:MaxNewSize) or -XX:NewRatio并列，都是设置年轻代大小。默认值为2, 也就是新生代占堆大小的1&#x2F;3， 个人喜欢把对半分， 增大新生代的大小，能减少GC的频率（但也会加大每次GC的停顿时间），主要是看老生代里没多少长期对象的话，占2&#x2F;3太多了。可以用-Xmn 直接赋值(等于-XX:NewSize and -XX:MaxNewSize同值的缩写)，或把NewRatio设为1来对半分(但如果想设置新生代比老生代大就只能用-Xmn)\n参数中带Ratio的还有一个-XX:SurvivorRatio，从字面意思看好像是新年代占比、survivor占比。其实是反的。\n-XX:NewRatio&#x3D;4表示年老代与年轻代的比值为4:1\n-XX:SurvivorRatio&#x3D;8表示Eden区与Survivor区的大小比值是8:1:1, 因为Survivor区有两个\n监控类-XX:+PrintCommandLineFlags\n让JVM打印出那些已经被用户或者JVM设置过的详细的XX参数的名称和值，还会打印出以及因为这些参数隐式影响的参数\n打印出来，需要核实线上运行状态时，有据可查\n-XX:-OmitStackTraceInFastThrow\n有时查线上问题时，看到有异常信息，但只有\n...java.lang.NullPointerExceptionjava.lang.NullPointerExceptionjava.lang.NullPointerException...\n具体的异常栈没了，有时异常监控不位，人工发现这些异常时，却看不出哪里的问题，很是恼火\nJVM对一些特定的异常类型做了Fast Throw优化，如果检测到在代码里某个位置连续多次抛出同一类型异常的话，C2会决定用Fast Throw方式来抛出异常，而异常Trace即详细的异常栈信息会被清空。这种异常抛出速度非常快，因为不需要在堆里分配内存，也不需要构造完整的异常栈信息\n特定异常：\nNullPointerExceptionArithmeticExceptionArrayIndexOutOfBoundsExceptionArrayStoreExceptionClassCastException\n\n-XX:+PrintGCCause\n打印产生GC的原因，比如AllocationFailure什么的，在JDK8已默认打开，JDK7要显式打开一下\n-XX:+PrintGCApplicationStoppedTime\n这是个非常非常重要的参数，但它的名字没起好，其实除了打印清晰的完整的GC停顿时间外，还可以打印其他的JVM停顿时间，比如取消偏向锁，class 被agent redefine，code deoptimization等等，有助于发现一些原来没想到的问题\n2018-10-18T03:27:39.204+0800: 33729.026: Total time for which application threads were stopped: 0.0059280 seconds, Stopping threads took: 0.0001000 seconds\n\n-XX:+PrintGCDateStamps\n输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）\n用PrintGCDateStamps而不是PrintGCTimeStamps，打印可读的日期而不是时间戳\n-XX:+PrintGCDetails\n输出GC的详细日志\n-XX:ErrorFile\n-XX:ErrorFile&#x3D;${MYLOGDIR}&#x2F;jvmerr_%p.log\nJVM crash时，hotspot 会生成一个error文件，提供JVM状态信息的细节。如前所述，将其输出到固定目录，避免到时会到处找这文件。文件名中的%p会被自动替换为应用的PID\n-XX:+HeapDumpOnOutOfMemoryError\n两个配合使用 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;${LOGDIR}&#x2F;\n在Out Of Memory，JVM快死掉的时候，输出Heap Dump到指定文件。不然开发很多时候还真不知道怎么重现错误。\n路径只指向目录，JVM会保持文件名的唯一性，叫java_pid${pid}.hprof。因为如果指向文件，而文件已存在，反而不能写入。\n但在容器环境下，输出4G的HeapDump，在普通硬盘上会造成20秒以上的硬盘IO跑满，也是个十足的恶邻，影响了同一宿主机上所有其他的容器\n\n优化类-XX:AutoBoxCacheMax\n-XX:AutoBoxCacheMax&#x3D;20000\n这个参数的意义是缓存自动装箱最大值\n\n设为20000后，我们应用的QPS有足足4%的影响\n\n看代码\nInteger i = 129;Integer j = 129;i == j //true or false ?\nJDK默认只缓存 -128 ~ +127的Integer 和 Long，超出范围的数字就要即时构建新的Integer对象;\n如果这儿配置了最大值20000，那就是[-128,20000]都不再创建新对象，但有点奇怪的时，你不能认为AutoBoxCacheMax的默认值是127\n为什么配置值是20000呢，就得说到-XX:+AggressiveOpts参数，这是是一些还没默认打开的优化参数集合, -XX:AutoBoxCacheMax是其中的一项。但这个参数在关键系统里不建议打开\n\nThere’s a JVM option -XX:+AggressiveOpts that supposedly makes your JVM faster. Lots of people turn this on in Eclipse to try to make it faster. But it makes your JVM less correct. Today I found it to be the cause of a longstanding bug in dx.http://code.google.com/p/android/issues/detail?id=5817\n\n\n-XX:+AggressiveOpts was deprecated in JDK 11 and should be removed in JDK 12\n\n-     bool AggressiveOpts                           := false           &#123;product&#125;+     bool AggressiveOpts                           := true            &#123;product&#125;-     intx AutoBoxCacheMax                           = 128             &#123;C2 product&#125;+     intx AutoBoxCacheMax                           = 20000           &#123;C2 product&#125;\n通过上面的打印设置配置值的参数，可以看出此项默认值是128,在打开AggressiveOpts参数时，是20000\n-XX:-UseCounterDecay\n禁止JIT调用计数器衰减。默认情况下，每次GC时会对调用计数器进行砍半的操作，导致有些方法一直温热，永远都达不到触发C2编译的1万次（server默认值）的阀值，详细可参考《JIT优化》\n-XX:-UseBiasedLocking\nJDK1.6开始默认打开的偏向锁，会尝试把锁赋给第一个访问它的线程，取消同步块上的synchronized原语\n如果始终只有一条线程在访问它，就成功略过同步操作以获得性能提升\n为什么会有偏向锁出现？因为经验表明，其实大部分情况下，都会是同一个线程进入同一块同步代码块\n但线上应用基本都是使用多线程，一旦出现锁竞争，就会锁膨胀，GC日志中有不少RevokeBiasd的纪录，像GC一样Stop The World的干活，虽然只是很短的停顿，但对于多线程并发的应用，取消掉它反而有性能的提升\n-XX:+PerfDisableSharedMem\nJVM经常会默默的在&#x2F;tmp&#x2F;hperf目录写上一点statistics数据，如果刚好遇到PageCache刷盘，把文件阻塞了，就不能结束这个Stop the World的安全点\n禁止JVM写statistics数据的代价，是jps和jstat用不了；详细可看jstat的具体实现\n-XX:MaxTenuringThreshold&#x3D;4\n这是改动效果最明显的一个参数了。对象在Survivor区最多熬过多少次Young GC后晋升到年老代，JDK8里默认是15\nYoung GC是最大的应用停顿来源，而新生代里GC后存活对象的多少又直接影响停顿的时间，所以如果清楚Young GC的执行频率和应用里大部分临时对象的最长生命周期，可以把它设的更短一点，让其实不是临时对象的新生代对象赶紧晋升到年老代，别呆着。\n用-XX:+PrintTenuringDistribution观察下，如果后面几代的大小总是差不多，证明过了某个年龄后的对象总能晋升到老生代，就可以把晋升阈值设小，比如JMeter里2就足够了\n-XX:+UnlockDiagnosticVMOptions -XX: ParGCCardsPerStrideChunk&#x3D;1024\n\nLinkined的黑科技， 上一个版本的文章不建议打开，后来发现有些场景的确能减少YGC时间，详见《难道这些 Java 大牛说的都是真的？》，简单说就是影响YGC时扫描老生代的时间，默认值256太小了，但32K也未必对，需要自己试验\n\n-XX:+ExplicitGCInvokesConcurrent\nfull gc时，使用CMS算法，不是全程停顿，必选\n-XX:+AlwaysPreTouch\n启动时访问并置零内存页面；启动时就把参数里说好了的内存全部舔一遍，可能令得启动时慢上一点，但后面访问时会更流畅，比如页面会连续分配，比如不会在晋升新生代到老生代时才去访问页面使得GC停顿时间加长。ElasticSearch和Cassandra都打开了它\n\nGC策略配置-server时默认使用ParallelScavenge系的GC,是个吞吐量优先的收集器\n虽然现在有了G1 GC,甚至JDK11后的ZGC,但在大型互联网项目上估计CMS还是主流\nCMS三个基本配置\n-XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction&#x3D;75 -XX:+UseCMSInitiatingOccupancyOnly\n\n因为我们的监控系统会通过JMX监控内存达到90%的状况（留点处理的时间），所以设置让它75%就开始跑了，早点开始也能避免Full GC等意外情况(概念重申，这种主动的CMS GC，和JVM的老生代、永久代、堆外内存完全不能分配内存了而强制Full GC是不同的概念)。为了让这个设置生效，还要设置-XX:+UseCMSInitiatingOccupancyOnly，否则75只被用来做开始的参考值，后面还是JVM自己算\n\n-XX:+ParallelRefProcEnabled -XX:+CMSParallelInitialMarkEnabled\n并行的处理Reference对象，如WeakReference，默认为false，除非在GC log里出现Reference处理时间较长的日志，否则效果不会很明显，但我们总是要JVM尽量的并行，所以设了也就设了。同理还有-XX:+CMSParallelInitialMarkEnabled，JDK8已默认开启，但小版本比较低的JDK7甚至不支持\n建议参数-XX:ParallelGCThreads&#x3D;? -XX:ConcGCThreads&#x3D;?\n-XX:ParallelGCThreads&#x3D;n\tGC在并行处理阶段多少个线程，默认值和平台有关。（译者注：和程序一起跑的时候，使用多少个线程)\n-XX:ConcGCThreads&#x3D;n\t并发收集的时候使用多少个线程，默认值和平台有关。（译者注:stop-the-world的时候，并发处理的时候使用多少个线程)\nParallelGCThreads＝Processor &lt; 8 ? 8 : 8 +( Processor - 8 ) ( 5&#x2F;8 )；\nConcGCThreads &#x3D; (ParallelGCThreads + 3)&#x2F;4\n24个处理器，小于8个处理器时ParallelGCThreads按处理器数量，大于时按上述公式YGC线程数＝18， CMS GC线程数＝5。\nCMS GC线程数的公式太怪，也有人提议简单改为YGC线程数的1&#x2F;2。\n一些不在乎停顿时间的后台辅助程序，比如日志收集的logstash，建议把它减少到2，避免在GC时突然占用太多CPU核，影响主应用。\n而另一些并不独占服务器的应用，比如旁边跑着一堆sidecar的，也建议减少YGC线程数。\n一个真实的案例，24核的服务器，默认18条YGC线程，但因为旁边有个繁忙的Service Mesh Proxy在跑着，这18条线程并不能100%的抢到CPU，出现了不合理的慢GC。把线程数降低到12条之后，YGC反而快了很多。 所以那些贪心的把YGC线程数＝CPU 核数的，通常弄巧成拙。\n不要-XX:+DisableExplicitGC\n像R大说的，System GC是保护机制（如堆外内存满时清理它的堆内引用对象），禁了system.gc() 未必是好事，只要没用什么特别烂的类库，真有人调了总有调的原因，所以不应该加这个烂大街的参数。\nReference关键业务系统的JVM参数推荐\nJVM源码分析之Jstat工具原理完全解读\n《难道这些 Java 大牛说的都是真的？》\nSecureRandom的江湖偏方与真实效果\n","tags":["jvm"]},{"title":"中台是什么","url":"/blog/what-is-zhongtai.html","content":"中台，在过去两年是个流量顶级词汇，谈什么都得带上中台，干什么都得扯点中台，不说中台，那绝对不是个合格的技术人\n但经过了谈中台、建中台、拆中台，潮起潮落，不管是看好，还是贬低；可以看出在技术大词的浪潮里，不管是应激者怕掉队，还是投机者想上位，真正懂它的人不多，或者大多都还停留在以以往经验来判定的新事物\n在历史遗忘之际，我来重温一下它\n起源在中台的发展进程中，首先得回到它的起源，至少有两个版本：\n一是正史，马云一行，参观了芬兰一家游戏公司supercell，大受震撼，回来就提出了“中台战略”\n一是野史，张勇的挟中台以令诸侯\n从这两史中至少可以看出一些东西：\n\n中台是由企业掌舵者提出以及使用的，它不是一个技术人员提出的，甚至说是CTO级别提出的，提出的起源与技术占不上边\n中台的战略地位，不管是愿景实现还是战略落地，都发挥着巨大作用\n\n所以很多技术人不解的地方，为什么谈到中台，需要谈企业战略，需要企业级组织变更，而不仅仅在于研发内部，不是使用的技术多牛，而是因为中台本身就有战略属性\n因此在讨论中台时，需要从业务环境，组织结构，人力构成和技术架构各方面统筹考虑，抛开这些单从技术角度，是没有全局视角衡量中台的优劣，也是没有意义的，所以中台得结合企业本身综合情况，而不是技术迁移就能完成的\n定义现在提到中台，一连串的词汇会涌现出现，比如共享、复用、积木化\n那么什么才叫中台呢？至少指出者没有给出定义，但它有特性，就是在高速发展环境之下，企业需要具备相应的响应速度去支撑企业运营的需求，而依靠小而灵活的前台团队，频繁而低成本的试错是一种应对此商业环境具有竞争力的模式\n“小而灵活”是关键：小意味着人员少，成本低；灵活意味着对外快速响应市场，对内流程敏捷，快速失败\n而能支撑这种小而灵活前台团队的系统就称为中台，这是从中台的作用来描述它，经过这几年的发展，有各式各样的定义\n我比较认同王健老师的定义：企业级能力复用平台\n企业级：\n定义了中台的范围。它不是单业务级，是从企业全局出发，考虑多条业务线；一个企业也不是只有一个中台，可以有多个中台。也就是企业与中台的关系是多对多的\n企业级这表明了中台不单是技术问题，而是上升到企业架构的问题\n能力：\n定义了中台主要承载的对象。能力的抽象解释了为什么有那么多种类的中台，也解释了为什么每家中台都是不一样的，因为每家企业的核心能力是不一样的\n复用：\n定义了中台的核心价值，建设中台的过程就是推倒烟囱系统的过程，也是去重复用的过程；“去重”讲的更多是向后看，是技术驱动；“复用”讲的更多是向前看，是业务驱动和用户驱动的\n中台需要从“去重”到“复用”的视角转变\n“复用”是中台更加关注的目标\n“可复用性”和“易复用性”是衡量中台建设好坏的重要指标\n“业务响应力”和“业务满意度”是考核中台建设进度的重要标准\n平台：\n定义了中台的主要形式。区别于传统的应用系统拼凑的方式，通过对于更细粒度能力的识别与平台化沉淀，实现企业能力的柔性复用，更好地支撑前台业务\n种类自从中台概念流行，各个词都与中台组词了，研发中台、技术中台、组织中台、业务中台…只要把以前谈的词语带上中台，就是高大上的\n经过过去几年的喧嚣，沉寂。人们对中台品种达成了一定的共识：业务数据双中台\n网易副总裁汪源曾在网易云创峰会上提到：“所有中台都是业务中台”。从中台起源出发，的确，中台就是为业务，为企业更好地以更低成本、更高质量、更快响应速度售出产品、换取利润服务的\n而数据中台，更多的是大数据时代到来，大势所趋，业务中台是产生数据，数据中台是做数据二次加工，并将结果再服务于业务，为业务进行数据和智能的赋能\n创新这两年，拆中台的声音呼啸而起。尤其以当年带起中台的阿里等一系列巨头，都在拆。人们又开始跟风中台不行了\n戏称，我们作业才抄到一半，你说写错了\n为什么要拆呢？想那盒马不就是中台成功的典范，但在犀牛制造却提出不拿中台一针一线了，自己从零开始\n这其实就是任何软件平台的特性\n平台的能力越丰富，上层应用可以利用的越多，去完成某类功能的成本就越低，因而平台能力通常被看作效能下限\n应用利用平台能力获得效能，是通过放弃一部分自主性获取，而低自主性就影响创新的可能，所以应用自主度被看作创新上限\n“效能下限”与“创新上限”就像翘翘板，产生了哑铃效应，而中台则是追求效能的极致，同时却也降低了创新上限\n对于像巨头在中台已经沉淀多年，有了相当应对当前市场的能力，但想要争取更多的市场份额，创新需求日益剧增,尤其需要颠覆式创新\n因此，别人拆的时候，你能拆吗？建中台需要综合考虑，拆中台同样需要考虑\n总结中台曾经的顶级流量热词，不管当初的是应激怕掉队，还是投机想上位，浪潮退去之时，我们才能静下心来思考它是什么，它能干什么\n虽然现在已经冷却，但威力不减，提升企业竞争力一把好手，它的出发点不是技术基建，而是寻找更好的组织结构和技术架构，以支持业务的快速增长和发展\n","tags":["中台"]},{"title":"不要终身低效学习","url":"/blog/do-not-study-inefficiently-all-your-life.html","content":"那一年有个程序员在github上撕心裂肺痛首疾呼\n\n这句呐喊，喊出了多少程序员内心的苦楚，行业更新迭代太快，而年龄在不断增长，精力在下降，尤其现如今的内卷文化，怎么才能不掉队，保持竞争力？似乎唯有保持学习能力一条路。\n我们是怎么学习的呢？学习的效果如何？需要去对学习有一定的元认知能力。\n李笑来老师有个专栏，叫学习学习再学习。意思是讲先把学习这件事学习会了，再去学习其他知识。\n我也一直在反思自己的学习能力，学习效果与速度，所以也一直在学习怎么学习，怎么学习才有效果，脱离低级学习效能。毕竟学习本身不仅对自身有帮助，也是家中无矿普通大众唯一可以传承给后代的财富，知识时代，缺什么也不能缺少学习能力。\n功夫我们学习的动机是什么？\n一开始我们靠兴趣，但是兴趣多变；然后我们追新知，发现新知进化得比我们学习的速度还快；之后我们回身去读经典，却发现经典一辈子也读不完；于是我们开始寻求底层逻辑。\n然而底层逻辑是高度抽象的，人类对抽象的认知都是非常困难的，幸运的是所有对抽象的认知都是源于对大量具体事物认知的抽象。\n我们一般都不是骨骼清奇的天才，大多数时候只能渐修顿悟。就算是真经放在眼前，也没有识货的能力。\n举个切身经历的案例，在我刚入职场时，那时我还很痴迷于阅读源码，一天我灵机一动，学生时代就倒腾了几年的web开发，都是跑在web container中的，为何不看看tomcat源码呢，下班看，上班干完手上活也看。一天领导问我在干吗，我兴致勃勃地说在看tomcat源码，写得真精妙。\n领导把我叫到一边，语重心长地说，学习源码是不错，但对我们当前工作有直接帮助吗？我们开发游戏，用的是TCP协议，使用的是mina、netty网络框架，如果现在项目中要准备使用web了，再看也不迟。就算你现在看了，以后我们真用上，其他人去学习，你也不一定比他们提前多少。\n“切，又忽悠我多干活，压榨”。这是我当时第一反应。你觉得这是真经吗？\n领导的这番教导，我也是过了很久才慢慢醒悟。是什么底层认知逻辑，且看文末总结。\n因此我们还是得踏踏实实地积累基础知识，同时，需要勤于思考，学会抽象，学会抓本质。\n花功夫，事上修。否则读遍经书也枉然。\n如何学习学习一样技能，需要经过三个过程\n1、编码：知道并理解，形成一些潜在的心理表征\n2、巩固：强化心理表征，通过遗忘，再考试，再练习不断地被挑战\n3、检索：学以致用\n细化一下这个过程\n大概会经过这几个步骤：获取、理解、拓展、纠错、应用\n获取不再像过去贫瘠时代，获取知识本身的难度，现今是如何面对信息大爆炸时代，过滤出精品。\n获取知识的两个要点：\n1、速度\n2、质量\n对于速度，有几个方法：\n首先让自己变成一个文字型学习者，现在有视频、音频等多媒体信息，而文字是最快速的获取方式。回想微信聊天，是看文字快还是语音快？\n其次学习一些快速阅读的技能\n1、指读法：对的，你没看错，用手指指着文字阅读。\n2、练习阅读法：刻意练习，比如手指移动更快些，又快又能最大吸收信息\n3、积极阅读法：也就是带着问题阅读，或者读完问自己几个问题，这一节主要观点是什么；怎么能记住主要观点；观点拓展以及应用\n比如最近有篇转来转去的文章《我在美团的八年》，作者总结了几个原则，第一次看觉得作者讲得真不错，可当在聊天群中再次看到被人转发时，只是想这文章我看过，作者写得不错。但具体内容可能都忘光了。这时不妨回忆下，作者说了哪个原则？最认同哪个？能再加减点别的原则。再阅读比对一下。\n而对于质量，是要去学习第一手资料学习原理并且及时更新，尤其像程序员，不然看到的知识可能是错的。\n比如，我两年前总结的一篇JVM参数文章：《百万QPS系统JVM参数》，如果你现在看到直接照本全收，估计有些参数有效，有些无效，整体效果你会失望，但也别说我乱写，因为JVM在发展，参数也在更新，而且也是在我当时的系统背景下得出的结论，我的认知也可能是不完整的。\n但你掌握了JVM调优原理，并结合最新的JVM规范因地制宜，是没问题的，质量也是有保障的。\n再比如你正在看的这篇文章，也是很多手信息后的产物。不是说就不要看了，至少可以激发你的思考，进而去拓展学习。\n质量和速度兼并的学习技能是联机学习，我们要做知识的路由器\n\n通过交流交换思想，再深入思考，整合归纳。相比个人学习，不管是速度还是质量都会有更大的提升。\n为什么要去大厂，不就是能更方便地遇到更牛B的人，快速吸收他们的最新思考成果。\n拓展一味地获取内容和信息，并不一定能达到想要的效果。启发思考才是学习的目的，所以反思是学习真正发生的时候，这样才能去改变我们的行为和思维。\n拓展就是思考与反思阶段，只有拓展得好，才会将学到的知道举一反三、触类旁通。也只有这样，后期我们才能应用好知识。\n拓展有三种方式：\n1、深度拓展\n不仅仅理解一个结论就结束，还得挖掘知识从何而来？结论来自何处？一个发现是如何做出来的？结论之前的试验是怎么做的？怎么想起来做的？\n一句话，我们要知其然还得知其所以然，多问why，以及how。\n2、横向拓展\n与知识周围建立联系。\n知识不会孤立地存在，与此类似的结论还有哪些？是哪些地方类似？不同的地方在哪里？同一时期还有哪些其他的发现，同一个发现者还有哪些发现，在同一个领域里还有哪些发现？\n3、纵向拓展\n知识都遵循一定的模式，同样的模式在其他知识中也会出现，能将一个公式与一个自然事件相联系吗？\n纵向拓展是有相当难度的。也是最有创造性的学习方式。\n比如达芬奇看到鸟在天上飞，他就琢磨鸟在天上飞和鱼在水里游到底有什么共同之处，为什么鱼在水里游那个敏捷的程度明明有水做阻力，但看起来比鸟还快。为什么？后来他就慢慢搞出了流体力学。\n这三种方式似乎有些难以理解，可以类比在《架构与架构师》中提到的架构师技术能力包含的知识深度、宽度、广度。\n再如最近我写的《大明湖畔的领域模型》，领域模型因OOA被提出，让我们寻找现实中的概念类，万物皆对象，映射到具体软件实现类。而同时期Martin Fowler也提出了Domain Model，却是对OO升华，要充血模型，不要贫血模型。再到现如今大家热议DDD中的领域模型，Eric推崇的分析模型与实现模型统一融合。\n一个概念被各方位拓展后，原始的软件方法论被突破，各种全新软件方法论被创造。\n高效学习赚钱只能赚到认知范围内的钱，不然凭运气赚取的钱也会被实力亏掉；同样，学习也是如此。只是知道如何学习，无法内化这些认知，学习行为的效率依然低下。\n如何能高效学习，我们需要再一次反思自己对学习的元认知。\n错觉我们的元认知非常容易出现偏差，常会产生两个误区：\n1、不知道自己学习中的薄弱之处，不知道要在哪里花更多精力才能提高自己的知识水平\n2、爱使用那些会让自己错误地认为掌握了知识的学习方法，也就是拼命记笔记、拼命画下划线、拼命地用荧光笔、拼命地反复阅读\n怎么解决这两个误区？巩固与检索。\n学习越轻松，效果越不好，看来起来非常勤奋，不停地背书，一遍一遍地背，拿笔一遍一遍地画，甚至是一遍一遍地抄，看起来很勤奋耗费大量的时间，但他的学习过程是很轻松的，没有做到有挑战的事情。\n通过检索、考试，不断地挑战来巩固记忆。\n比如要跳槽了，怎么去准备面试呢？拿出浩瀚如烟的资料去慢慢复习吗？或者找一堆面试题来刷吗？\n这些都很低效，不如自己玩一把角色扮演，扮演下面试官，给自己出一份面试题，出题需要检索知识点，解题也需要挑战记忆。\n再按知识模块与各种资料比对自己的知识掌握度，查漏补缺，事半功倍。\n问题树认知心理学认为，有三个前提要求时，学习效率最高：\n1、有目标导向，俗称带着问题学习\n2、有即时反馈，为什么游戏好玩？\n3、最近发展区，当前水平与通过学习获得的潜力之间的差异叫最近发展区\n那么怎么样的学习方式才会同时拥有这几个前提呢？使用问题树的思维方式替代知识树的思维方式。\n知识树的思路，是典型的专业知识细分的学习路径。工业时代分工高度稳定，每个领域都相对独立、发展缓慢，一个人有机会学完一个细分领域的所有知识。沿着一棵长成的大树向上爬，这种学习路径效率最高。\n但在一个高度变化、多领域跨界的时代，完成任何任务都需要调取多领域的知识，全部靠自己学习显然来不及。\n\n当我们想学习某一知识时，常列个计划，搜集资料，罗列书单、阅读清单，可涉及面很广，这样难免有很大的随机时，书单虽全虽好，最后没有动力去读，读了也没有实践的动力。\n而以问题为切入点，问题使目标更清晰，不会在知识树里迷路；动力也更强，一个问题解锁后，会带来更多、更大、更有趣的问题。\n时代是水流，答案是河岸，而问题是船只。\n在水流不快的时代，可以在河岸上慢慢走，也许跟得上水流；但在知识爆炸、洪流时代，只有登上船只，才能保持和时代同步。守在岸上，只能被远远抛下，望洋兴叹。\n不要学习相对现如今提出的终身学习者，是不是有些反人类。\n不要学习，指的是在没有明确自己究竟想达到什么目的，就去不停地“学习”，实在是对宝贵时间资源的浪费。而且学习得多，未必收获得就好。\n打个比方，学习就好比整个食物经过咀嚼、消化、吸收的过程，它不是表面看起来“吃”的动作。人们不可能永远吃个不停，所以学习行为不是越多越好。\n学习需要挑选吃的食物（获取信息）、咀嚼（明白阶段）、消化（理解阶段）、吸收（应用阶段）。\n犹如ThoughtWorks中国区CTO徐昊在他的专栏《业务建模》中所说，技术没有反哺过我的生活，反而我的人生给养了在技术上的洞见。吃喝玩乐并不耽误事，因为学习是一种状态（being），而不是一种行为（doing）。在学习的状态中，吃喝玩乐都可以让我成为更好的程序员。\n找到自己的目标，不要人云亦云，刻意宣传终身学习更多时刻是商家制造的焦虑感收缴人们的智商税。\n总结世人都知道认知能力重要性时，我们更需要去认知一下如何更好地获得认知的能力。\n“学习”本身不是一件容易的事，在我们长期实践“学习”的空隙，需要对“学习”保留一份反思，学习学习，加深对学习元认知的认识。\n不需要刻意终身学习，更不必因终身学习而焦虑，它就是我们的血液。是这个时代赋予我们的第二呼吸。\n学习行为像吃饭，学习状态像呼吸。不要为了学习而学习，贪图勤奋的假象带来的快感。\n回到篇首，提到我的切身经历，问题的本质是认知效率：认知收益与时间精力之比，牛人真正的秘诀是在最精华的资源上，以高很多倍的认知资源来学习。要事第一。\n当然在认知水平不够时，也不要吝啬自己的时间。毕竟我们已经与牛人有了差距，花功夫才能得到真功夫。\n最后的最后，如果你对学习主题也感兴趣，可以延伸阅读《刻意练习》、《认知天性》、《如何高效学习》、《人是如何学习的》、《卡片笔记法》、《跃迁》。\n","tags":["学习"]},{"title":"主动GC是否需要","url":"/blog/is-active-gc-required.html","content":"看一段线上的gc日志，这是一段CMS完整步骤的日志，对于GC日志格式，不了解的可以再温习一下《GC及JVM参数》\n2017-07-18T21:28:41.422+0800: 11941915.242: [GC (CMS Initial Mark) [1 CMS-initial-mark: 786446K(1048576K)] 789098K(1992320K), 0.2623622 secs] [Times: user=0.00 sys=0.00, real=0.26 secs] 2017-07-18T21:28:41.684+0800: 11941915.505: Total time for which application threads were stopped: 0.2630097 seconds, Stopping threads took: 0.0000587 seconds2017-07-18T21:28:41.685+0800: 11941915.505: [CMS-concurrent-mark-start]2017-07-18T21:29:02.443+0800: 11941936.263: [CMS-concurrent-mark: 20.758/20.758 secs] [Times: user=3.22 sys=1.67, real=20.75 secs] 2017-07-18T21:29:02.443+0800: 11941936.263: [CMS-concurrent-preclean-start]2017-07-18T21:29:02.502+0800: 11941936.322: [CMS-concurrent-preclean: 0.059/0.059 secs] [Times: user=0.02 sys=0.01, real=0.06 secs] 2017-07-18T21:29:02.502+0800: 11941936.322: [CMS-concurrent-abortable-preclean-start] CMS: abort preclean due to time 2017-07-18T21:29:07.600+0800: 11941941.420: [CMS-concurrent-abortable-preclean: 0.889/5.098 secs] [Times: user=1.72 sys=0.31, real=5.10 secs] 2017-07-18T21:29:07.602+0800: 11941941.422: Application time: 25.9175914 seconds2017-07-18T21:29:07.603+0800: 11941941.423: [GC (CMS Final Remark) [YG occupancy: 491182 K (943744 K)]2017-07-18T21:29:07.603+0800: 11941941.423: [Rescan (parallel) , 0.0654053 secs]2017-07-18T21:29:07.668+0800: 11941941.488: [weak refs processing, 0.6491578 secs]2017-07-18T21:29:08.317+0800: 11941942.138: [class unloading, 4.2229435 secs]2017-07-18T21:29:12.540+0800: 11941946.361: [scrub symbol table, 0.0536739 secs]2017-07-18T21:29:12.594+0800: 11941946.414: [scrub string table, 0.0009992 secs][1 CMS-remark: 786446K(1048576K)] 1277629K(1992320K), 5.0003976 secs] [Times: user=0.96 sys=0.01, real=5.00 secs] 2017-07-18T21:29:12.603+0800: 11941946.423: Total time for which application threads were stopped: 5.0011973 seconds, Stopping threads took: 0.0000483 seconds\n对应着七个步骤： \n\n初始标记(CMS-initial-mark) ,会导致swt； \n并发标记(CMS-concurrent-mark)，与用户线程同时运行； \n预清理（CMS-concurrent-preclean），与用户线程同时运行； \n可被终止的预清理（CMS-concurrent-abortable-preclean） 与用户线程同时运行； \n重新标记(CMS-remark) ，会导致swt； \n并发清除(CMS-concurrent-sweep)，与用户线程同时运行； \n并发重置状态等待下次CMS的触发(CMS-concurrent-reset)，与用户线程同时运行；\n\n通过\n[Times: user=0.96 sys=0.01, real=5.00 secs]\n看出STW了5s,对于一个单台1万QPS的系统来讲，那5s就影响了上万次服务，这显示然达不到高可用的要求\n通过对user,sys,real的对比，user+sys的时间远远小于real的值，这种情况说明停顿的时间并不是消耗在cpu执行上了，不是cpu那就是io导致的了\n此时，可以通过sar命令查看一下\nsar（System Activity Reporter系统活动情况报告）是目前 Linux 上最为全面的系统性能分析工具之一，可以从多方面对系统的活动进行报告，包括：文件的读写情况、系统调用的使用情况、磁盘I&#x2F;O、CPU效率、内存使用状况、进程活动及IPC有关的活动等\n\nsar -B 输出说明：\n输出项说明：\npgpgin&#x2F;s：表示每秒从磁盘或SWAP置换到内存的字节数(KB)\npgpgout&#x2F;s：表示每秒从内存置换到磁盘或SWAP的字节数(KB)\nfault&#x2F;s：每秒钟系统产生的缺页数,即主缺页与次缺页之和(major + minor)\nmajflt&#x2F;s：每秒钟产生的主缺页数.\npgfree&#x2F;s：每秒被放入空闲队列中的页个数\npgscank&#x2F;s：每秒被kswapd扫描的页个数\npgscand&#x2F;s：每秒直接被扫描的页个数\npgsteal&#x2F;s：每秒钟从cache中被清除来满足内存需要的页个数\n%vmeff：每秒清除的页(pgsteal)占总扫描页(pgscank+pgscand)的百分比\nSWAP可以看到大量的pgin，这儿就不得不再普及一下linux的swap\n\nLinux divides its physical RAM (random access memory) into chucks of memory called pages. Swapping is the process whereby a page of memory is copied to the preconfigured space on the hard disk, called swap space, to free up that page of memory. The combined sizes of the physical memory and the swap space is the amount of virtual memory available.\n\n\nSwap space in Linux is used when the amount of physical memory (RAM) is full. If the system needs more memory resources and the RAM is full, inactive pages in memory are moved to the swap space. While swap space can help machines with a small amount of RAM, it should not be considered a replacement for more RAM. Swap space is located on hard drives, which have a slower access time than physical memory.Swap space can be a dedicated swap partition (recommended), a swap file, or a combination of swap partitions and swap files.\n\n\nLinux内核为了提高读写效率与速度，会将文件在内存中进行缓存，这部分内存就是Cache Memory(缓存内存)。即使你的程序运行结束后，Cache Memory也不会自动释放。这就会导致你在Linux系统中程序频繁读写文件后，你会发现可用物理内存变少。当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间被临时保存到Swap空间中，等到那些程序要运行时，再从Swap分区中恢复保存的数据到内存中。这样，系统总是在物理内存不够时，才进行Swap交换。\n\nswap vs 虚拟内存windows：虚拟内存\nlinux：swap分区\nwindows即使物理内存没有用完也会去用到虚拟内存，而Linux不一样 Linux只有当物理内存用完的时候才会去动用虚拟内存（即swap分区）\nswap类似于windows的虚拟内存，不同之处在于，Windows可以设置在windows的任何盘符下面，默认是在C盘，可以和系统文件放在一个分区里。而linux则是独立占用一个分区，方便由于内存需求不够的情况下，把一部分内容放在swap分区里，待内存有空余的情况下再继续执行，也称之为交换分区，交换空间是其中的部分windows的虚拟内存是电脑自动设置的\n为什么会停顿这么长时间呢？\n堆内存分配多大，当gc时，的确需要很长时间\n内存不够用时，使用了swap,在gc时，需要从swap加载到内存，耗时\n\n解决思路对于上面的原因，可以找出对应的方案：\n\n分配小点，通过小而快的方式达到快速gc\n定期检测old gen使用情况，当快要到达临界值时候(old gen使用率大于50%)主动执行cms gc\n\n主动Gc可能会影响服务，所以可能需要服务先下线，gc完，再上线\n参考资料CMS垃圾回收器详解\nGC Algorithms: Implementations\n","categories":["java"],"tags":["jvm","gc"]},{"title":"云时代微服务划分原则是什么","url":"/blog/what-are-the-principles-of-micro-service-division-in-the-cloud-era.html","content":"微服务架构是云时代的首选架构风格。\nMartin Fowler 在 2014 年写的文章《微服务的前置条件》中提到如果使用微服务架构，则需要先拥有一些先决条件：\n1、快速的环境提供能力\n2、基本的监控能力\n3、快速的应用部署能力\n而这三个能力，正是云原生提供的基本能力。\n新技术带来的价值既然现在是云时代，是不是我们就不用考虑其它架构风格，直接使用微服务架构呢？答案显示并不是。我们不要为了新技术而新技术。当然，对于找工作肯定是有利的。但我们还是从实际出发，从业务价值出发。\n在《架构师的自我拯救》中提到，架构师还得多考虑商业价值。使用新技术就是我们的借力。目标还是为了提升商业价值。\n所有的技术演进，都是围绕着用户对这个产品的核心诉求展开的，通过技术层面的架构改造，来解决用户当下的痛点。\n在阿里大牛毕玄的访谈中，提到了服务化的核心是解决了两个问题：\n一、为了解决系统的水平伸缩能力的问题。每个应用，每个系统，承担的责任变少了，伸缩性就变强了。对应到商业价值，以更细致的粒度，控制系统运营的成本。\n二、研发协作问题。以前100人开发一个系统，大家都没有分工，接一个需求，要改就从头到尾全改，这个时候有可能会出现冲突，因为可能每个人都在改同一个地方，大家合并代码的时候就非常痛苦，效率很低。\n服务化分工了，你就改这块儿，他就改那块儿，虽然增加了协作成本，但它毕竟能让100人甚至上千人的研发团队可以并行做下去，现代软件变得更复杂，做任何软件上来就是一帮人，必须考虑到一帮人协作的问题。\n正是《拆完中台再拆微服务》中阐述的微服务是为了提升程序效能和团队效能。\n云时代的特性假如一个电商网站，平时只有几千用户同时使用，只需要100台机器就足以支撑这个系统了；而到了双十一，用户量可能猛增几百倍，那需要比如说10000台机器支持这个系统。\n而云平台，可以动态调整系统需要的机器数量，让我们按需使用。这样我们就不需要在闲时投入过高的机器成本，也就是非双十一期间，维持10000台机器的开销。但同时也不会错过在业务高峰获取收益的机会，因为云平台会自动帮我们从100台扩容到10000台机器。\n这种动态调节的能力被称为云的弹性，它是云平台一切美好特质的基础。\n为了实现这种弹性，运行在云平台之上的系统，需要满足一个条件：这个系统可以通过水平扩展进行扩容。\n水平扩展，指通过增加机器数量、构造集群的方法，来满足容量的需求。\n垂直扩展，指当遇到扩容需求时，通过更换更强有力的机器，来获得更好的性能。\n各种基础设施服务云平台，它们其实只有复制和剪切两个能力：\n1、根据给定镜像，产生符合镜像内容的机器的能力。也就是将镜像复制为机器的能力。\n2、撤销不需要的机器，将其放回资源池的能力，也就是剪切机器的能力。\n通过复制和剪切这两个能力，云平台就能对某个镜像提供水平扩展。这种扩展方案通常被称作为弹性负载均衡。\n那么怎样利用弹性负载均衡提供的水平扩展，才能更有效地架构系统呢？关键在于将弹性需求不同的组件分离。\n假如你在运营一个在线电商平台，我们可以粗略地将这个电商 平台的业务分成产品目录和支付两大块。在双十一期间，肯定会遇到比平时更大的流量，因而需要更高的系统容量去支持业务。\n但问题来了，产品浏览和完成支付两个部分增加的流量是一致的吗？从个人实际参与抢购的经验看，双十一之前，用户对产品浏览的需要比平时多；而在双十一当天，可能会对支付的需求更多。\n因此我们对支付和产品目录两块功能，制定不同的水平扩展策略，然后由不同弹性负载均衡控制。这样就可以有针对性地在不同阶段为两块功能提供不同的容量。\n按这个角度，我们把弹性作为主要指标，对系统进行划分，将不同弹性变化的组件放入到不同的弹性边界中。\n通过弹性边界，可以更细致的粒度，控制系统运营成本，也才能真正发挥云平台的能力。所以当要想要利用云平台架构软件时，寻找合理的弹性边界是很重要的事。\n微服务划分原则微服务怎么划分？总体来讲，从功能性需求和非功能性需求两方面考虑。\n从功能性方面考虑：微服务的划分应该有利于保证系统概念的一致性，更容易灵活扩展功能，而这些又要求开发团队顺畅的沟通协作。\nDDD限界上下文正好在这方面提供了理论指导，奠定了划分基础。\n根据限界上下文划分，既考虑到了传统模块化思维中对业务概念的松耦合、高内聚的要求，又考虑到团队的认知负载和认知边界。\n这样一方面解决了团队协作和概念一致性问题。另一方面，每个限界上下文又是一个业务概念内聚的边界。在这个边界内部，就更容易建立可维护、易扩展的模型。\n合理的微服务划分，应该是对于多数需求变更，只需要改动一个或少量的微服务。而划分不合理的话，对多数业务需求，都要修改多个微服务。\n从非功能考虑：在性能、安全、可用性，甚至发布周期，看是不是需要进一步划分。或者考虑把几个限界上下文合并到一个微服务。极端情况下，把有上下文合并到一个服务，又变成一个单体。\n到此，微服务的划分，我们当前都是以限界上下文优先来划分的。这也符合面向对象建模中的聚合概念，是一种“一致性优化”的模型结构。是“概念一致性边界”，“事务边界”。\n但结合上一章节“弹性边界”，在云时代，弹性是个很重要指标。如果两个上下文明显具有不同的弹性诉求，那就应该拆分。而如果具有一致的弹性诉求，就可以不拆。\n弹性边界跟软件模块之间存在依赖关系一样，弹性边界间也会存在依赖。而弹性边界间的依赖（也就是服务间调用关系，或是数据交换关系），会造成流量的传递。如果上游弹性边界突然需要处理大量的流量，那么这些流量自然也会传递到下游弹性边界中。\n这在实现中常发生，当平台的入口系统流量上升后，后面依赖的系统流量也上升了，整个一条调用链路上的系统都得扩容。这种不同弹性边界间流量的传递就是弹性依赖。\n只要组件之间存在交互，弹性依赖就不可避免。在云平台更擅长处理依赖于吞吐量的弹性依赖，但对依赖于响应时间的弹性依赖，就没有好办法了。这背后的原因在于水平扩展并不能保证改进响应时间，而只能提高吞量。也就是云平台的弹性并不总能改进响应时间，但一定可以提高吞吐量。\n正因为云平台不擅长处理依赖于响应时间的弹性依赖，这类弹性依赖被称为弹性耦合，以表示与依赖于吞吐量的弹性依赖的区别。\n怎么避免弹性耦合，才能充分利用云平台的能力。最简单的方式，是将组件的同步调用模式改为异步。因为服务与组件间的同步调用，会带来响应时间的依赖；而异步调用，则能将其改变为吞量的依赖。也就是将弹性耦合变成了弹性依赖，使得整个系统可以更好地利用云平台能力。\n不过，当由同步变成异步时，意味着，原先产生的数据可能存在中间状态。比如支付，由原来的开始支付 -&gt; 支付成功&#x2F;失败；变成开始支付 -&gt; 支付中 -&gt; 支付成功&#x2F;失败。\n带来的中间件状态，在业务上是否有特殊含义，这在业务建模时，是需要考虑的第一个问题；再者，异步带来的一致性改变，对业务会产生什么影响，是需要考虑的第二个问题。\n归根到底，为了解决弹性耦合的问题，我们需要将原味面向对象风格中默认的同步模型改为异步。\n高内聚微服务划分原则，不管是以限界上下文为主，还是以弹性边界为主。更多的还是要考虑业务形态。为业务赋能才是目标。多维度去权衡划分原则。\n不能只考虑限界上下文，不管业务功能性还是团队认知负载是合理的，但弹性耦合了，一个扩容，链路上的所有系统都得扩容。也不能只考虑弹性边界，把简单同步的业务上下文都使用异步处理，忽略业务上的耦合必然性。为了异步而异步。\n总结起来，还是要权衡，不要单维度走极端。这些永远正确的废话，真的很有道理。最近看饿了么CTO张雪峰的访谈，正好聊到了微服务问题，可以结合理论体会一下：\n\n饿了么原来就是个单体，所有的业务逻辑就是一个东西、一个源代码库，C 端、B 端、D 端（Delivery，物流）全在一起，牵一发动全身，也就是说你在部署的时候，每个服务器都要布一坨这个东西，一是影响性能，二是发布很麻烦。只要有同学发布，即使跟你无关，你也要发布一遍，所有的机器都要扫一遍。我们做技术的就要拆解，肯定要至少再分一级。\n\n\n拆分与否，我们当时就遵循一个原则：只要一个人有变化，一堆人要随着你动，或者叫“牵一发动大部分”的时候，这一定是有问题的。其实这也是逻辑原则或数学原则。所以我跟他们说，不要扯什么领域驱动、微服务了，就用这个原则。这个原则确实最容易讲清楚，但实践的时候要多次试、反复试。单体是一个极端，微服务或单一原则是另一个极端。\n\n\n饿了么从来没有真正提过微服务，从来没有过，我不去用这个概念。我们就是从业务的合理性去拆分。对领域驱动呢，我当时也是持观望态度，不能说保留态度，我觉得领域驱动是一个模棱两可的东西（顶尖 DDD 牛人或在大规模超复杂体系下成功实践过的同仁勿喷，毕竟让绝大部分技术同学吃透 DDD，无论 ROI 还是效率都很低），就跟架构一样，所以我希望回归朴素，就是从逻辑的角度，或者数学角度，给大家解释。所以当时我们也不做领域，我把以前的经验带过来，开始有一些中台的萌芽，比如说把交易系统、营销系统拆出来，把用户系统拆出来等等。\n\n\n从逻辑上讲，当你十次里面有八次“牵一发要动大部分”的时候，你就没必要去拆，你就让它耦合（内聚）在那，哪怕最后合出来一个巨大的东西，那证明这个业务就是这样的，没办法。你要么抱怨很倒霉进入这个业务领域，要么你就自己想办法克服。当然还有一个办法就是你通过技术去改革这个业务，那意味着这个业务甚至整个行业的游戏规则都要变，在短时间内几乎不可能。之前也讲过，对绝大部分公司的技术团队来说，妄图通过技术驱动业务，还是省省吧。\n\n\n\n后来我发现物流系统还有个很大的问题，搞物流系统这批同学，就是另一类极客。饿了么刚开始拆分服务，物流拆分得很夸张，直接同步变异步了。我说你们犯了一个错误，叫“为了异步而异步”。大家以前的代码（交互）尽量都是一路撸到底嘛，直接写完，这个叫单体。后来搞微服务就要拆开了，结果他们不光拆开，拆开之后，还要用消息通知。我举个不太恰当但大家明白意思就行的例子，比如说算工资，本来可以直接算出来，他们非要先送一个你的职级，再送一个你的社保基数，然后送过来之后还不是马上给你，你要自己去取，我只是通知你有这个数据了。你取过来之后慢慢算，算完之后再推给另一个涉及工资计算的模块，诸如此类。物流同学就是用类似方式，他们真的把异步做到了“极致”（饿了么价值观：极致、激情、创新）。但是他们做异步的初衷是什么？是因为物流的量很大。以前宕机是因为量很大，用同步的话服务器撑不住，所以就改异步。他们说至少可以缓和五秒钟，但后来我发现这五秒钟没意义。我自己也体验过，比如我点个外卖，提交订单之后习惯性去刷一下，看看商户有没有接单，然后过一分钟看看骑手有没有接单。还要看地图，有时候看到小哥明明经过我这了，怎么先去送另一个人了？可能很多人都有这样的疑问，这个不能怪骑手，也不能怪系统，有各种原因，此处暂时不表。大家都会去刷，后来我们发现用户在饿肚子时的心理承受能力就是三到五秒（淘宝、携程没这问题，大家对订单或物流状态变化的容忍度高很多），你是通过异步让这个订单不至于当场爆掉，但你延后五秒之后，堆积起来也很厉害，东西多了之后，最后还是爆掉，你只是让用户前五秒感觉系统没有宕机，但最终结果还是宕机。最后我们异地多活搞出来，几乎就没有大的事情了。\n\n\n我们原来设想异地多活只能一次性切换，因为我们的业务是强耦合的，不像携程，携程机票、酒店关联度不大的，你要订机票 + 酒店，做个简单聚合就行了，但我们不一样，饿了么是用户下了单，商户接了单，物流就要送单，上下游其实是强耦合（高内聚）。程序员可能会说，现实业务没你说的那么理想，该强耦合就强耦合，其实不是强耦合，另一个词叫高内聚，该内聚的时候你不要去追求什么微服务那些乱七八糟的东西，就应该高内聚，因为就是一个业务形态，业务才是最重要的判断耦合或内聚的依据。谁（调用方 &#x2F; 消费方）也离不了谁（被调用方 &#x2F; 服务方），你每次调用都涉及到它，干嘛非强扯开来？没太大好处，当然，可以分开发布算一个好处，但也仅是技术上的好处，不是业务或领域上的好处。\n\n总结我们将微服务架构看作是一种以业务上下文为弹性边界的云原生架构模式。弹性优先原则不仅仅适用于微服务架构，而是适用于所有云原生架构。\n把功能需求和流量传导分为静态和动态的角度\n静态的功能需求：\n如果少数大需求需要跨微服务，是正常的，但是也要注意任务拆分，把大需求拆分到多个微服务，约定好接口，各自开发，各自部署，集中联调。\n如果大多数需求需要跨微服务，那多半你的微服务拆分的是有问题的，你需要重新考虑你的微服务的拆分是否合理，必要的话合并一些微服务。\n动态的流量传导：则是弹性边界，一旦流量上升，链路上所有系统都会被传导并进行扩容，那是不是拆分也不太合理，或者能否从弹性耦合变为弹性依赖。\n微服务架构只是一种技术手段，使用微服务架构的目的，不是为了让你的架构更流行更酷，也不是为了让你的服务尽可能小，而是借助微服务的架构，让团队规模变小，大开发部门变成各个小的开发小组，并且各个小组应该尽可能独立，减少相互依赖，减少沟通成本。\n而一个常见的问题就是错把手段当目的，为了微服务而微服务，服务拆的太细，反而维护和沟通成本大增。\n理想的微服务架构，一个需求在一个微服务内就解决了，独立测试独立上线，基本不需要太多跨团队的协作。同时一个小团队维护的微服务也是有限的。\n","tags":["微服务"]},{"title":"什么样的继承才是好的继承","url":"/blog/what-kind-of-inheritance-is-good-inheritance.html","content":"继承的本质是提高代码的复用。\n然而自从继承出世后，被人们过多滥用，以至于像耦合恐惧一样恐惧继承，得了“继承创伤应激障碍”。\n是不是有像耦合必然性一样，解决继承的创伤呢？\n里氏替换原则这个原则最早是在1986年由 Barbara Liskov 提出：\n\n若对每个类型T1的对象o1，都存在一个类型T2的对象o2，使得在所有针对T2编写的程序P中，用o1替换o2后，程序P的行为功能不变，则T1是T2的子类型\n\n在1996年，Robert Martin 重新描述了这个原则：\n\nFunctions that use pointers of references to base classes must be able tu use objects of derived classes without knowing it\n\n通俗地讲，就是子类型必须能够替换掉它们的基类型,并且保证原来的逻辑行为不变及正确性不被破坏。\n比如那个著名的长方形的例子。Rectangle 表示长方形，Square 继承 Rectangle，表示正方形。现在问题就来了，这个关系在数学中是正确的，但表示为代码却不太正确。长方形可以用成员函数单独变更长宽，但正方形却不行，长和宽必须同时变更。\nRectangle rect = new Square();rect.setHeight(4); // 设置长度rect.setWidth(5);  // 设置宽度assertThat(rect.area(), is(20)); // 对结果进行断言\n\n当正方形 Square 替换长方形 Rectangle 时，发现程序不能正确运行，这样就不满足LSP，也就不适合使用继承。\n还有那个同样著名的鸟类的例子。基类 Bird 有个 Fly 方法，所有的鸟类都应该继承它。但企鹅、鸵鸟这样的鸟类却不会飞，实现它们就必须改写 Fly 方法\npublic class AbstractBird &#123;  //...省略其他属性和方法...  public void fly() &#123; //... &#125;&#125;public class Ostrich extends AbstractBird &#123; //鸵鸟  //...省略其他属性和方法...  public void fly() &#123;    throw new UnSupportedMethodException(&quot;I can&#x27;t fly.&#x27;&quot;);  &#125;&#125;\n\n这样的设计\n一方面，徒增了编码的工作量\n另一方面，也违背了我们之后要讲的最小知识原则（Least Knowledge Principle，也叫最少知识原则或者迪米特法则），暴露不该暴露的接口给外部，增加了类使用过程中被误用的概率。\n想验证有没有违背里氏替换原则，主要是两方面：\n1、IS-A的判定是基于行为，只有行为相同，才能说是满足IS-A关系。\n2、通常说来，子类比父类的契约更严格，都是违反里氏替换原则的。\n在类的继承中，如果父类方法的访问控制是 protected，那么子类 override 这个方法的时候，可以改成是 public，但是不能改成 private。因为 private 的访问控制比 protected 更严格，能使用父类 protected 方法的地方，不能用子类的 private 方法替换，否则就是违反里氏替换原则的。相反，如果子类方法的访问控制改成 public 就没问题，即子类可以有比父类更宽松的契约。同样，子类 override 父类方法的时候，不能将父类的 public 方法改成 protected，否则会出现编译错误。\n而像长方形例子中，正方形继承了长方形，但是正方形有比长方形更严格的契约，即正方形要求长和宽是一样的。因为正方形有比长方形更严格的契约，那么在使用长方形的地方，正方形因为更严格的契约而无法替换长方形。\n多态和里氏替换有点类似，但它们的关注的角度是不一样的。多态是面向对象编程的一大特性，也是面向对象编程语言的一种语法。它是一种代码实现的思路。而里氏替换是一种设计原则，是用来指导继承关系中子类该如何设计的，子类的设计要保证在替换父类的时候，不改变原有程序的逻辑以及不破坏原程序的正确性。\n其实还是回归继承本质，就是为了代码复用，子类最好不要覆盖父类的任何方法，只做额外增强\n组合优于继承组合优于继承：如果一个方案既能用组合实现，也能用继承实现，那就选择组合实现。\n上面提到的鸟类例子，通过 AbstractBird 类派生出两个更加细分的抽象类：会飞的鸟类 AbstractFlyableBird 和不会飞的鸟类 AbstractUnFlyableBird。当还要关注“鸟会不会叫”的时候，那就需要再定义四个抽象类（AbstractFlyableTweetableBird、AbstractFlyableUnTweetableBird、AbstractUnFlyableTweetableBird、AbstractUnFlyableUnTweetableBird）\n\n类的继承层次会越来越深、继承关系会越来越复杂。而这种层次很深、很复杂的继承关系\n一方面，会导致代码的可读性变差。因为我们要搞清楚某个类具有哪些方法、属性，必须阅读父类代码、父类的父类的代码，一直追溯到最顶层父类的代码。\n另一方面，这也破坏了类的封装特性，将父类的实现细节暴露给了子类。子类的实现依赖父类的实现，两者高度耦合，一旦父类代码修改，就会影响所有子类的逻辑。\n\n简而言之，继承最大的问题就在于：继承层次过深、继承关系过于复杂会影响到代码的可读性和可维护性。\n而利用组合、接口、委托三个技术手段，重构一下上面的继承问题\npublic interface Flyable &#123;  void fly()；&#125;public class FlyAbility implements Flyable &#123;  @Override  public void fly() &#123; //... &#125;&#125;//省略Tweetable/TweetAbility/EggLayable/EggLayAbilitypublic class Ostrich implements Tweetable, EggLayable &#123;//鸵鸟  private TweetAbility tweetAbility = new TweetAbility(); //组合  private EggLayAbility eggLayAbility = new EggLayAbility(); //组合  //... 省略其他属性和方法...  @Override  public void tweet() &#123;    tweetAbility.tweet(); // 委托  &#125;  @Override  public void layEgg() &#123;    eggLayAbility.layEgg(); // 委托  &#125;&#125;\n\n总结尽管我们鼓励多用组合少用继承，但组合也并不是完美的，继承也并非一无是处。继承改写成组合意味着要做更细粒度的类的拆分。这意味着，我们要定义更多的类和接口。类和接口的增多也就或多或少地增加代码的复杂程度和维护成本。\n如果类之间的继承结构稳定，继承层次比较浅（比如，最多有两层继承关系），继承关系不复杂，我们就可以大胆使用继承。反之，系统越不稳定，继承层次很深，继承关系复杂，就尽量使用组合替代继承。\n","tags":["SOLID"]},{"title":"仅且仅创建一次对象","url":"/blog/create-the-object-only-and-only-once.html","content":"此篇算是对《voliatile,synchronized,cas》理论的一种实践\n全局引用场景单例模式不用讲，这是首先想到的方式。\n饿汉式 static final fieldpublic class Singleton&#123;    //类加载时就初始化    private static final Singleton instance = new Singleton();        private Singleton()&#123;&#125;    public static Singleton getInstance()&#123;        return instance;    &#125;&#125;\n这是最简单又安全的方式。但也有缺点：\n\n它不是一种懒加载模式（lazy initialization）\n一些场景中将无法使用：譬如 Singleton 实例的创建是依赖参数或者配置文件的，在 getInstance() 之前必须调用某个方法设置参数给它，那样这种单例写法就无法使用了。\n\n静态内部类public class Singleton &#123;      private static class SingletonHolder &#123;          private static final Singleton INSTANCE = new Singleton();      &#125;      private Singleton ()&#123;&#125;      public static final Singleton getInstance() &#123;          return SingletonHolder.INSTANCE;     &#125;  &#125;\n这种写法仍然使用JVM本身机制保证了线程安全问题；由于 SingletonHolder 是私有的，除了 getInstance() 之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本\n双重检验锁public class Singleton &#123;    private volatile static Singleton instance; //声明成 volatile    private Singleton ()&#123;&#125;    public static Singleton getSingleton() &#123;        if (instance == null) &#123;                                     synchronized (Singleton.class) &#123;                if (instance == null) &#123;                           instance = new Singleton();                &#125;            &#125;        &#125;        return instance;    &#125;   &#125;\n这个写法得注意到volatile\n主要在于instance &#x3D; new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。\n\n给 instance 分配内存\n调用 Singleton 的构造函数来初始化成员变量\n将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了）但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。\n\n声明为volatile，使用其一个特性：禁止指令重排序优化。\n也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障（生成的汇编代码上），读操作不会被重排序到内存屏障之前。比如上面的例子，取操作必须在执行完 1-2-3 之后或者 1-3-2 之后，不存在执行到 1-3 然后取到值的情况。从「先行发生原则」的角度理解的话，就是对于一个 volatile 变量的写操作都先行发生于后面对这个变量的读操作（这里的“后面”是时间上的先后顺序）。\nvolatile的更多特性，可以看一下上篇文章《voliatile,synchronized,cas》\n间接被引用情景需要创建一次的对象不是直接被全局的引用所引用，而是间接地被引用。经常有这种情况，全局维护一个并发的ConcurrentMap, Map的每个Key对应一个对象，这个对象需要只创建一次\nCASprivate final ConcurrentMap&lt;String, InstanceObject&gt; cache        = new ConcurrentHashMap&lt;&gt;();    public InstanceObject get(String key) &#123;        InstanceObject single = cache.get(key);        if (single == null) &#123;            InstanceObject instanceObject = new InstanceObject(key);            single = cache.putIfAbsent(key, instanceObject);            if (single == null) &#123;                single = instanceObject;            &#125;        &#125;        return single;    &#125;\n使用这个很可能会产生多个InstanceObject对象，但最终只有一个InstanceObject有用\n但并不没有达到仅创建一个的目标\n如果创建InstanceObject的成本不高，那也不用太讲究\n但一旦是大对象缓存，那么这很可能就是问题了，因为缓存中的对象获取成本一般都比较高，而且通常缓存都会经常失效，那么避免重复创建对象就有价值了\n影子类private final ConcurrentMap&lt;String, Future&lt;InstanceObject&gt;&gt; cache1 = new ConcurrentHashMap&lt;&gt;();    public InstanceObject get1(final String key) &#123;        Future&lt;InstanceObject&gt; future = cache1.get(key);        if (future == null) &#123;            Callable&lt;InstanceObject&gt; callable = new Callable() &#123;                @Override                public InstanceObject call() throws Exception &#123;                    return new InstanceObject(key);                &#125;            &#125;;            FutureTask&lt;InstanceObject&gt; task = new FutureTask&lt;&gt;(callable);            future = cache1.putIfAbsent(key, task);            if (future == null) &#123;                future = task;                task.run();            &#125;        &#125;        try &#123;            return future.get();        &#125; catch (Exception e) &#123;            cache.remove(key);            throw new RuntimeException(e);        &#125;    &#125;\n这儿使用Future来代替真实的对象，多次创建Future代价比创建缓存大对象小得多\n自旋锁觉得Future对象还是重了，那就使用更轻的AtomicBoolean,那其实主要使用的还是volatile的特性\nprivate final ConcurrentMap&lt;String, AtomicBoolean&gt; spinCache = new ConcurrentHashMap&lt;&gt;();   public InstanceObject getAtomic(final String key)  &#123;       InstanceObject single = cache.get(key);       if (single == null) &#123;           AtomicBoolean newBoolean = new AtomicBoolean(false);           AtomicBoolean oldBoolean = spinCache.putIfAbsent(key, newBoolean);           if (oldBoolean == null) &#123;               cache.put(key, new InstanceObject(key));               newBoolean.set(true);           &#125; else &#123;               //其他线程在自旋状态上自旋，等等被释放               while (!oldBoolean.get()) &#123;&#125;           &#125;           single = cache.get(key);       &#125;       return  single;   &#125;\n\n总结保守写法可以使用synchronized,lock，他们的性能也不低；但为了性能极致，可以使用上面的方式。\n完整的测试代码：https://github.com/zhuxingsheng/javastudy/blob/master/src/main/java/com/jack/createonlyone/CreateOnlyOneMain.java\n"},{"title":"代码小析 - 异步回调","url":"/blog/code-analysis---asynchronous-callback.html","content":"\n天下皆知美之为美，斯恶已;此专栏本想取名代码之美，但有傍名之嫌，也给别误解，所以就叫代码小析吧，看到一段好代码，思路清奇，奇巧淫技，拿出来鉴赏一番\n\n之前是计划one week one  alogrithm,结果算法是个短板，不仅要理解，还得再写出代码，特别烧脑，所以中间穿插一下，换换脑子\n之前有类似一篇《仅且仅创建一次对象》\n最近看到一个段子：\n老板有毛病吧，写完排序就叫我走人，我还嫌你这9K工资低了呢\n感觉能想到这思路的也算清奇，哈哈！\n回调if you call me, i will call back\n回调分类：同步回调，异步回调\n场景建立TCP连接是很耗时的，所以在创建Socket Channel时，可以通过异步回调方式解决\n代码/** * 异步取得channel * @param index * @param callback */public void asynGetChannel(int index,final Callback callback) &#123;    // 1. 随机获取一条channel    final int pos = ThreadLocalRandom.current().nextInt(MAX_CONNECTIONS);    Channel target = channels[pos];    // 2. 如果获取到了连接，直接返回    if (target != null &amp;&amp; target.isActive()) &#123;        logger.info(&quot;direct success &quot;+index);        callback.onSuccess(target);        return;    &#125;    synchronized (locks[pos]) &#123;        target = channels[pos];        // 2. 如果获取到了连接，直接返回        if (target != null &amp;&amp; target.isActive()) &#123;            callback.onSuccess(target);            return;        &#125;        // 3.如果连接正在创建中，则加入queue        if (target instanceof EmptyChannel) &#123;            boolean result = jobs.offer(callback);            if (result) &#123;                return;            &#125; else &#123;                throw new RuntimeException(&quot;Can&#x27;t connet to target server and the waiting queue is full&quot;);            &#125;        &#125;        // 4. 连接尚未创建        channels[pos] = new EmptyChannel();       Connector.connect(host, port, new Callback() &#123;           @Override           public void onSuccess(Channel channel) &#123;               logger.info(index + &quot; ------------connect success---------&quot;+pos + &quot; channel:&quot; +channels[pos].getClass().getName());               List&lt;Callback&gt; tmpJobs;//建立一个tempJobs，快速释放锁               synchronized (locks[pos]) &#123;                   // 设置channels，拷贝jobs队列，释放锁                   channels[pos] = channel;                   tmpJobs = drainJobs();               &#125;               for(Callback pendingCallback : tmpJobs) &#123;                   try &#123;                       if(pendingCallback != callback) &#123;                           pendingCallback.onSuccess(channel);                       &#125;                   &#125; catch (Exception e) &#123;                       logger.error(&quot;call connectionCallback fail&quot;, e);                   &#125;               &#125;           &#125;           @Override           public void onError(Throwable e) &#123;               List&lt;Callback&gt; tmpJobs;//建立一个tempJobs，快速释放锁               synchronized (locks[pos]) &#123;                   // 设置channels，拷贝jobs队列，释放锁                   channels[pos] = null;                   tmpJobs = drainJobs();               &#125;               for(Callback pendingCallback : tmpJobs) &#123;                   try &#123;                       if(pendingCallback != callback) &#123;                           pendingCallback.onError(e);                       &#125;                   &#125; catch (Exception x) &#123;                       logger.error(&quot;call connectionCallback fail&quot;, x);                   &#125;               &#125;           &#125;       &#125;);    &#125;&#125;\n\n完整的代码:https://github.com/zhuxingsheng/javastudy\n亮点思路很简单，亮点就在于job队列，连接在没有建立成功时，会先建立一个EmptyChannel，有些类似lazy load中的影子对象放到队列中，不造成阻塞，当channel建立完成后，回调\nVS Future模式异步回调的套路与Future模式特别类似\nFuture future = doTask1();doTask2();doTask3();Result result = future.get();\nFuture 模式中，一个任务的启动和获取结果分成了两部分，启动执行是异步的，调用后立马返回，调用者可以继续做其他的任务，而等到其他任务做完，再获取Future的结果，此时调用 get 时是同步的，也就是说如果 doTask1 如果还没有做完，等它做完。\n看出最大区别，异步回调不需要返回值，准确说调用者不用太关心返回值，甚至不需要关心真正执行情况，而future模式就不一样了，调用者是一定要拿到返回值的\n参考同步调用，异步回调和 Future 模式\n"},{"title":"你最好的一条职业建议是什么？","url":"/blog/what's-your-best-career-advice.html","content":"Twitter上有人发了一个推，说他之前问过一个问题：“你最好的一条职业建议是什么？”，他得到了1300多个答案，最后他整理了12条最好的建议。🔗 twitter、com&#x2F;chrishlad&#x2F;status&#x2F;1502650707274608644\n1、 尽可能为别人减少不确定性\n\nUber解决了打车的不确定性\n亚马逊解决了送包裹的不确定性\n你也可以通过及时更新项目进展来帮老板解决不确定性\n\n2、 公司比职位更重要\n3、 一旦接受了一个任务，无论多小或者多么不起眼，要把它做的特别好，超出别人的预期。这样你就能建立起一个良好的声誉，让别人知道你总能高质量的完成工作。当你建立了这种声誉，你就能得到更多的机会，更大的知名度，以及更大的成功。\n4、 如果我不能信任你，你再聪明都没用。\n5、 在你的职业生涯中，陪你走到最后的只有你自己。不是你的公司，不是你的经理，不是你的团队，只有你自己。在做你所有职业生涯的决定时，优先考虑你自己。\n6、 影响你职业生涯的三件事：\n\n你做什么？（工作）\n你为谁工作？（客户）\n和你一起工作的人是谁？（团队）\n\n如果你热爱你的工作、客户和团队，你会非常非常幸运。\n7、 和一个聪明的能激励你走向伟大的人结婚。\n8、 要么能学东西，要么能赚钱。否则果断离职，去找一个这两者至少占一样的工作。\n9、 如果一个问题你不问，那么答案一定是“不”。\n10、 选择你的老板。你有权选择谁当你的老板，而在找工作的过程中很多人没有考虑到这一点。一个优秀的老板可以为你的职业发展提供极大的助力。\n11、 学会阐明你所做的事情的商业价值，而不仅仅是你的工作头衔或者项目。不好的例子：“我是一个数据科学家。我创建了3个自服务数据应用”更好的例子：“我帮助管理层发现了一个可以节约2300万美元成本的机会”\n12、 “职业”，本质是一个营销名词，是由那些经营特定类别的梦想的人卖给你的，而他们在贩卖这个梦想时赚了很多钱。赚钱，承担风险，有冒险精神。但不要让“职业”来限制自己\n"},{"title":"优秀架构师的四个素质","url":"/blog/four-qualities-of-an-excellent-architect.html","content":"架构师，程序员追求的最高title。\n那么想成为一名架构师，就会出现一系列的疑问：\n什么是架构师？\n怎么才能成为架构师？\n优秀架构师需要哪些素质？\n之前根据《郭东白的架构课》总结了《成为首席架构师的打怪升级之路》。这也是郭东白对架构师的思考之路。\n其实在2021年5月28日的Qcon软件大会上郭东白就做了一场主题是《如何成为一名优秀的架构师》演讲。相当精彩。特地找到PPT，学习一下。可惜是没有找到完整的演讲视频。\n什么是架构师\n架构师:\n1)a person engaged in the design of certain large constructions. – dictionary.com\n设计人员从事某些大型建筑物设计的人\n2)a person who designs and guides a plan or undertaking. – Merriam-Webster\n设计和指导计划或事业的人。\n在之前的总结文章中，其实都没有给出架构师的定义，只是说比普通程序员更牛的程序员，以前提出了“技术+影响力+领导力”的能力模型。\n而郭东白给出了一个更确切的定义：\n\n具备架构能力的人。\n\n架构能力是指为相对复杂的场景设计并引导一个或多个研发团队，来实施结构化软件系统的能力。\n兼职架构师与全职架构师\n对于任何一家公司，架构设计永远是必要的。\n其实在很多公司，架构师职位是有职无岗的，就是有架构师职责的需要，但不会独立设置架构师的岗位。很多时候都是由TL兼任。\n架构师的生存必要条件一：目标正确一个优秀的架构师应该具备对软件做出正确的设计和决策的基本能力，在做这些决策时往往需要考虑很多限制条件，如：时间成本、人力成本、资金成本、范围要求、质量要求、组织结构等，架构师从来不是独行侠，他是上承需求，下接实现的一种角色。\n\n总结一下就是要有工程化思维。\n必要条件二：能力满足\n这些能力，从硬实力再到软件实力，一条也不能落下。\n能力范围从普通研发到兼职架构师，再到全职架构师，层次递增。\n\n对于能力攻关，是先宽度再深度，还是先深度再宽度？\n建议先深度再宽度，这样可以一通百通，没有深度是谈不上宽度的。\n架构师的素质第一是：有眼光，什么叫有眼光？就是要有深度的业务理解，能看到好的机会；\n第二是：善于思考，有足够的技术视野能找到正确的技术和组织设计，亦即独立思考能力；\n第三是，有良知，这是一个架构师随着时间的流逝，沉淀在身上最重要的品质。什么是有良知？为人正直，选择做正确的事情。很多人是非常聪明的，业务理解能力强，技术实践丰富，但他不一定为公司或为组织做最正确的事情。有良知是非常重要的一个事情，如果架构师没有素质，他会让一家公司的损失很惨重。\n第四是：能感召，能感招是什么概念？他要能够引导组织作出正确的决策，大多数架构师不是决策者，但他是决策的建议者，因为他是个决策的建议者，所以他的沟通能力，表达能力可以引导一个组织最终走向正确的选择，这也是架构师必须具备的素质。\n\n这几点，可以对应上前面的能力模型：技术、影响力、领导力。但这四点总结得更完善些\n1、眼光其实就是业务，有了业务理解深度，才能知道价值点，进而通过影响力发挥价值\n2、思考是根本，不管是对技术，还是业务。这是第一源能力\n3、良知是德\n4、感召力，对应上领导力，能引导他人一起走向正确的选择\n对于思考能力，再补充点，业务理解是什么？什么是业务理解不够？\n架构师的价值创造来自于独立、理性的、有深度的思考。从技术视角看业务，从业务中发现技术机会。通过复盘发现思考漏洞，提升思考质量。\n\n讲一个技术人做业务理解，是在技术视角往上看到业务，从技术视角理解业务叫业务理解。\n并不是一个做业务的，把业务怎么做说的很详细，没用，要从技术视角看到对业务的理解，同样，技术洞察，从业务视角反过来看技术，找到洞察，这才是要的洞察。\n技术做技术的洞察，业务做业务的思考，这两个完全是割裂的。\n总结架构以及架构师，是程序员奋斗的事业和目标。所以虽然已经总结了很多了篇文章，但还是不时从高手那儿不停地吸取和反复思考。这是一个持续过程。现在有，未来还有。\n通过不断地思考架构的本源和架构师的价值，成为一名德才兼备的优秀架构师。\n基于”如何成为一名优秀的架构师”的分享总结\nQCon大会官方PPT下载（源PPT下载）\nInfoQ官方视频合辑（可能有视频上传）\n","tags":["架构师"]},{"title":"做技术还是做管理","url":"/blog/technology-or-management.html","content":"新晋管理者都有一些相同的烦恼和忧愁。\n“管理事太杂了，没时间写代码，越来越虚”\n“如何平稳技术与管理？”\n“管理事太琐碎，离技术越来越远，未来职业怎么规划？”\n“做管理最大的挑战，就是舍弃技术，特别难”\n这些问题的本源是因为新晋管理者正在进入一个全新的领域，离开以往的舒适区。\n以往的舒适区是技术范围，而且主要是技术实现。接受一个功能需求，通过技术实现出来。\n而成为管理后，不再是技术实现，而是任务分配，团队建设，资源协调等等脱离技术的事项。\n走出舒适区是相当痛苦的，它会让人产生不安全感，让人容易自我质疑，以及自我否定，进而退回舒适区。\n新晋管理者都有类似这种前怕狼后怕虎的焦虑。\n前怕狼后怕虎，狼是啥？管理之路不好走，事很杂，心里虚。虎是啥？离技术越来越远，失去了技术优势。\n从自身安身立命安全感角度讲，是青黄不接的时候，管理还没有摸出门道，不知道怎么搞定，倍感焦虑；而熟练掌握的技术，却投入的时间越来越少。\n这种纠结的状态，归纳为一个词叫：患得患失。还没有得到时，担心得不到；得到后，又担心失去。\n\n\n如何才能突破这一关卡，或者说如何挣脱刚开始做管理时，患得患失的思维逻辑呢？\n最近在看《技术管理实践36讲》，整理了份思维导图，来梳理作者的观点：\n\n首先，对管理本身就不太了解，对未知事物总有种畏惧感。尤其技术人更喜欢与确定性事务打交道。其次成功路径依赖，喜欢与干得好其实是相互促进的关系，干得越好越喜欢，越喜欢就干得越好。并且会在做其他事情时，不自主地迁移原先的成功路径。\n怎么解决“患失”？成为管理后，怎么保持技术能力。不能丢失原先的优势。\n做技术时，技术能力来源于自己的实践。而管理后，没有整块的时间技术实现。但作为技术管理，技术判断力是核心能力，怎么提升判断力呢？\n\n1、转变思维，不再是技术实现者，而是技术应用者。在实现目标的过程中，技术能带来什么？\n2、不再是考虑怎么实现，而是以目标为导向，考虑要不要投入资源，并且评估值不值得做。\n3、值不值得做，需要从资源投入成本、维护成本、机会成本、协作成本四方面考虑。\n最重要的还是要保持学习。怎么保持学习呢？不再只靠自己的时间投入，依靠的是团队的力量。\n1、学习型组织，组织定期分享，技术交流\n2、做专项技术调研，让负责人做调研汇报\n3、与技术大牛交流\n4、听取汇报，相互探讨\n怎么解决“患得”？ 首先需要明确，管理带来的价值。技术人三条腿“技术”、“管理”、“业务”就包含了管理。其次，管理代表了更大的责任，也表示可以输出更大的价值。最后能得到更立体的视角和灵活的思维方式。\n退一步，就算管理失败了，也积累了些管理能力，这部分能力可以迁移到技术带头人，还有架构师也是需要部分管理能力。\n所以说就算没有得到，也不算完全失去。\n当然最重要的，如果管理是未来必经之路，那当下开始积累管理能力，就是最好的准备。\n\n其实不管是做技术，还是做管理。都不是为了做而做，我们都是为了自我成长，成长为更好的自己。保持开放心态，拥抱变化，从单纯的技术维度到相对复杂的管理维度。可以帮我们更快速地全面提升。\n","tags":["管理"]},{"title":"再议DDD分层","url":"/blog/further-discussion-on-ddd-layering.html","content":"之前整理过《DDD分层》 以及《分层架构》\n最近看网友讨论，整理一些有亮点的地方\n现在分层架构+整洁架构似乎是个万金油组合了\n之前DDD的标准分层结构：\n\n右边传统分层，左边经过DIP改进型，两者有什么区别呢？\n\n眼尖的人可以看出来，两者确实差了不少\n线条1：application到infrastructure被反转了\n线条2：这条线没有了，在MVC里面这线是常见的，applicaton与domain没分开，但DDD中这条线是不推荐的，就算在松散分层架构中也一般不使用,除非简单的CRUD项目\n线条3：也被反转了，这其实类似CQRS中的Q部分\n\n以上来源于群友的讨论，真的是世上无难事，只怕有心人；这点区别真没留意过\n\n这图来源于阿里大牛殷浩之手，《阿里DDD四弹》中进行过总结，DTOAssembler放在了application层,有些不太合理\n在《分层架构》中thrift的TService，为了不与controller重复，所以需要一个application service,此时thrift与controller可以有相同的业务请求\n也就是说controller对外有多种输入，但对应用层来说都是同一个user case，如果放在应用层内转化，是不是应该层为了同一个use case要爆露多过方法\n\n适配层做三件事：\n\n协议适配（如采用controller，通过 @RequestMapping 注解和 JSON 序列化)\n参数规则验证（如，不能为空、手机是数字并且11位、邮箱要有@之类简单验证）\n为调用下层（应用层）转化输入（assembler）\n\n如果说分4层的话：\n\ncontroller （assembler、转化）\nappliction\ndomain\nrepository（convertor、转化）\n\n应用层是真正的业务入口，是很披的一层：\n\n用来协调领域操作 这里一般看系统架构不一样会有所不同，主要再分为同步调用的方式，和步骤事件的方式。\n关注点分离的操作（如日志、通知等）\n\napplication service编排业务，domain service编排领域\n\n","tags":["DDD","分层"]},{"title":"再识RPC-thrift","url":"/blog/recognize-rpc-thrift-again.html","content":"RPC原理\n什么是Stub？\nStub是一段代码，用来转换RPC过程中传递的参数。处理内容包括不同OS之间的大小端问题。另外，Client端一般叫Stub，Server端一般叫Skeleton。\n生产方式：\n\n手动生成，比较麻烦；\n自动生成，使用IDL（InterfaceDescriptionLanguate），定义C&#x2F;S的接口\n\nRPC的套路：自古深情留不住 唯有套路留人心\nRPC最本质的就是通过socket把方法信息传输到远程服务器并执行相应method\n在java界的rpc框架的实现手法：\n\n服务端：socket + 反射\n客户端：动态代理 + socket\n\n之前也解析过motain框架，《motain客服端分析》、《motain服务端分析》\nthrift由于我司框架是通过thrift改造，发现这个框架没有按java套路出牌，可能这是跨语言类RPC的套路，有必要了解一下\n\nthrift最初由facebook开发用做系统内各语言之间的RPC通信 。2007年由facebook贡献到apache基金 ，08年5月进入apache孵化器,支持多种语言之间的RPC方式的通信：php语言client可以构造一个对象，调用相应的服务方法来调用java语言的服务 ，跨越语言的C&#x2F;S RPC调用\n　　\n\n\n示例IDL文件//HelloService.thrfitnamespace java com.jack.thriftservice HelloService&#123;    string helloString(1:string what)&#125;\n\n生成代码运行  thrift -gen HelloService.thrfit\n会生成一个HelloService类\n实现服务端与客服端让服务端打印出客户端传入的参数\n服务端public class ThriftServer &#123;    /**     * 启动thrift服务器     * @param args     */    public static void main(String[] args) throws Exception &#123;        try &#123;            System.out.println(&quot;服务端开启....&quot;);            TProcessor tprocessor = new HelloService.Processor&lt;HelloService.Iface&gt;(new HelloServiceImpl());            // 简单的单线程服务模型            TServerSocket serverTransport = new TServerSocket(9898);            TServer.Args tArgs = new TServer.Args(serverTransport);            tArgs.processor(tprocessor);            tArgs.protocolFactory(new TBinaryProtocol.Factory());            TServer server = new TSimpleServer(tArgs);            server.serve();        &#125;catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n客户端public class ThriftClient &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;客户端启动....&quot;);        TTransport transport = null;        try &#123;            transport = new TSocket(&quot;localhost&quot;, 9898, 30000);            // 协议要和服务端一致            TProtocol protocol = new TBinaryProtocol(transport);            HelloService.Client client = new HelloService.Client(protocol);            transport.open();            String result = client.helloString(&quot;哈哈&quot;);            System.out.println(result);        &#125; catch (TTransportException e) &#123;            e.printStackTrace();        &#125; catch (TException e) &#123;            e.printStackTrace();        &#125; finally &#123;            if (null != transport) &#123;                transport.close();            &#125;        &#125;    &#125;&#125;\n\n解析可以看出server,client代码相对很简单，主要看看生成的HelloService类，这个类就是stub代码\n来看一下，这个类是如何封装，把method和args传输到远程的\nclientHelloService.Client client = new HelloService.Client(protocol);String result = client.helloString(&quot;哈哈&quot;);\n\n关键点在HelloService.Client.helloString()方法\npublic String helloString(String what) throws org.apache.thrift.TException    &#123;      send_helloString(what);      return recv_helloString();    &#125;\n\n发送消息public void send_helloString(String what) throws org.apache.thrift.TException    &#123;      helloString_args args = new helloString_args();      args.setWhat(what);      sendBase(&quot;helloString&quot;, args);    &#125;\n\n把args抽象成了一个类\n属性赋值\n发送\n\n主要看下sendBase()方法\nprivate void sendBase(String methodName, TBase&lt;?,?&gt; args, byte type) throws TException &#123;   oprot_.writeMessageBegin(new TMessage(methodName, type, ++seqid_));   args.write(oprot_);   oprot_.writeMessageEnd();   oprot_.getTransport().flush(); &#125;\n\n1.oprot_.writeMessageBegin  根据Protocol写数据，比如这儿使用的TBinaryProtocol，以二进制写数据\n\npublic void writeMessageBegin(TMessage message) throws TException &#123;    if (strictWrite_) &#123;      int version = VERSION_1 | message.type;      writeI32(version);      writeString(message.name);      writeI32(message.seqid);    &#125; else &#123;      writeString(message.name);      writeByte(message.type);      writeI32(message.seqid);    &#125;  &#125;\n再深入看看怎么写二进制数据的\nint类型\npublic void writeI32(int i32) throws TException &#123;    inoutTemp[0] = (byte)(0xff &amp; (i32 &gt;&gt; 24));    inoutTemp[1] = (byte)(0xff &amp; (i32 &gt;&gt; 16));    inoutTemp[2] = (byte)(0xff &amp; (i32 &gt;&gt; 8));    inoutTemp[3] = (byte)(0xff &amp; (i32));    trans_.write(inoutTemp, 0, 4);  &#125;\n\nstring类型，先写长度，再写bytes\npublic void writeString(String str) throws TException &#123;    try &#123;      byte[] dat = str.getBytes(&quot;UTF-8&quot;);      writeI32(dat.length);      trans_.write(dat, 0, dat.length);    &#125; catch (UnsupportedEncodingException uex) &#123;      throw new TException(&quot;JVM DOES NOT SUPPORT UTF-8&quot;);    &#125;  &#125;\n这儿写最终还是使用Transport.write,比如这儿使用的TSocket\npublic void write(byte[] buf, int off, int len) throws TTransportException &#123;    if (outputStream_ == null) &#123;      throw new TTransportException(TTransportException.NOT_OPEN, &quot;Cannot write to null outputStream&quot;);    &#125;    try &#123;      outputStream_.write(buf, off, len);    &#125; catch (IOException iox) &#123;      throw new TTransportException(TTransportException.UNKNOWN, iox);    &#125;  &#125;\n就是写到\noutputStream_ = new BufferedOutputStream(socket_.getOutputStream(), 1024);\n\n\n2.args.write(oprot_);\n\npublic void write(org.apache.thrift.protocol.TProtocol oprot, helloString_args struct) throws org.apache.thrift.TException &#123;        struct.validate();        oprot.writeStructBegin(STRUCT_DESC);        if (struct.what != null) &#123;          oprot.writeFieldBegin(WHAT_FIELD_DESC);          oprot.writeString(struct.what);          oprot.writeFieldEnd();        &#125;        oprot.writeFieldStop();        oprot.writeStructEnd();      &#125;\n这就是写field,也就是向输出流里写参数内容\n\n3.oprot_.writeMessageEnd();这表示消息写完成了，各个协议处理不同，比如二进制就是空实现，但如json就需要写个”}”，以完成json格式\n\n4.oprot_.getTransport().flush();  直接flush\n\n\n/**   * Flushes the underlying output stream if not null.   */  public void flush() throws TTransportException &#123;    if (outputStream_ == null) &#123;      throw new TTransportException(TTransportException.NOT_OPEN, &quot;Cannot flush null outputStream&quot;);    &#125;    try &#123;      outputStream_.flush();    &#125; catch (IOException iox) &#123;      throw new TTransportException(TTransportException.UNKNOWN, iox);    &#125;  &#125;\n\nclient总结整个发送消息就结束了，虽然没有按套路使用动态代理，而是通过生成的stub代码，把methodName,args给封装好了\nserver服务端也没有通过反射的方式\n主要逻辑在生成的HelloService$Processor类中\npublic static class Processor&lt;I extends Iface&gt; extends org.apache.thrift.TBaseProcessor&lt;I&gt; implements org.apache.thrift.TProcessor &#123;    private static final org.slf4j.Logger _LOGGER = org.slf4j.LoggerFactory.getLogger(Processor.class.getName());    public Processor(I iface) &#123;      super(iface, getProcessMap(new java.util.HashMap&lt;String, org.apache.thrift.ProcessFunction&lt;I, ? extends org.apache.thrift.TBase&gt;&gt;()));    &#125;    protected Processor(I iface, java.util.Map&lt;String, org.apache.thrift.ProcessFunction&lt;I, ? extends org.apache.thrift.TBase&gt;&gt; processMap) &#123;      super(iface, getProcessMap(processMap));    &#125;    private static &lt;I extends Iface&gt; java.util.Map&lt;String,  org.apache.thrift.ProcessFunction&lt;I, ? extends org.apache.thrift.TBase&gt;&gt; getProcessMap(java.util.Map&lt;String, org.apache.thrift.ProcessFunction&lt;I, ? extends  org.apache.thrift.TBase&gt;&gt; processMap) &#123;      processMap.put(&quot;helloString&quot;, new helloString());      return processMap;    &#125;    public static class helloString&lt;I extends Iface&gt; extends org.apache.thrift.ProcessFunction&lt;I, helloString_args&gt; &#123;      public helloString() &#123;        super(&quot;helloString&quot;);      &#125;      public helloString_args getEmptyArgsInstance() &#123;        return new helloString_args();      &#125;      protected boolean isOneway() &#123;        return false;      &#125;      @Override      protected boolean handleRuntimeExceptions() &#123;        return false;      &#125;      public helloString_result getResult(I iface, helloString_args args) throws org.apache.thrift.TException &#123;        helloString_result result = new helloString_result();        result.success = iface.helloString(args.what);        return result;      &#125;    &#125;  &#125;\n\n\n1.先看构造函数\n\nprotected Processor(I iface, java.util.Map&lt;String, org.apache.thrift.ProcessFunction&lt;I, ? extends org.apache.thrift.TBase&gt;&gt; processMap) &#123;      super(iface, getProcessMap(processMap));    &#125;    private static &lt;I extends Iface&gt; java.util.Map&lt;String,  org.apache.thrift.ProcessFunction&lt;I, ? extends org.apache.thrift.TBase&gt;&gt; getProcessMap(java.util.Map&lt;String, org.apache.thrift.ProcessFunction&lt;I, ? extends  org.apache.thrift.TBase&gt;&gt; processMap) &#123;      processMap.put(&quot;helloString&quot;, new helloString());      return processMap;    &#125;\n这段把methodName与对应的处理类映射，那后面的事就简单了，当接受到消息，取得methodName,通过map获取对就的处理类回调就可以\npublic static class helloString&lt;I extends Iface&gt; extends org.apache.thrift.ProcessFunction&lt;I, helloString_args&gt; &#123;      public helloString() &#123;        super(&quot;helloString&quot;);      &#125;      public helloString_args getEmptyArgsInstance() &#123;        return new helloString_args();      &#125;      protected boolean isOneway() &#123;        return false;      &#125;      @Override      protected boolean handleRuntimeExceptions() &#123;        return false;      &#125;      public helloString_result getResult(I iface, helloString_args args) throws org.apache.thrift.TException &#123;        helloString_result result = new helloString_result();        result.success = iface.helloString(args.what);        return result;      &#125;    &#125;\n处理类，继承ProcessFunction类，实现getResult(),这个方法就是调用了对应service.helloString()\n可以再深入看一下,在socket监听消息时\nclient = serverTransport_.accept();        if (client != null) &#123;          processor = processorFactory_.getProcessor(client);          inputTransport = inputTransportFactory_.getTransport(client);          outputTransport = outputTransportFactory_.getTransport(client);          inputProtocol = inputProtocolFactory_.getProtocol(inputTransport);          outputProtocol = outputProtocolFactory_.getProtocol(outputTransport);          if (eventHandler_ != null) &#123;            connectionContext = eventHandler_.createContext(inputProtocol, outputProtocol);          &#125;          while (true) &#123;            if (eventHandler_ != null) &#123;              eventHandler_.processContext(connectionContext, inputTransport, outputTransport);            &#125;            if(!processor.process(inputProtocol, outputProtocol)) &#123;              break;            &#125;          &#125;\n关键行：processor.process(inputProtocol, outputProtocol)\npublic boolean process(TProtocol in, TProtocol out) throws TException &#123;    TMessage msg = in.readMessageBegin();    ProcessFunction fn = processMap.get(msg.name);    if (fn == null) &#123;      TProtocolUtil.skip(in, TType.STRUCT);      in.readMessageEnd();      TApplicationException x = new TApplicationException(TApplicationException.UNKNOWN_METHOD, &quot;Invalid method name: &#x27;&quot;+msg.name+&quot;&#x27;&quot;);      out.writeMessageBegin(new TMessage(msg.name, TMessageType.EXCEPTION, msg.seqid));      x.write(out);      out.writeMessageEnd();      out.getTransport().flush();      return true;    &#125;    fn.process(msg.seqid, in, out, iface);    return true;  &#125;\n这就很明显了，通过methodName从map中取得ProccessFunction，再执行process方法，调用相应service的方法\n总结虽然thrift没有按以往java套路出牌，但最根本的把method发送到远程执行是一致的。可能对于多语言来讲，便于所以语言一致性，的确需要通过生成的stub代码手法来实现RPC\n当然thrift并不简单，还有很多的内容需要深挖学习，但至少这个简单示例可以了解跨语言型的RPC，相关IDL,Stub的知识，有清晰认知，而不局限于概念\n","categories":["源码解读"],"tags":["rpc","thrift"]},{"title":"分层架构","url":"/blog/layered-architecture.html","content":"最近连续做了两个新项目，借着新项目的机会，重新审视一下之前一些实践方法，进而寻求一下背后的理论支撑\n新项目开始，首先一个就是会新建一个project，那么这个project怎么分层，怎么创建module，怎么分包呢？\n经典分层以传统方式，经典的MVC分层，就controller,service,model\n\n找来一张servlet时代的经典处理流程，虽然技术手段日益更新，但处理流程是一样的\n\n抽象一下，经典的分层就是：\n\n现在大多数系统都是这种分层结构。JavaBean里面只有简单的get和set方法，被很多人鄙视的“贫血模型”；业务逻辑变得复杂时，service会变得很臃肿，出现很多的“上帝类”\n回想一下，我们的所有的代码都写在ServiceImpl里面，前几行代码是做validation的事，接下来几行是做convert的事，然后是几行业务处理逻辑的代码，穿插着，我们需要通过RPC或者DAO获取更多的数据，拿到数据后，又是几行convert的代码，在接上一段业务逻辑代码，然后还要落库，发消息…等等\n这也是事务脚本开发方式，横行于世。数据与行为被分离。\n简单业务这样开发是合适的，但业务一复杂起来，需求频繁变更后，就没人能理解任何一段代码,业务逻辑和技术细节糅杂在一起，业务领域模型没法清晰表达出来,开发人员只知道怎么处理了数据，但背后的业务语义完全不知道\n其实呢？还有很多的包，如config,common,core等等，如果使用了一些中间件，如rabbitmq，还会相应创建上对应的包，简单点可能就被放在了service包下\n从有了maven之，module概念更加显现化\n&lt;modules&gt;    &lt;module&gt;service&lt;/module&gt;\t&lt;module&gt;common&lt;/module&gt;\t&lt;module&gt;core&lt;/module&gt;\t&lt;module&gt;test&lt;/module&gt;&lt;/modules&gt;\n\n我们的那么多包有了更加明确的地方放置，不再是直接放置在工程目录下\n由于上面的这些问题 ，我们似乎可以指出经典的三层架构的弱点：\n\n架构被过分简化，如果解决方案中包含发送邮件通知，代码应该放置在哪些层？\n它虽然提出了业务逻辑隔离，但没有明确的架构元素指导我们如何隔离\n\n\nDDD虽然技术日新月异，但大多仅仅是技术，带了实现的便利性，但对于业务层次，更多的还是经验。随着业务的复杂性提升，系统的腐化速度和复杂性呈指数上升。\nDDD带了很多的认知的改变，最大的好处是将业务语义显现化，不再是分离数据与行为，而是通过领域对象将领域概念清晰的显性化表达出来\n当然这世间并没有银弹，但至少能给我们带来一种改进经典分层的理论支撑\nDDD中带来了Repository概念，以及基础设施层，再结合【DIP原则】，可以把三层结构变成\n\n\n再细看一下Controller，这一层，做些什么呢？\n轻业务逻辑，参数校验，异常兜底。通常这种接口可以轻易更换接口类型，所以业务逻辑必须要轻，甚至不做具体逻辑\n但在现实中，有些更极端，在servlet时代，还做下HttpRequest转换成DTO,传入service，现在有了springmvc，struts2框架的转换，不需要转换了，那么controller成了一个透传层，直接调用service\n这儿有两个问题，既然controller是透传，那有必要存在吗？ controller调用的service，这个service指的服务是什么呢？\n第一controller显然有必要存在，不再于业务，而在于技术实现。不管是http,rpc都得有个请求入口。像thrift可能会比其他的一些rpc框架例如dubbo会多出一层,作用和controller层类似\n\nTservice与controller的作用是一样的\n第二service服务指的是什么？领域服务吗？如果一个复杂的业务，那么会跨越多个领域，自然需要多个领域服务。如果放在controller里面，也就是在controller里面去编排领域服务，如果切换到thrift，那Tservice就得重复\n因此，此时需要另一个service，在DDD中就是应用服务\n\n应用服务算是领域服务的facade，应用层是高层抽象的概念，但表达的是业务的含义，领域层是底层实现的概念，表达的是业务的细节\n\n\n&lt;modules&gt;        &lt;module&gt;controller&lt;/module&gt;        &lt;module&gt;application&lt;/module&gt;        &lt;module&gt;domain&lt;/module&gt;        &lt;module&gt;infrastructure&lt;/module&gt;        &lt;module&gt;start&lt;/module&gt;&lt;/modules&gt;\n\ncontroller模块：restfull风格的少不了这层\napplication模块：类似以前的service包\ndomain模块：如果是事务脚本方式，domain模块就没有了\ninfrastructure模块：基础模块，类似之前的dao包，但这里面都是实现类，而像repository接口则在domain模块，还需要对应的convertor\n模块里面各个包，可能需要按实践情况而定了，后面再从项目中抽取个archetype，使用maven直接生成\n"},{"title":"分布式Semaphore","url":"/blog/distributed-semaphore.html","content":"\nsemaphore的定义，意义\n在没有juc semaphore之前怎么实现\nsemaphore使用\n分布式semaphore实现\n\n信号量最早用来解决进程同步与互斥问题的机制:包括一个称为信号量的变量及对它进行的两个原语操作(PV操作)\n什么是信号量？\n信号量（semaphore）的数据结构为一个值和一个指针，指针指向等待该信号量的下一个进程。信号量的值与相应资源的使用情况有关。\nPV操作由P操作原语和V操作原语组成（原语是不可中断的过程）\n(注,P是荷兰语的Passeren，相当于英文的pass,V是荷兰语的Verhoog,相当于英文中的incremnet)\n对信号量进行操作，具体定义如下：\n\nP（S）：\n①将信号量S的值减1，即S&#x3D;S-1；\n②如果S&gt;&#x3D;0，则该进程继续执行；否则该进程置为等待状态，排入等待队列\n\n\nV（S）：\n①将信号量S的值加1，即S&#x3D;S+1；\n②如果S&gt;0，则该进程继续执行；否则释放队列中第一个等待信号量的进程\n\n\n\nPV操作的意义：我们用信号量及PV操作来实现进程的同步和互斥。PV操作属于进程的低级通信\n使用PV操作实现进程互斥时应该注意的是：\n\n每个程序中用户实现互斥的P、V操作必须成对出现，先做P操作，进临界区，后做V操作，出临界区。若有多个分支，要认真检查其成对性\nP、V操作应分别紧靠临界区的头尾部，临界区的代码应尽可能短，不能有死循环\n互斥信号量的初值一般为1\n\n//许可数量private int permits = 1;public synchronized void P() &#123;    permits--;    if(permits &lt; 0 )&#123;        try &#123;            wait();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;public synchronized void V()&#123;    permits++;    if(permits &lt;=0)&#123;        notifyAll();    &#125;&#125;\n\nJ.U.C SemaphoreJUC提供了工具类之一就是Semaphore，提供了丰富的API，不再需要自己实现\n// 创建具有给定的许可数和非公平的公平设置的 Semaphore。Semaphore(int permits)// 创建具有给定的许可数和给定的公平设置的 Semaphore。Semaphore(int permits, boolean fair) // 从此信号量获取一个许可，在提供一个许可前一直将线程阻塞，否则线程被中断。void acquire()// 从此信号量获取给定数目的许可，在提供这些许可前一直将线程阻塞，或者线程已被中断。void acquire(int permits)// 从此信号量中获取许可，在有可用的许可前将其阻塞。void acquireUninterruptibly()// 从此信号量获取给定数目的许可，在提供这些许可前一直将线程阻塞。void acquireUninterruptibly(int permits)// 返回此信号量中当前可用的许可数。int availablePermits()// 获取并返回立即可用的所有许可。int drainPermits()// 返回一个 collection，包含可能等待获取的线程。protected Collection&lt;Thread&gt; getQueuedThreads()// 返回正在等待获取的线程的估计数目。int getQueueLength()// 查询是否有线程正在等待获取。boolean hasQueuedThreads()// 如果此信号量的公平设置为 true，则返回 true。boolean isFair()// 根据指定的缩减量减小可用许可的数目。protected void reducePermits(int reduction)// 释放一个许可，将其返回给信号量。void release()// 释放给定数目的许可，将其返回到信号量。void release(int permits)// 返回标识此信号量的字符串，以及信号量的状态。String toString()// 仅在调用时此信号量存在一个可用许可，才从信号量获取许可。boolean tryAcquire()// 仅在调用时此信号量中有给定数目的许可时，才从此信号量中获取这些许可。boolean tryAcquire(int permits)// 如果在给定的等待时间内此信号量有可用的所有许可，并且当前线程未被中断，则从此信号量获取给定数目的许可。boolean tryAcquire(int permits, long timeout, TimeUnit unit)// 如果在给定的等待时间内，此信号量有可用的许可并且当前线程未被中断，则从此信号量获取一个许可。boolean tryAcquire(long timeout, TimeUnit unit)\n\n对于JUC的Semaphore源码，此篇不阐述了，另开新篇；但对分布式的Semaphore倒是可以研究下\n分布式SemaphoreRedission中有对应的RSemaphore\nRSemaphore semaphore = redisson.getSemaphore(&quot;semaphore&quot;);semaphore.acquire();//或semaphore.acquireAsync();semaphore.acquire(23);semaphore.tryAcquire();\n\n可过期信号量\nRPermitExpirableSemaphore semaphore = redisson.getPermitExpirableSemaphore(&quot;mySemaphore&quot;);String permitId = semaphore.acquire();// 获取一个信号，有效期只有2秒钟。String permitId = semaphore.acquire(2, TimeUnit.SECONDS);// ...semaphore.release(permitId);\n\n直接上最本质的源码片段，lua脚本很简单，对信号量进行计数，acquire时，信号量减1，release时，信号量加1；主要是保证操作的原子性\n@Overridepublic RFuture&lt;Boolean&gt; tryAcquireAsync(int permits) &#123;    if (permits &lt; 0) &#123;        throw new IllegalArgumentException(&quot;Permits amount can&#x27;t be negative&quot;);    &#125;    if (permits == 0) &#123;        return RedissonPromise.newSucceededFuture(true);    &#125;    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,              &quot;local value = redis.call(&#x27;get&#x27;, KEYS[1]); &quot; +              &quot;if (value ~= false and tonumber(value) &gt;= tonumber(ARGV[1])) then &quot; +                  &quot;local val = redis.call(&#x27;decrby&#x27;, KEYS[1], ARGV[1]); &quot; +                  &quot;return 1; &quot; +              &quot;end; &quot; +              &quot;return 0;&quot;,              Collections.&lt;Object&gt;singletonList(getName()), permits);&#125;@Overridepublic RFuture&lt;Void&gt; releaseAsync(int permits) &#123;    if (permits &lt; 0) &#123;        throw new IllegalArgumentException(&quot;Permits amount can&#x27;t be negative&quot;);    &#125;    if (permits == 0) &#123;        return RedissonPromise.newSucceededFuture(null);    &#125;    return commandExecutor.evalWriteAsync(getName(), StringCodec.INSTANCE, RedisCommands.EVAL_VOID,        &quot;local value = redis.call(&#x27;incrby&#x27;, KEYS[1], ARGV[1]); &quot; +        &quot;redis.call(&#x27;publish&#x27;, KEYS[2], value); &quot;,        Arrays.&lt;Object&gt;asList(getName(), getChannelName()), permits);&#125;\n\n在最本质的基础上，再深入看一下还做了哪些事，能真正达到一个工业生产标准\ntryAcquire()非阻塞式，有信息量就正常获取，没有刚快速返回，就是lua本质，没有做额外的事情\nacquire()@Overridepublic void acquire(int permits) throws InterruptedException &#123;    if (tryAcquire(permits)) &#123;        return;    &#125;    RFuture&lt;RedissonLockEntry&gt; future = subscribe();    commandExecutor.syncSubscription(future);    try &#123;        while (true) &#123;            if (tryAcquire(permits)) &#123;                return;            &#125;            getEntry().getLatch().acquire(permits);        &#125;    &#125; finally &#123;        unsubscribe(future);    &#125;&#125;\n阻塞式，相对非阻塞式就多了一些事\n\n1.先tryAcquire，看是否能获取到信号量\n2.订阅channel事件\n3.无限循环\n3.1.先tryAcquire()，尝试一下\n3.2.通过getEntry().getLatch()，也就是j.u.c.Semaphore,acquire()阻塞\n\n\n4.取消订阅\n\n订阅事件内部细节，另开篇再说了，他的目的其实就是释放Semaphore\n想像一下，同一个client的两个线程A，B 同时需要获取信号量，如果A成功获取，那么B将被Semaphore阻塞住了，何时退出阻塞呢？\n就在线程A进行release()之后，会publish,细节可查看上面的release()中的lua脚本，当B监听到事件时，就会调用Semaphore.release(),再次进行tryAcquire()\ntryAcquire(int permits, long waitTime, TimeUnit unit)如果在给定的等待时间内此信号量有可用的所有许可，并且当前线程未被中断，则从此信号量获取给定数目的许可\n@Overridepublic boolean tryAcquire(int permits, long waitTime, TimeUnit unit) throws InterruptedException &#123;    long time = unit.toMillis(waitTime);    long current = System.currentTimeMillis();    if (tryAcquire(permits)) &#123;        return true;    &#125;    time -= (System.currentTimeMillis() - current);    if (time &lt;= 0) &#123;        return false;    &#125;    current = System.currentTimeMillis();    RFuture&lt;RedissonLockEntry&gt; future = subscribe();    if (!await(future, time, TimeUnit.MILLISECONDS)) &#123;        return false;    &#125;    try &#123;        time -= (System.currentTimeMillis() - current);        if (time &lt;= 0) &#123;            return false;        &#125;                while (true) &#123;            current = System.currentTimeMillis();            if (tryAcquire(permits)) &#123;                return true;            &#125;            time -= (System.currentTimeMillis() - current);            if (time &lt;= 0) &#123;                return false;            &#125;            // waiting for message            current = System.currentTimeMillis();            getEntry().getLatch().tryAcquire(permits, time, TimeUnit.MILLISECONDS);            time -= (System.currentTimeMillis() - current);            if (time &lt;= 0) &#123;                return false;            &#125;        &#125;    &#125; finally &#123;        unsubscribe(future);    &#125;//        return get(tryAcquireAsync(permits, waitTime, unit));&#125;\n\n其实await(future, time, TimeUnit.MILLISECONDS)是使用的CountDownLatch\n如果计数到达零，则返回 true；如果在计数到达零之前超过了等待时间，则返回 false\n当前是第一个请求，或者别的释放，那就再往下进入循环\nCountDownLatch.await()+Semaphore.tryAcquire()配合使用\n每一次等待时间后，都需要检查是否超过等待时间\n为什么需要引入CountDownLatch.await()呢？ 都使用Semaphore.tryAcquire()不行吗？这个需要再次深入挖掘了\n总结分布式信号量，原理很明了，主要还是通过lua保障redis操作的原子性\n阅读redisson源码，发现里面的操作基本都是异步化，底层又是基于netty，大量使用了future模式，如果不知道future模式，会很绕，debug都会晕掉，所以在深入redisson之前，需要再对future模式温习一下\n","tags":["分布式"]},{"title":"功夫在诗外","url":"/blog/kung-fu-is-beyond-poetry.html","content":"功夫在诗外算是对今年，以及去年这两年的读书的一点思考，总结\n为什么会有去年，因为今年读书过程中，让人不自然地想起了去年的类似内容。说的书类型不重复，但出现了很多相同的内容\n可能与这些内容有缘分\n迷思每次跳槽的时候，都会去思考我的核心竞争力到底是什么？这个问题代表了两个对立的思想一方面代表了不自知，迷茫，对未来的焦虑；另一方面代表了自不知，三人有我师，前进的动力。\n职场规划一片迷茫，股票所学也是一无长进，甚是苦恼。想起了陆游的这句话，《汝果欲学诗，功夫在诗外》；所以去年开始读了很多与专业不相关的书籍。\n名人传记，历史书籍，小说，这类书的价值在于引导成长；\n心智，心理类也是所好，可惜所得甚少。一些书籍还得多读，多思\n如《乌合之众》，知了很多年，却没读得很少，也没读懂。\n路漫漫其修远兮\n所得在读《超级交易者》上半段时，突然有了一细细恍惚。好些内容都似曾相识，让人不得不想起一句老话，失败者的失败各有各的不同，而成功者的成功却具有惊人的相似之处。\n责任这个词就像是个空词，人人都会把这个词挂在嘴边，但何为责任，责任有何妙处\n这在《人生五章》诗中也有体现\n《人生五章》 \n1、 \n我走上街， \n人行道上有一个深洞， \n我掉了进去。 \n我迷失了……我绝望了。 \n这不是我的错， \n费了好大的劲才爬出来。 \n2、 \n我走上同一条街。 \n人行道上有一个深洞， \n我假装没看到， \n还是掉了进去。 \n我不能相信我居然会掉在同样的地方。 \n但这不是我的错。 \n还是花了很长的时间才爬出来。 \n3、 \n我走上同一条街。 \n人行道上有一个深洞， \n我看到它在那儿， \n但还是掉了进去…… \n这是一种习惯。 \n我的眼睛张开着， \n我知道我在那儿。 \n这是我的错。 \n我立刻爬了出来。 \n4、 \n我走上同一条街， \n人行道上有一个深洞， \n我绕道而过。 \n5、 \n我走上另一条街。\n这首诗的内容在读《股票作手加快录》时，就有体会，大意就是一个人从意识到自身问题，到要改变，再到彻底改变的过程是相当艰辛的，习惯上升到性格再到内质的人性，是相当难以改变的。\n这一切的改变，自省的起始就在于责任两字，无责任怎么会想到自身问题。\n自己永无过错，一切都是别人的问题；代码没问题，是环境问题，自己买卖没问题，是庄家问题。\n写作为什么写作？其实有各种理由\n\n文字可以重塑人\n写作是与自己的对话，引人思考\n输出倒逼输入\n形成闭环，输入输出完整的IO系统\n写作是睡后收入\n\n我算是写作的践行者，有什么意义呢？写作了很多年，有什么益处呢？\n之前我是记录时间日志，是在看《时间就是朋友》这本书得来的。\n后来李笑来又说要记注意力日志。还没有太多的实践，从时间开销日志来讲，只是发现了自我的浪费时间，这也算是所得之一吧。\n从去年开始写博客，为什么要写呢？关键是“形成有效的输入输出系统，以输出倒逼输入”，“写作也记录下学习过程，防止狗咬尾巴”。\n现在的博客目标是每篇文章写尽一个知识点，有广度，也得有深度。但任何知识都不是单点，‘台上一分钟，台下十年功’，‘冰山理论’。\n晨写也没有以前的质量和数量了，上次交易玫瑰讲了量化：一是两张A4纸，二是得有三十分钟。\n还有关键一点，我也疏忽的一点，没有及时回顾日记。需要温故知新。\n冥想这个之前实践了几天，后来也没有坚持。这以后还是得有空多练习，看看效果了\n读书很多人的理想生活就是 读万卷书，行万里路\n我现在的读书方法，以及读书效果还是很差，不让人满意。关键是缺少总结，一本书，至少要自己组织语言总结其主旨。\n不然读再多的书，还是一无所得，浪费时间，自我心理满足。不能学以致用。\n上次读李笑来的财富自由之路，一个读书亮点：慢读。\n现在很多的书籍都教人快速阅读以应对当代快速膨胀的知识，以快致胜。而李笑来提出，要慢读。\n快速膨胀的是信息，而不是知识。知识的出现需要很久的时间积累。所以要慢读，要有深度，现在流行快餐文化，让世人缺少了深度思考的过程，以致人浮于思，任何事都没有深度，人云亦云。\n导图对于以上所得共同点，画了张思维导图更能一目了然\n\n书单这些书单是今年看过超出一半内容的书籍，有几本是年初读的，现在都已经忘记内容了。主要就是没有写一段自己理解的总结。这些书，明年还会再读，重读。吸取知识的能力实在是差。\n《西藏生死书》\n《刻意练习》\n《简单思考》\n《自卑与超越》\n《超级交易员》\n《我做散户这十年：三万赚到千万》\n《走进我的交易室》\n《炒股的智慧》\n《红尘天幕》\n今年没有达到目标，计划是一个月一本的，不找客观原因，明年还得继续努力。育儿方面的内容也得加强。\n今年的博客也是打算一月一篇的，也没有正常发布。\n计划是用来执行的。\n"},{"title":"务实的程序员有什么样的特征","url":"/blog/what-are-the-characteristics-of-pragmatic-programmers.html","content":"重读经典–《程序员修炼之道》\n是什么造就了务实的程序员？早期的采纳者&#x2F;快速的适配者\n你对技术和技巧有一种直觉，喜欢尝试。当接触到新东西时，你可以很快地掌握它们，并把它们与其他的知识结合起来。你的信心来自经验。\n好奇\n你倾向于问问题。这真不错–你怎么做到的？你对那个库有意见吗？总在听人说起的量子计算到底是什么？符号链接是怎么实现的？\n你热衷于收集各种细微的事实，坚信它们会影响自己多年后的决策。\n批判性的思考者\n你在没有得到证实前很少接受既定的现实。当同事们说“因为就该怎么做”，或者供应商承诺会解决所有的问题时，你会闻到挑战的味道。\n现实主义\n你试图理解所面临的每个问题的本质。这种现实主义让你对事情有多困难、需要彡多长时间有一个很好的感知。一个过程应该很难，或是需要点时间才能完成，对这些深刻理解，给了你坚持下去的毅力。\n多面手\n你努力熟悉各种技术和环境，并努力跟上新的进展。虽然目前的工作可能要求你在某个专门领域成为行家，但你总是能够进入新的领域，迎接新的挑战。\n","tags":["读书","程序员的修炼之道"]},{"title":"剖析分布式锁","url":"/blog/parsing-distributed-locks.html","content":"\n我们不生产代码,我们是代码的搬运工\n\n前不久，阿里大牛虾总再次抛出了分布式锁的讨论，对照之前项目中实现的redis分布式锁总结一下\n\n天才是1%的灵感，加上99%的汗水；编程是1%的编码，加上99%的在Google&#x2F;StackOverflow&#x2F;Github上找代码残酷的现实是，找来的代码可能深藏bug，而不知\n\n锁\n在多核多线程环境中，通过锁机制，在某一个时间点上，只能有一个线程进入临界区代码，从而保证临界区中操作数据的一致性\n怎么样才是把好锁？\n可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。这把锁要是一把可重入锁（避免死锁）支持阻塞和非阻塞：和 ReentrantLock 一样支持 lock 和 trylock 以及 tryLock(long timeOut)这把锁最好是一把公平锁（根据业务需求考虑要不要这条）有高可用的获取锁和释放锁功能获取锁和释放锁的性能要好\n\n分布式锁三要素\n外部存储\n 分布式锁是在分布式部署环境中给多个主机提供锁服务，需要另外的存储载体\n\n全局唯一标识\n在多线程环境中，锁可以使一个对象引用，也可以是变量，都有唯一的标识来区分锁保护的不同资源；在分布式环境下，也需要，比如对某一特定用户资源操作，业务+userId即可唯一标识\n\n至少有两种状态，获取和释放\n锁至少需要两种状态：加锁（lock）和解锁（unlock）。用状态区分当前尝试获取的锁是否已经被其他操作占用，被占用只有等待锁释放后才能尝试获取锁并加锁，保护共享资源\n\n\n实现理论知识知道得再多，还得落地才行；只要遵从三要素，就能打造一把好锁，不要拘泥于某一种工具。\n网上有很多实现方式，主要是”外部存储“使用了不同的组件，比如数据库，redis,zk，由于这些组件各自特性的不同，实现复杂度各有不同\n这儿主要说下在实际工作中使用到的两种方式，数据库与redis\n数据库数据库，任何系统都需要的组件，常规手法，都是使用version来实现乐观锁\nversion\n比如A、B操作员同时读取一余额为1000元的账户，A操作员为该账户增加100元，B操作员同时为该账户扣除50元，A先提交，B后提交。最后实际账户余额为1000-50&#x3D;950元，但本该为1000+100-50&#x3D;1050。这就是典型的并发问题\n假设数据库中帐户信息表中有一个version字段，当前值为1；而当前帐户余额字段(balance)为1000元。假设操作员A先更新完，操作员B后更新。a、操作员A此时将其读出(version&#x3D;1)，并从其帐户余额中增加100(1000+100&#x3D;1100)。b、在操作员A操作的过程中，操作员B也读入此用户信息(version&#x3D;1)，并从其帐户余额中扣除50(1000-50&#x3D;950)。c、操作员A完成了修改工作，将数据版本号加一(version&#x3D;2)，连同帐户增加后余额(balance&#x3D;1100)，提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录version更新为2。d、操作员B完成了操作，也将版本号加一(version&#x3D;2)试图向数据库提交数据(balance&#x3D;950)，但此时比对数据库记录版本时发现，操作员B提交的数据版本号为2，数据库记录当前版本也为2，不满足 “提交版本必须大于记录当前版本才能执行更新 “的乐观锁策略，因此，操作员B的提交被驳回。这样，就避免了操作员B用基于version&#x3D;1的旧数据修改的结果覆盖操作员A的操作结果的可能。\nset balance=1100,version=version+1 where id=#&#123;id&#125; and version=#&#123;version&#125;;\n\n\nversion简单，除了对业务数据表有侵入性，还有一些场景是胜任不了\n比如，在操作一个数量之前，需要确认一下能不能操作\nint countLimit = select count from limit where id = $&#123;id&#125;;if(countlimit&gt;0)&#123;    set balance=1100,version=version+1 where id=#&#123;id&#125; and version=#&#123;version&#125;;&#125;update count;\n这儿操作了多张表，此时就需要再配合事务，才能保证原子性\nredis由于db性能的限制，而redis性能卓越，很多时候会选择redis实现方式\n怎么使用redis正确地实现分布式锁，需要了解两方面\n\n实现分布式锁时，使用到的redis命令\n网上示例可能都有毒\n\nredis命令setnx 命令（『SET if Not eXists』(如果不存在，则 SET)的简写）：设置成功，返回 1设置失败，返回 0该命令是原子操作\ngetset 命令：自动将key对应到value并且返回原来key对应的value。如果key存在但是对应的value不是字符串，就返回错误。 返回值：返回之前的旧值，如果之前Key不存在将返回nil。该命令是原子操作。\nget 命令：get  获取key的值，如果存在，则返回；如果不存在，则返回nil；\ndel 命令：del  删除key及key对应的值，如果key不存在，程序忽略\nSET 命令：set key value [EX seconds] [PX milliseconds] [NX|XX]将字符串值 value 关联到 key 如果 key 已经持有其他值， SET 就覆写旧值，无视类型。对于某个原本带有生存时间（TTL）的键来说， 当 SET 命令成功在这个键上执行时， 这个键原有的 TTL 将被清除。\n可选参数从 Redis 2.6.12 版本开始，SET 命令的行为可以通过一系列参数来修改：\nEX second ：设置键的过期时间为 second 秒。 SET key value EX second 效果等同于 SETEX key second value \nPX millisecond：设置键的过期时间为 millisecond 毫秒。 SET key value PX millisecond 效果等同于 PSETEX key millisecond value \nNX ：只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value \nXX：只在键已经存在时，才对键进行设置操作。\n示例原来项目中使用分布式锁，整个逻辑：\n\nsetnx(lockkey, 当前时间+过期超时时间)，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。\nget(lockkey) 获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。\n计算 newExpireTime &#x3D; 当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值currentExpireTime。判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前 getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。\n在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行 delete 释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。\n\n获取锁\nprivate boolean acquireLock(Jedis j,String lock) throws Exception&#123;    int timeOut = timeoutSeconds*1000;    boolean acquired = false;    long start = System.currentTimeMillis();    int times = 0;    do &#123;        String value = String.valueOf(System.currentTimeMillis() + timeOut + 1);        // 第一个得到这个锁        if (j.setnx(lock, value) == 1) &#123;            logger.info(&quot;第一次获取全局锁:&#123;&#125; 成功&quot;, lock);            acquired = true;            break;        &#125;        // j.expire(lock, timeoutSeconds); 网络抖动，可能失败        String currentValue = j.get(lock);        // 小于时，可能是上次没有清除，自上次超时后没有别的线程操作过        if (currentValue != null &amp;&amp; Long.valueOf(currentValue) &lt; System.currentTimeMillis()) &#123;            // 这是同步操作，只会一个成功            String oldValue = j.getSet(lock, value);            // 别的线程没有赋上值，当前成功得到锁            if (oldValue != null &amp;&amp; oldValue.equals(currentValue)) &#123;                acquired = true;                logger.info(&quot;获取全局锁:&#123;&#125; 成功，尝试了&#123;&#125;次,经过了&#123;&#125;ms&quot;,lock,times,System.currentTimeMillis()-start);                break;            &#125;        &#125;        times++;        Thread.sleep(100);    &#125; while (start + timeOut &gt; System.currentTimeMillis());    if(!acquired)&#123;        logger.info(&quot;获取全局锁:&#123;&#125; 失败，尝试了&#123;&#125;次&quot;,lock,times);    &#125;\t\t\t    return acquired;&#125;\n\n解锁\nprivate void releaseLock(Jedis j,String lock)&#123;    String currentValue = j.get(lock);    if(currentValue != null)&#123;        if(System.currentTimeMillis() &lt; Long.valueOf(currentValue) )&#123;            j.del(lock);            logger.info(&quot;释放锁&#123;&#125;&quot;,lock);        &#125;    &#125;&#125;\n\n示例缺陷特地从多年前的项目中把这段代码找出来，当年写完，心里还挺美\n网上有很多资料也是差不多样的，但事实并不那么完美，甚至是错误的\n加锁\n使用jedis.setnx()和jedis.expire()组合实现加锁\n\nLong result = jedis.setnx(lockKey, value); if (result == 1) &#123;     // 若在这里程序突然崩溃，则无法设置过期时间，将发生死锁     jedis.expire(lockKey, expireTime); &#125;\n这个问题很明显，setnx与expire不是同一个事务，不俱备原子性；程序崩溃或者网络抖动都会出现死锁问题\n\nSystem.currentTimeMillis()这个需要各个client时间必须一致，一旦不一致，就可能加锁失败\n\ngetSet()如果锁为了灵活性，会把timeout作为入参\n\n\n当锁过期的时候，如果多个客户端同时执行jedis.getSet()方法，那么虽然最终只有一个客户端可以加锁，但是这个客户端的锁的过期时间可能被其他客户端覆盖\n解锁\njedis.del()直接删除\n\n这种不先判断锁的拥有者而直接解锁的方式，会导致任何客户端都可以随时进行解锁，即使这把锁不是它的\n有种错误改进,增加参数传入requestId\npublic static void releaseLock(Jedis jedis, String lockKey, String requestId) &#123;     // 判断加锁与解锁是不是同一个客户端     if (requestId.equals(jedis.get(lockKey))) &#123;         // 若在此时，这把锁突然不是这个客户端的，则会误解锁         jedis.del(lockKey);    &#125; &#125;\n还是原子性的问题如代码注释，问题在于如果调用jedis.del()方法的时候，这把锁已经不属于当前客户端的时候会解除他人加的锁。那么是否真的有这种场景？答案是肯定的，比如客户端A加锁，一段时间之后客户端A解锁，在执行jedis.del()之前，锁突然过期了，此时客户端B尝试加锁成功，然后客户端A再执行del()方法，则将客户端B的锁给解除了\n缺陷总结心里认为本来很简单的事，代码大概：\nLock lock = DistributedReentrantLock.newLock(&quot;testlock11&quot;);//定义testlock11为key的锁，默认可重入锁if(lock.tryLock())&#123;    try&#123;     xxxxxx    &#125;finally&#123;      lock.unlock(); //释放testlock11为key的锁，释放需要放在finally里，防止出异常导致锁没有及时释放    &#125;  &#125;\n为了提高性能，通过redis原子性接口SETNX:\n\n使用SETNX命令获取锁，若返回0（key已存在，锁已存在）则获取失败，反之获取成功\n为了防止获取锁后程序出现异常，导致其他线程&#x2F;进程调用SETNX命令总是返回0而进入死锁状态，需要为该key设置一个“合理”的过期时间释放锁\n使用DEL命令将锁数据删除\n\n结果为了弥补setnx()与expire()两个接口的原子性问题，引入了一堆问题，外强中干\n缺陷修正加锁Redis 2.6.12版本后，增强了set()命令\n/** * 尝试获取分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @param expireTime 超期时间 * @return 是否获取成功 */public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123;\tString result = jedis.set(lockKey, requestId, &quot;NX&quot;, &quot;PX&quot;, expireTime);\tif (LOCK_SUCCESS.equals(result)) &#123;\t\treturn true;\t&#125;\treturn false;&#125;\n\n加锁就一行代码：jedis.set(String key, String value, String nxxx, String expx, int time)，这个set()方法一共有五个入参：\n\n第一个为key，我们使用key来当锁，因为key是唯一的\n第二个为value，我们传的是requestId，通过给value赋值为requestId，就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成\n第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作；\n第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定\n第五个为time，与第四个参数相呼应，代表key的过期时间\n\n高可用：\n\nset()加入了NX参数，可以保证如果已有key存在，则不会调用成功，也就是只有一个客户端能持有锁，满足互斥性\n由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁\n将value赋值为requestId，代表加锁的客户端请求标识，那么在解锁的时候就可以进行校验是否是同一个客户端，防止锁交叉\n\n解锁/** * 释放分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @return 是否释放成功 */public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) &#123;\tString script = &quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;;\tObject result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId));\tif (RELEASE_SUCCESS.equals(result)) &#123;\t\treturn true;\t&#125;\treturn false;&#125;\n\n首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）\n使用eval()配置lua保证原子性\n\n在eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令\n\n有效时间为什么需要一个有效时间呢？主要就是防止死锁\n疑难\n执行业务代码操作共享资源的时间大于设置锁的过期时间？\n\n客户端需要设置接口访问超时,接口超时时间需要远远小于锁超时时间,比如锁自动释放的时间是10s,那么接口超时大概设置5-50ms\n【虽然能解决问题，但时间设置成了难点，微服务中多少接口，而且接口的timeout都是可配置的，不能每次调整接口timeout时，还是考虑一下锁的timeout】\n\nGC的STW\n\n\n客户端1获得了锁，正准备处理共享资源的时候，发生了Full GC直到锁过期。这样，客户端2又获得了锁，开始处理共享资源。在客户端2处理的时候，客户端1 Full GC完成，也开始处理共享资源，这样就出现了2个客户端都在处理共享资源的情况\n续命丸引入锁续约机制，也就是获取锁之后，释放锁之前，会定时进行锁续约，比如以3min间隔周期进行锁续约\n这样如果应用重启了，最多3min等待时间，不会因为时间太长导致的死锁问题，也不会因为时间太短导致被其他线程抢占的问题，也就是锁分布式锁不需要设置过期时间，过期时间对于这个锁来说是滑动的\nRedission虾总给了总结性阐述：\n\n首先启动Daemon线程，一直循环检测所有的分布式key，异步递延分布锁的过期时间，只要在处理业务逻辑，就递延分布锁过期时间3min。每次添加分布式锁key，同时会生成一个uuid token，定义一个ConcurrentHashMap构造一个全局map维护所有的分布式key，上面Daemon线程会遍历这个map，每次解锁需要比对这个token，token一致才能解锁。这样以来如果应用重启了，最多会有3min等待时间，不会导致时间太长导致的死锁问题，也不会因为时间太短导致的被其他线程抢占的问题，也就是锁分布式锁不需要设置过期时间，过期时间对于这个锁来说是滑动的\n\n跟随虾总思路，找到了一个开源组件：Redisson\nRedisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务。\n相对于平时使用的jedis，redission进行比较高的抽象\nredission中的lock主要是RLock接口，继承的juc的Lock接口\npublic interface RLock extends Lock, RExpirable, RLockAsync \n\nLock先看lock(),有两种形式，一个不带leaseTime,一个带leaseTime\npublic void lock() ;public void lock(long leaseTime, TimeUnit unit) ;\n\n边看源码，边解释\n两个方法共用了lockInterruptibly()\npublic void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException &#123;\tlong threadId = Thread.currentThread().getId();\tLong ttl = tryAcquire(leaseTime, unit, threadId);\t// lock acquired\tif (ttl == null) &#123;\t\treturn;\t&#125;\tRFuture&lt;RedissonLockEntry&gt; future = subscribe(threadId);\tcommandExecutor.syncSubscription(future);\ttry &#123;\t\twhile (true) &#123;\t\t\tttl = tryAcquire(leaseTime, unit, threadId);\t\t\t// lock acquired\t\t\tif (ttl == null) &#123;\t\t\t\tbreak;\t\t\t&#125;\t\t\t// waiting for message\t\t\tif (ttl &gt;= 0) &#123;\t\t\t\tgetEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS);\t\t\t&#125; else &#123;\t\t\t\tgetEntry(threadId).getLatch().acquire();\t\t\t&#125;\t\t&#125;\t&#125; finally &#123;\t\tunsubscribe(future, threadId);\t&#125;//        get(lockAsync(leaseTime, unit));&#125;\n\n尝试获取锁tryAcquire\n获取失败，订阅此channel的消息（订阅的意义，在解锁时就会发现）\n进入循环，不停的尝试获取锁，其中使用了JUC的Semaphore\n一旦获取成功，则跳出循环\n取消订阅\n\n尝试获取锁tryAcquire里面会用到两个核心方法tryAcquireAsync(),tryLockInnerAsync()\n@Overrideprivate &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, final long threadId) &#123;\tif (leaseTime != -1) &#123;\t\treturn tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG);\t&#125;\tRFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);\tttlRemainingFuture.addListener(new FutureListener&lt;Long&gt;() &#123;\t\t@Override\t\tpublic void operationComplete(Future&lt;Long&gt; future) throws Exception &#123;\t\t\tif (!future.isSuccess()) &#123;\t\t\t\treturn;\t\t\t&#125;\t\t\tLong ttlRemaining = future.getNow();\t\t\t// lock acquired\t\t\tif (ttlRemaining == null) &#123;\t\t\t\tscheduleExpirationRenewal(threadId);\t\t\t&#125;\t\t&#125;\t&#125;);\treturn ttlRemainingFuture;&#125;\n\n1.根据锁的持续时间不同，处理也不同\n2.没有设置持续时间，那就是阻塞型，一直等待\n2.1.为了防止业务方法执行时间超过锁timeout,则定时续约scheduleExpirationRenewal()\n\n\n3.设置了持续时间，则不需要进行续约\n\nprivate void scheduleExpirationRenewal(final long threadId) &#123;\tif (expirationRenewalMap.containsKey(getEntryName())) &#123;\t\treturn;\t&#125;\tTimeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() &#123;\t\t@Override\t\tpublic void run(Timeout timeout) throws Exception &#123;\t\t\t\t\t\tRFuture&lt;Boolean&gt; future = renewExpirationAsync(threadId);\t\t\t\t\t\tfuture.addListener(new FutureListener&lt;Boolean&gt;() &#123;\t\t\t\t@Override\t\t\t\tpublic void operationComplete(Future&lt;Boolean&gt; future) throws Exception &#123;\t\t\t\t\texpirationRenewalMap.remove(getEntryName());\t\t\t\t\tif (!future.isSuccess()) &#123;\t\t\t\t\t\tlog.error(&quot;Can&#x27;t update lock &quot; + getName() + &quot; expiration&quot;, future.cause());\t\t\t\t\t\treturn;\t\t\t\t\t&#125;\t\t\t\t\t\t\t\t\t\tif (future.getNow()) &#123;\t\t\t\t\t\t// reschedule itself\t\t\t\t\t\tscheduleExpirationRenewal(threadId);\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;);\t\t&#125;\t&#125;, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS);\tif (expirationRenewalMap.putIfAbsent(getEntryName(), new ExpirationEntry(threadId, task)) != null) &#123;\t\ttask.cancel();\t&#125;&#125;protected RFuture&lt;Boolean&gt; renewExpirationAsync(long threadId) &#123;\treturn commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,\t\t\t&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot; +\t\t\t\t&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; +\t\t\t\t&quot;return 1; &quot; +\t\t\t&quot;end; &quot; +\t\t\t&quot;return 0;&quot;,\t\tCollections.&lt;Object&gt;singletonList(getName()), \t\tinternalLockLeaseTime, getLockName(threadId));&#125;\n\n以internalLockLeaseTime&#x2F;3间隔时间，定时续约\n如果当前client自身有并发时，通过putIfAbsent保证只有一个task\n续约：当lock存在时，使用pexpire设置过期时间\n\n&lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123;\tinternalLockLeaseTime = unit.toMillis(leaseTime);\treturn commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,\t\t\t  &quot;if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 0) then &quot; +\t\t\t\t  &quot;redis.call(&#x27;hset&#x27;, KEYS[1], ARGV[2], 1); &quot; +\t\t\t\t  &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; +\t\t\t\t  &quot;return nil; &quot; +\t\t\t  &quot;end; &quot; +\t\t\t  &quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot; +\t\t\t\t  &quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot; +\t\t\t\t  &quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot; +\t\t\t\t  &quot;return nil; &quot; +\t\t\t  &quot;end; &quot; +\t\t\t  &quot;return redis.call(&#x27;pttl&#x27;, KEYS[1]);&quot;,\t\t\t\tCollections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));&#125;protected String getLockName(long threadId) &#123;     return id + &quot;:&quot; + threadId;&#125;\n\n1.lockname不存在\n1.1.hset(lockname,uuid+threadid,1),value&#x3D;uuid+threadid，有uuid可以区分各个client，有threadid区分各个线程，这样锁就具备了可重入性\n1.2.pexpire设置过期时间，防止client挂掉，造成死锁\n\n\n2.lockname存在\n2.1.hexists(lockname,uuid+threadid),这样保证了是同一个锁在同一个client\n2.2.hincrby 再次进锁，计数器+1\n2.3.pexpire 再次设置超时\n\n\n3.lockname存在，并且不在同一client\n3.1.pttl 返回剩余有效时长\n\n\n\nunLock@Overridepublic RFuture&lt;Void&gt; unlockAsync(final long threadId) &#123;\tfinal RPromise&lt;Void&gt; result = new RedissonPromise&lt;Void&gt;();\tRFuture&lt;Boolean&gt; future = unlockInnerAsync(threadId);\tfuture.addListener(new FutureListener&lt;Boolean&gt;() &#123;\t\t@Override\t\tpublic void operationComplete(Future&lt;Boolean&gt; future) throws Exception &#123;\t\t\tif (!future.isSuccess()) &#123;\t\t\t\tcancelExpirationRenewal(threadId);\t\t\t\tresult.tryFailure(future.cause());\t\t\t\treturn;\t\t\t&#125;\t\t\tBoolean opStatus = future.getNow();\t\t\tif (opStatus == null) &#123;\t\t\t\tIllegalMonitorStateException cause = new IllegalMonitorStateException(&quot;attempt to unlock lock, not locked by current thread by node id: &quot;\t\t\t\t\t\t+ id + &quot; thread-id: &quot; + threadId);\t\t\t\tresult.tryFailure(cause);\t\t\t\treturn;\t\t\t&#125;\t\t\tif (opStatus) &#123;\t\t\t\tcancelExpirationRenewal(null);\t\t\t&#125;\t\t\tresult.trySuccess(null);\t\t&#125;\t&#125;);\treturn result;&#125;void cancelExpirationRenewal(Long threadId) &#123;\tExpirationEntry task = expirationRenewalMap.get(getEntryName());\tif (task != null &amp;&amp; (threadId == null || task.getThreadId() == threadId)) &#123;\t\texpirationRenewalMap.remove(getEntryName());\t\ttask.getTimeout().cancel();\t&#125;&#125;\n\n从方法名看，虽然对外好像是直接解锁，但内部是异步执行的\nunlockInnerAsync()进行解锁\n从expirationRenewalMap移除，并把task.cancel()\n\nprotected RFuture&lt;Boolean&gt; unlockInnerAsync(long threadId) &#123;\treturn commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,\t\t\t&quot;if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 0) then &quot; +\t\t\t\t&quot;redis.call(&#x27;publish&#x27;, KEYS[2], ARGV[1]); &quot; +\t\t\t\t&quot;return 1; &quot; +\t\t\t&quot;end;&quot; +\t\t\t&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[3]) == 0) then &quot; +\t\t\t\t&quot;return nil;&quot; +\t\t\t&quot;end; &quot; +\t\t\t&quot;local counter = redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[3], -1); &quot; +\t\t\t&quot;if (counter &gt; 0) then &quot; +\t\t\t\t&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[2]); &quot; +\t\t\t\t&quot;return 0; &quot; +\t\t\t&quot;else &quot; +\t\t\t\t&quot;redis.call(&#x27;del&#x27;, KEYS[1]); &quot; +\t\t\t\t&quot;redis.call(&#x27;publish&#x27;, KEYS[2], ARGV[1]); &quot; +\t\t\t\t&quot;return 1; &quot;+\t\t\t&quot;end; &quot; +\t\t\t&quot;return nil;&quot;,\t\t\tArrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));&#125;\n\nlockname不存在，说明已经解锁，publish channelname unlockmessage；return 1\nlockname存在，但对于uuid+id不存在，说明不是加锁的client,return nil\nlockname存在，并且是当前加锁client\n对lockname uuid+id进行-1，如果counter&gt;0则走5，如果&#x3D;0 则走6\ncounter&gt;0 说明锁重入了，计数器-1，并expire\ncounter&#x3D;0 说明最终解锁，直接del key，并publish channelname unlockmessage;return 1\n\nredission缺陷使用cluster时\n一个场景：A在向主机1请求到锁成功后，主机1宕机了。现在从机1a变成了主机。但是数据没有同步，从机1a是没有A的锁的。那么B又可以获得一个锁。这样就会造成数据错误。\nredlock主要思想就是做数据冗余。建立5台独立的集群，当我们发送一个数据的时候，要保证3台（n&#x2F;2+1）以上的机器接受成功才算成功，否则重试或报错\nredlock实现会更复杂，但从他的算法上看，有zk选举的味道。对于更高可用分布锁，可以借助zk本身特性去实现\n总结对于锁，主要考虑性能与安全，即要保持锁的活跃性，又得保证锁的安全性\n分布式锁，除了以上两点，还要考虑实现时的三要素\n对于redission，对于锁部分的源码，还有很多的内容，很多的细节需要挖掘，此篇就不写了，太长。\n后面再结合JUC，写篇更详细的源码分析\n参考资料Redis分布式锁的正确实现方式\nredission\n","tags":["分布式"]},{"title":"单体架构转为微服务架构的12个要素","url":"/blog/12-elements-of-transforming-monomer-architecture-into-micro-service-architecture.html","content":"微服务架构已经很流行了，并且有大量文章描述相对单体架构，微服务架构带来的众多优点。\n怎么从单体架构更优雅地转化为微服务架构呢？\n有一种被实践证明有效的方法论：The Twelve-Factor App\n\n1、Codebase\n一份基准代码，多份部署\n\n\n尽管每个应用只对应一份基准代码，但可以同时存在多份部署。每份 部署 相当于运行了一个应用的实例。通常会有一个生产环境，一个或多个预发布环境。此外，每个开发人员都会在自己本地环境运行一个应用实例，这些都相当于一份部署\n2、Dependencies\n显式声明依赖关系\n\n12-Factor规则下的应用程序不会隐式依赖系统级的类库。 它一定通过依赖清单 ，确切地声明所有依赖项\n3、配置\n在环境变量中存储配置\n\n通常，应用的配置在不同部署 (预发布、生产环境、开发环境等等)间会有很大差异。这其中包括：\n\n数据库，Memcached，以及其他 后端服务 的配置\n第三方服务的证书，如 Amazon S3、Twitter 等\n每份部署特有的配置，如域名等\n\n有些应用在代码中使用常量保存配置，这与12-Factor所要求的代码和配置严格分离显然大相径庭。配置文件在各部署间存在大幅差异，代码却完全一致。\n4、后端服务\n把后端服务(backing services)当作附加资源\n\n后端服务是指程序运行所需要的通过网络调用的各种服务，如数据库（MySQL，CouchDB），消息&#x2F;队列系统（RabbitMQ，Beanstalkd），SMTP 邮件发送服务（Postfix），以及缓存系统（Memcached）。\n\n每个不同的后端服务是一份 资源 。例如，一个 MySQL 数据库是一个资源，两个 MySQL 数据库（用来数据分区）就被当作是 2 个不同的资源。12-Factor 应用将这些数据库都视作 附加资源 ，这些资源和它们附属的部署保持松耦合。\n5、构建，发布，运行基准代码 转化为一份部署(非开发环境)需要以下三个阶段：\n\n构建阶段 是指将代码仓库转化为可执行包的过程。构建时会使用指定版本的代码，获取和打包 依赖项，编译成二进制文件和资源文件。\n发布阶段 会将构建的结果和当前部署所需 配置 相结合，并能够立刻在运行环境中投入使用。\n运行阶段 （或者说“运行时”）是指针对选定的发布版本，在执行环境中启动一系列应用程序 进程。\n\n\n12-factor 应用严格区分构建，发布，运行这三个步骤。 举例来说，直接修改处于运行状态的代码是非常不可取的做法，因为这些修改很难再同步回构建步骤。\n6、进程\n以一个或多个无状态进程运行应用\n\n运行环境中，应用程序通常是以一个和多个进程运行的。\n12-Factor 应用的进程必须无状态且无共享。 任何需要持久化的数据都要存储在后端服务内，比如数据库。\n7、端口绑定\n通过端口绑定(Port binding)来提供服务\n\n互联网应用有时会运行于服务器的容器之中。例如 PHP 经常作为 Apache HTTPD 的一个模块来运行，正如 Java 运行于 Tomcat 。\n12-Factor 应用完全自我加载 而不依赖于任何网络服务器就可以创建一个面向网络的服务。互联网应用 通过端口绑定来提供服务 ，并监听发送至该端口的请求。\n8、并发\n通过进程模型进行扩展\n\n任何计算机程序，一旦启动，就会生成一个或多个进程。互联网应用采用多种进程运行方式。例如，PHP 进程作为 Apache 的子进程存在，随请求按需启动。Java进程则采取了相反的方式，在程序启动之初 JVM 就提供了一个超级进程储备了大量的系统资源(CPU和内存)，并通过多线程实现内部的并发管理。上述2个例子中，进程是开发人员可以操作的最小单位。\n9、易处理\n快速启动和优雅终止可最大化健壮性\n\n应用程序的进程应该是一次性的，以便它们可以快速启动、停止和重新部署，而不会丢失数据。这有助于快速弹性扩展、代码和配置更改的快速部署以及生产部署的稳健性。\n10、开发环境与线上环境等价\n尽可能的保持开发，预发布，线上环境相同\n\n从以往经验来看，开发环境（即开发人员的本地 部署）和线上环境（外部用户访问的真实部署）之间存在着很多差异。这些差异表现在以下三个方面：\n\n时间差异： 开发人员正在编写的代码可能需要几天，几周，甚至几个月才会上线。\n人员差异： 开发人员编写代码，运维人员部署代码。\n工具差异： 开发人员或许使用 Nginx，SQLite，OS X，而线上环境使用 Apache，MySQL 以及 Linux。\n\n12-Factor 应用想要做到 持续部署 就必须缩小本地与线上差异。 再回头看上面所描述的三个差异:\n\n缩小时间差异：开发人员可以几小时，甚至几分钟就部署代码。\n缩小人员差异：开发人员不只要编写代码，更应该密切参与部署过程以及代码在线上的表现。\n缩小工具差异：尽量保证开发环境以及线上环境的一致性。\n\n11、日志\n把日志当作事件流\n\n将日志流式传输到选定的位置，而不是将它们转储到日志文件中。日志可以定向到任何地方。例如，它们可以被定向到 NoSQL 中的数据库、另一个服务、存储库中的文件、日志索引和分析系统或数据仓库系统。\n12、管理进程\n后台管理任务当作一次性进程运行\n\n将管理任务与应用程序的其余部分分开，以防止一次性任务导致正在运行的应用程序出现问题。容器使这很容易，因为可以启动容器只是为了运行任务然后将其关闭。\n","tags":["微服务","架构"]},{"title":"再起航三混沌","url":"/blog/restart-three-chaos.html","content":"\n再起航系列,一枚互联网菜鸟的成长历程\n\n春风三月，却是很多职场人的混沌时节\n总结性文章，让人难以落笔。可能观察生活、体察自己不够细心；也许是成长缓慢，后知后觉；更可能本身就是平庸，普通人平平淡淡，没有什么轰烈可期的事情。但不管多难，终需落笔，无论什么原因，总得回顾总结\n来到互联网行业已经两年，在这个时间节点，可能再次处于混沌\n在第一年里，从好奇，新鲜，无知，疑惑 到 熟悉，充足；再到第二年，可能就是重复，机械，麻木，厌烦了。\n在刚换行时，一切都是新鲜，好奇的。经过一年时间的积累，对业务已经熟悉，能够应对各种业务需求，并能很好地实践业务场景中的技术栈，自己的能力圈在扩大，给人一种很充实的感觉\n慢慢地，从刚开始还能对技术栈的细节，深度保持一颗期待之心，陷入了各种业务需求中，毕竟是要解决问题体现价值的，不能仅仅学习新鲜事物，这也是前辈们常讲的不要抱着进大公司学习技术的心态，热爱学习的人在哪儿都能学习，并且学好\n你也是这么被洗脑的，因此你熟悉了各种业务场景，处理各样的业务咨询以及各环境的故障，帮上下游解决问题，开始重复生活，机械操作，厌烦了，总会厌烦，也有能力厌烦，毕竟你支撑了团队，混熟了业务线上的同事，老油条诞生了，大公司的螺丝钉也铸成了\n这些感受都是来自外界的刺激，似乎是常理的周期反应，此时需要一丝保持平静，进步的心，都会向外寻找答案，寻求机会。一切都得向外扩张\n但不管如何向外，都会落空，不踏实，终需回归自我，向内而问。不忘初心，方得始终\n从工作之初，有一种思想一直占据内心，那就是跟随团队，公司成长，是最夯实，也是最快的成长试。奈何，在实现中，几任老东家都走向了末路，而我也付之东流。尤其这次，完全换了行业，一切从零开始，命也，运也？\n以前厌倦了项目总是失败，总是从头开始，总想着能有一个成功的项目，不停地迭代，走向完美。这一次终于满足了，就一个项目不停地迭代，让你迭代个够。每一次迭代，历史包袱特别大，想想都替命运着急，过去走在创新的路上，嫌弃没有积累，现在迭代，又抱怨历史包袱了，人真难伺候\n混沌期总是迷茫，没有方向。牛人总有规划，人生规划。普通人总是在寻找方向，选择方向，而又没有方向\n在《再起航三转行互联网》中，提到程序员分为两类：技术型和产品型\n技术型，一直在路上，只要没有脱离技术型公司，这永远在路上，技术人不可能，也不能丢弃技术。不管老酒装新瓶，还是新酒装老瓶，都是保持与技术的距离。但也得认清自己，不可能做到技术大牛，技术领跑者。智商，经历沉淀都已经让我无法走上这条路\n产品型，但你能跨越三十五岁魔咒吗？体力，精力方面是得向年轻人低头的。\n那前途在何方？哪片土地是你希望的田野？\n管理领导？但现在不在其位置，考虑学习太多理论，都是形而上学。终归要落实到形而下学上\n路在何方呢？\n何时拨开云雾，走出混沌！\n可能需要未来的你给出答案\n\n现在可以没有答案，甚至说未来也没有答案，但行动不能停止，思考更不能停止\n从第二年的开始，已经开始关注速度《再起航二成长速度》，第一年得以业务为核心，了解熟悉业务，把手头工作处理好。第二年就得把在第一年关注好奇的技术进行深入研究了，所以开始以组件为单位，一个一个了解学习，以微服务为基架，深入每一个环节\n是的，来大公司不是学习的，老板聘用你，不是让你来学习的，但自己得知道，学习一刻都不能停，到大公司，的确不是学习的，在哪儿都能学习，主要是有一个场景，一个能更加深入层次学习的场景，好比之前的《剖析分布式锁》，在一般公司错误的写法，准确的说，不严谨的实现也能胜任，但更大业务量时，能不能胜任，需要思考，更多的时候，需要一个场景告诉你，你当下的完美，可能是个大大的残次品\n现在不管是外部大环境，还是公司内部小环境，都不理想，尤其公司现在的体量，是不需要我的陪伴成长的，所以前方还有别的路，创业别想，成熟条件完全没有，那只能去一家与自己相匹配的公司，一起成长\n公司不能大，也不能小。中型有成长的公司，核心业务部门，深入业务；或者基础架构，让面试造火箭，名副其实\n\n可能现在格局太小，总是以技术为一切；此篇只是总结当前的一种状态，不抱怨，不迷信，何时开悟走出混沌，尽人事，知天命，一切随缘\n"},{"title":"可测试性系列之测试替身Test Double","url":"/blog/test-double-of-testability-series.html","content":"在做程序测试时，常会用到测试替身来协助我们快速完成测试。\n\n有时候被测试系统(system under test(SUT))很难测试，因为在测试环境下依赖的组件不能正常使用。如外部系统。\n当在一个不能使用真实依赖组件(depended-on component(DOC))的地方写test时，我们可以使用Test Double。\n\n\nTest DoubleTest Double概括起来，有以下几种：\n\nMartin Fowler在Mocks Aren’t Stubs\n中给出解释：\n\nMartin Fowler解释的还不是太明白，我又收集了更明白一点的解释：\n\nDummy - just bogus values to stisfy the API\n\n\nExample: If you’re testing a method of a class which requires many mandatory parameters in a constructor which have no effect on your test, then you may create dummy objects for the purpose of creating new instances of a class.\n\n\nFake - create a test implementation of a class which may have a dependency on some external infrastructure. (It’s good practice that your unit test does NOT actually interact with external infrastructure.)\n\n\nExample: Create fake implementation for accessing a database, replace it with in-memory collection.\n\n\nStub - override methods to return hard-coded values,also refered to as state-based\n\n\nExample:Your test class depends on a method calculate() taking 5 minutes to complete.Rather than warit for 5 minutes you can replace its real implementation with stub that returns hard-coded values;taking only a small faction of the time.\n\n\nMock - very similar to Stub But interaction-based rather than state-based.This means you don’t expect from Mock to return some value,but to assume that specific order of method calls are made.\n\n\nExample:You’re testing a user registration class.After calling save,it should call send ConfirmationEmail.\n\n上面的解释已经很明白了，简单总结一下：\nDummy:主要是用来填充参数，以构造需要测试的对象\nFake:简单模拟实现，如Dao,但只是空实现\nStub:相对fake多了点硬编码返回值，两者很相似\nMock:相对状态验证更多的是行为验证\n阅读到这儿大概率已经明白了，也就fake与stub还有点模糊，要想明白更清晰的区别，需要先了解一下生命周期和验证方式：\n1、生命周期\n每个测试都是由四个依次执行的阶段：\n初始化（SetUp）、执行测试（Exercise）、验证结果（Verify）和复原（Teardown）\n2、验证方式\n在验证阶段，通常有两种验证方式：状态验证与行为验证\n状态验证：\n//肯定会使用的assertassertEquals(expected,actual);\n\n行为验证:\n//Mockito中的verifyverify(mock, times(3)).do();\n\n徐昊老师有个生动的描述：\n万恶淫为首，论迹不论心，论心世上少完人；不关心过程，只看结果。结果验证\n百善孝为先，论心不论迹，论迹贫家无孝子；看重过程，不看重结果。行为推断\n所以我们判断淫棍总比判断孝子准确\n\n测试策略是要保证有效性的同时，尽可能降低测试成本。\nfake、stub、spy、mock 以此排序，成本越来越低，同时有效性也越来越低。\nspy与mock在使用Mockito时能明显感受到它们俩的区别，fake与stub的区别，从上面的定义看，很接近。\n徐昊老师引入进程的视角来进一步区分：\n跨进程边界是fake，进程之间的stub就是fake。\n结合上面的解释明确多了，当使用数据库时，fake一个内存数据库。\n以进程划分：\n进程间替身:dummy fake spy\n进程内替身:stub mock spy\n以验证方式划分：\n严格来说，我们状态验证使用fake stub，行为验证使用mock。\ndummy和spy都不验证，dummy是不能验，spy是还没验。\nspy可以按状态（比如回放）也可以按行为（比如对比）验证。\nspy已经在行为验证和状态验证的边上。spy是记录调用，对调用加上验证就是mock\n如果用记录来reply就是录播测试，比如你在两个系统间做了spy，把请求和结果播放出来，这样相当于用spy的数据做了stub。\n把请求结果和目标结果做对比，实际相当于拿spy数据做了mock\nspy本身只取数据不验证，但是正常的doc内部数据不可知，因而spy是一种替身技术，并不是验证技术。\nspy is dumb mock\n总结测试策略是要保证有效性的同时，尽可能降低测试成本。因此Test Double是SUT中测试中不可或缺的，Test Double的形式有dummy fake stub spy mock,以进程维度与验证方式维度能更好地区分它们。\n","tags":["可测试性"]},{"title":"团队执行力不够都是下属问题","url":"/blog/insufficient-team-execution-is-a-problem-for-subordinates.html","content":"对于技术管理者来说，团队执行力这件事，不是什么难事，因为工程师有一种确定性思维，“靠谱”是好的工程师天生的品质，凡是明确答应过的事情，往往都会如数兑现。\n虽然如此，但也不能确保每件事都是落地有声。也有很多时候，技术管理者也有如下的心声：\n1、这事我来干，一天就搞定了，怎么搞了一周？\n2、如果A也像B那么积极主动，这个项目就不会出问题了，所以A，你能不能更主动一些呢？\n3、我们各种各样的流程都有，很完整也很系统，但是大家就是不按照流程办事\n\n如何有效地推进事项的进展，按计划成功落地。需要做好三件事：事前规划，事中跟进，事后总结。\n事前规划此阶段，重点就是做好计划。把事安排得明明白白。计划就是达到目标的路径图。\n优先级首先得有“资源是永远不足”的认知。公司本身也是在有限资源下利益最大化。\n到每个团队的资源更是如此。常用判断策略就是：重要紧急四象限。\n换个角度，我们都是要趋利避害的，从收益大小来看事情的重要性，从损失大小看事情的紧急性。\n那么重要紧急四象限就换种画法：\n\n计划各个任务的优先级确定完成之后，就得给优先处理的任务制定落地计划。\n而达成计划共识和计划落地是计划中两个重要的部分。\n计划共识共识的第一层境界：听懂\n讲得人要讲得清楚，听得人要听得明白\n共识的第二层境界：认同\n认同就是认可和赞同，实现上下同欲\n共识的第三层境界：行动\n共识的终极目标就是要促发下属行动\n计划落地计划制定完成，也与团队达到计划共识，剩下的就是计划落地，开始执行了。\n这个阶段有两点比较关键：\n1、职责清晰，责任到人\n2、团队的排兵布阵\n\nOGSM模型目的、目标、策略、衡量标准\n\n事中跟进下属不会执行你要求的，但会执行你检查的。检查到哪儿，执行到哪儿。\n\n事中阶段有三个重点：行动、规范和进程\n行动：检查计划有没有在推进，能力和意愿是否到位，及时辅导和鼓励\n规范：过程规范，结果才正确。检查基本流程和机制是否缺失，工作流程是否规范\n进程：按照其实制订的工作计划，定时检查工作进度\n事后总结总结最好方式就是复盘。\n不管工作的结果好与坏，看看工作过程中有哪些经验，有哪些问题，接下来目标如何调整，计划如何调整，执行如何优化，经验如何固化。\n其目的是着眼未来，确保下个阶段工作做得更好。\n寻找任务成功的必要条件，也就是关键节点。\n思维导图《技术管理实战》\n\n《不确定的危机下做确定的业绩》\n\n","tags":["管理"]},{"title":"大明湖畔的领域模型","url":"/blog/domain-model-of-daming-lake.html","content":"不管在做系统分析，还是系统设计时，我们大概率都会提到领域模型这个词，奇妙的是虽然大家都在谈论领域模型，但每个人心中都有一份对领域模型的认知。\n套用DDD，我们需要统一语言，首先需要对“领域模型”有一个统一认知。达成共识。\n你可以暂时挂起大脑进程，想想：“领域模型是什么？怎么描述？”\n世事万物都在变化中发展，就如同“手机”，十年前和现在，人们对它的认知也是不一样的。所以我们一起回顾一下最原始的“领域模型”是什么，你是否记起大明湖畔的领域模型。\n“领域模型”最早流行于OOA中，简单回顾一下OOA&#x2F;D\nOOA&#x2F;D分析：强调的是对问题和需求的调查研究，而不是解决方案。例如，如果需要一个新的在线交易系统，那么，应该如何使用它？它应该具有哪些功能？\n设计：强调的是满足需求的概念上的解决方案，而不是实现。例如，对数据库方案和软件对象的描述。设计思想通常排斥底层或“显而易见”的细节。最终设计可以实现，而实现则表达了真实和完整的设计。\n++分析和设计可以概括为：做正确的事和正确地做事++\nOOA：强调在问题领域内发现和描述对象（或概念）。例如，在航班信息系统里包含飞机、航班和飞行员等概念。\nOOD：强调的是定义软件对象以及它们如何协作以实现需求。例如，软件对象Plane可以有tailNumber(飞机唯一标识)和getFightHistory方法(飞行过的航班)\n领域模型领域模型是OOA中最重要的和经典的模型。\n定义领域模型是对领域内的概念类或现实世界中对象的可视化表。也称为概念模型、领域对象模型和分析对象模型。\n不是描述软件类、软件架构领域层或有职责软件对象的组图。\nWhy为什么需要领域模型？去掉修饰语，为什么需要模型，这在DDD系列文章中已经解释：模型是对业务复杂度的简化和提炼。帮助我们更好地理解业务。\n同理领域模型能够使我们理解关键概念和业务知识。\n我们在设计和实现时，软件类名称也大多源于领域模型的名称，以使对象具有源于领域的信息和职责。\n\n这样可以降低我们思维与OO建模之间的表示差异\nHow如何创建领域模型？\n\n寻找概念类\n将其绘制为UML类图中的类\n添加关联和属性\n\n寻找概念类根据领域模型定义，需要先找到概念类。\n概念类是思想、事物或对象。可以从其符号、内涵和外延考虑。\n符号：表示概念类的词语或图形\n内涵：概念类的定义\n外延：概念类所适用的一组示例\n\n考虑购买交易事件的概念类。\n可以使用符号Sale对其命名。\nSale的内涵陈述为“表示购买交易的事件，并且具有日期和时间”\nSale的外延是所有销售的例子，或者说是世界上所有销售实例的集合\n描述类图领域模型描述的信息可以采用纯文本方式表示。\n但是在可视化语言中更容易理解这些术语，特别是它们之间的关系，因为我们的思维更擅长理解形象的元素和线条连接。\n在应用UML时，领域模型被描述为一组没有定义操作的类图。\n关联关联是类之间的关系，表示有意义和值得关注的连接。\n关联能够满足当前所开发场景的信息需求，并且有助于理解领域。\n\n关联被表示为类之间的连线，并冠以首字母大写的关联名称。\n关联末端可以包含多重性表达式，用于指明类的实例之间的数量关系。\n关联本质上是双向的，方向箭头只是为了方便阅读，默认是从左往右。\n总结没有所谓唯一正确的领域模型。所有模型都是对我们试图要理解的领域的近似。\n领域模型主要是特定群体中用于理解和沟通的工具。\n有效的领域模型捕获了当前需求语境下本质抽象和理解 领域所需要的信息，并且可以帮助理解领域的概念、术语和关系。\n\n到此，已经完成追忆大明湖畔的领域模型，也是OO风云初起时代领域模型的含义。\n如果你想更多的回忆，可以去看看以往OO方便书籍，本文内容大多来自《UML和模式应用》。\n现今，领域模型演义出更多新的含义，如Martin Fowler提出的充血模型，以及DDD中的领域模型。\n在与别人交流时，我们得听声听音，是否在同一频道。\n","tags":["DDD","OO"]},{"title":"局部变量为何修饰为final","url":"/blog/why-is-the-local-variable-modified-as-final.html","content":"最近在团队中引入checkstyle ，自动执行规范检查，加入到ci步骤里面，让流程工具化，工具自动化，摆脱人工检查，在团队开发中硬性统一，更便于协作顺畅\ncheckstyle里面有个规范：所有local variable必须修饰为final\n这是为什么呢？\n\nfinal是Java中的一个保留关键字，它可以标记在成员变量、方法、类以及本地变量上。一旦我们将某个对象声明为了final的，那么我们将不能再改变这个对象的引用了。如果我们尝试将被修饰为final的对象重新赋值，编译器就会报错\n\n这么简单的一个关键字，怎么需要强制修饰一个局部变量\n局部变量class文件public static void main(String[] args) &#123;    String name = &quot;Whoops bug&quot;;    int pluginType = 3;&#125;public void testFinal()&#123;    final String name = &quot;Whoops bug&quot;;    int pluginType = 3;&#125;\n\n两个方法一个局部变量修饰为final,一个不修饰为final\n通过javap查看字节码\npublic static void main(java.lang.String[]);   Code:      0: ldc           #2                  // String Whoops bug      2: astore_1      3: iconst_3      4: istore_2      5: return   LineNumberTable:     line 13: 0     line 14: 3     line 15: 5   LocalVariableTable:     Start  Length  Slot  Name   Signature         0       6     0  args   [Ljava/lang/String;         3       3     1  name   Ljava/lang/String;         5       1     2 pluginType   I public void testFinal();   Code:      0: ldc           #2                  // String Whoops bug      2: astore_1      3: iconst_3      4: istore_2      5: return   LineNumberTable:     line 18: 0     line 19: 3     line 20: 5   LocalVariableTable:     Start  Length  Slot  Name   Signature         0       6     0  this   Lcom/jack/lang/LocalFinalTest;         3       3     1  name   Ljava/lang/String;         5       1     2 pluginType   I\n方法参数与局部变量用final修饰是纯编译时信息，到Class文件里就已经没有踪迹了，JVM根本不会知道方法参数或者局部变量有没有被final修饰\n曾经的阿里巴巴规范提出：\n\n推荐】final可提高程序响应效率，声明成final的情况：\n\n\n（1）不需要重新赋值的变量，包括类属性、局部变量；\n\n\n（2）对象参数前加final，表示不允许修改引用的指向；\n\n\n（3）类方法确定不允许被重写\n\n最新规范已经没有这种描述了，R大也回复过这个理由不成立，与性能无关\n不变性按上面class文件看，已经与性能无关，那么只能是它的本性：不变性\n\nfinal is one of the most under-used features of Java. Whenever you compute a value and you know it will never be changed subsequently put a final on it. Why?\n\n\nfinal lets other programmers (or you reviewing your code years later) know they don’t have to worry about the value being changed anywhere else.\n\n\nIf you get in the habit of always using final, when it is missing, it warns people reading your code there is a redefinition of the value elsewhere.\n\n\nfinal won’t let you or someone else inadvertently change the value somewhere else in the code, often by setting it to null. final helps prevent or flush out bugs. It can sometimes catch an error where an expression is assigned to the wrong variable. You can always remove it later.\n\n\nfinal helps the compiler generate faster code, though I suspect a clever compiler could deducing finality, even when the final is missing. final values can sometimes be in-lined as literals. They can be further collapsed at compile time in other final expressions.\n\n\nI have got into the habit of using final everywhere, even on local variables and if I am in doubt, I use final on every declaration then take it off when the compiler points out that I modified it elsewhere. When I read my own code, a missing final is a red flag there is something complicated going on to compute a value.\n\n\nIf you reference a static final in another class, that value often becomes part of your class at compile time. The source class then need not be loaded to get the value and the source class need not even be included in the jar. This helps conserve RAM (Random Access Memory) and keep your jars small.\n\n\nAt the machine language level, static finals can be implemented with inline literals, the most efficient form of addressing data.\n\n\nA little known feature of Java is blank finals. You can declare member variables final, but not declare a value. This forces all constructors to initialise the blank final variables. A final idiom\n\npublic void test() &#123;        // Use of final to ensure a variable is always assigned a value,// and is assigned a value once and only once.        int a = 4;        final int x;        if (a &gt; 0) &#123;            x = 14;        &#125; else if (a &lt; 0) &#123;            x = 0;        &#125; else &#123;            x = 3;        &#125;        System.err.println(x);    &#125;\n\n修饰为final是为了解决正确性、合理性、严谨性。用来提醒自己以及其他人，这里的参数&#x2F;变量是真的不能被修改，并让Java编译器去检查到底有没有被乱改\npublic void testSwitch()&#123;    final String name;    int pluginType = 3;    switch (pluginType) &#123;        case 1:            name = &quot;Candidate Stuff&quot;;            //break;            //should have handled all the cases for pluginType        case 2:            name = &quot;fff&quot;;    &#125;    // code, code, code    // Below is not possible with final    //name = &quot;Whoops bug&quot;;&#125;\n如果switch遗漏了break，或者switch完整的，在外面给final变量再次赋值，编译器就会报错\n类变量对于final修饰的局部变量有了清晰的认识，再延伸一下final类变量\n这儿涉及到一个问题,为什么JUC中很多的方法在使用类final变量时，都在方法中先引用一下\npublic class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt;        implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123;        /** Main lock guarding all access */    final ReentrantLock lock;         public int remainingCapacity() &#123;        final ReentrantLock lock = this.lock;        lock.lock();        try &#123;            return items.length - count;        &#125; finally &#123;            lock.unlock();        &#125;    &#125;\n\nDoug Lea给的答复是\n\nIt’s ultimately due to the fundamental mismatch between memory modelsand OOPJust about every method in all of j.u.c adopts the policy of reading fields as locals whenever a value is used more than once.This way you are sure which value applies when.This is not often pretty, but is easier to visually verify.The surprising case is doing this even for “final” fields.This is because JVMs are not always smart enough to exploit the fine points of the JMM and not reload read final values, as they would otherwise need to do across the volatile accesses entailed in locking. Some JVMs are smarter than they used to be about this, but still not always smart enough.\n\n翻译大意：\n\n归根究底是由于内存模型与OOP之间的原则不一致。几乎j.u.c包中的每个方法都采用了这样一种策略：当一个值会被多次使用时，就将这个字段读出来赋值给局部变量。虽然这种做法不雅观，但检查起来会更直观。final字段也会做这样处理，可能有些令人不解。这是因为JVM并不足够智能，不能充分利用JMM已经提供了安全保证的可优化点，比如可以不用重新加载final值到缓存。相比过去，JVM在这方面有很大进步，但仍不够智能\n\nprivate volatile Integer v1 = 1;    public void test()&#123;        Integer a = v1;        Integer b = v1;        System.err.println(v1);    &#125;    \n\n看一下字节码\npublic class com.jack.lang.LocalFinalTest &#123;  private final java.lang.Integer v1;    descriptor: Ljava/lang/Integer;public void test();    descriptor: ()V    Code:       0: aload_0       1: getfield      #3                  // Field v1:Ljava/lang/Integer;       4: astore_1       5: aload_0       6: getfield      #3                  // Field v1:Ljava/lang/Integer;       9: astore_2      10: getstatic     #4                  // Field java/lang/System.err:Ljava/io/PrintStream;      13: aload_0      14: getfield      #3                  // Field v1:Ljava/lang/Integer;      17: invokevirtual #5                  // Method java/io/PrintStream.println:(Ljava/lang/Object;)V      20: return\n\n使用局部变量引用一下\nprivate final Integer v1 = 1;public void test()&#123;    final Integer v2 = v1;    Integer a = v2;    Integer b = v2;    System.err.println(v2);&#125;\n对应字节码\npublic void test();descriptor: ()VCode:   0: aload_0   1: getfield      #3                  // Field v1:Ljava/lang/Integer;   4: astore_1   5: aload_1   6: astore_2   7: aload_1   8: astore_3   9: getstatic     #4                  // Field java/lang/System.err:Ljava/io/PrintStream;  12: aload_1  13: invokevirtual #5                  // Method java/io/PrintStream.println:(Ljava/lang/Object;)V  16: return\n\n少了很多次的\n0: aload_01: getfield \n这就是Doug Lea所讲的没有充分利用JMM已经提供了安全保证的可优化点吗？\n其实还有一个关键字与final类似，那就是volatile\nprivate volatile FieldType field；      FieldType getField()&#123;      FieldType result = field;      if(result == null)&#123;  // first check (no locking)         synchronized(this)&#123;            result = field;            if(result == null) // second check (with locking)               field = result = computeFieldValue();         &#125;      &#125;      return result;   &#125; \n在单例模式懒汉方式下，加个局部的result变量，会有25%性能会提高（effective java 2第71条）\n这儿的性能提升，似乎也是这个原因\n其实final和volatile还有更多的内存语义，禁止重排序。但在class文件中没有，使用hsdis与jitwatch查看JIT后的汇编码，可以发现一些端倪\n0x0000000114428e3e: inc    %edi0x0000000114428e40: mov    %edi,0xc(%rsi)0x0000000114428e43: lock addl $0x0,(%rsp)     ;*putfield v1                                ; - com.jack.lang.LocalFinalTest::test@9 (line 17)\n\n在对volatile写操作时，会加上lock，就是内存屏障store指令\n而对于final没有看到相应汇编语句\n\n现在我们以 x86 处理器为例，说明 final 语义在处理器中的具体实现。上面我们提到，写 final 域的重排序规则会要求译编器在 final 域的写之后，构造函数 return 之前，插入一个 StoreStore 障屏。读 final 域的重排序规则要求编译器在读 final 域的操作前面插入一个 LoadLoad 屏障。\n\n\n由于 x86 处理器不会对写 - 写操作做重排序，所以在 x86 处理器中，写 final 域需要的 StoreStore 障屏会被省略掉。同样，由于 x86 处理器不会对存在间接依赖关系的操作做重排序，所以在 x86 处理器中，读 final 域需要的 LoadLoad 屏障也会被省略掉。也就是说在 x86 处理器中，final 域的读 &#x2F; 写不会插入任何内存屏障！\n\n既然没有相应内存屏障指令，那对于类变量加个局部变量，更大的理由就是少了aload、getfield指令\n参考资料final : Java Glossary\nhttps://zhuanlan.zhihu.com/p/136819200\n","tags":["java"]},{"title":"如何精准达到目标","url":"/blog/how-to-achieve-goals-accurately.html","content":"读完刘媛媛的《精准努力》，想起了冯唐说的“结构化思维，结构化表达”。当你再怎么焦虑、恐慌时，不只是情绪表现，而应该提出为什么焦虑，焦虑怎么消除？怎么体现结构化思维，最佳表现形式，就是绘制一张思维导图。\n在《精准努力》中，作者针对我们常见的问题：目标、策略、执行、心态、学习、社交六个方面进行了结构化表达。\n\n目标篇制定目标，我们一般会想到SMART原则，但作者提出了独特的视角：\n最主要的思想就是二八原则，找到那20%的因素，作为核心目标，进行攻克。\n产品质量管理中有一个法则：重要少数法则\n这个法则是由质量管理专家约瑟夫朱兰提出的。朱兰认为，大多数品质不良的问题能够形成，可以归因为重要的少数，其余的小瑕疵，才是属于不重要的多数造成的。\n在发生质量问题的时候，20%的问题是由基层操作人员的失误造成的，但是80%的问题是由领导者造成的；而80%的领导问题，又是在20%的重要环节上造成的，这就是质量管理当中的“二八原则”。\n有用不等于值得\n值不值得，要把机会成本考虑进去\n为何你的努力和别的人的努力总是有差别？\n如果能够抓住关键的环节，就可以更少的投入，收获更大的回报。\n这不是投机取巧，我们只是追求有效。人的专注力、时间、精力都是有限的。我们必须选择一种有节制的、更专注的努力方式，去追求更高的效率，追求有用功。\n当我们不知道什么问题是关键问题的时候，要把通往目标遇到的所有问题全部列举出来。问自己：\n是哪些问题，导致你对现在的生活不满意？\n其中的哪些问题是你认为的主要问题？\n这些问题的解决，是否可以促进其他问题的解决？\n通过自问自答，圈定其中关键的部分，然后在这20%的领域，投入专注的卓越努力，去得到80%的收获。\n改掉只要有用就去做的思维，也可以反过来思考这个问题：如果我只做三件事，我应该做哪三件？如果只做一件呢？\n策略篇做事的正确顺序：策略，勤奋地执行策略，然后成功。\n要做成一件事：\n1、要有一个目标\n2、思考通往目标的途径\n3、最后才是执行层面的事情\n每个人都应该去追求成功。在这个过程中，无论是靠天分、靠勤奋，还是靠机遇，都靠不住。最可靠的是属于自己的方法论。方法论带来的成功是必然的，只不过来得早或晚而已。\n六步循环自我定位-瞄准目标-制定策略-执行反馈-调整行动-最终完成\n自我定位\n什么是目标？“我想考北大”这不是目标，说得好听点，叫想法、愿望。目标要有可执行性和衡量标准。也就是要符合SMART原则。比如“我要考到240分”，这算是一个目标。\n什么叫作学会解释目标？\n比如要考北大，意味着两门专业课都必须要考120分；意味着这张卷子当中80%的考点我都要知道；意味着考试范围内的80%我必须得知道。如果我只知道10%的话，那么还要搞定70%，那整个复习的过程就会变成这样：找到不会的地方，变成会的，直到这个百分比达到80%。\n这就是目标被解释的过程，从“我想考北大”到“我要考到240分”，到“我要搞定那此不会做的题目直到百分比达到80%”，到“我今天已经做了50%，还有30%”。\n策略\n策略意味着：\n第一，找到通往目标的真正问题和障碍\n第二，为这些问题和障碍去设计方案\n第三，方案应该是一个互相促进和统一的系统\n第四，集中精力去执行自己的方案，放弃其他的事情\n执行\n一件事情最后的成果如何，取决于以下几个要素：\n效果&#x3D;时间x精力x目标x策略x专注度x熟练度\n执行篇1、专注力\n2、拖延症\n3、精力管理\n4、专注\n5、坚持\n\n","tags":["读书"]},{"title":"实现业务逻辑三种方式：事务脚本、贫血模型、DDD","url":"/blog/three-ways-to-implement-business-logic-transaction-script-anemia-model-and-ddd.html","content":"在《领域驱动设计》这本书里面，列举了三种可将业务逻辑建模为软件模型的模式，也就是大家常听说的事务脚本、贫血模型、DDD。\n之前我还把这三种模式搞混淆了，too young too simple了。\n举个简单的示例：\n\n用户转帐，从一个帐户转到另一个帐户\n\n\n\n事务脚本Transaction Script\n\n看代码，就是所有业务逻辑都放在了dao里面，有点类似于旧时代的存储过程。\n事务脚本的思路有点类似于面向过程编程，要达到目标，需要哪些步骤，然后一步一步操作。业务逻辑被包含在一系列的操作行为中。\n贫血模型Anemic Model\n\n贫血模型似乎从摒弃存储过程之后，把存储过程的搬迁到service中，实体对象与表一一对应。也被称为Table Module,表模块。\n尤其有了ORM框架后，这种方式推上了高潮。\n甚至在互联网场景的引领下，数据库的很多特性也放弃了，如外键。数据库不过就是存放数据的袋子，只要把数据能正确存放到里面就行了。\n这种模型已经有很久的历史，如ER数据建模法。但在OO时代，被Martin Fowler列为反模式。\n让人不得不思考一下，为什么OO时代，这种模型依然如此流行？\n我们使用对象建模，就是把业务逻辑建模为 数据变化，然后把数据的改变和改变数据的行为放一起，数据变化，以及生命周期变化是业务的核心逻辑。\n这个原因不得不回顾下面向对象的发展历史。在当前流行的面向对象语言诞生之前，第一代面向对象语言其实是Smalltalk。而且当时架构风格都是单体架构，这样就有一个相对现在隐藏的背景条件：在同一个节点中，能得到所有的上下文信息，都在内存中。\n\n如上图，可以看出整个smalltalk的整体体系，除了虚拟机之外，还有虚拟镜像。虚拟镜像相当于虚拟机内存中数据持久化。每次虚拟机启动时，都会把虚拟镜像中的数据恢复到虚拟机内存中。\n在这种背景下，在逻辑处理时，Collection相当于数据库，所有的数据都在里面，存取都很自然。\n像现在的Java,C++并没有像smalltalk一样处理，时代来到了分层架构时代，经过了一系列的演变从最初的CS架构到三层，多层架构。\n\n历史的发展都有延续性和局限性。虽然现代OO语言保留了集合类型，却去掉了虚拟镜像，集合数据不再完整地在内存中，而且由于分层架构的特性，逻辑与数据被切分开来，自然而然地当逻辑需要数据时，就会去DB获取数据。\n到此，我们就明白了为什么贫血模型的火热原因。\n而且，正因为有这种局限性，当我们想去构建OO充血模型时，这种分裂阻碍了我们。比如N+1性能问题，还需要对象追踪技术，如dirty tracking\nDDDRich Model\n\n在DDD是什么也有提到，当前软件复杂性越来越高，程序员其实不是在编写代码，而是在摸索业务领域知识。\n如代码\npublic void setPassword(String password) &#123;    this.password = password&#125;\n\npassword的确是被赋值了，但是为什么赋值，不知道。是注册了新用户，还是用户修改了密码。完全不知道是什么业务。导致当有新需求变更时，成本会越来越高。\n为了不影响以前不知所云的代码，只能做累加，也就加重了代码不必要复杂性，整个软件交付会越来越难。\n这种模式结合了上面两个种模式，事务脚本重视的是交互行为，贫血模式重视的是数据，而充血模式结合数据与行为，这也是面向对象建模的优势。\n\n分离领域模型怎么才能得到充血模型，Eric给出了思路，就是分离领域模型。\n\n解决来自领域方面问题的软件部分通常只占整个软件系统的一小部分，这与它的重要性相比是不成比例的。\n\n在面向对象的程序中，用户界面、数据库和其他支持代码，经常被直接写到业务对象中。在UI和数据库脚本的行为中嵌入额外的业务逻辑。这正是上面两种模式的做法。\n当与领域相关的代码和大量的其他代码混在一起时，就很难阅读并理解了。对UI的简单改动就会改变业务逻辑。改变业务规则可能需要小心翼翼地跟踪UI代码、数据库代码或者其他的程序元素。实现一致的模型驱动对象变得不切实际，而且自动化测试也难以使用。如果在程序的每个行为中包括了所有的技术和逻辑，那么它必须很简单，否则难以理解。\n\nDDD分层就是一种解决方式。\n分层架构的目的是通过关注点分离来降低系统的复杂度，同时满足单一职责、高内聚、低耦合、提高可复用性和降低维护成本。\nOO是最优解吗？面向对象还是默认的最优模型构建方式吗？\n这是一个有意思的问题，我也从没有深入思考过。说几个当前流行的一些架构风格。\n当前DDD还是很火热的，大家都在追求充血模型。\n最近我在实践中，会加一层facade层，不管是提供API，还是提供SDK。有点类似application service。\n为系统提供一个统一门面，至于系统内部是用贫血模型，还是充血模型，对外部来讲是个黑盒，客户端不用关心。\n那么再放大点，现在微服务架构是标配，我们只要知道服务在哪儿，提供了什么能力。内部怎么构建，不用关心。架构师的考虑点不再是一个个对象，而是一个个endpoint。\n再就是像serverless架构风格，数据与行为是分开的，是以funcation为基本去构建服务。关注一个个function，process。\n再比如大数据架构，像hadoop，数据是巨大的，搬迁是不太可能，通过mapreduce，我们是移动process。\n经过这几种风格对比，随着AI的兴起，还会再出现新的模型方法，将来OO还是追求的最优解吗？\n总结实现业务架构的三种方式，贫血模型随处可见，而事务脚本与充血模型倒却难得一见。\n事务脚本的确已经被抛弃，充血模型却是很多人爱不起来。看着很漂亮，但落地时又有性能、循环依赖、分层等等具体的问题。如何应对，且看专栏《DDD》。\n","tags":["DDD"]},{"title":"如何管理一个项目","url":"/blog/how-to-manage-a-project.html","content":"《技术为径：带领公司走向卓越的工程师》–如何管理一个项目\n所谓项目管理，就是将一个复杂的最终目标分成一些小目标，同时将这些目标以最高效的方式进行排序，识别出其中可以并行开展的工作，以及这些工作前后的依赖关系。\n同时，还应该试图找出那些可能导致项目延期或者彻底失败的高风险环节。\n项目管理的过程，就是试图将不确定的部分更确定化、将不可知的问题变成可知问题的过程。\n同时，我们也应该认识到在这个过程中犯错误和漏掉一些未知风险是不可避免的。\n1、将工作进行拆分拿一张表格，或者采用甘特图的形式，抑或采用你最习惯的其他形式，尝试将你的大目标（例如，重写应收账款系统）拆分成一些具体的小目标，继续迭代。这个过程不一定要完全由你自己来完成。\n如果系统的某个方面你不是很了解，就让其他人来帮助你。\n你将目标拆分到一定程度的时候，就要专注于这些任务的排序。哪些任务可以马上开始？\n将其拆分成一个个具体的任务进行推进。\n2、持续关注细节与未知部分做好项目管理的秘诀就是，迎难而上，永不停止。\n项目管理本身就是一项非常烦琐、累人的工作。所以不管这项工作有多烦人，有多无聊，有多痛苦，你都不要停止。\n一个好的上级领导会和你一起完成这项工作，帮助你指出计划的不足之处，同时向你提出自己的看法。没有人喜欢制订项目计划，但是这是一个和上级领导共同工作的好机会，同时也是一个很好的学习过程。\n一定要持续跟进项目中的未知之处，一直到无可追踪为止。\n3、真正落实项目计划并时刻调整之前的周密计划制订过程的价值所在，就是帮助你了解项目的真实进度，以及与达成最终目标的距离。\n在项目进展过程中，如果出现延期情况，一定要向所有人及时通报信息。\n有计划在手，你就不再需要盲目地猜测项目进度，而是可以清晰地知道项目的哪些目标已经达成，而哪些目标还没有达成。\n4、利用计划过程中获得的知识来管理需求变更在按照原始需求进行任务拆分的过程中，你对项目有了更深刻的了解。如果中途发生了需求变更的情况，这些知识可以帮助你更好地应对。\n如果某项变更大大增加了项目风险，或者需要大量的额外工作，你就可以与他人明确这项变更的成本。\n如果正在做的项目有一个非常严格的截止日期，那么了解每项细分工作所需的时间可以让你更好地排列优先级，甚至是割舍某些工作，平衡项目的整体质量、进度与交付时间。\n5、随着项目的推进不断完善细节信息当项目快要进入尾声的时候，烦琐的工作又出现了。\n这正是落实项目每一项小细节的阶段。还差哪些任务没做完？测试做完了吗？交付验证做了吗？\n可以考虑进行一次复盘模拟，提前将项目发布时可能出现的各种问题场景都预演一遍。\n这也就是在落实“足够好”这个标准线的时候，让团队内的每个人都了解这个标准线，并且要具体落实到自己负责的部分。\n排队那些无关紧要的工作，让整个团队都专注在落实真正重要的细节问题上。\n制订一份发布计划，再制订一份回滚计划。\n","tags":["读书"]},{"title":"应对变化","url":"/blog/coping-with-change.html","content":"之前对SOLID做了一个总结 《SOLID》总结 \n这些原则是前辈们经过无数实践提炼出来的，百炼成刚，那是不是成了放之四海皆准的道理呢？某种程度上讲，还真就是准的，常被人耳提面命写的代码要遵守这些原则，想想code review时，是不是代码常常对比这些原则，被人指出没有遵循哪个原则\n总结篇中画了这幅图，SOLID也的确是我们达到高内聚低耦合很重要的手段\n\n//读取配置文件和计算class Computer&#123;    public int add() throws NumberFormatException, IOException &#123;        File file = new File(&quot;D:/data.txt&quot;);        BufferedReader br = new BufferedReader(new FileReader(file));        int a = Integer.valueOf(br.readLine());        int b = Integer.valueOf(br.readLine());        return a+b;    &#125;&#125;\n\n这是一段被用来演示SRP的反例，从示例代码中看出，这个方法职责的确不单一，引起它变化的至少有两个地方：一是数据不一定从配置文件读取、二是计算方式可能会变\n在code review时，不管是自己还是别人，的确让人觉得不够完美\n因此，我们会花一番功夫，来让方法达到SOLID的要求，可如果此方法从系统上线运行几个月，甚至几年都无需变动，那我们花费的这些时间也只是自我感动，毕竟我们最终目标是给客户交付带来价值的系统，以最快的速度给公司带来效益\n这其实是成本的问题，没错，程序员要有技术追求，但也得考虑成本\n可总不能为了成本，忽略一切吧，那怎么处理呢，我们要达到“高内聚、低耦合”，SOLID是重要路径，但又不能不计成本地进行SOLID，更不能为了SOLID而SOLID\n所以不能走两个极端，既不能坐视不管，也不能一味求全，在这两层之间应该还有一片灰色地带\n\n\n这灰色地带是什么样的？怎么做才能不去穷举变化疲惫应对，而当真正变化来临时又能轻松应对？大佬提供了思路，不能以这些原则去应对软件变化，应该以无法为有法，以无限为有限。以实际需求变化来帮助我们识别变化，管理变化。这思路就是袁英杰提出的正交设计，有四大策略\n四大策略策略一：消除重复重复代码，不管接手老项目还是住持新项目，都特别重视重复代码的比率，为什么呢？\n\n重复代码增加维护成本，变动同一个逻辑会遗漏修改\n重复代码说明团队沟通不畅，团员间没有交流或者没有必要的code review\n\n这只是实践带来的观察，那么从理论角度说说消除重复的重要性\n“重复”极度违背高内聚、低耦合原则，从而会大幅提升软件的长期维护成本;而我们所求的高内聚是指关联紧密的事物放在一起，两段完全相同的代码关联最为紧密，重复就意味着低内聚\n更糟糕的是，本质重复的代码，都在表达同一项知识。如果他们表达（即依赖）的知识发生了变化，这些重复代码都需要修改，因而重复代码也意味着高耦合\n\n当完全重复的代码进行消除，会让系统更加高内聚、低耦合\n小到代码块，大到模块也一样，如果两个模块之间部分重复，那么这两个模块都至少存在两个变化原因或两重职责；站在系统的角度看，它们之间有重复部分，也有差异部分，那这两个模块都存在两个变化原因\n\n对于这一类型重复，比较典型的情况有两种：实现重复和客户重复\n\n\n这个策略非常明确，极具操作性，消除重复后，明显提高系统内聚性，降低耦合性，在消除重复过程中，也提高了系统的可重用性，而且对于客户重复，还提高了扩展性\n策略二：分离不同的变化方向对于策略一使用时机，可以随时进行，重复也容易判定。除重复代码外，另一个驱动系统朝向高内聚方向演进的信号是：我们经常需要因为同一类原因，修改某个模块。而这个模块的其它部分却保持不变\n分离不同变化方向，目标在于提高内聚度。因为多个变化方向，意味着一个模块存在多重职责。将不同的变化方向进行分离，也意味着各个变化职责的单一化\n\n对于变化方向分离，也得到了另外一个我们追求的目标：可扩展性\n策略二相对策略一，最重要的就是时机，不然就会回到我们文章开头时的窘境：早了，过度设计；晚了，则被再次愚弄\n当你发现需求导致一个变化方向出现时，将其从原有的设计中分离出去。此时时机刚刚好，不早不晚；Uncle Bob也曾给出答案：被第一颗子弹击中时，也就是当第一个变化方向出现时\n这个世界里，本质上只存在三个数字：0，1，和N。\n0意味着当一个需求还没有出现时，我们就不应该在系统中编写一行针对它的代码。\n1意味着某种需求已经出现，我们只需要使用最简单的手段来实现它，无需考虑任何变化。\nN则意味着，需求开始在某个方向开始变化，其次数可能是2，3，…N。但不管最终的次数是多少，你总应该在由1变为2时就需要解决此方向的变化。随后，无论最终N为何值，你都可以稳坐钓鱼台，通过一个个扩展来满足需求\n如果我们足够细心，会发现策略消除重复和分离不同变化方向是两个高度相似和关联的策略:\n它们都是关注于如何对原有模块进行拆分，以提高系统的内聚性。(虽然同时也往往伴随着耦合度的降低，但这些耦合度的降低都发生在别处，并未触及该如何定义API以降低客户与API之间耦合度)。\n另外，如果两个模块有部分代码是重复的，往往意味着不同变化方向。\n尽管如此，我们依然需要两个不同的策略。这是因为：变化方向，并不总是以重复代码的形式出现的（其典型症状是散弹式修改，或者if-else、switch-case、模式匹配）；尽管其背后往往存在一个以重复代码形式表现的等价形式（这也是为何copy-paste-modify如此流行的原因）。\n策略三：缩小依赖范围前面两个策略解决了软件单元如何划分问题，现在需要关注合的问题：模块之间的粘合点API的定义\n\n\n首先，客户和实现模块的数量，会对耦合度产生重大的影响。它们数量越多，意味着 API 变更的成本越高，越需要花更大的精力来仔细斟酌。\n其次，对于影响面大的API（也意味着耦合度高），需要使用更加弹性的API定义框架，以有利于向前兼容性。\n\n因此缩小依赖范围，就是要精简API\n\nAPI包含尽可能小的知识。因为任何一项知识的变化都会导致双方变化\nAPI也要高内聚，不应强迫API的客户依赖不需要的东西\n\n策略四：向稳定的方向依赖虽然缩小依赖范围，但终究还是要有依赖范围，还是必然存在耦合点。降低耦合度已到尽头。\n耦合最大的问题在于：耦合点的变化，会导致依赖方跟着变化。这儿意味着如果耦合点不变，那依赖方也不会变化。换句话说，耦合点越稳定，依赖方受耦合变化影响的概率就越低\n因此得出第四个策略：向稳定的方向依赖\n耦合点也就是API，什么样的API更侧向于稳定？站在What，而不是 How 的角度；即站在需求的角度，而不是实现方式的角度定义API；也就是站在客户的角度，思考用户的本质需要，由此来定义API，而不是站在技术实现的方便程度角度来思考API定义\nSOLID一个好的面向对象设计，自然是符合高内聚，低耦合原则的对象划分和协作方式。\n单一职责和开放封闭，更多的在强调类划分时的高内聚；而里氏替换，依赖倒置，接口隔离则更多的强调类与类之间协作接口（即API）定义的低耦合\n单一职责，通过对变化原因的识别，将一个承担多重职责的类，不断分割为更小的，只具备单一变化原因的类。而单一变化原因指的是：一个变化，会引起整个类都发生变化。只有关联极其紧密的情况，才会导致这样的局面。因而，单一职责和高内聚某种程度是同义词。\n但单一职责原则本身，并没有明确指示我们该如何判定一个类属于单一职责的，以及如何达到单一职责的状态。而策略消除重复，分离不同变化方向，正是让类达到单一职责的策略与途径\n开放封闭原则，正是通过将不同变化方向进行分离，从而达到对于已经出现的变化方向，对于修改是封闭的，对于扩展是开放的\n\n里氏替换原则强调的是，一个子类不应该破坏其父类与客户之间的契约。唯有如此，才能保证：客户与其父类所暴露的接口（即API）所产生的依赖关系是稳定的。子类只应该成为隐藏在API背后的某种具体实现方式。\n\n依赖倒置原则则强调：为了让依赖关系是稳定的，不应该由实现侧根据自己的技术实现方式定义接口，然后强迫上层（即客户）依赖这种不稳定的API定义，而是应该站在上层（即客户）的角度去定义API（正所谓依赖倒置）\n但是，虽然接口由上层定义，但最终接口的实现却依然由下层完成，因此依赖倒置描述为：上层不依赖下层，下层也不依赖上层，双方共同依赖于抽象。\n\n最后，接口隔离原则强调的是：不应该强迫客户依赖它不需要的东西。显然，这是缩小依赖范围策略在面向对象范式下的产物\n\n总结尽管理论上讲，任意复杂的系统都可以被放入同一个函数里。但随着软件越来复杂，即便是智商最为发达的程序员也发现，单一过程的复杂度已经超出他的掌控极限。这逼迫人们必须对大问题进行分解，分而治之，这也是必须模块化的原因\n模块化主要是两方面：\n\n软件模块该如何划分？（怎么分）\n模块间API该如何定义？（怎么合）\n\n本文四个策略，前两个指导怎么高内聚，也就是怎么分；后两个指导耦合方式，怎么合\n重要的是使用各个策略的使用时机，变化驱动识别变化、重构变化\n变化导致的修改有两类：\n\n一个变化导致多处修改（重复）；\n多个变化导致一处修改（多个变化方向）；\n\n由此得到前两个策略：消除重复；分离不同变化方向。\n除此之外，我们要努力消除变化发生时不必要的修改，也有两种方式：\n\n不依赖不必要的依赖；\n不依赖不稳定的依赖；\n\n这就是后面两个策略：缩小依赖范围，向着稳定的方向依赖。\nReference变化驱动：正交设计\n","tags":["SOLID"]},{"title":"应对复杂性","url":"/blog/dealing-with-complexity.html","content":"资本家主要目标是赚钱、赚很多很多的钱；他们给提出的要求是降本增效\n那么作为架构师，目标是什么呢？\n在《整洁架构》书中作者写到架构的主要目的是支持系统的生命周期。良好的架构使系统易于理解，易于开发，易于维护和易于部署。最终目标是最小化系统的寿命成本并最大化程序员的生产力\n大多数程序员心里觉得应该是展示最牛B的技术才对，可现实却只是资本家的工具而已，是不是有些惊讶\n软件的核心是它为用户解决领域相关问题的能力，保持业务价值的持续交付\n可在软件行业，交付能力的持续性是相当有挑战性的，也许前期交付很快，但慢慢交付就很慢，质量也会下降，甚至哪怕一次小小的改动都要经历很久，更可怕的是无法交付，为什么呢？\n在之前的相关文章中也提过，有两张图：\n《架构师》中提到软件需求并不只是功能需求：\n\n软件复杂度并不仅仅是业务复杂度：\n\n在一起起看似快速交付背后，不合理的设计或者实现积累了过多的技术债，造成无法交付\n所以架构师最重要的事就是解决软件中的复杂性\n\n在软件项目中，任何方法论如果最终不能落在“减少代码复杂度”，都是有待商榷的\n软件架构设计的实质，是让系统能够更快地响应外界业务变化，并且使得系统能够持续演进\n架构设计的主要目的是为了解决软件复杂度带来的问题\n《DDD应对复杂》中也提到复杂的来源，对于软件复杂性以及应对方案，特定总结画了一幅图\n\n","tags":["架构"]},{"title":"建模没必要","url":"/blog/modeling-is-not-necessary.html","content":"Eric在DDD第一章节就介绍了模型，可见模型的作用不言而喻，说DDD是一种模型驱动设计方法，绝对没有问题\n那是不是我们在拿到业务需求时，就急呼呼的跟业务方来一起构造模型呢？毕竟模型是万事之首嘛\n在《DDD开篇》提过DDD是一种基于面向对象的设计方法，我们既然已经有了面向对象，而且OOAD也很强大，为什么还需要DDD呢？\n要想弄清楚这两个问题，首先我们需要拿个示例来仔细比对一下\nOOP小示例在《面向对象是什么》一文中提到的游戏小示例\n有个游戏，基本规则就是玩家装备武器去攻击怪物\n\n玩家（Player）可以是战士（Fighter）、法师（Mage）、龙骑（Dragoon）\n怪物（Monster）可以是兽人（Orc）、精灵（Elf）、龙（Dragon），怪物有血量\n武器（Weapon）可以是剑（Sword）、法杖（Staff），武器有攻击力\n玩家可以装备一个武器，武器攻击可以是物理类型（0），火（1），冰（2）等，武器类型决定伤害类型\n\n作为一名受过OO熏陶的程序员，借助OO的继承特性把类结构设计成：\n\npublic abstract class Player &#123;      Weapon weapon&#125;public class Fighter extends Player &#123;&#125;public class Mage extends Player &#123;&#125;public class Dragoon extends Player &#123;&#125;public abstract class Weapon &#123;    int damage;    int damageType; // 0 - physical, 1 - fire, 2 - ice etc.&#125;public Sword extends Weapon &#123;&#125;public Staff extends Weapon &#123;&#125;\n\n攻击规则如下：\n\n兽人对物理攻击伤害减半\n精灵对魔法攻击伤害减半\n龙对物理和魔法攻击免疫，除非玩家是龙骑，则伤害加倍\n\npublic class Player &#123;    public void attack(Monster monster) &#123;        monster.receiveDamageBy(weapon, this);    &#125;&#125;public class Monster &#123;    public void receiveDamageBy(Weapon weapon, Player player) &#123;        this.health -= weapon.getDamage(); // 基础规则    &#125;&#125;public class Orc extends Monster &#123;    @Override    public void receiveDamageBy(Weapon weapon, Player player) &#123;        if (weapon.getDamageType() == 0) &#123;            this.setHealth(this.getHealth() - weapon.getDamage() / 2); // Orc的物理防御规则        &#125; else &#123;            super.receiveDamageBy(weapon, player);        &#125;    &#125;&#125;public class Dragon extends Monster &#123;    @Override    public void receiveDamageBy(Weapon weapon, Player player) &#123;        if (player instanceof Dragoon) &#123;            this.setHealth(this.getHealth() - weapon.getDamage() * 2); // 龙骑伤害规则        &#125;        // else no damage, 龙免疫力规则    &#125;&#125;\n\n如果此时，要增加一个武器类型：狙击枪，能够无视一切防御，此时需要修改\n\nWeapon,扩展狙击枪Gun\nPlayer和所有子类（是否能装备某个武器）\nMonster和所有子类（伤害计算逻辑）\n\n除了伤害逻辑有各种规则，还有装备武器也会有各种规则\n比如，战士只能装备剑，法师只能装备法杖，但他们都可以装备匕首\n再比如，当我们有不同的对象，但又有相同或类似的行为时，OOP会不可避免的导致代码的重复\n在这个例子里，如果我们去增加一个“可移动”的行为，需要在Player和Monster类中都增加类似的逻辑：\npublic abstract class Player &#123;    int x;    int y;    void move(int targetX, int targetY) &#123;        // logic    &#125;&#125;public abstract class Monster &#123;    int x;    int y;    void move(int targetX, int targetY) &#123;        // logic    &#125;&#125;\n一个可能的解法是有个通用的父类：\npublic abstract class Movable &#123;    int x;    int y;    void move(int targetX, int targetY) &#123;        // logic    &#125;&#125;public abstract class Player extends Movable;public abstract class Monster extends Movable;\n\n但如果再增加一个跳跃能力Jumpable呢？一个跑步能力Runnable呢？如果Player可以Move和Jump，Monster可以Move和Run，怎么处理继承关系？要知道Java（以及绝大部分语言）是不支持多父类继承的，所以只能通过重复代码来实现\n\n原生OOP力不从心从OO角度看待，逻辑简单，代码也算过得去，也基本符合充血模型需要的数据与行为结合性要求\n但如果业务比较复杂，未来会有大量的业务规则变更时，简单的OOP代码会在后期变成复杂的一团浆糊，逻辑分散在各地，缺少全局视角，各种规则的叠加会触发bug。\n在这个小示例中，可以看到新增加一次规则几乎重写很多类，改造成本相当高，这还写得不够OO吗？\n总体而言，上面的代码没有处理好这三个问题：\n\n业务规则的归属到底是对象的“行为”还是独立的”规则对象“？\n业务规则之间的关系如何处理？\n通用“行为”应该如何复用和维护？\n\n\nDDD应对示例和单纯使用面向对象的问题已经很明晰了，DDD如何应对呢？\n当然，可以申辩\n虽然示例代码已经很OO，但却没有遵守OO原则SOLID，至少没有达到OCP目标\n尤其开始就掉进OOP的陷阱，使用继承来实现看似是继承关系的逻辑，没有遵循组合优先于继承的原则\n尤其没有提取出业务规则，并理清业务规则的归属，不应该与实体对象混合\n建模示例本身很简单，如果我们建模，大概是这样：\n\n但很怪，模型则偏重于数据角度，描述了在不同业务维度下，数据将会如何改变，以及如何支撑对应的计算与统计，也就是说模型上看，会有实体以及实体间的关系，隐藏了业务维度，可以我们这个模型上却包含了动词，来描述业务行为\n当然这个模型可以再充实一下，比如把业务规则标识上去，这也说明了传统模型的缺点，如果你对其他模型感兴趣，请关注我，后期会详情介绍模型系列文章\n我们回到有问题的本质原点，为什么要建模呢，为了抽象复杂业务逻辑，降低理解业务的成本，挖掘更多的业务隐藏知识\n可上面的示例太清楚了，一览无余。一句话可以概述出整个业务需求：\n玩家使用武器攻击怪物，对怪物造成伤害，直至怪物死亡\n把规则加进去：\n玩家按规则使用武器按规则攻击怪物，对怪物、玩家、武器造成一定规则的影响(怪物受到伤害，玩家可能会有反弹伤害，武器持久属性会下降直到武器消失)，直至怪物死亡\n这其实是任何一款ARGP游戏的核心业务\n软件开发的核心难度在于处理隐藏在业务知识中的复杂度，模型就是对这种复杂度的简化与精练，DDD改进版还使用事件风暴方式挖掘业务知识，而像这种业务知识没有隐藏的简明型业务系统，我们已经把核心问题描述得很清楚，无需再去知识消化，事件风暴，为了DDD而DDD，所以建模价值不高，甚至毫无必要\nDDD应对在上面的申辩中，我们已经发现了并不是OO不行，而是使用OO方式不对，虽说要把OO原则深入骨髓，可有没有一种方法能直接上升一层次，就像我们在使用面向过程语言时，也要有面向对象思维，实践没那么容易，直接使用面向对象语言，会让我们更容易使用面向对象思维，领略OO精髓\nDDD正好就是这样一种方法，基于OO的升华，主要看看领域层的规范\n实体，充血的实体这一点与原生OO一样，数据与行为相结合\npublic class Player &#123;    private String name;    private long health;    private WeaponId weaponId;        public void equip(Weapon weapon) &#123;       // ...    &#125;&#125;\n\n\n任何实体的行为只能直接影响到本实体（和其子实体）\n因为 Weapon 是实体类，但是Weapon能独立存在，Player不是聚合根，所以Player只能保存WeaponId，而不能直接指向Weapon\n实体需要依赖其他服务时，也不能直接依赖，使用Double Dispatch\n\npublic class Player &#123;    public void equip(Weapon weapon, EquipmentService equipmentService) &#123;        if (equipmentService.canEquip(this, weapon)) &#123;            this.weaponId = weapon.getId();        &#125; else &#123;            throw new IllegalArgumentException(&quot;Cannot Equip: &quot; + weapon);        &#125;    &#125;&#125;\n\n领域服务(Domain Service)单对象这种领域对象主要面向的是单个实体对象的变更，但涉及到多个领域对象或外部依赖的一些规则\n跨对象领域服务当一个行为会直接修改多个实体时，不能再通过单一实体的方法作处理，而必须直接使用领域服务的方法来做操作。\n在这里，领域服务更多的起到了跨对象事务的作用，确保多个实体的变更之间是有一致性的\n不能学习实体的Double Dispatch\npublic class Player &#123;    void attack(Monster, CombatService) &#123;        CombatService.performAttack(this, Monster); // ❌，不要这么写，会导致副作用    &#125;&#125;\n\n这个原则也映射了“任何实体的行为只能直接影响到本实体（和其子实体）”的原则，即Player.attack会直接影响到Monster，但这个调用Monster又没有感知\n通用组件型像Movalbe、Runnable通用能力，提供组件化的行为，但本身又不直接绑死在一种实体类上\n策略对象（Domain Policy）Policy或者Strategy设计模式是一个通用的设计模式，但是在DDD架构中会经常出现，其核心就是封装领域规则。\n一个Policy是一个无状态的单例对象，通常需要至少2个方法：canApply 和 一个业务方法。其中，canApply方法用来判断一个Policy是否适用于当前的上下文，如果适用则调用方会去触发业务方法。通常，为了降低一个Policy的可测试性和复杂度，Policy不应该直接操作对象，而是通过返回计算后的值，在Domain Service里对对象进行操作。\n总结DDD是一种模型驱动设计方法，但使用DDD也并不是一定要按固定方式方法一步步执行，建模是为了对复杂问题的简化和精炼，挖掘隐藏的业务知识。\n如果能通过简明方式就能把业务核心问题描述清楚，比其他一切手段都有用，也都重要。那我们就没必要再去为了DDD而DDD，去进行事件风暴，知识消化慢迭代方式\n本文中虽然提取了一些DDD领域层规范直接升华OO，但你有没有注意到一个问题，Player如果拥有很多能力，比如Moveable,Runnable,Jumpable,Fireable，那这个实体如何实现？\n首先我们肯定会面向接口编程，提取出interface Moveable,interface Runnable,interface Jumpable,interface Fireable，可Player呢？\npublic class Player implements Moveable,Jumpable,Fireable &#123;    void move(int targetX, int targetY) &#123;        // logic    &#125;        void jump() &#123;        // logic    &#125;        void fire() &#123;        // logic    &#125;    &#125;\n可以想象，随着能力越来越强大，player类会越来越臃肿，发展成超大类，充满坏味道，可我们这次也没有违反什么原则？难道达到了原生面向对象的能力极限？\n如果你有好的想法，欢迎留言交流。如果你觉得文章有帮助，多转发，点击右下角『看一看』\n","tags":["DDD"]},{"title":"康威定律与逆康威定律","url":"/blog/conway-law-and-inverse-conway-law.html","content":"康威定律随着微服务架构兴起的步伐慢慢复苏，重新进入人们的视线，但他的威力远远不仅限于简单的指导如何拆分微服务，不管是整个团队的战力，还是架构方案能否顺利落地都起着重要的作用。\n康威定律先回顾一下什么是康威定律：1968年，计算机系统研究院的梅尔康威在Datamation杂志上发表了一篇论文How Do Committees Invent?\n这篇论文中有一句话被总结为康威定律：“设计系统的组织由于受到约束，这些设计往往是组织内部沟通结构的副本。”\n下面先通过一次切身经历来阐述定律如何发挥威力，以及如何通过逆康威定律得到我们想要的架构方案\n起初我带领一支团队负责一个业务，先称它为APP1，经过一段时间，老板找我谈话，说：“APP1在你的带领下，运行得不错，应该承担更大的责任，后面APP2团队也由你负责”。\n经过一段时间的迭代，APP2需要一个配置服务，支撑差异化运营\nAPP2架构师根据最新业务需求，提出了给APP2增加一个配置服务，对于APP2来讲，架构师都无需赘述，此架构方案无疑是合理的\n但从整体看APP1已经有配置服务\n\n此时就有了两个方案：\n\n按架构师规划，APP2构建新的配置服务\n增强APP1的配置服务，让它同时支撑APP1和APP2\n\n怎么决择呢？\n从架构角度，方案一似乎更有优势，独立，两个APP之间也不会相互干扰，原先的配置服务也无需改动，相对去改造一个旧系统，构建新系统负担还小一些\n但从组织结构讲，组织效能角度也更高效，大局出发，也不需要两个相似的配置服务，组织结构与架构结构也更有同态性\n\n此时，康威定律就发挥了至关重要的作用：“如果系统的架构和组织结构不一致，那么组织结构将成为赢家”\n\n当我在计划着进一步整合两个团队时，事情发生了变化，老板又找我谈话了，“经过这段时间，发现你带两个团队有些吃力，这样吧，以后你就只负责APP2团队”\n随着业务的继续开展，发现了个问题，当APP2团队需求需要变更配置服务时，为难了\nAPP1使用配置服务深度和广度都高于APP2，所以在划分时，配置服务归于APP1了，之前都是同一个大团队，资源协调很简单，内部沟通很容易\n此时怎么办？\n原先团队内部的沟通，需要跨团队沟通了，再简单的一次变更，都需要提前沟通，协调排期，制约了高效迭代交付能力\n所以APP2团队不得不剥离APP1的配置服务，另起炉灶，回到当初架构师的方案一\n这其实还是康威定律发挥着威力：组织内部的沟通路径（无论是否和正式汇报线一致）严重制约了组织所能设计的解决方案的类型\n逆康威定律这是ThoughtWorks技术总监James Lewis突发奇想地提出的，组织要根据他们想得到的软件架构来设计团队结构，而不是期望团队盲从一个被设计好的团队结构。\n其核心观点在于，将软件架构看作一个独立的概念，认为它可以被孤立设计，然后交由任何团队来实现，这从根本上就是错误的\n我们把上面的示例，顺序倒置过来，就是逆康威定律。\n我详细阐述下：\n刚开始，APP1和APP2是两个独立完整的团队，都有各自的配置服务，也就是\n\n虽然他们功能相似，但由于在两个团队里面，与组织结构和沟通路径都是匹配的\n从公司全局架构看，发现配置服务只需要一个就够了，推倒烟囱式架构，整合资源，配置服务中台化，这也是近些年各公司崇拜的中台文化\n怎么办呢？简单啊，提取共性，抽象整合呗。\n现实没那么轻松，如果两大APP团队，是支撑公司盈利的两大业务，营收压力也很大，基本上整合是句空话，看看有多少公司的BU都是各自为战，烟囱式系统一个比一个强悍，谁能动得了？\n此时怎么办？整合组织结构，让两个团队组合成更大的团队，拥有独立的架构团队，团队内部自己就会催生出整合的力量\n再看一个示例，假设有四个独立团队，每个都由前后端开发工程师组成，他们分别负责系统的不同部分，然后对DBA提出数据库变更请求。\n\n如果这四支团队独立的前端和后端开工程师推动了UI和应用层的前后端分离，而有一个共享的DBA团队，那么很可能会带来这样一个单一的共享数据库。\n因为康威定律的同态力会强烈地牵引软件架构“自然而然”地体现出当前的组织设计和沟通路径。\n当我们在使用微服务架构时，每个独立服务都需要有属于自己的数据存储。\n\n通过应用逆康威定律，可以在各个独立的客户端应用和API开发团队里面增加一名数据库开发人员，那架构结构自然就体现出来了。\n总结想想架构风格千千万万，为什么分层架构却是最流行的，也是最容易实践成功的，因为有独立的前端团队，后端团队，基础服务团队，对于业务数据流向，正好也是从UI发起，逻辑层处理，数据库存储，组织结构与架构结构是匹配的。这就是康威定律的威力。\n组织结构和团队间真实的沟通路径会直接影响所构建系统的架构。如果有四个小组合作开发一个编译器，那么你将得到一款具有四个步骤的编辑器。对于一家软件产品公司来说，组织结构预示着产品架构。\n过去很多组织结构调整的潜在目标都是为了减少员工或者围绕管理者和领导者的权势建立山头。可对于一家软件公司，势必慎重，必须要考虑架构，更可以应用逆康威定律：设计团队满足理想的软件架构\n简而言之，在设计软件架构或进行组织结构调整时，将康威定律纳入考虑因素之中，就能够受益于兼顾软件架构和团队设计的同态力。\n","tags":["管理","架构"]},{"title":"开发流程规范","url":"/blog/development-process-specification.html","content":"这是近期在公司做的一次分享，这几年的互联网开发，算比较幸运，团队一直践行完善这套规范，没有太多的阻碍，得益于公司整体氛围，以及团队对规范和写文档的不排斥，形成了良好的开发习惯\n在这次分享后，发现好些大V也在谈规范，写文档，估计是前段时间阿里又发布了开发手册(华山版)，借鉴于一下，对一些细节做些补充，整理出来\n整体流程\n这个流程整体分为三个大阶段：需求阶段，开发阶段，上线阶段\n需求阶段需求分析这个阶段主要是产品主导，收集痛点，归集需求，制定目标，与架构师讨论架构方案，与安全评估业务安全性\n这儿可根据需求大小，具体行事，比如有些需求涉及方比较多，可能需要多次分组开会，不管是可行性分析，还是讨论方案，不是一次就能完成的\n需求评审当产品已经确定好这些方面，开始输出PRD，与研发、测试一起评审需求\n研发与测试需要理解需求，更要挑战需求；\n挑战需求的目的不是砍需求，而是确认产品在需求分析阶段的工作完备程度，比如遗留数据处理，对当前系统的影响层面，是否与当前系统重复度过高，业务价值\n只有经过充分讨论，才能理解需求，完善需求，防止后期需求返工，某个细节没有考虑，影响整体设计实现\n这儿各个团队实践方式各不相同，比如有些是所有团队成员都要参与，而有些只有具体参与开发测试参与\n个人推崇所有成员都参与，这样一是讨论可以更充分，二是信息共享，防止因某成员个人原因，推迟需求进度\n需求排期对需求大家都达成了共识，此时就需要产品去需求确定优先级，排期开发\n确定开发周期，这儿也有很多具体做法，有些团队是TL根据需求难易程序，变动大小，结合具体开发人员直接给出时间；有些团队是具体开发自行评估时间\n一般都是由开发人员自行评估，只要在合理范围内，都给予认同\n当然在确定开发周期时，必须给出依据，依据来源于详细设计，对于详细设计文档具体形式后面再谈，至少开发人员知道需要增加多少接口，修改多少接口，大概逻辑；不然评估时长就是一个空谈，造成整个项目的失控\n开发阶段需求阶段，从产品需求分析到开发人员评估出开发周期就已经结束了；下一个阶段进入开发阶段\n开发阶段的进度，可以说八成是依赖第一阶段的成果。编码速度，实现手段只要是正常业务需求，一般都不会拖延时长\n第一阶段成果，对于开发人员来讲，就是详细设计文档，文档中有了相应流程图，伪代码，具体涉及接口也有了，此时就是一个代码翻译过程\n此阶段测试，需要输出测试用例，进行冒烟，回归测试；\n自动化脚本完善\n上线阶段测试完成之后，就准备上线了。\n根据确定的上线日期，提前核对checklist\n对一些需要提前的变更开始申请审批流程\n配合监控系统，需要对一些业务监控项进行配置\n产品开始对预发布环境进行验收，验收成功后；发布正式环境\n上线收尾收尾工作，这个阶段，还有大量工作需要去做\n\n产品对需求进行总结，收集数据，分析效果，为下一期需求做准备\n开发需要对代码进行整理，比如有些是为了灰度而生的无用代码可以删除\n\n\n一个完整的需求开发流程到此结束，当然这只是理想状态，还有很多不可预测问题，当然你也会吐槽，这是典型的瀑布开发模型，在敏捷大行其道时，是不是太守旧，太迟钝，都2091年了，为什么还在玩这一套\n理想是丰满的，现实是骨感的。好比敏捷开发的参与者是一群开发经验丰富和才华横溢的开发人员，而这样的团队有多少？强硬为了敏捷而敏捷会不会造成项目的不可控呢？\n当然瀑布模型也有天生的缺点：每个阶段的严格性，缺乏灵活性，而现实需求却是经常变化的\n所以单纯地选择哪个模型是不可取的，只能根据实际情况出发，为业务提供最大化服务\n\n细则规范很多人都在要规范，但好像从没思考过为什么需要规范？\n\n《阿里巴巴java开发手册》：手册的愿景是码出高效，码出质量\n\n\n现代软件架构的复杂性需要协同开发完成，如何高效地协同呢？无规矩不成方圆，无规范难以协同，比如，制订交通法规表面上是要限制行车权，实际上是保障公众的人身安全，试想如果没有限速，没有红绿灯，谁还敢上路行驶？对软件来说，适当的规范和标准绝不是消灭代码内容的创造性、优雅性，而是限制过度个性化，以一种普遍认可的统一方式一起做事，提升协作效率，降低沟通成本。 代码的字里行间流淌的是软件系统的血液，质量的提升是尽可能少踩坑，杜绝踩重复的坑，切实提升系统稳定性，码出质量\n\n从上段可以看出几个目的\n\n高效协同，降低沟通成本；书同文，车同轨\n码出质量，降低故障率；\n工匠精神，追求卓越\n\n\n评审会议很多开发人员最怕开会，更要命的是很多会议是效率低下的。主要表现：\n\n在没有基本的认知共识就被拉去开会：这可能是主持者没有提前知会，同步资料；以及没有在线下达到一定共识就开会，结果会上各种讨论;也可能是参会人员本身也没有提前准备\n会后没有结论，或者结论不明确\n\n所以在参与评审后，需要有一份输出，文档或者邮件，主要包括以下内容\n\n评审日期与轮次\n业务需求的目的及价值描述\n参与人员及角色\n评审附件（PRD或邮件）\n评审结论\n评审遗留问题及跟进人\n\n需求PRD开发人员，最烦就是口头需求，一句话需求，需要明文禁止\n产品写PRD，其实是个基本职业素养，结果现在还要明文规定，也算是个悲哀。\n为什么要出PRD，其实不是开发人员故意为难产品，而是让产品深刻理解需求，看这又是个怪事，产品还有不理解业务需求的，但就是常有产品自己都不理解业务，还一本正经给研发提开发需求。\n写PRD的过程，就是梳理思考的过程，让需求更明确，流程更完整，细节更透彻，这样就不会出现提交给开发时，被开发一堆问题阻塞住。也可以防止在开发过程中，却发现整个业务没有形成闭环，造成返工，延时\n那么开发如何拒绝口头需求，一句话需求呢？\n有时产品比较强势，开发人员不好沟通，此时TL就应该对团队明确规定，禁止产品此类行为，也要禁止开发接受此类需求，不能为了一时快，而整个工期慢\n在接受到此类需求时，也需要一定的沟通技巧：\n\n多问几个为什么：这比如你这个需求背后的目的和价值是什么？做了之后有什么预期的收益，为什么这么做就可以达到这个收益，你可以不直接问业务方，但是你也需要问自己，业务方的这个目标和做这个需求的路径是否可以匹配得上，如果实现路径存在逻辑漏洞或者不是最佳的则这个需求也就没有做的必要性\n\n给出替代方案：经过上面的步骤，其实你会发现你已经过滤了一批无效的一句话需求，而有些需求可能是有一定的存在价值，但是可能业务方提到的点并不是有效的方案或者说成本太大的方案，这时你就需要思考替代方案，尽量通过现有方案或者小成本的方式来满足业务方，间接的达到“拒绝”的效果\n\n不能直接说不，但可以有条件的说是：当你确定这个需求是ok的，但你确实暂时抽不出时间来搞定这个事情的时候，这时关键在于我们不能直接拒绝业务方，长此以往会影响到后续的合作关系，这种情况你可以说，这个需求我接受，但是我可能需要较长一些的缓冲时间或者砍一些需求(部分满足)，又或者必须要按时上的话，不能保证项目的上线后的效果、质量等，让业务方来做部分的取舍\n\n\n详细设计文档首先禁止没有文档，直接修改代码；这跟需求PRD类似，强迫开发人员思考需求，完善需求，胸中有丘壑，下笔自有神；不能在编码过程，边写边思考，不仅慢，还会漏洞百出\n其实让团队写文档，也是个难事，推动很难，尤其管理者没有引起重视，就更难。这是个怪事，不喜欢写文档，却喜欢被返工，在开发过程因需求逻辑不完备而加班赶点，从上到下默认了这种怪事的正常化\n为什么要写设计文档？\n\n对自己，让自己在动手写代码之前，帮助自己想得更清楚；\n对项目，保证信息的一致性，保证项目的可控性，减少项目风险；\n对团队，确保知识的沉淀与传承；\n\n项目涉及多少个子系统，每个子系统涉及多少个模块，模块间的依赖关系如何，彼此要提供多少个接口，每个接口的参数如何，接口实现过程中上下游交互如何，核心逻辑用什么技术方案实现…\n难道相关技术人都一清二楚么？很多自信的技术大神，“以为”懂了，但却讲不明白，其实就是不懂。很多“讲得明白”，却“写不清楚”，其实就是没懂透。把一个项目，一个技术问题，按照逻辑，用文字来一遍，才表示真正的想清楚了\n这也是现在流行的，一解释都懂，一问都不知，一讨论就吵架\n\n不再写过多为什么要写文档了，一个习惯的改变不可能一下子就改变，这需要一个过程，也需要自我大胆尝试\n这儿给出一些实践，详细设计文档写些什么\n其实一份详细设计文档，整体分为两个部分：功能需求与非功能需求\n1、需求信息\n这儿包括需求背景，业务价值，预计上线时间，架构设计wiki,产品及开发负责人，涉及到的服务，上下游服务\n2、系统流程图\n阐述整体设计思路，涉及算法时，还需要详细算法思路\n包含上下游系统交互和数据流向，建议viso或者astash图，要保存原图文件以防后期维护修改\n当然最好还要把设计思路背景说明一下，有多种方案时也罗列一下，因为系统现有状况，进度安排，历史数据等等原因，而选择了当前方案，这样自我分析完整，也免将来别人接手时可以追溯 \n3、接口列表\n这儿列出所有涉及到的接口列表\n标明新增加或者修改，以及接口详细入参，返回值\n一般会有api doc，或者类似swagger工具，接口变化时，也可以相应变化；如果没有，那只能在文档中详细输出\n4、定时任务\n有些任务不需要，有些任务可能有很多，需要指出任务功能，频率\n5、存储变更\n比如缓存，数据结构，过期时间，预计数据增长\nDB表设计，表修改，索引信息，数据增长量；有新的业务场景，一定要请DBA帮忙评估索引或者其他信息\n6、配置组件\n配置：比如配置中心，增加修改配置项，常为了灰度增加一些开关之类\n组件：第三方依赖jar，不管是公司自研，还是外部开源；关注新特性给系统带来的变化；这个对开发工作量很小，只需要修改版本号，但测试可能需要一些回归量，尤其常出现的包冲突，造成日志不能正常输出\n7、非功能需求\n接口在日常和大促时的调用量评估，是否有降级方案，灰度方案，能不能重试，需不需要压测，这些都是围绕服务治理做预案\n这其实是个很大的模块，很多已经深入骨髓，变成常态，比如灰度，现在都是7*24小时在线服务的，前后版本的兼容必须考虑到\n总结当然这些并不是必须的，可以根据实际情况变通，有增有减；当然你也可能从不写文档，很多人喜欢看源码，而不看文档；其实这有些本末倒置，源码只是告诉你了how,而文档才解释了what,why\n架构师是很多码农的追求，架构师如何设计系统，如何让开发人员去实施呢？当然是文档，总不能直接给代码吧\n","tags":["规范"]},{"title":"常识四堆外内存","url":"/blog/common-sense-four-out-of-heap-memory.html","content":"\n常识系列,作为一名互联网门外汉的科普系列\n\n堆外内存除了在像netty开源框架中，在平常项目中使用的比较少，在现前的项目中，QPS要求高的系统中，堆外内存作为其中一级缓存是相当有成效的。所以来学习一下，文中主要涉及到这三分部内容\n\n\n堆外内存是什么？与堆内内存的区别\n怎么分配，与GC的影响\n开源框架使用\n\n\n这篇文章写到最后，发现还只是回答了开源框架OHC的Why not use ByteBuffer.allocateDirect()?\n概念堆内内存现在流行的还是使用分代管理方式\n\n之前写过相关文章GC及JVM参数\n在jvm参数中只要使用-Xms，-Xmx等参数就可以设置堆的大小和最大值\n堆外内存和堆内内存相对应，堆外内存就是把内存对象分配在Java虚拟机的堆以外的内存，这些内存直接受操作系统管理（而不是虚拟机）\n堆外内存有以下特点：\n\n对于大内存有良好的伸缩性\n对垃圾回收停顿的改善可以明显感觉到\n在进程间可以共享，减少虚拟机间的复制\n\n堆外内存分配与回收其实堆外内存一直在使用,却没有真正关注过。最常见的nio,Netty，里面大量使用了堆外内存\n这儿会涉及到很多知识点，一步步来，抽丝剥茧\nBuffer这儿回顾下io知识，java提供了两种io处理方式，一种是io，另一种是nio\nJava NIO和IO之间最大的区别是IO是面向流（Stream）的，NIO是面向块（buffer）的，所以，这意味着什么？\n面向流意味着从流中一次可以读取一个或多个字节，拿到读取的这些做什么你说了算，这里没有任何缓存（这里指的是使用流没有任何缓存，接收或者发送的数据是缓存到操作系统中的，流就像一根水管从操作系统的缓存中读取数据）而且只能顺序从流中读取数据，如果需要跳过一些字节或者再读取已经读过的字节，你必须将从流中读取的数据先缓存起来。面向块的处理方式有些不同，数据是先被 读&#x2F;写到buffer中的，根据需要你可以控制读取什么位置的数据。这在处理的过程中给用户多了一些灵活性，然而，你需要额外做的工作是检查你需要的数据是否已经全部到了buffer中，你还需要保证当有更多的数据进入buffer中时，buffer中未处理的数据不会被覆盖\n对于stream流来讲，一个一个字节处理效率太差了，所以还提供了带buffer的bufferedStream\n对就到api，就是\nread()read(byte b[])write()write(byte b[])\n\nnio是面向buffer的，所以有专门抽象了Buffer\n\nzero copy虽然通过调节buffer的大小，使用bufferedstream可以提升性能，但还不够\n还可以通过Zero-Copy大大提高了应用程序的性能，并且减少了kernel和user模式上下文的切换\n这儿需要再深入底层机制，来看系统内核与应用程序的交互过程\nlinux科普这儿再回顾一下linux相关知识点\n\n\n内核态：控制计算机的硬件资源，并提供上层应用程序运行的环境。比如socket I&#x2F;0操作或者文件的读写操作等\n用户态：上层应用程序的活动空间，应用程序的执行必须依托于内核提供的资源。\n系统调用：为了使上层应用能够访问到这些资源，内核为上层应用提供访问的接口。\n\n\n因此我们可以得知当我们通过JNI调用的native方法实际上就是从用户态切换到了内核态的一种方式。并且通过该系统调用使用操作系统所提供的功能。\nQ：为什么需要用户进程(位于用户态中)要通过系统调用(Java中即使JNI)来调用内核态中的资源，或者说调用操作系统的服务了？A：intel cpu提供Ring0-Ring3四种级别的运行模式，Ring0级别最高，Ring3最低。Linux使用了Ring3级别运行用户态，Ring0作为内核态。Ring3状态不能访问Ring0的地址空间，包括代码和数据。因此用户态是没有权限去操作内核态的资源的，它只能通过系统调用外完成用户态到内核态的切换，然后在完成相关操作后再有内核态切换回用户态。\n鉴于linux系统的特性，IO之流程就如下图\n\ncopy过程大部分web服务器都要处理大量的静态内容，而其中大部分都是从磁盘文件中读取数据然后写到socket中。这种操作对cpu的消耗是比较小的，但也是十分低效的：内核首先从磁盘文件读取数据，然后从内核空间将数据传到用户空间，应用程序又将数据从用户空间返回到内核空间然后传输给socket(如果好奇数据为何如此来回传输，请继续看下文)。实际上，应用程序就相当于是个低效的中间者，从磁盘拿数据放到socket。\nread&#x2F;write模式代码抽象：\nread(file, tmp_buf, len);write(socket, tmp_buf, len);\n\n首先调用read将静态内容，这里假设为文件A，读取到tmp_buf, 然后调用write将tmp_buf写入到socket中\n\n1、当调用 read 系统调用时，通过 DMA（Direct Memory Access）将数据 copy 到内核模式\n2、然后由 CPU 控制将内核模式数据 copy 到用户模式下的 buffer 中\n3、read 调用完成后，write 调用首先将用户模式下 buffer 中的数据 copy 到内核模式下的 socket buffer 中\n4、最后通过 DMA copy 将内核模式下的 socket buffer 中的数据 copy 到网卡设备中传送。\n从上面的过程可以看出，数据白白从内核模式到用户模式走了一圈，浪费了两次 copy(第一次，从kernel模式拷贝到user模式；第二次从user模式再拷贝回kernel模式，即上面4次过程的第2和3步骤。)，而这两次 copy 都是 CPU copy，即占用CPU资源\nsendfile模式\n通过 sendfile 传送文件只需要一次系统调用，当调用 sendfile 时：\n1、首先通过 DMA copy 将数据从磁盘读取到 kernel buffer 中\n2、然后通过 CPU copy 将数据从 kernel buffer copy 到 sokcet buffer 中\n3、最终通过 DMA copy 将 socket buffer 中数据 copy 到网卡 buffer 中发送\nsendfile 与 read&#x2F;write 方式相比，少了 一次模式切换一次 CPU copy。但是从上述过程中也可以发现从 kernel buffer 中将数据 copy 到socket buffer 是没必要的。\nsendfile模式改进Linux2.4 内核对 sendfile 做了改进，下图所示\n\n改进后的处理过程如下：\n1、DMA copy 将磁盘数据 copy 到 kernel buffer 中\n2、向 socket buffer 中追加当前要发送的数据在 kernel buffer 中的位置和偏移量\n3、DMA gather copy 根据 socket buffer 中的位置和偏移量直接将 kernel buffer 中的数据 copy 到网卡上。\n经过上述过程，数据只经过了 2 次 copy 就从磁盘传送出去了。（事实上这个 Zero copy 是针对内核来讲的，数据在内核模式下是 Zero－copy 的）。\n当前许多高性能 http server 都引入了 sendfile 机制，如 nginx，lighttpd 等。\njava zero copyZero-Copy技术省去了将操作系统的read buffer拷贝到程序的buffer，以及从程序buffer拷贝到socket buffer的步骤，直接将read buffer拷贝到socket buffer. Java NIO中的FileChannal.transferTo()方法就是这样的实现\npublic void transferTo(long position,long count,WritableByteChannel target);\ntransferTo()方法将数据从一个channel传输到另一个可写的channel上，其内部实现依赖于操作系统对zero copy技术的支持。在unix操作系统和各种linux的发型版本中，这种功能最终是通过sendfile()系统调用实现。下边就是这个方法的定义：\n#include &lt;sys/socket.h&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);\n可以通过调用transferTo()方法来替代上边的File.read()、Socket.send()\n通过transferTo实现数据传输的路径：\n\n展示了内核态、用户态的切换情况:\n\n使用transferTo()方式所经历的步骤：\n1、transferTo调用会引起DMA将文件内容复制到读缓冲区(内核空间的缓冲区)，然后数据从这个缓冲区复制到另一个与socket输出相关的内核缓冲区中。\n2、第三次数据复制就是DMA把socket关联的缓冲区中的数据复制到协议引擎上发送到网络上。\n这次改善，我们是通过将内核、用户态切换的次数从四次减少到两次，将数据的复制次数从四次减少到三次(只有一次用到cpu资源)。但这并没有达到我们零复制的目标。如果底层网络适配器支持收集操作的话，我们可以进一步减少内核对数据的复制次数。\n在内核为2.4或者以上版本的linux系统上，socket缓冲区描述符将被用来满足这个需求。这个方式不仅减少了内核用户态间的切换，而且也省去了那次需要cpu参与的复制过程。从用户角度来看依旧是调用transferTo()方法，但是其本质发生了变化：\n1、调用transferTo方法后数据被DMA从文件复制到了内核的一个缓冲区中。\n2、数据不再被复制到socket关联的缓冲区中了，仅仅是将一个描述符（包含了数据的位置和长度等信息）追加到socket关联的缓冲区中。DMA直接将内核中的缓冲区中的数据传输给协议引擎，消除了仅剩的一次需要cpu周期的数据复制。\n\nByteBuffer创建以上的知识点都是点缀，真正的主角上场了,看下java中是如何抽象上述理论的\nByteBuffer有两种分配buffer的方式：\n分配HeapByteBuffer\nByteBuffer buffer = ByteBuffer.allocate(int capacity);  \n\n分配DirectByteBuffer\nByteBuffer buffer = ByteBuffer.allocateDirect(int capacity);  \n两者的区别，JDK里面说得很清楚\n\nA byte buffer is either direct or non-direct. Given a direct byte buffer, the Java virtual machine will make a best effort to perform native I&#x2F;O operations directly upon it. That is, it will attempt to avoid copying the buffer’s content to (or from) an intermediate buffer before (or after) each invocation of one of the underlying operating system’s native I&#x2F;O operations.A direct byte buffer may be created by invoking the allocateDirect factory method of this class. The buffers returned by this method typically have somewhat higher allocation and deallocation costs than non-direct buffers. The contents of direct buffers may reside outside of the normal garbage-collected heap, and so their impact upon the memory footprint of an application might not be obvious. It is therefore recommended that direct buffers be allocated primarily for large, long-lived buffers that are subject to the underlying system’s native I&#x2F;O operations. In general it is best to allocate direct buffers only when they yield a measureable gain in program performance.A direct byte buffer may also be created by mapping a region of a file directly into memory. An implementation of the Java platform may optionally support the creation of direct byte buffers from native code via JNI. If an instance of one of these kinds of buffers refers to an inaccessible region of memory then an attempt to access that region will not change the buffer’s content and will cause an unspecified exception to be thrown either at the time of the access or at some later time. \n\n从文中大致可以看到DirectByteBuffer的特点如下：\n\n对于native IO operation，JVM会有最佳的性能效果(它不需要一个中间缓冲区，而是可以直接使用，避免了将buffer中的数据再复制到中间缓冲区)。\n由于DirectByteBuffer分配与native memory中，不在heap区，不会受到heap区的gc影响。（一般在old gen的full gc才会收集。）\n分配和释放需要更多的成本。\n\n从上可以总结DirectByteBuffer大致的应用场景如下（socket通信和大文件处理还是比较适用的）：\n\n频繁的native IO操作。\n系统的要求处理响应速度快和稳定，即高吞吐和低延迟。\nByteBuffer的生命周期长且容量需求较大，会占用较多的内存空间。\n\n看下代码，更直观一些\nHeapByteBuffer分配在堆上的，直接由Java虚拟机负责垃圾收集，你可以把它想象成一个字节数组的包装类\nclass HeapByteBuffer    extends ByteBuffer&#123;    HeapByteBuffer(int cap, int lim) &#123;            // package-private        super(-1, 0, lim, cap, new byte[cap], 0);        /*        hb = new byte[cap];        offset = 0;        */    &#125;&#125;    public abstract class ByteBuffer    extends Buffer    implements Comparable&lt;ByteBuffer&gt;&#123;    // These fields are declared here rather than in Heap-X-Buffer in order to    // reduce the number of virtual method invocations needed to access these    // values, which is especially costly when coding small buffers.    //    final byte[] hb;                  // Non-null only for heap buffers    final int offset;    boolean isReadOnly;                 // Valid only for heap buffers    // Creates a new buffer with the given mark, position, limit, capacity,    // backing array, and array offset    //    ByteBuffer(int mark, int pos, int lim, int cap,   // package-private                 byte[] hb, int offset)    &#123;        super(mark, pos, lim, cap);        this.hb = hb;        this.offset = offset;    &#125;\n\n\nDirectByteBuffer这个类就没有HeapByteBuffer简单了\nDirectByteBuffer结构\n\nDirectByteBuffer(int cap) &#123;                   // package-private        super(-1, 0, cap, cap);        boolean pa = VM.isDirectMemoryPageAligned();        int ps = Bits.pageSize();        long size = Math.max(1L, (long)cap + (pa ? ps : 0));        Bits.reserveMemory(size, cap);        long base = 0;        try &#123;            base = unsafe.allocateMemory(size);        &#125; catch (OutOfMemoryError x) &#123;            Bits.unreserveMemory(size, cap);            throw x;        &#125;        unsafe.setMemory(base, size, (byte) 0);        if (pa &amp;&amp; (base % ps != 0)) &#123;            // Round up to page boundary            address = base + ps - (base &amp; (ps - 1));        &#125; else &#123;            address = base;        &#125;        cleaner = Cleaner.create(this, new Deallocator(base, size, cap));        att = null;\nBits.reserveMemory(size, cap) 方法\nstatic void reserveMemory(long size, int cap) &#123;        synchronized (Bits.class) &#123;            if (!memoryLimitSet &amp;&amp; VM.isBooted()) &#123;                maxMemory = VM.maxDirectMemory();                memoryLimitSet = true;            &#125;            // -XX:MaxDirectMemorySize limits the total capacity rather than the            // actual memory usage, which will differ when buffers are page            // aligned.            if (cap &lt;= maxMemory - totalCapacity) &#123;                reservedMemory += size;                totalCapacity += cap;                count++;                return;            &#125;        &#125;        System.gc();        try &#123;            Thread.sleep(100);        &#125; catch (InterruptedException x) &#123;            // Restore interrupt status            Thread.currentThread().interrupt();        &#125;        synchronized (Bits.class) &#123;            if (totalCapacity + cap &gt; maxMemory)                throw new OutOfMemoryError(&quot;Direct buffer memory&quot;);            reservedMemory += size;            totalCapacity += cap;            count++;        &#125;    &#125;\n在DirectByteBuffer中，首先向Bits类申请额度，Bits类有一个全局的totalCapacity变量，记录着全部DirectByteBuffer的总大小，每次申请，都先看看是否超限,堆外内存的限额默认与堆内内存(由-Xmx 设定)相仿，可用 -XX:MaxDirectMemorySize 重新设定。\n如果不指定，该参数的默认值为Xmx的值减去1个Survior区的值。\n\n如设置启动参数-Xmx20M -Xmn10M -XX：SurvivorRatio&#x3D;8,那么申请20M-1M&#x3D;19M的DirectMemory\n\n如果已经超限，会主动执行Sytem.gc()，期待能主动回收一点堆外内存。\n\nSystem.gc()会触发一个full gc，当然前提是你没有显示的设置-XX:+DisableExplicitGC来禁用显式GC。并且你需要知道，调用System.gc()并不能够保证full gc马上就能被执行。\n\n\n所以在使用netty这类框架时，一定要注意JVM优化，如果DisableExplicitGC那就可能会OOM了\n\n然后休眠一百毫秒，看看totalCapacity降下来没有，如果内存还是不足，就抛出OOM异常。如果额度被批准，就调用大名鼎鼎的sun.misc.Unsafe去分配内存,返回内存基地址\n// Used only by direct buffers// NOTE: hoisted here for speed in JNI GetDirectBufferAddresslong address;\n这样我们后面通过JNI对这个堆外内存操作时都是通过这个address来实现的了。\nUnsafe的C++实现在此，标准的malloc。然后再调一次Unsafe把这段内存给清零。跑个题，Unsafe的名字是提醒大家这个类只给Sun自家用的\nJDK7开始，DirectByteBuffer分配内存时默认已不做分页对齐，不会再每次分配并清零实际需要＋分页大小(4k)的内存，这对性能应有较大提升，所以Oracle专门写在了Enhancements in Java I&#x2F;O里。\n最后，创建一个Cleaner，并把代表清理动作的Deallocator类绑定 – 降低Bits里的totalCapacity，并调用Unsafe调free去释放内存。Cleaner的触发机制后面再说。\nDirectByteBuffer中\nbyte _get(int i) &#123;                          // package-private        return unsafe.getByte(address + i);    &#125;void _put(int i, byte b) &#123;                  // package-private    unsafe.putByte(address + i, b);&#125;\n\n在前面我们说过，在linux中内核态的权限是最高的，那么在内核态的场景下，操作系统是可以访问任何一个内存区域的，所以操作系统是可以访问到Java堆的这个内存区域的。\nQ：那为什么操作系统不直接访问Java堆内的内存区域了？\nA：这是因为JNI方法访问的内存区域是一个已经确定了的内存区域地质，那么该内存地址指向的是Java堆内内存的话，那么如果在操作系统正在访问这个内存地址的时候，Java在这个时候进行了GC操作，而GC操作会涉及到数据的移动操作[GC经常会进行先标志在压缩的操作。即，将可回收的空间做标志，然后清空标志位置的内存，然后会进行一个压缩，压缩就会涉及到对象的移动，移动的目的是为了腾出一块更加完整、连续的内存空间，以容纳更大的新对象]，数据的移动会使JNI调用的数据错乱。所以JNI调用的内存是不能进行GC操作的，JNI不能直接访问Java堆内的内存区域\nQ：如上面所说，JNI不能直接访问Java堆内的内存区域，那该如何解决了？\nA：①堆内内存与堆外内存之间数据拷贝的方式(并且在将堆内内存拷贝到堆外内存的过程JVM会保证不会进行GC操作)：\n比如我们要完成一个从文件中读数据到堆内内存的操作，即FileChannelImpl.read(HeapByteBuffer)。这里实际上File I&#x2F;O会将数据读到堆外内存中，然后堆外内存再讲数据拷贝到堆内内存，这样我们就读到了文件中的内存。\npublic int read(ByteBuffer var1) throws IOException &#123;        this.ensureOpen();        if(!this.readable) &#123;            throw new NonReadableChannelException();        &#125; else &#123;            Object var2 = this.positionLock;            synchronized(this.positionLock) &#123;                int var3 = 0;                int var4 = -1;                try &#123;                    this.begin();                    var4 = this.threads.add();                    if(!this.isOpen()) &#123;                        byte var12 = 0;                        return var12;                    &#125; else &#123;                        do &#123;                            //关键点在这行                            var3 = IOUtil.read(this.fd, var1, -1L, this.nd);                        &#125; while(var3 == -3 &amp;&amp; this.isOpen());                        int var5 = IOStatus.normalize(var3);                        return var5;                    &#125;                &#125; finally &#123;                    this.threads.remove(var4);                    this.end(var3 &gt; 0);                    assert IOStatus.check(var3);                &#125;            &#125;        &#125;    &#125;\nIOUtil\nstatic int read(FileDescriptor var0, ByteBuffer var1, long var2, NativeDispatcher var4) throws IOException &#123;        if (var1.isReadOnly()) &#123;            throw new IllegalArgumentException(&quot;Read-only buffer&quot;);        &#125; else if (var1 instanceof DirectBuffer) &#123;            return readIntoNativeBuffer(var0, var1, var2, var4);        &#125; else &#123;            // 分配临时的堆外内存            ByteBuffer var5 = Util.getTemporaryDirectBuffer(var1.remaining());             int var7;            try &#123;                // File I/O 操作会将数据读入到堆外内存中                int var6 = readIntoNativeBuffer(var0, var5, var2, var4);                var5.flip();                if (var6 &gt; 0) &#123;                    // 将堆外内存的数据拷贝到堆内内存中                    var1.put(var5);                &#125;                 var7 = var6;            &#125; finally &#123;                // 里面会调用DirectBuffer.cleaner().clean()来释放临时的堆外内存                Util.offerFirstTemporaryDirectBuffer(var5);            &#125;             return var7;        &#125;    &#125;\n而写操作则反之，我们会将堆内内存的数据线写到对堆外内存中，然后操作系统会将堆外内存的数据写入到文件中。\n假设我们要从网络中读入一段数据，再把这段数据发送出去的话，采用Non-direct ByteBuffer的流程是这样的：\n\n网络 –&gt; 临时的Direct ByteBuffer –&gt; 应用 Non-direct ByteBuffer –&gt; 临时的Direct ByteBuffer –&gt; 网络\n\n② 直接使用堆外内存，如DirectByteBuffer：\n这种方式是直接在堆外分配一个内存(即，native memory)来存储数据，程序通过JNI直接将数据读&#x2F;写到堆外内存中。因为数据直接写入到了堆外内存中，所以这种方式就不会再在JVM管控的堆内再分配内存来存储数据了，也就不存在堆内内存和堆外内存数据拷贝的操作了。这样在进行I&#x2F;O操作时，只需要将这个堆外内存地址传给JNI的I&#x2F;O的函数就好了。\n采用Direct ByteBuffer的流程是这样的：\n\n网络 –&gt; 应用 Direct ByteBuffer –&gt; 网络\n\n可以看到，除开构造和析构临时Direct ByteBuffer的时间外，起码还能节约两次内存拷贝的时间。那么是否在任何情况下都采用Direct Buffer呢？\n不是。对于大部分应用而言，两次内存拷贝的时间几乎可以忽略不计，而构造和析构DirectBuffer的时间却相对较长。在JVM的实现当中，某些方法会缓存一部分临时Direct ByteBuffer，意味着如果采用Direct ByteBuffer仅仅能节约掉两次内存拷贝的时间，而无法节约构造和析构的时间。就用Sun的实现来说，write(ByteBuffer)和read(ByteBuffer)方法都会缓存临时Direct ByteBuffer，而write(ByteBuffer[])和read(ByteBuffer[])每次都生成新的临时Direct ByteBuffer。\n根据这些区别，如下的建议：\n\n如果你做中小规模的应用（在这里，应用大小是按照使用ByteBuffer的次数和规模来做划分的），而且并不在乎这该死的细节问题，请选择Non-direct ByteBuffer\n如果采用Direct ByteBuffer后性能并没有出现你所期待的变化，请选择Non-direct ByteBuffer\n如果没有Direct ByteBuffer Pool，尽量不要使用Direct ByteBuffer\n除非你确定该ByteBuffer会长时间存在，并且和外界有频繁交互，可采用Direct ByteBuffer\n如果采用Non-direct ByteBuffer，那么采用非聚集(gather)的write&#x2F;read(ByteBuffer)效果反而可能超出聚集的write&#x2F;read(ByteBuffer[])，因为聚集的write&#x2F;read的临时Direct ByteBuffer是非缓存的\n\n基本上，采用Non-direct ByteBuffer总是对的！因为内存拷贝需要的开销对大部分应用而言都可以忽略不计。\nByteBuffer回收HeapByteBuffer就不要说了，GC就帮忙处理了。这儿主要说下DirectByteBuffer\n基于GC回收DirectByteBuffer存在于堆内的DirectByteBuffer对象很小，只存着基地址和大小等几个属性，和一个Cleaner，但它代表着后面所分配的一大段内存，是所谓的冰山对象。\n在内存中基本是这样子其中first是Cleaner类的静态变量，Cleaner对象在初始化时会被添加到Clener链表中，和first形成引用关系，ReferenceQueue是用来保存需要回收的Cleaner对象。\n如果该DirectByteBuffer对象在一次GC中被回收了此时，只有Cleaner对象唯一保存了堆外内存的数据（开始地址、大小和容量），在下一次Full GC时，把该Cleaner对象放入到ReferenceQueue中，并触发clean方法。\n快速回顾一下堆内的GC机制，当新生代满了，就会发生young gc；如果此时对象还没失效，就不会被回收；撑过几次young gc后，对象被迁移到老生代；当老生代也满了，就会发生full gc。\n这里可以看到一种尴尬的情况，因为DirectByteBuffer本身的个头很小，只要熬过了young gc，即使已经失效了也能在老生代里舒服的呆着，不容易把老生代撑爆触发full gc，如果没有别的大块头进入老生代触发full gc，就一直在那耗着，占着一大片堆外内存不释放。\n这时，就只能靠前面提到的申请额度超限时触发的system.gc()来救场了。但这道最后的保险其实也不很好，首先它会中断整个进程，然后它让当前线程睡了整整一百毫秒，而且如果gc没在一百毫秒内完成，它仍然会无情的抛出OOM异常。还有，万一，万一大家迷信某个调优指南设置了-DisableExplicitGC禁止了system.gc()，那就不好玩了。\n所以，堆外内存还是自己主动点回收更好，比如Netty就是这么做的\n主动回收DirectByteBuffer对于Sun的JDK这其实很简单，只要从DirectByteBuffer里取出那个sun.misc.Cleaner，然后调用它的clean()就行。\nByteBuffer byteBuffer = ByteBuffer.allocateDirect(1024 * 1024 * 500);((DirectBuffer)byteBuffer).cleaner().clean();\n\n前面说的，clean()执行时实际调用的是被绑定的Deallocator类，这个类可被重复执行，释放过了就不再释放。所以GC时再被动执行一次clean()也没所谓。\n在Netty里，因为不确定跑在Sun的JDK里(比如安卓)，所以多废了些功夫来确定Cleaner的存在\nCleaner类public class Cleaner extends PhantomReference&lt;Object&gt; &#123;    private static final ReferenceQueue&lt;Object&gt; dummyQueue = new ReferenceQueue();    private static Cleaner first = null;    private Cleaner next = null;    private Cleaner prev = null;    private final Runnable thunk;    \nPhantomReference 这个虚引用类很少见，它是java中最弱的引用类型\n\nPhantomReference 类只能用于跟踪对被引用对象即将进行的收集。\n\n\n同样，它还能用于执行 pre-mortem 清除操作。 PhantomReference 必须与 ReferenceQueue 类一起使用。需要 ReferenceQueue 是因为它能够充当通知机制。当垃圾收集器确定了某个对象是虚可及对象时， PhantomReference 对象就被放在它的 ReferenceQueue 上。将 PhantomReference 对象放在 ReferenceQueue 上也就是一个通知，表明 PhantomReference 对象引用的对象已经结束，可供收集了。这使您能够刚好在对象占用的内存被回收之前采取行动。\n\n当GC时发现它除了PhantomReference外已不可达（持有它的DirectByteBuffer失效了），就会把它放进 Reference类pending list静态变量里。然后另有一条ReferenceHandler线程，名字叫 “Reference Handler”的，关注着这个pending list，如果看到有对象类型是Cleaner，就会执行它的clean()，其他类型就放入应用构造Reference时传入的ReferenceQueue中，这样应用的代码可以从Queue里拖出这些理论上已死的对象，做爱做的事情——这是一种比finalizer更轻量更好的机制。\n比如创建DirectByteBuffer，会新建Cleaner对象，该对象添加到Cleaner链表中。对象被GC，如果是Cleaner对象，则会执行该对象的clean方法,Clean方法会将对应的cleaner对象从链表中移除，同时会回收DirectByteBuffer申请的资源\n看下ReferenceHandler源码:\n/* High-priority thread to enqueue pending References     */    private static class ReferenceHandler extends Thread &#123;        ReferenceHandler(ThreadGroup g, String name) &#123;            super(g, name);        &#125;        public void run() &#123;            for (;;) &#123;                Reference&lt;Object&gt; r;                synchronized (lock) &#123;                    if (pending != null) &#123;                        r = pending;                        pending = r.discovered;                        r.discovered = null;                    &#125; else &#123;                        // The waiting on the lock may cause an OOME because it may try to allocate                        // exception objects, so also catch OOME here to avoid silent exit of the                        // reference handler thread.                        //                        // Explicitly define the order of the two exceptions we catch here                        // when waiting for the lock.                        //                        // We do not want to try to potentially load the InterruptedException class                        // (which would be done if this was its first use, and InterruptedException                        // were checked first) in this situation.                        //                        // This may lead to the VM not ever trying to load the InterruptedException                        // class again.                        try &#123;                            try &#123;                                lock.wait();                            &#125; catch (OutOfMemoryError x) &#123; &#125;                        &#125; catch (InterruptedException x) &#123; &#125;                        continue;                    &#125;                &#125;                // Fast path for cleaners                if (r instanceof Cleaner) &#123;                    ((Cleaner)r).clean();                    continue;                &#125;                ReferenceQueue&lt;Object&gt; q = r.queue;                if (q != ReferenceQueue.NULL) q.enqueue(r);            &#125;        &#125;    &#125;\n\n回顾下Finalize回收\nsun不推荐实现finalize，实际上JDK内部很多类都实现了finalize。\n\n如果对象实现了finalize，在对象初始化后,会封装成Finalizer对象添加到 Finalizer链表中。\n对象被GC时，如果是Finalizer对象，会将对象赋值到pending对象。Reference Handler线程会将pending对象push到queue中。\nFinalizer线程poll到对象，先删除掉Finalizer链表中对应的对象，然后再执行对象的finalize方法(一般为资源的销毁)\n方案的缺点：\n\n对象至少跨越2个GC，垃圾对象无法及时被GC掉，并且存在多次拷贝。影响YGC和FGC\nFinalizer线程优先级较低，会导致finalize方法延迟执行\n\n开源堆外缓存框架\nEhcache 3.0：3.0基于其商业公司一个非开源的堆外组件的实现。\nChronical Map：OpenHFT包括很多类库，使用这些类库很少产生垃圾，并且应用程序使用这些类库后也很少发生Minor GC。类库主要包括：Chronicle Map，Chronicle Queue等等。\nOHC：来源于Cassandra 3.0， Apache v2。\nIgnite: 一个规模宏大的内存计算框架，属于Apache项目。\n\nOHCDirectByteBuffer是使用unsafe(JNI)申请堆外空间(unsafe.allocateMemory(size))。还有一种申请堆外空间的手段：JNA。\nJNA的描述(https://github.com/java-native-access/jna)\nJNA provides Java programs easy access to native shared libraries without writing anything but Java code - no JNI or native code is required\n堆外缓存OHC便是使用JNA来申请堆外空间。\n线下测试：JNA内存申请的性能是unsafe（JNI）的2倍。\nWhy not use ByteBuffer.allocateDirect()?\nTL;DR allocating off-heap memory directly and bypassing ByteBuffer.allocateDirect is very gentle to the GC and we have explicit control over memory allocation and, more importantly, free. The stock implementation in Java frees off-heap memory during a garbage collection - also: if no more off-heap memory is available, it likely triggers a Full-GC, which is problematic if multiple threads run into that situation concurrently since it means lots of Full-GCs sequentially. Further, the stock implementation uses a global, synchronized linked list to track off-heap memory allocations.\n\n\nThis is why OHC allocates off-heap memory directly and recommends to preload jemalloc on Linux systems to improve memory managment performance.\n\n这是OHC的wiki说明\n其实OHC实现了JNI(malloc),JNA(jemalloc)两种方式，默认使用了JNA(jemalloc),性能的提升最关键的是malloc与jemalloc的区别了\n\n在org.caffinitas.ohc.chunked.Uns类中，创建IAllocator类片段代码\nprivate static final String __ALLOCATOR = System.getProperty(OHCacheBuilder.SYSTEM_PROPERTY_PREFIX + &quot;allocator&quot;);IAllocator alloc;            String allocType = __ALLOCATOR != null ? __ALLOCATOR : &quot;jna&quot;;            switch (allocType)            &#123;                case &quot;unsafe&quot;:                    alloc = new UnsafeAllocator();                    LOGGER.info(&quot;OHC using sun.misc.Unsafe memory allocation&quot;);                    break;                case &quot;jna&quot;:                default:                    alloc = new JNANativeAllocator();                    LOGGER.info(&quot;OHC using JNA OS native malloc/free&quot;);            &#125;            allocator = alloc;        &#125;\n\nUnsafeAllocator\nField field = sun.misc.Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);field.setAccessible(true);unsafe = (sun.misc.Unsafe) field.get(null);                        public long allocate(long size)    &#123;        try        &#123;            return unsafe.allocateMemory(size);        &#125;        catch (OutOfMemoryError oom)        &#123;            return 0L;        &#125;    &#125;\n\nJNANativeAllocator\npublic long allocate(long size)    &#123;        try        &#123;            return Native.malloc(size);        &#125;        catch (OutOfMemoryError oom)        &#123;            return 0L;        &#125;    &#125;\n\n其它OHC这只是一个开端，只是分配内存部分，它还有淘汰策略等等，之后说缓存时，再谈了\n参考资料Netty之Java堆外内存扫盲贴\n千丝万缕的FGC与Buffer pool\nJVM源码分析之堆外内存完全解读\nJVM源码分析之FinalReference完全解读\n","tags":["cache"]},{"title":"微服务-熔断机制","url":"/blog/microservice---circuit-breaker-mechanism.html","content":"背景由于微服务间通过RPC来进行数据交换，所以我们可以做一个假设：在IO型服务中，假设服务A依赖服务B和服务C，而B服务和C服务有可能继续依赖其他的服务，继续下去会使得调用链路过长，技术上称1-&gt;N扇出\n\n问题如果在A的链路上某个或几个被调用的子服务不可用或延迟较高，则会导致调用A服务的请求被堵住，堵住的请求会消耗占用掉系统的线程、io等资源，当该类请求越来越多，占用的计算机资源越来越多的时候，会导致系统瓶颈出现，造成其他的请求同样不可用，最终导致业务系统崩溃\n\n服务器失败影响服务质量\n超负荷导致整个服务失败\n服务失败造成的雪崩效应\n\n\n\n\n熔断熔断模式：这种模式主要是参考电路熔断，如果一条线路电压过高，保险丝会熔断，防止火灾。放到我们的系统中，如果某个目标服务调用慢或者有大量超时，此时，熔断该服务的调用，对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。\n定义里面有几个量化的地方\n\n目标服务调用慢或者超时：开启熔断的阀值量化\n\n可以通过两个维度：时间与请求数\n时间多长时间内的超时请求达到多少，触发熔断\n请求数从服务启动，超时请求数达到多少，触发\n这两个维度都需要记录超时请求数和统计总请求数\n\n情况好转，恢复调用\n\n如何量化情况好转：多长时间之后超时请求数低于多少关闭熔断\n熔断状态\n三种状态的切换\n开 – 半开 – 关\n开：使用快速失败返回，调用链结束\n半开：当熔断开启一段时间后，尝试阶段\n关：调用正常\n实现机制可以使用一段伪代码表示：\n//正常requestif( request is open) &#123;    //fastfail&#125; else if( request is halfopen) &#123;    if ( request success count &gt; recoverySampleVolume) &#123;        //state --&gt; close    &#125;&#125; //失败requestif( request is failcount &gt; requestVolumeThreshold &amp;&amp; errorPercentage &gt; threshold) &#123;    //close --&gt; open&#125;\n请求熔断开启时，直接快速失败\n是halfopen状态，如果成功处理次数是否大于恢复配置，就关闭熔断\n如果失败次数超过阀值，开启熔断\n而对于open–&gt;halfopen的转换，可以通过定时器主动触发\n具体实现现在有很多开源的\nfailsafe:https://github.com/jhalterman/failsafe\nHystrix\n个案实现在没有熔断时，请求链路：\nclient –&gt; request –&gt; balance – &gt; handler\n一个请求过来，通过负载均衡找到具体的server,再执行\n加入熔断后：\nclient –&gt; request –&gt; circuitBreakerfilter –&gt; balance – &gt; handler\nCircuitBreakerFilter过滤掉被熔断的server,在负载均衡时，不再被选中\n\ngetAllServers() 获取所有服务器列表\n根据requestService,requestMethod获取熔断的servers\n从allserverList中剔除这些server\n\n\n\n熔断服务列表怎么维护呢？\n正常状态 –&gt; 熔断状态1. 收到失败请求(e.g.超时，系统异常)2. 判断此service是否配置了熔断策略 map&lt;serviceName,circuitBreakerpolicy&gt;    - 根据serviceName,method,serverInfo获取CircuitBreakerCounter    - counter对失败次数+1    - 此server是否在half open状态  HalfOpenServersMap&lt;serverName+method,serverList&gt;        - 在：如果失败次数超过RecoverySampleVolume，openserversmap&lt;servername+method,serverlist&gt;进行put操作、并从HalfOpenServersMap中remove        - 不在：请求数大于等于10笔(requestVolumeThreshold)，且错误率达到60%(errorPercentage),openserversmap&lt;servername+method,serverlist&gt;进行put操作\n熔断状态 –&gt; 正常状态1. 收到请求2. 判断此service是否配置了熔断策略 map&lt;serviceName,circuitBreakerpolicy&gt;    - 根据serviceName,method,serverInfo获取CircuitBreakerCounter    - counter调用次数+1    - 若half-open 状态下的服务instance被调用次数超过取样的sample数,从HalfOpenServersMap中remove\n\n疑问\n错误率怎么计算？\ncounter的实现\n上面是close与open的转换，怎么转换到halfopen？\n\n错误率&#x3D; 错误次数&#x2F;请求次数\nhalfopen状态\n在上面的提到，被熔断的服务，如果情况好转就会关闭熔断！“情况好转”：什么时候去判断情况好转，怎么判断情况好转两方面\n\n在加入到openserversmap时，同时开启延迟时间窗口后的定时任务\n从openserversmap中移除，加入到halfOpenServersMap\n\n\n\ncounter实现\n\n简单点：AtomicLong，如当是halfopen时，使用这种简单的计数器叠加\n滑动时间窗口实现\n\nVS 降级提到熔断，不得不起一下降级。两者的区别\n有时语言真是乏力，不容易表达清楚，罗列一下\n熔断是框架提供，不管业务什么样，防止系统雪崩，都需要提供一下基本功能；而降级与业务有关，自动或手动。比如支付，有很多种支付方式，储蓄卡，信用卡，支付宝，微信。若发现某一支付通道不稳定，或压力过大，手动先关闭，这就是一种降级\n由此可看出：\n\n触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；\n管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始）\n实现方式不一样\n\n参考微服务熔断与隔离\nCircuitBreaker\n","tags":["微服务"]},{"title":"微服务-监控","url":"/blog/microservices---monitoring.html","content":"前言这篇其实本来也打算放在《常识》系列中的，介绍一下分布式日志追踪系统，这在互联网界理论，技术，产品已经很成熟，国内外各大厂都有自己成熟的产品。是个不错的互联网门外汉科普知识点\n微服务，已经火了多年，也已经落地实施。对服务的监控需求顺理成章。监控系统的本质其实也就是分布式日志追踪系统。就归类到《微服务》系列中吧\n本篇大体内容\n\n《微服务设计》第八章监控\n监控理念Dapper\n流行监控框架架构\naspectj\n\n《微服务》之监控本来是说，要写个读书笔记的，但没有那么多完整的时间，正好学习监控，就把书拿出来，一并读了。理论结合实践，效果更好。\n监控模型三种监控模型\n\n单一服务，单一服务器\n单一服务，多个服务器\n多个服务，多个服务器\n\n单一服务单一服务器\n主机状态\n\nCPU、内存等，可以使用监控软件Nagios,Zabbix或者像New Relic这样的托管服务来帮助监控主机\n\n服务状态\n\n直接查看服务应用日志，或者web容器日志\n单一服务多个服务器\n主机状态\n\n这种情况稍微复杂了一点，如前所述，如果我们想监控CPU，当CPU占用率过高时，如果这个问题发生在所有的服务器上，有可能是微服务本身的问题，但如果只发生在一台，则有可能是主机本身的问题。\n我们需要关注每台服务器的日志数据，我们既想把数据聚合起来，又想深入分析每台主机，Nagios允许以这样的方式组织我们的主机。\n\n服务状态\n\n如果只有几个主机，可以用像ssh-multiplexers这样的工具，在多个主机上运行相同的命令。用一个大显示屏，运行grep “Error” app.log来定位错误。对于响应时间，可以在负载均衡器中跟踪，负载均衡器本身也需要跟踪。\n多个服务多个服务器这个情况就更复杂了，我们如何在多个主机上，成千上万行的日志中定位错误的原因？如果确定是一个服务器异常，还是一个系统性的问题？如何在多个主机跟踪一个错误的调用链，找出引起错误的原因？\n答案是：从日志到应用程序指标，集中收集和聚合更可能多的数据\n日志，更多的日志需要将日志能够集中到一起方便使用\n可以使用ELK\nELK由Elasticsearch、Logstash和Kibana三部分组件组成；\nElasticsearch是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。\nLogstash是一个完全开源的工具，它可以对你的日志进行收集、分析，并将其存储供以后使用\nkibana 是一个开源和免费的工具，它可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助您汇总、分析和搜索重要数据日志\n\n监控指标系统指标：比如cpu 内存等，这些可以collectd进行收集\n服务指标：比如接口调用次数，线程池空闲线程数等\n语义指标：类似业务指标，比如订单量，活动用户数等\n关联标识\n其实这就是服务追踪，调用链监控\n因为微服务化后，各种系统之间的调用关系很复杂，因此排查一个问题会比较难受，你不需要一个系统一个系统去找问题。所以服务追踪就变得非常关键。他能够追踪一次会话的所有调用，哪里有了问题，一目了然\n这个更详细的后面介绍google的dapper\n其它标准化：将监控api标准化。考虑受众：谁看？运营还是开发？更加实时：监控应该具有实时性，出问题第一时间反应。避免级联危险：可以使用hystrix。\n小结对每个服务：跟踪请求响应时间、错误率和应用程序级指标；跟踪所有下游服务的健康状态，如调用时间、错误率；标准化如何收集和存储指标；以标准格式讲日志记录到一个标准位置；监控底层操作系统。\n对系统：聚合CPU等主机层级的指标和程序级指标；确保指标存储工具可以在系统和服务级别做聚合，也能查看单台主机信息；指标存储工具允许维护数据足够长时间，以了解趋势；使用单个可查询工具对日志进行聚合和存储；强烈考虑标准化关联标识的使用；了解什么样的情况需要行动，并构造警报和仪表盘；调查对各种指标聚合和统一化的可能性。\nGoogle Dapper\n分布式服务的跟踪系统需要记录在一次特定的请求后系统中完成的所有工作的信息。举个例子，图展现的是一个和5台服务器相关的一个服务，包括：前端（A），两个中间层（B和C），以及两个后端（D和E）。当一个用户（这个用例的发起人）发起一个请求时，首先到达前端，然后发送两个RPC到服务器B和C。B会马上做出反应，但是C需要和后端的D和E交互之后再返还给A，由A来响应最初的请求。对于这样一个请求，简单实用的分布式跟踪的实现，就是为服务器上每一次你发送和接收动作来收集跟踪标识符(message identifiers)和时间戳(timestamped events)。\ngoogle dapper译文：http://bigbully.github.io/Dapper-translation/\nDapper有三个设计目标：\n\n低消耗：跟踪系统对在线服务的影响应该做到足够小。\n\n应用级的透明：对于应用的程序员来说，是不需要知道有跟踪系统这回事的。如果一个跟踪系统想生效，就必须需要依赖应用的开发者主动配合，那么这个跟踪系统显然是侵入性太强的。\n\n延展性：Google至少在未来几年的服务和集群的规模，监控系统都应该能完全把控住。\n\n\n监控框架大的互联网公司都有自己的分布式跟踪系统，比如Twitter的zipkin，淘宝的鹰眼，新浪的Watchman，京东的Hydra等\n这些系统大多是基于dapper论文而来。\n\naspectj监控系统，又名日志追踪系统，那主要还是打印日志嘛。\n无侵入性的日志打印，AOP绝对是上选了\n写了几个aspectj小示例https://github.com/zhuxingsheng/aspectjdemo\n当然，aspectj只是埋点，后面还有日志存储，实时计算，日志分析，监控展示\n参考http://www.cnblogs.com/gudi/p/6683653.html\nhttp://blog.csdn.net/guwei9111986/article/details/51798394\n微服务监控案例之一\n","tags":["微服务"]},{"title":"微服务不是银弹也不是哑弹","url":"/blog/micro-service-is-not-a-silver-bullet-or-a-dud.html","content":"微服务的核心思路就在于将业务能力封装成独立的松耦合的服务。通过这样一组服务，构建企业内的能力生态系统。除了能满足当前应用的需要之外，也为未来可能的新应用提供了紧实的基础。\n在《拆完中台再拆微服务》中也阐述了微服务是为了提升程序效能和团队效能。\n当提到微服务时，总会想到各种各样的好处：1、使大型的复杂应用程序可以持续交付和持续部署\n2、每个服务都相对较小并容易维护\n3、服务可以独立部署\n4、服务可以独立扩展\n5、微服务架构可以实现团队的自治\n6、更容易实验和采纳新的技术\n7、更好的容错性\n当然，没有一项技术是“银弹”。\n微服务架构也存在一些显著的弊端和问题：1、服务的拆分和定义是一项挑战\n2、分布式系统带来的各种复杂性，使开发、测试和部署变得更困难\n3、当部署跨越多个服务的功能时需要谨慎地协调更多开发团队\n4、开发者需要思考到底应该在应用的什么阶段使用微服务架构\n近些年，反对微服务的声音越来越多。\n在twitter上有个很热门的贴子：twitter.com&#x2F;xuwenhao&#x2F;status&#x2F;1593469165892820992 作者显明的数落了微服务的种种不是。为了更方便你了解作者的看法，我简单罗列下：\n1、微服务的适应场景非常有限。这么多巨头互联网公司的核心业务逐渐微服务化，的确是在特定的历史时期和场景下的解决方案。\n2、大型系统的开发，核心的挑战其实只有一个，就是“控制复杂性”。微服务不会减小复杂性，只会转移复杂性，它天然是为了解决极度复杂的计算、存储问题，中小规模系统其实是根本不需要的，至少在成为大型系统之前。\n3、在系统开发上，控制复杂性的方式，可以用三个关键词来描述，那就是“抽象”、“封装”和“复用”。\n4、服务化的第一个挑战：是“服务”并不是无状态的，“服务”也绑定了数据。以电商业务为例。商场生成订单，必在服务内持久化下来。然后，这个订单会发给到订单履约系统，也会持久化下来。然后两边都有可能触发订单状态的变更，商场用户可能取消订单，履约系统可能因为商品缺货也取消订单。两边都需要有对应的接口和实现，去完成这样的状态同步。这个过程中，就容易引入数据不一致的问题。\n5、第二个挑战：因为是不同的服务，就会面临“向前兼容”的问题，不同的系统并不是完全同步迭代的。而已经发布的服务，意味着对外有了明确的协议承诺。在服务发布新版本的时候，必须要确保向前兼容。\n6、第三个挑战：因为服务化划分了明确的边界，系统更容易变成异构的，更容易引入更多的技术栈。并且有些功能，会在两个不同的语言、框架下各实现一遍，也容易进一步放大之前所说的业务数据不一致的第一个挑战\n三种典型的伪微服务在James Lewis 和 Martin Fowler的名作《微服务》中，将微服务定义为一种架构风格，并总结了它的九种特质：\n1、通过服务实现组件化\n2、服务按照业务能力划分组织\n3、服务以产品而不是项目研发\n4、逻辑集中在服务中，编排简单\n5、每个服务自主决策（技术栈、语言等等）\n6、每个服务自主管理数据（不强制使用统一数据源）\n7、基础设施自动化\n8、将服务失败当作常态纳入设计考量\n9、演进式设计（不求一步到位）\n在实现中，如果对上面的特质理解出现偏差，就会出现三种典型的伪微服务风格\n1、分布式服务服务按照业务能力划分组织\n微服务中的服务应该以业务能力为粒度。这间接回答了“微服务到底多微合适”，既不是单纯的技术能力（比如查询、获取系统时间），也不是完整的应用，而是用以支撑构建应用的业务能力。\n通常所说的“恰当粒度”是在业务与实现两个维度上平衡的结果。并不会存在“只从单一维度入手，越怎么样就越好”这么简单粗暴的结论。所以微服务并不是越小越好，当小到不能表示业务能力，就不再是微服务了。\n如果不顾及服务是否按照业务能力划分组织，就是一种典型的伪微服务模式。被称之为分布式服务。当然分布式服务并不是反模式，它有其特有的用处，只不过它并不是微服务而已。\n2、微工作组服务以产品而不是项目研发\n这主要是从生命周期角度看，产品和项目的差异体现在团体结构和生命周期上。\n产品的生命周期分为初始、稳定、支持和结束生命几个阶段。那么产品的不同版本，可能处在不同的生命周期中。所以产品团队需要在同一时间内，支持多个处在不同生命周期的产品版本。而项目通常假设只有唯一产物，随着项目生命周期的进项，项目化服务一直在改变。\n因此产品化服务的生命周期，实际上相当于承诺在产品生命周期内，服务是不变的。也就是说只要1.0不结束生命，那么我们就可以一直使用它。哪怕发布了1.5、2.0、3.0，只要1.0满足我的需要，并且还在生命周期内，作为消费者，可以无视你的后续版本。\n微服务需要服务间不仅仅在接口上松耦合，还在要生命周期上松耦合。也就是微服务可以自主发布，其他服务不应该受到影响。产品化是实现这一点的根本途径。\n如果服务缺乏产品化生命周期，那就会产生一组在生命周期上紧密耦合的服务，从而完全丧失微服务的意义。随着服务数量变多，这种生命周期的耦合还会带来难以承受的沟通成本。\n3、傻服务逻辑集中在服务中，编排简单\n逻辑越在服务中集中，所需要的编排就越简单，通常通过RESTful API或者轻量的消息机制即可完成。\n如果服务中的逻辑简单，那就会有大量的逻辑泄露到编排逻辑中，此时就需要使用复杂的编排工具辅助我们工作。\n选择编排复杂的逻辑，听越来很有道理：既然我们希望在不同场景下复用服务，那么总有一些需要改变的订制代码，我们需要将它们与服务本身分离。分离之后，就能通过编排引擎，帮助我们在不同的场景下重用这些服务\n但按照这个逻辑下去，服务往往会变成对于数据的CRUD，然后大量的逻辑存在于编排引擎中，这也是典型的伪微服务。像傻服务一样。\n总结其实任何技术都可以说它既不是银弹也不是哑弹。就是优势与缺点并存。我们需要权衡的是在什么样的阶段引入什么样的技术来帮我们更好更快地解决问题。\n"},{"title":"成为首席架构师的打怪升级之路","url":"/blog/the-way-to-become-the-chief-architect.html","content":"经过多年职场成长，发现架构与管理有很多的相似之处，最大相似之处就是要与个人特性融合实践。也就是纸上得来终觉浅，绝知此事要躬行。\n读再多的架构或者管理书籍，那不过是个最基础的起点，你外围触之可及的手段，但离最终的知行合一还存在着很远的距离。\n在《架构师的能力模型》中提出架构师的能力模型：\n\n程序员只需要专注于“专”，而架构师需要“博而不专”，牺牲技术深度来提高技术广度。\n对于一个全能型架构师对架构的决策，需要广度+深度+经验三者兼顾\n广度决定能找到的方法+深度决定选择方法的正确性+经验决定找到正确方法的速度\n架构师的能力维度从技术+业务+管理升华为技能+影响力+领导力\n1.技能是实践架构的基础。它需要知识以及应用知识的能力\n2.影响力用来衡量架构师在项目中应用技能后给项目或公司带来多大的效益\n3.领导力确保了架构实践的状态能稳步向前推进，同时培养更多的架构师\n\n\n从上面的文章和阐述，似乎只能看出架构师要全能，不但要技术强，而且不管有没有管理title都得引导架构方案成功落地。\n那作为一位程序员怎么成长为一名合格的架构师，甚至首席架构师或CTO，需要经历哪些阶段，怎么样的脱变，轻重优先级怎么划分，认知需要怎么提升转变呢?\n在《郭东白的架构课》里面作者给出成长路线，总结学习一下。\n首先架构师是具备架构能力的人，架构能力是指为相对复杂的场景设计并引导一个或多个研发团队，来实施结构化软件系统的能力。\n其中结构化代表这个软件在其设计范围内的设计理念、代码结构和实现方式上是同质的。“同质”表示设计范围内处处一致。\n要想成为首席架构师，需要经历程序员、兼职架构师、全职架构师、首席架构师关卡。在这四道关卡上，对结构同质的关注侧重点也将有所差别。\n程序员程序员是入门后的第一阶梯。\n职责很清晰：\n1、负责功能的实现方案设计，编码实现\n2、追踪bug，分析并攻关解决\n当然随着打怪升级，经验丰富，负责的功能会越来越复杂、核心；解决的bug也会从易到难，直至各种疑难杂症。\n对照架构师的终极目标，程序员在结构化层面需要有如下的认知：\n\n对于结构化，程序员就是在代码层面做到高内聚低耦合，在整个打怪升级路径中，这一阶段可以说是对代码最有掌控权的，只要能把需求功能实现，无bug。遵循团队统一规范，其他一切几乎都能自我实现。\n在代码层面，想要做到结构化，可以详看以往两个主题：《Clean Code》 和 《SOLID原则》\n兼职架构师从程序员升级到下一关卡，就是兼职架构师。何为兼职架构师呢？主要是解决团队内部的横向问题，那什么时横向问题呢？其实就是《架构与架构师》中提到的软件质量问题，或者称为架构特性：如稳定性，安全性，扩展性，高并发等等。\n在团队中，一般也不会设计这些职位，完成看个人主观能动性。慢慢成为团队中的技术大拿。\n但还是在代码层面的非功能需求的结构化：\n\n想要成为兼职架构师，也很简单，一切取决于个人意愿，只要肯花时间，下功夫。\n在 《程序员职级》 中，有5年左右时间，就可以通过这个关卡。\n全职架构师成为兼职架构师后，只要公司业务还在向前发展，有机会，国内大多环境，会码而优则仕。\n想成为架构师，大公司环境会更有机会，小公司则会变成TL。\n成为研发Leader后，大体职责：\n1、团队任务管理：开发工作量评估、任务分配\n2、团队生产力提升：统一规范、最佳实践总结、自动化工具开发\n3、团队生产质量提升：代码审核、风险管理\n4、团队专业力提升：招聘、新人指导、复盘总结改进\n其实不管是TL还是全职架构师，都有相似之处：思维认知第一次脱变。成为TL，走上管理，是人生的一次转身，相当多的人在这个过程是脱了一层皮，会转身失败，有性格因素，也有认知原因。同样的，成为全职架构师，如下面思维导图中指出，要突破的障碍，明面上都有硬技能和软技能，背后是人的障碍，怎么有勇气应对挑战和不当和事佬。\n两项的挑战对程序员群体都不小。\n\n首席架构师关卡来到这一层，可以说是相当艰难，一是这样的职位相当少，二更是要跨越人性。人都是追求确定性的，而首席架构师却是要面对不确定性。\n而且在打怪升级的过程中，需要有高风险决策的机会。虽然很难，但可以通过这个职级指导其他职级，也更加印证了架构第二原则：原因比方法更重要。架构师需要详细记录架构决策以及背后权衡的逻辑。\n\nCTOCTO就更难了，不过应了那句话：来时赤裸裸，走时赤裸裸。入行前无技术，到了最高层次，还得抛弃技术，也就是跳出技术追求解决问题方案。\n\n不过从上面的思维导图中，让我得到更多的不是怎么成为CTO，而是向上管理。CTO的上级是CEO，CTO怎么支撑CEO？怎么向上管理。\n对应到我们任何一个层级，都需要常问自己：我的领导想要什么？遇到什么难题，从我角度怎么支撑他成功。\n总结成为首席架构师打怪升级的整个路径相当清晰了，对结构化的关注范围：从代码层面、单个领域、多个领域、再到最高的公司整体领域，一层层扩大。\n对于架构师，关注两个架构定律，第一一切都是在做权衡、第二原因比方法重要。架构师需要关注自己做了哪些架构决策，尤其在可见的风险之下决策，并承担风险。以终为始，为最高阶的首席架构师做好准备，以便在未来不确定性下更好地做架构决策。\n","tags":["架构师"]},{"title":"我的一行代码值多少钱","url":"/blog/how-much-is-my-line-of-code-worth.html","content":"在《程序员软技能》中，提到过一种思维，要把自己当成一家企业，而就职公司是我们的客户。\n既然如此，我想需要考虑的最重要的事情应该是我给客户提供了什么产品，产品是什么价格？\n对于程序员来讲，提供的最根本产品自然是代码，我们现在需要考虑的事就是代码的价格，平均到基本单位，就是每一行代码值多少钱？\n当下市场，先考虑一下代码语言种类：\n使用java语言写的一行代码\n使用go语言写的一行代码\n使用python语言写一行代码\n亦或写一行sql\n甚至调试一个AI模型参数\n这些代码它们的价格肯定是不一样的。想到的第一个因素估计是写的人不一样。都写相同的语言代码，什么在决定价格？自然是写代码程序员的水平了。如同时期研究生相对本科生自然值钱些。\n即使都是出于同一人之手。那么是什么决定了价格？是因为牛逼吗？\nPHP是最好的语言？从高维度讲sql man与AI调试师没什么不同，那决定价格的最根本因素是什么？\n\n在市场上，决定价格的最重要因素是需求\n\n现在写一行VB语言会比java语言值钱吗？不是VB语言不好，终究是因为市场需求。当更先进更高阶的技术出现，更能满足市场需求时，价格自然上涨。这也是为什么苦逼程序员必须随着技术更迭不停地学习。甚至要预判技术趋势，提前投入精力学习。才能保障自己写的代码价值不被贬值。\n除了市场需求因素，程序员水平，还有什么因素呢？我们还需要考虑哪些问题？\n把需求换种说法，就是写的代码是否有用？\n从关注程序员自身来讲，可以考虑再深入点：\n1、我写的代码对别人有没有用呢？\n\n写个hello world，或者写了个微信，似乎都有用\n\n2、我写的代码对别人有用的话，有多大用处呢？如何做到最有用？\n\nhello world作用可以作教程，对小白编程基础培训，微信可以通讯、支付、摇一摇，似乎用处都不小。因此它们的作用不能从程序员侧考虑，而得从客户侧考虑。\n\n3、我写的代码对别人有用的话，对多少人有用？如何做到对更多人有用？\n\nhello world面对的人群是刚要入门编程人员，而微信是全民应用；要想对更多人有用，全民编程似乎不太可能\n\n4、我写的代码对别人有用的话，在多长时间段对别人有用呢？如何做到让这个时段更长些\n…\n除了上面的问题，还需要从客户侧考虑，不能只是埋头写一行行的代码，还得考虑客户的需求，这样又需要考虑一些问题：\n1、他们真正的需求是什么？最需要的是什么？\n需要程序员？需要35岁以下的程序员？\n2、我是那个能满足他们需求的人吗？\n在优化人员时，优化名单上会出现你的名字吗？\n3、如果我能，我有没有可能成为必需？\n4、如果我不能，我怎样才能？\n5、有必要一定由我去满足他们的需求吗？\n…\n这么多的问题，总结成一句话，行动指南：挑最需要的事情做，自然就成了最被需要的人。\n\n常听些大佬讲，要有商业sense，而一切商业模式的根本，怎么赚钱，赚什么钱，赚多少钱。\n在现如今充满物质喧嚣的大环境中，总包、副业刚需、内卷这些词时时充斥我们时，更应该考虑下商业底层逻辑。\n我想作为程序员，“我的一行代码值多少钱？”，这个问题是最基本的商业sense。\n","tags":["程序人生"]},{"title":"微服务超时与重试","url":"/blog/microservice-timeout-and-retry.html","content":"前言其实不只在微服务中，在平常网络请求，或者与第三方系统进行交互都需要设置超时时间\n为什么需要超时与重试？ 总体上讲，肯定是为了增加系统可靠性，具体表现在两个方面\n\n系统自我保护：快速失败，在业务最大允许等待时间内未收到返回数据，主动放弃等待，释放占用资源，避免请求不断累积带来的客户端雪崩效应\n成功率：服务处理超时原因有很多，但常见的超时都是短暂的，主要是GC，或者有网络抖动等。这些短时间影响服务端状态的情况而造成请求成功率下降，需要补救措施。简单的补救有超时重试操作：当前请求超时后，将会重试到非当前服务器，降低重试超时的机率\n\n这一篇将由浅入深探索timeout机制，以及在微服务下的实践\n超时经常被提起的两种超时：connection timeout、socket timeout\n通过最底层的Socket,ServerSocket演示一下这两种超时的表现，nio框架都会有对应的配置选项\nconnectionTimeout建立连接超时时间\n客户端,随便写个IP，设置一个timeout\nSocket socket = new Socket();socket.connect(new InetSocketAddress(&quot;10.0.0.1&quot;,8080),20000);\n\n在timeout时间到时，就会抛出connect timed out异常\nException in thread &quot;main&quot; java.net.SocketTimeoutException: connect timed out\tat java.net.DualStackPlainSocketImpl.waitForConnect(Native Method)\tat java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:85)\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\tat java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\tat java.net.Socket.connect(Socket.java:589)\n\n\nsocketTimeout\nEnable&#x2F;disable SO_TIMEOUT with the specified timeout, in milliseconds. With this option set to a non-zero timeout, a read() call on the InputStream associated with this Socket will block for only this amount of time. If the timeout expires, a java.net.SocketTimeoutException is raised, though the Socket is still valid. The option must be enabled prior to entering the blocking operation to have effect. The timeout must be &gt; 0. A timeout of zero is interpreted as an infinite timeout.\n\n服务端，只要让客户端能连接上就行，不发送数据\nServerSocket serverSocket = new ServerSocket(8080);while ( true) &#123;    Socket socket = serverSocket.accept();    new Thread(new P(socket)).start();&#125;\n\n客户端，进行读数据\nSocket socket = new Socket();socket.connect(new InetSocketAddress(&quot;localhost&quot;,8080),20000);socket.setSoTimeout(3000);\n\n3s后，就抛出Read timed out\njava.net.SocketTimeoutException: Read timed out\tat java.net.SocketInputStream.socketRead0(Native Method)\tat java.net.SocketInputStream.socketRead(SocketInputStream.java:116)\tat java.net.SocketInputStream.read(SocketInputStream.java:170)\tat java.net.SocketInputStream.read(SocketInputStream.java:141)\tat java.net.SocketInputStream.read(SocketInputStream.java:223)\n\nnio对NIO，看网上一些示例基本没有关注到这一点，所以值得思考，难道是nio不需要关注timeout?\n客户端对服务器的连接:\nSelector selector = Selector.open();InetSocketAddress isa = new InetSocketAddress(host, port);// 调用open静态方法创建连接到指定主机的SocketChannelSocketChannel sc = SocketChannel.open(isa);\n\n在调用SocketChannel.open()方法时,如果连接不上服务器,那么此方法就会长时间阻塞,为了解决这个问题,我们可以在调用open()方法前,启动一个定时器,这个定时器会在指定的时间内检查是否已连接成功,这个指定的时间也就是我们希望设置的连接超时时间,当检查已连接上服务器时,提示用户已连接成功;若没有连接上,可在代码中抛出SocketTimeoutException,并提示用户连接超时\npublic void connect()&#123;\ttry&#123;\t\tselector = Selector.open();\t\tInetSocketAddress isa = new InetSocketAddress(host, port);\t\t//10秒连接超时\t\tnew Timer().schedule(tt, 10000);\t\t// 调用open静态方法创建连接到指定主机的SocketChannel\t\tsc = SocketChannel.open(isa);\t\t// 设置该sc以非阻塞方式工作\t\tsc.configureBlocking(false);\t\t// 将Socketchannel对象注册到指定Selector\t\tsc.register(selector, SelectionKey.OP_READ);\t\tMessage msg = new Message();\t\tmsg.what = 0;\t\tmsg.obj = sc;\t\thandler.sendMessage(msg); // 连接成功\t\tnew Thread(new NIOReceiveThread(selector, handler)).start();\t&#125;catch (IOException e)\t&#123;\t\te.printStackTrace();\t\thandler.sendEmptyMessage(-1); // IO异常\t&#125;&#125;TimerTask tt = new TimerTask()&#123;\t@Override\tpublic void run()&#123;\t\tif (sc == null || !sc.isConnected())&#123;\t\t\ttry&#123;\t\t\t\tthrow new SocketTimeoutException(&quot;连接超时&quot;);\t\t\t&#125;catch (SocketTimeoutException e)&#123;\t\t\t\te.printStackTrace();\t\t\t\thandler.sendEmptyMessage(-6); // 连接超时\t\t\t&#125;\t\t&#125;\t&#125;&#125;;\n\n在stackoverflow上有人回答了Read timeout for an NIO SocketChannel?\n\n\nYou are using a Selector, in which case you have a select timeout which you can play with, and if it goes off (select(timeout) returns zero) you close all the registered channels, or\nYou are using blocking mode, in which case you might think you should be able to call Socket.setSoTimeout() on the underlying socket (SocketChannel.socket()), and trap the SocketTimeoutException that is thrown when the timeout expires during read(), but you can’t, because it isn’t supported for sockets originating as channels, or\nYou are using non-blocking mode without a Selector, in which case you need to change to case (1).\n\n\nnettynetty业界公认的高成熟nio产品，也是大多数微服务底层使用的通信框架，内部细节值得挖一挖处理方式，篇幅有限，另开篇深挖\n先看在微服务产品中的使用\nconnectionTimeout这种场景很简单，在使用netty时,对应的配置选项\nBootstrap b = new Bootstrap();b.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000)\n\nsocketTimeout这种场景各个框架在处理里，手法不尽相同，各有特色\nmotanMotan是一套高性能、易于使用的分布式远程服务调用(RPC)框架，新浪微博开源。\n之前解读过motan源码，《motan客户端解析》，《motan服务端解析》\nNettyChannel.request：\n\n获取此method的配置timeout\n在write时，awaitUninterruptibly\n超时就抛出timeoutException\n\npublic Response request(Request request) throws TransportException &#123;    int timeout = nettyClient.getUrl().getMethodParameter(request.getMethodName(), request.getParamtersDesc(),            URLParamType.requestTimeout.getName(), URLParamType.requestTimeout.getIntValue());\tif (timeout &lt;= 0) &#123;           throw new MotanFrameworkException(&quot;NettyClient init Error: timeout(&quot; + timeout + &quot;) &lt;= 0 is forbid.&quot;,                   MotanErrorMsgConstant.FRAMEWORK_INIT_ERROR);       &#125;\tNettyResponseFuture response = new NettyResponseFuture(request, timeout, this.nettyClient);\tthis.nettyClient.registerCallback(request.getRequestId(), response);\tChannelFuture writeFuture = this.channel.write(request);\tboolean result = writeFuture.awaitUninterruptibly(timeout, TimeUnit.MILLISECONDS);\tif (result &amp;&amp; writeFuture.isSuccess()) &#123;\t\tresponse.addListener(new FutureListener() &#123;\t\t\t@Override\t\t\tpublic void operationComplete(Future future) throws Exception &#123;\t\t\t\tif (future.isSuccess() || (future.isDone() &amp;&amp; ExceptionUtil.isBizException(future.getException()))) &#123;\t\t\t\t\t// 成功的调用 \t\t\t\t\tnettyClient.resetErrorCount();\t\t\t\t&#125; else &#123;\t\t\t\t\t// 失败的调用 \t\t\t\t\tnettyClient.incrErrorCount();\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;);\t\treturn response;\t&#125;\twriteFuture.cancel();\tresponse = this.nettyClient.removeCallback(request.getRequestId());\tif (response != null) &#123;\t\tresponse.cancel();\t&#125;\t// 失败的调用 \tnettyClient.incrErrorCount();\tif (writeFuture.getCause() != null) &#123;\t\tthrow new MotanServiceException(&quot;NettyChannel send request to server Error: url=&quot;\t\t\t\t+ nettyClient.getUrl().getUri() + &quot; local=&quot; + localAddress + &quot; &quot;\t\t\t\t+ MotanFrameworkUtil.toString(request), writeFuture.getCause());\t&#125; else &#123;\t\tthrow new MotanServiceException(&quot;NettyChannel send request to server Timeout: url=&quot;\t\t\t\t+ nettyClient.getUrl().getUri() + &quot; local=&quot; + localAddress + &quot; &quot;\t\t\t\t+ MotanFrameworkUtil.toString(request));\t&#125;&#125;\n\n注意到其中的NettyResponseFuture，看名字就明白是个Future模式，在《代码小析 - 异步回调》中有分析过\n接收到服务端返回\nNettyResponseFuture responseFuture = NettyClient.this.removeCallback(response.getRequestId());if (responseFuture == null) &#123;\tLoggerUtil.warn(\t\t\t&quot;NettyClient has response from server, but resonseFuture not exist,  requestId=&#123;&#125;&quot;,\t\t\tresponse.getRequestId());\treturn null;&#125;if (response.getException() != null) &#123;\tresponseFuture.onFailure(response);&#125; else &#123;\tresponseFuture.onSuccess(response);&#125;\n\n获取真实结果NettyResponseFuture.getValue()\n通过long waitTime &#x3D; timeout - (System.currentTimeMillis() - createTime);计算一下真正的wait时间\npublic Object getValue() &#123;\tsynchronized (lock) &#123;\t\tif (!isDoing()) &#123;\t\t\treturn getValueOrThrowable();\t\t&#125;\t\tif (timeout &lt;= 0) &#123;\t\t\ttry &#123;\t\t\t\tlock.wait();\t\t\t&#125; catch (Exception e) &#123;\t\t\t\tcancel(new MotanServiceException(&quot;NettyResponseFuture getValue InterruptedException : &quot;\t\t\t\t\t\t+ MotanFrameworkUtil.toString(request) + &quot; cost=&quot;\t\t\t\t\t\t+ (System.currentTimeMillis() - createTime), e));\t\t\t&#125;\t\t\t// don&#x27;t need to notifylisteners, because onSuccess or\t\t\t// onFailure or cancel method already call notifylisteners\t\t\treturn getValueOrThrowable();\t\t&#125; else &#123;\t\t\tlong waitTime = timeout - (System.currentTimeMillis() - createTime);\t\t\tif (waitTime &gt; 0) &#123;\t\t\t\tfor (;;) &#123;\t\t\t\t\ttry &#123;\t\t\t\t\t\tlock.wait(waitTime);\t\t\t\t\t&#125; catch (InterruptedException e) &#123;\t\t\t\t\t&#125;\t\t\t\t\tif (!isDoing()) &#123;\t\t\t\t\t\tbreak;\t\t\t\t\t&#125; else &#123;\t\t\t\t\t\twaitTime = timeout - (System.currentTimeMillis() - createTime);\t\t\t\t\t\tif (waitTime &lt;= 0) &#123;\t\t\t\t\t\t\tbreak;\t\t\t\t\t\t&#125;\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;\t\t\tif (isDoing()) &#123;\t\t\t\ttimeoutSoCancel();\t\t\t&#125;\t\t&#125;\t\treturn getValueOrThrowable();\t&#125;&#125;\n\ntotalTimeout有了timeout基本已经满足需求，但这儿再提一个totalTimeout，为什么需要一个总超时时间\n\n比如客户端希望服务端在60ms内返回，由于成功率要求必须加一次重试，但是设置超时时间30ms重试一次会很浪费（绝大部分重试很快，但预留了30ms则压缩了初次调用的时间）。设置40ms重试一次就可能出现整体耗时大于60ms。所以希望可以配置整体超时时间为60ms，单次40ms加重试一次，这样既充分利用看重试机会也不会导致整体超过60ms\n\n一次服务调用的正常请求的最长时间为：timeout * failovertimes + success_invocation_time\n比如某个服务的timeout为100ms，failovertimes为1，正常调用的平均耗时为10ms，那么它的上游在重试情况下的耗时就是：乐观估计100 * 1+10&#x3D;110ms；悲观估计100 * 1+100&#x3D;200ms\n为了保证总体超时时间，只能把单次超时时间压缩，使得某些情况下可能不需求重试的场景也进行了重试\n对比一下，设置totalTimeout与不设置的情况：\n\n某服务通常能在20ms返回，但是因为某些意外（比如gc），连续两次都要40ms\n\n\n只能设置单次timeout的情况下，timeout&#x3D;30ms，failovertimes&#x3D;1因此对于client来说，它看到的调用耗时就是：30ms（超时） + 30ms（超时） &#x3D; 60ms\n分开设置首次超时和总体超时的情况下，timeout&#x3D;40ms，total_timeout&#x3D;60ms，failovertimes&#x3D;1因此对于client来说，它看到的调用耗时就是：40ms（超时）+ （60ms-40ms）（超时） &#x3D; 60ms\n\n\n某服务通常能在20ms返回，但是因为某些意外（比如gc），这次需要35ms才能返回。\n\n\n只能设置单次timeout的情况下，timeout&#x3D;30ms，failovertimes&#x3D;1。因此对于client来说，它看到的调用耗时就是：30ms（超时） + 20ms &#x3D; 50ms\n分开设置首次超时和总体超时的情况下，timeout&#x3D;40ms，total_timeout&#x3D;60ms，failovertimes&#x3D;1。因此对于client来说，它看到的调用耗时就是：35ms（正常返回） &#x3D; 35ms\n\n重试因某个服务实例短暂状态不佳而造成的超时，使用重试处理可以让请求转向其他服务实例的做法可以很好改善非集中式问题的成功率。\n但如果超时重试只做简单的重试策略：有超时便重试，这样可能会导致服务端的崩溃。\n例如：当前基础组件（如db）压力过大而造成超时，如果一律重试的话，会导致服务端集群实际接受请求量翻倍，这会使得基础组件压力无减反增，可能会导致其最终崩溃\n实现\n思路简单，配置重试次数，出现非业务异常就重试，达到次数上限或者中途成功结束\n重试限流,重试造成雪崩的可能性，所以重试需要控制流量\n\nmotan之前解读过motan源码，《motan客户端解析》，motan的failover就是这么处理的\n// 先使用method的配置int tryCount =        refUrl.getMethodParameter(request.getMethodName(), request.getParamtersDesc(), URLParamType.retries.getName(),                URLParamType.retries.getIntValue());// 如果有问题，则设置为不重试if (tryCount &lt; 0) &#123;    tryCount = 0;&#125;for (int i = 0; i &lt;= tryCount; i++) &#123;    Referer&lt;T&gt; refer = referers.get(i % referers.size());    try &#123;        request.setRetries(i);        return refer.call(request);    &#125; catch (RuntimeException e) &#123;        // 对于业务异常，直接抛出        if (ExceptionUtil.isBizException(e)) &#123;            throw e;        &#125; else if (i &gt;= tryCount) &#123;            throw e;        &#125;        LoggerUtil.warn(String.format(&quot;FailoverHaStrategy Call false for request:%s error=%s&quot;, request, e.getMessage()));    &#125;&#125;\n\n超时重试但像我司框架就没有这样处理，只关注超时重试，因为超时重试主要是解决因偶尔短暂状态不佳而对成功率造成的影响，所以把重点放在处理短暂处于超时状态超时请求，对于长时间处于较大量的超时状态时，将选择不进行重试fail fast \n限流主要是防止重试次数过多，引起系统雪崩，有必要进行一下限流\n在《微服务-熔断机制》中提到过限流算法，细节可参考《计数器算法》\n参考资料Read timeout for an NIO SocketChannel?\n","tags":["微服务"]},{"title":"怎么做软件设计才美","url":"/blog/how-to-make-software-design-beautiful.html","content":"之前学习了极客时间上的一个专栏《软件设计之美》，作者对软件设计、编程范式、设计原则与模式、设计方法进行了讲解，内容全面。\n专栏里面的一些内容，我也有些接触，但认知还不够深，比如面向对象。而且专栏把这些内容都串联起来，跟着专栏内容总结梳理一下。\n\n\n\n软件设计是什么软件设计：依据需求分析结果转化为软件设计模型与技术文档\n\n\nDesign is there to enable you to keep changing the software easily in the long term  –Kent Beck\n\n设计是为了让软件在长期更容易适应变化。\n相对于软件设计，现在人好像更喜欢说架构。它们俩有什么区别，是不是本质上是同一件事，只是称呼不同而已？\n以前有人总结：从0到1是架构，从表到里是抽象，从粗到细是设计\n两者似乎是一样的，只是一个相对宏观，一个相对微观。\n架构，之前已经写过很多，可以参考《架构专栏》\n架构会关注两点：\n一是软件提供功能：作者上升为模型，一个软件之所以是这个软件的核心。\n二是架构特征，也就是架构质量：各种约束规范。\n软件设计学习的难度，不在于一招一式，而在于融会贯通。\n软件设计重要因素？软件设计为了什么？为了更加容易地扩展软件能力。再深一层，软件开发为了什么？当然是为了解决由需求带来的问题，而解决的结果则是一个可以运行的交付物。\n那么什么制约了软件的扩展能力，是现实需求的复杂性。之前总结过复杂性的来源：\n\n如何解决复杂性：分而治之。一是把整体软件分解成粒度大小适合的模块功能；二是分解不同层次的东西，也就是分离关注点。如把技术与业务拆解。\n除了分解，还有一个常被忽略的重要因素：可测试性。当一个软件拆分成一个一个的小模块后，如果不尽可能地保证每个小模块的正确性，就没法保证软件整体的正确性。如同盖楼一样，不保证钢筋、水泥、砖土质量合格，却想盖出合格大楼是荒谬的。\n软件设计的三个部分要了解一个软件设计，可以从三个部分入手：模型、接口和实现\n模型：这个系统与其它系统有所区别的关键，理解整个软件设计最核心的部分\n接口：通过怎么样的方式将模型提供的能力暴露出去，以及我们与这个软件交互的入口\n实现：软件提供的模型和接口在内部是如何实现的软件能力得以发挥的根基\n编程范式编程范式：程序的编写模式，意味着主要使用的是什么样的代码结构。\n由最经典的结构化编程，限制goto语句，它对程序控制权的直接转移施加约束；再到面向对象编程，限制使用函数指针，它是对程序控制权的间接转移施加了约束；再到最新的函数式编程，限制使用赋值语句，它是对程序中的赋值施加了约束。\n每种范式在现代语言都看到它的影子，因此现在像混合格斗，不再是独门独派。我们吸取百家之长，采用面向对象来组织程序中的各个模块，采用函数式编程指导类的接口设计，在具体的实现中使用结构化编程提供的控制结构。\n设计原则与模式这部分内容，在《SOLID系列》中已经总结的差不多了。\n当然还有很多原则，我们重要的是如何在各个原则之间追求平衡。\n设计方法这一部分也是我们常讨论的DDD了，详细的可以查看《DDD》专栏\n总结怎么才能做好软件设计，从文中内容推断软件架构师犹如软件体系里面的全能神。\n所以难点不在于一招一式，而在于融会贯通。吸百家之精华，大成也！\n","tags":["架构"]},{"title":"我的长处是什么","url":"/blog/what-are-my-strengths.html","content":"这两天一直在看被誉为“现代管理学之父”与“管理大师中的大师”的彼得·德鲁克（Peter F．Drucker）写的《自我管理》这篇文章\n我的长处是什么？这是自我管理8个问题的其中一个，也是第一个\n只有当所有工作都从自己的长处着眼，你才能真正做到卓尔不群\n以前的人没有什么必要去了解自己的长处，因为一个人的出身就决定了他一生的地位和职业：农民的儿子也会当农民，工匠的女儿会嫁给另一个工匠等。但是，现在人们有了选择。我们需要知己所长，才能知己所属\n要发现自己的长处，唯一途径就是回馈分析法（feedback analysis）。每当做出重要决定或采取重要行动时，你都可以事先记录下自己对结果的预期。9到12个月后，再将实际结果与自己的预期比较\n\n比如开始写作，希望一年达到什么效果。跳槽了，一年内达到什么改变？\n在九到十二个月之后，拿出之前的预期对比实际效果，看看预期是达成了，超标了，还是偏离了\n运用这个简单的方法，就能知道自己的长处，也知道自己正在做的哪些事情不能发挥自己的长处，看到哪些方面能力不是特别强，哪些方面完全不擅长，做不出成绩来\n根据回馈分析法的结果，需要采取如下行动：\n“施展长处”：\n首先专注于你的长处，把自己放到能发挥长处的地方，不要试图去完成自己不在行的领域，要从无能到平庸比从一流到卓越需要付出多得多的努力\n“改善长处”：\n其次加强你的长处。回馈分析会迅速显示在哪些方面需要改善自己的技能或学习新技能；同时纠正影响工作成效和工作表现的不良习惯\n例如，一位企划人员可能发现自己美妙的计划最终落空，原因是他没有把计划贯彻到底。同那些才华横溢的人一样，他也相信好的创意能够移动大山。但是，真正移山的是推土机，创意只不过是为推土机指引方向，让它知道该到何处掘土。这位企划人员必须意识到不是计划做好就大功告成，接下来还得找人执行计划，并向他们解释计划，在付诸行动前须做出及时的调整和修改，最后要决定何时终止计划\n“增强长处”：\n发现自己的不知道，以免由于恃才傲物而造成的偏见和无知，不知道自己不知道过渡到知道自己不知道，放空自己，虚怀若谷，其实意思是虽然一技之长很重要，但现如今各领域相互融合，边界模糊，更需要综合能力，让自己的一技之长更加有的放矢\n回馈分析法不是总结，也不是复盘，是当生活中的重大改变和做出的重大决定，长期坚持使用可以让你找到自己擅长做的事情，并在职场中找到适合自己的定位\n\n","tags":["管理","认知"]},{"title":"技术人的三个阶段","url":"/blog/three-stages-of-technician.html","content":"技术人员的未来是什么？\n我想作为一名技术人，在夜深人静时候，都会想想这个直击灵魂的问题。\n作为一名搬砖人，哪里需要哪里搬？\n不甘于作为工具人，但出路在何方？\n新技术层出不穷，学到何年何月？怎么保持活到老学到老的状态？\n在之前的一系列文章中，写过《程序员成长职级》、《最好的职业建议》、《首席架构师的打怪之路》等，其实也都是来源于对上述问题的思考。\n怎么突破呢？其实市场也给了部分答案，比如市场要求从几年前的T型人才到π型人才，这也是作为一名技术人，需要三条腿：技术、业务、管理。\n尤其业务，对于技术人员的重要性，很多技术人不理解，甚至工作多年的人也不理解。技术只是工具，达到目标的手段。而业务才是最终目标。不懂业务，最后必然会成为工具人。\n很多技术人被沦为随时可替代的工具人也不自知，甚至对自身技术自鸣得意，孤芳自赏。\n也许会有人反驳，我再深入解释一下。技术人想干什么？技术牛啊，怎么体现技术牛呢？写个数据库，写个操作系统，写个docker，或者写个开源框架等等。\n为什么是这些东东呢？因为这些技术通用，与技术紧密关联，但其实这些只是更具技术属性而已，它们对外的统一特征是产品，首先是个产品，其次是个技术属性偏强的产品。\n如果你对自己要达到的目标都不了解，再牛的技术也会有种无力感，报国无门空自怨。\n回归到主题，技术人员的三个阶段。最近看到陶勇医生著作的《自造》，他讲了学医的三个阶段，我常见得对技术人是通用的。\n\n\n第一阶段：“技”\n这阶段既练内功也练外功，主要靠勤奋和坚持。\n对应到程序员，这个阶段是一样的，就是学习各种知识，不管是基础理论知识，还是上机操作实践。有一种进步感推动着自己。\n程序员这个阶段，学校的基础理论，再进入职场后5年左右时间。基本能独当一面了。多点努力，开始成为团队内的骨干，再有点运气会成为TL。\n第二阶段：“艺”\n“艺”就是艺术，需要创新，解决疑难杂症。这阶段靠谦卑和勇敢，敢于打破现有的自我，走向一个可能更费劲的阶段。\n对应到程序员，团队出现各种各样的难题，一些会是别人碰到的，一此可能是全新的，不管是解决方案还是落地步骤都得自己想办法了。\n类似于兼职架构师的职位，解决各种横向问题，以及制定业务落地方案。\n第三阶段：“理”\n“理”指哲理和道理。从术层面上升到道层面。\n就是我们人可能就像是在大河上面的一片树叶，你确实不好把握方向，东南西北，随波逐流。当你进入到“理”阶段，了解了更多的人生哲理和道理的时候，你仍然是河上的一片树叶，仍然不一定能把握东南西北的方向，但你就能感知到重力和浮力的关系，于是你就能对自己的定位有一个更清晰的感觉。\n类似在《不要终身低效学习》中提到的ThoughtWorks中国区CTO徐昊说，技术没有反哺过我的生活，反而我的人生给养了在技术上的洞见。\n这个阶段我想应该就是一通百通的阶段，像我当初学习微服务治理知识时，感觉互联网真是厉害。各种场景都有技术对应。感觉这个世界都应该去学习互联网的运作方式。\n直到有一天，我在高速上，因为是节假日，前方要限流。交警不会直接把路拦截，而是会使用锥形桶，形成一个漏斗状，慢慢控制车流速度。\n突然意识到，并不是互联网是创意的源头，其实现实世界中早有了类似方案，只是自己眼中只看到了互联网这一个场景而已。\n\n这三个阶段让我想起多年前读的一本小说：《遥远的救世主》\n\n透视社会依次有三个层面：技术、制度和文化。小到一个人，大到一个国家一个民族，任何一种命运归根到底都是那种文化属性的产物。强势文化造就强者，弱势文化造就弱者，这是规律，也可以理解为天道，不以人的意志为转移\n\n技术、制度和文化似乎也对应着这三个阶段。\n\n总结：\n常听人讲，我们要举一反三，触类旁通，一通百通。\n但现实没有这么理想。\n学习新东西，大概有两条路径：\n1、学习一个具体事务，经过实战，消化，再抽象吸引，达到一通百通。\n2、学习一个抽象理论，但还得事上练，绝知此事要躬行。由理论具象到每一件事。\n但大多数时候，大多数人，是没法一通百通的，因为这就像面向对象，可教的是基础，但要掌握得靠自己感悟。只要多实践，再萃取出自己的理论。\n再比如学了一门语言，别的语言是一样的？但你看看有多少人是全栈，全语言的。\n说透了，还是王阳明的知行合一，这是我们是追求的目标，但能达到目标的凤毛麟角。\n","tags":["认知"]},{"title":"技术人请远离技术","url":"/blog/technicians,-please-stay-away-from-technology.html","content":"\n一本正经的胡说八道\n\n对错自在你心，可能就是个饭后闲扯\n所得以前同事问，什么时候跳槽？或者什么时候会出去看看机会呢？我都会回答做到有所得的时候。有所得，当然不是说拷贝公司几份源码，那可是公司资产，不可误入歧途。但知识是自己的，成长是自己的\n一直也是这么践行的，从出校门不懂的书生到能把书本知识灵活运用到一线工作，从毫无经验到开发工业级产品，从职场小白到带队主导开发流程，虽然经历的大多数公司已经倒闭了，但自己是实实在在的成长了。\n是的，是所有得再考虑外面机会的，小池塘不能满足成长时，就要去大池塘\n前些天跟老同事见面聊游戏开发周期，我问现在立项时还是提议半年开发一款产品吗？同事呵呵两声回答，半年开发一款早就得卷地铺走人了，现在两周就得上线。着实吓了我一跳，原来他们现在是主攻小游戏，依赖完备的微信生态，快速产品，快速变现\n去年同事项目出了个爆款，公司整年有近3亿纯利，开发自然奖金不菲，当然也没有想像中那么多\n我思考他们的开发模式，直接模仿国外游戏，改头换皮，再稍加修改，上线。大多数产品肯定是上得快，死得也快。如此环境，对技术人员的成长有多少帮助\n绝大多数收益进入老板口袋，开发人员一直重复再重复，甚至有些游戏只是改了个名字，最后他们能得到什么？\n此类游戏业务简单，公司组织也扁平，尤其服务端，平台提供了各种服务，小游戏前端已经在喊着要干掉服务端的口号，不 管哪个开发岗位，在几年后，当面对新机会时，怎么阐述自己的价值，是抄得更快速？还是因为运气，出了多少爆款？\n由他而又思考到自己所谓的大公司，有人评价阿里工程师，说普遍被中间件惯坏了\n不是背后说人坏话，只是一种现象，可能是大公司人的普遍问题，进阿里是大多数技术人的梦想，包括我，但估计此生无缘，能力实在达不到阿里要求\n面试造火箭，入职拧螺丝；公司越成熟，基础建设就越完备、基建设施模块化程度越高，工具体验做得越好，平台做得越完善，那么对上层做业务来讲，底层细节也就屏蔽越多\n对业务来说本身是件好事，但对业务开发技术人员呢？有些领域技术变化很快，两三年可能迭代了好几轮，在深度、广度上有了质的飞跃，而你该怎么办，削足适履追求新技术吗？\n回顾自己技术实力时，脱离了这些基础设施，还有多少生产力？尤其微服务会打散各个业务线，可能一条完整的业务链路都理不清\n此时，还能有所得吗？得多少？褪去头顶公司光环，酒桌上的牛还能吹多大？\n所思有人说技术人就像丢在大海里的漂流瓶，努力漂泊，孤傲不羁，却怎么也不能融入大海，装不满自己空空如也的肚腩，因为他们不知道身体倾斜一点，才是最佳姿势，才有最快的装水速度\n也许真是远离技术看技术，才有更大的格局\n从事游戏开发很多年，一直觉得自己对游戏开发还是有见解的，但好像只是开发阶段的把握，而不是游戏本身的整体把握。\n早些年总是抱怨，为什么我们技术这么好，为什么游戏总是死呢？其实考虑面太窄，没想过运营，商务，维护，推广等等事项，手上有把锤子，到处只看到钉子了\n对于游戏类型，也很局限，最近看到一个外行人总结游戏类型，特别的汗颜\n\n依据不同的投入类型，我们可以把游戏分成三大类：\n1）反应。这类游戏，需要实时观察周围环境，并快速作出操作和应对。最典型的就是各种射击、动作、即时战略类游戏。\n2）策略。这类游戏，需要综合考虑各种可能性，对未来作出规划，并安排好下一步行动。典型如各种策略模拟游戏。\n3）沉浸。这类游戏，需要代入角色，理解和接受其世界观，阅读、记忆大量剧情，探索故事线。典型就是各种角色扮演游戏。\n游戏的玩法可以千奇百怪，类型可以随意组合，但好的游戏，对玩家的要求，基本都不出这三类\n\n这些只是单机玩法，大型网络游戏，还涉及到群体心理等等\n在游戏行业打拼多年，尽然没有一个外行总结到位，抽象高度太低太低\n技术里的世界不小，但技术外的世界更大\n是该放下手中的技术，抬头看看外面的世界\n功夫在诗外，也许再回头看技术时，别有一番天\n当然千万别一时亢奋放弃技术，远离技术是在追求技术无法再提升格局的时候，跳出来，回头看\n是从简入繁完成后，由繁化简的过程中的技法；无法打开一把锁时，不能只盯着锁看，因为钥匙可能在远离锁的地方\n那么如何远离技术呢？远离程度呢？也许多读书是个切入口，《关于读书》这篇文章也许对你有所帮助，如果能找到牛人指点更好。\n"},{"title":"拆完中台再拆微服务","url":"/blog/remove-the-micro-service-after-removing-the-middle-console.html","content":"这些年中台、微服务都是技术浪潮中的弄潮儿。两者的命运似乎是所有技术新词的缩影：先谈，再建，后拆，最后平静。\n如中台，开始时聊什么都得带上中台，战略层喜欢谈，执行层也喜欢谈，再后面跟随一线大厂纷纷搭建自己的中台，然后就是反思，拆除中台，最后平静看待中台。\n中台可以说已经经历完整的生命周期，而微服务周期也差不多，但对于“拆掉”，两者的声势与目标却不太相同。\n在《中台是什么》中提出，“效能下限”与“创新上限”就像翘翘板，产生了哑铃效应，而中台则是追求效能的极致，同时却也降低了创新上限\n建中台是为了效能，拆中台是为了创新。\n以阿里为代表的大厂对拆中台真是高举高打，但看看微服务，可没哪个大厂高喊要拆掉微服务，可见他们俩还是有本质差别的。\n更神奇的是，不管是拆微服务还是拆掉微服务，本质需求却是一致的：提升效能。\n为什么都是提升效能，从两种行为分别阐述一下\n为什么拆分微服务首先一起回顾一下，为什么要拆分微服务？对于这个问题不得不再向前回退，回到单体架构时代\n在微服务架构出现之前，单体架构是永恒，天经地义的。以致于“单体架构”一词都没人提出。\n项目起初，单体架构无疑是最佳选择，不仅易于开发、易于测试、易于部署，且由于系统中各个功能、模块、方法的调用都是进程通信，性能是最高的。\n甚至在项目从小型发展为中型时，也没有那么不堪。虽然是单体架构，但内部结构并非“铁板一块”，在业务量级可承载范围内，也有一定程度的扩展性。\n从两个视角观察扩展性\n在纵向角度，绝没有一个项目完全是个“大泥球”形态，至少都会以分层架构风格对代码进行纵向层次划分。\n在横向角度，单体架构也支持以功能、技术等维度划分，拆分成各个模块，以便代码重用和管理，甚至提取出各种形体组件，如jar\n那拆微服务解决了哪些效能问题？\n第一程序效能\n在于应用程序的某个方面给基础设施带来了过重负担，这反过来又很可能会导致糟糕的用户体验。\n如，图像处理需要大量CPU，如果CPU负载变得非常高，这将会导致应用其他处理资源的饿死现象。影响系统延迟，甚至影响系统可用性。\n也就是说应用程序中局部缺陷会造成全局问题。局部间没有隔离能力，一旦出现内存泄漏、线程爆炸、阻塞、死循环等问题，将影响整个程序。不仅导致单个功能不可用，甚至整个程序的效能都降至为零。\n从程序维护性来说，所有代码都在同一进程，无法做到单独停止、更新、升级某一部分代码。只能制定专门停机更新计划，整体做灰度发布，A&#x2F;B测试。\n第二团队效能\n与应用的关系不大，但关系到如何组织团队。在应用程序的特定部分，投入工作的人越多，开发和部署就会越慢，而且越容易出错。\n如，抢占持续部署同一服务，出现排队现象，意味着本可以交付产品的工程师只能坐等轮到他们进行部署。出事“紧急事件”时，多个团队代码都需要回滚。\n综上所述，简单总结一下，单体架构并不是一无是处，项目起始阶段依然是最佳选择；\n当对应用程序性能要求超过单机能力，以及软件的开发人员规模明显超过了“2 Pizza Team”时，不管是程序效能还是团队效能都已经达到瓶颈，此时可以通过微服务架构来解决这些问题。\n微服务怎么解决效能问题？对于程序效能，在单体架构时代，想要整体系统的可靠性，我们只能努力让每一个模块，每一行代码都可靠，以达到整体系统的最终可靠性。\n然而常常事与愿违，战术层面再优秀，也难以弥补战略层面的缺陷。在构建大规模系统时，人们的观念也从“尽量不出错”向正视“出错是必然”转变，在此前提下，历史悠久的单体架构终被挑战。\n微服务把独立的单体架构内部依赖组件，由“编译时期”推迟到了“运行时期”，对时间维度的解耦，带来了运行时动态扩展、服务间技术异构、服务独立交付等好处。\n也就解决了上面所述的局部间没有隔离能力造成的全局性故障，导致整体程序效能降至为零的情况。也实现了局部维护的能力，提升系统整体可维护性，保障系统整体可靠性与可用性。\n对于团队效能，系统不再是一块整体，团队更加独立地工作，独立地部署，从而发布更多产品。\n尤其在康威定律的指导下，划分组织边界以及服务职责范围，让组织之间更高效默契的沟通以及相互配合提升整体效益。\n为什么拆掉微服务微服务的确带来了很大的收益，不管在系统扩展性，还是在组织扩展性，都促使商业最大限度的规模化。\n然业务不是永远增长的，随着业务增长乏力，收益萎缩，需要探索新商业机会，原先高成长的业务团队规模也慢慢收缩，之前的服务系统也慢慢沦为遗留系统。\n从原先增长期的每个系统0.5人，到维护期每个人10个系统，服务与团队与康威定律极度不匹配。\n简而言之，在高增长期康威定律带来的所有收益，随着时间的推移，业务收缩，都变成了“遗留”团队的负债。\n所以需要拆掉微服务，改变服务边界以匹配团队边界，平稳回归康威定律。当然也不是彻底拆掉所有微服务回归单体架构。重点是重新调整职责范围，拆分成符合团队的服务边界。\n此时再回头看微服务概念时，当初纠结的“微”到底是多大的问题，已经完全不重要。微服务只是相对单体架构(Monolithic)的称呼，“微”不代表任何实际的内容。\n我们需要更多的关注“合适大小”，服务经过了恰当地设计，以满足其需求：它负责“合适数量”的功能。而且，至于什么是“合适”并不是一个静态的概念，它取决于团队，即团队的技能集、组织的状态、投资回报率（return-on-investment，ROI）的计算、持有成本以及该服务运行的时间点。\n简单总结一下，拆掉微服务，相对程序效能，更多的关注点在团队效能，服务边界匹配团队边界。其次，在整合团队，回归康威定律的过程中，业务流量也是在减少的，程序效能问题也再像扩张时期那么显著。\n总结一切技术都得服务于业务，而业务形态决定了技术形态。\n没有完美的业务，也必然没有完美的技术，只有两者相匹配时，才能相得益彰。\n不管是建，还是拆。都是适时的选择。架构只有顺应环境才能生存，最大化业务价值。\n参考拆掉微服务\n","tags":["中台","微服务"]},{"title":"接口隔离原则带来的复杂性","url":"/blog/complexity-brought-by-interface-isolation-principle.html","content":"ISP什么是ISP，之前总结过，详细内容可回顾《SOLID之ISP》\n简单总结：多餐少吃，不要大接口，使用职责单一的小接口。\njust so easy!\n不就是把大接口拆成小接口嘛！\n然而，最近在review之前的代码时，发现了点问题。\n简单介绍下背景业务知识，项目是处理发票业务，在公司报销过的人都了解，我们团建、出差，公办支出都会让商家开具一张发票，作为报销凭证。\n那么一张发票在被上传到报销软件，行为分为几个部分：\n1、上传识别：从一张发票图片，被OCR，识别出一份结构化数据\n2、修改：修改发票信息，包括删除、编辑识别出的发票内容，甚至手工填写一张发票信息\n3、验真：会调用国税接口，验证一下发票的真伪\n4、查询：查看发票详情\n每一部分都会有几个方法，为了避免胖接口，自然会拆分成职责更专注的小接口\n使用IDEA绘制出类结构：\n\nInvoiceVerifyService:表示发票验真职责\nInvoiceDiscernService:表示发票识别职责\nInoviceService:表示发票查询、编辑等职责\n思路清晰，结构中正。\n可在项目中却出现了一段这样的代码：\nif(invoiceService instanceof InvoiceVerifyService)&#123;    InvoiceVerifyService verifyService = (InvoiceVerifyService)invoiceService;&#125;\n\n看着instanceof关键字，就倍感别扭。要么抽象得不对，要么结构不对。\n如果没有拆分成三个接口，肯定不需要这样的判断。\n所以还得重新审视一下ISP。\nISP：接口隔离原则，里面两个关键词：“接口”和“隔离”；“隔离”相对比较简单，从单一职责角度，把职责不相关的行为拆分开。而“接口”则需要重新审视一下。\n接口其实每个人对接口的理解是不一样的，从分类上讲，大该两类，一是狭义：常被理解为像Java语言中的interface，或者模块内部的使用；二是广义：系统间交互契约。\nMartin Fowler给了两种类型接口：RoleInterface和HeaderInterface\n\nA role interface is defined by looking at a specific interaction between suppliers and consumers. A supplier component will usually implement several role interfaces, one for each of these patterns of interaction. This contrasts to a HeaderInterface, where the supplier will only have a single interface\n\n大致也是这个意思。\n广义主要是系统间交互的契约。类似于一个系统的facade对外提供的交互方式。\n就算你不设计接口，并不代表没有接口。不局限于语言层面的interface，而是一种契约。\n最重要的原则是KISS原则，最小依赖原则或者叫最少知识原则，让人望文知义。\n追求简单自然，符合惯例。\n比如一个微服务用户系统提供了一组跟用户相关的 API 给其他系统使用，比如：注册、登录、获取用户信息等。\n还包含了后台管理系统需要的删除用户功能，如果接口不作隔离，具体代码如下所示：\npublic interface UserService &#123;  boolean register(String cellphone, String password);  boolean login(String cellphone, String password);  UserInfo getUserInfoById(long id);  UserInfo getUserInfoByCellphone(String cellphone);    boolean deleteUserByCellphone(String cellphone);  boolean deleteUserById(long id);&#125;\n然而，删除操作只限于管理后台操作，对其他系统来讲，不仅是多余功能，还有危险性。\n通过使用接口隔离原则，我们可以将一个实现类的不同方法包装在不同的接口中对外暴露。应用程序只需要依赖它们需要的方法，而不会看到不需要的方法。\npublic interface UserService &#123;  boolean register(String cellphone, String password);  boolean login(String cellphone, String password);  UserInfo getUserInfoById(long id);  UserInfo getUserInfoByCellphone(String cellphone);&#125;public interface RestrictedUserService &#123;  boolean deleteUserByCellphone(String cellphone);  boolean deleteUserById(long id);&#125;public class UserServiceImpl implements UserService, RestrictedUserService &#123;  // ...省略实现代码...&#125;\n\n\n狭义狭义常被理解为像Java语言中的interface，或者模块内部的使用。\n单纯某一个接口，与单一职责一样，希望接口的职责单一，不要是胖接口、万能接口。\n模块内部设计时，不管是模块调用模块，还是模块调用第三方组件。\n我们一般有两种选择：\n一、是直接依赖所基于的模块或组件；\n二、是将所依赖的组件所有方法抽象成一个接口，让模块依赖于接口而不是实现。\n其实这在之前对面向对象反思的文章中，提到过，打开我们90%的项目，所有的service都有对应的service接口和serivceImpl实现，整齐划一，美其名曰，面向接口编程。\n然而，到项目生命周期结束，一个service都不会有两种实现。\n所以，建议还是直接依赖实现，不要去抽象。如无必要，勿增实体。\n如果我们大量抽象依赖的组件，意味着我们系统的可配置性更好，但复杂性也激增。\n什么时候考虑抽象呢？\n1、在需要提供多种选择的时候。比如经典的Logger组件。把选择权交给使用方。\n这儿也有过度设计的情况，比如数据库访问，抽象对数据库的依赖，以便在MySQL和MongoDB之间切换，在绝大数情况下，这种属于过度设计。毕竟切换数据库本身就是件小概率事件。\n2、需要解除一个庞大的外部依赖。有时我们并不是需要多个选择，而是某个依赖过重。我们在测试或其它场景会选择mock一个，以便降低测试系统的依赖\n3、在依赖的外部系统为可选组件时。这个时候可以实现一个mock的组件，并在系统初始化时，设置为mock组件。这样的好处，除非用户关心，否则就当不存在一样，降低学习门槛。\n\n\n回到文章篇头的问题，每个接口职责都是单一明确的，为什么还需要instanceof来判别类型？其实是更上层混合使用了\n类似于：\nMap&lt;String,InvoiceService&gt; invoiceServiceMap = SpringUtils.getBeans();\n\n客户端使用时，得拆分开：\nMap&lt;String,InvoiceVerifyService&gt; invoiceServiceMap = SpringUtils.getBeans();Map&lt;String,InvoiceService&gt; invoiceServiceMap = SpringUtils.getBeans();Map&lt;String,InvoiceDiscernService&gt; discernServiceMap = SpringUtils.getBeans();\n\n当需要具体能力时，可以从对应的集合中获取对应的Service。而不是通过instanceof去判断。通过空间的换取逻辑的明确性。\nVS SRP接口隔离原则跟单一职责原则有点类似，不过稍微还是有点区别。\n单一职责原则针对的是模块、类、接口的设计。\n而接口隔离原则相对于单一职责原则，一方面它更侧重于接口的设计，另一方面它的思考的角度不同。\n它提供了一种判断接口是否职责单一的标准：通过调用者如何使用接口来间接地判定。如果调用者只使用部分接口或接口的部分功能，那接口的设计就不够职责单一。\n总结表达原则的文字都很简单，但在实践时又会陷入落地时的困境。\n这些原则的背后，也体现了架构之道，虚实结合之道。从实悟虚，从虚就实。\n","tags":["SOLID"]},{"title":"新晋升管理者的几个坑","url":"/blog/several-pitfalls-for-newly-promoted-managers.html","content":"管理是一门实践科学，从“知道”到“做到”，还需要长期地刻意练习。\n管理有两个对象：一个是“事”，一个是“人”。\n“事”指的是目标，“人”指的是团队。也就是说管理有两大基本职责：一是达到目标，二是建设团队\n在担任管理职务之后，过去的业务思维和行为模式没有及时转变过来，则会在实际操练过程中，会碰到各种各样的问题，这是常态。\n如果提前知道前面有哪些“坑”是最容易踩到的，就可以提前规避，选择跨过去或绕过去。\n最近在读了几篇管理材料后，对于有哪些“坑”，做了简单的收集。\n《技术管理案例课》1、管理太细陷入微观管理；\n要么给部下制定出特别详细的解决问题细则，而不是给问下提出问题让他自己拿方案\n要么就是不停地去盯问下的进度和要求问下汇报工作，不等部下自己去思考和做事就先给一堆意见\n人的本性是要自由，要我的地盘我做主。\n要注意下属对自己话语权威性的追求和对自己是一个靠得住的人的自我认可\n2、大包大揽“与其等他做，我自己早就做完了”\n要么你不要把这件事交给下属做\n要么你就跟他说清楚他的责任，然后让他全权负责\n下属不吃点亏是长不大的。但这个“亏”必须是我们这个部门能承受的\n3、迷信流程误以为流程能解决一切问题\n要提高组织效率，不脱两层皮付出点代价是不可能的。\n我们真正的难点在于怎么用人，怎么拿捏流程不能处理的意外情况。\n想要用好人，首先就要了解这个人。知道每个下属擅长做什么？不擅长做什么？他在乎什么，反感什么？谁和谁搭配能够形成互补？这需要进行长期积累和挖掘。\n与其花大力气把这个人拗成你希望的样子，还不如专注在怎么用好他的长处。\n4、刷存在感邮件和会议里频繁出现，但很少看到他做关键决策\n必须问自己，为什么团队需要你来做经理，你给团队提供什么额外价值，你对于所管理的团队有推动感吗？\n对日常工作中的事情有了独立见解，也能做关键决策促进一些事情的解决，但没有长期目标，没有制定为了达到长期目标的阶段性举措。\n5、不能聚集对于多个项目，平均分配注意力\n要做成一件事，必须要聚集。如何判断有没有做到聚集？简单地说，就是你得有一个且只有一个目标。\n作为主管经理，在同一时间有好几个项目，你的主要精力只能放在其中一个项目上，绝对不要平均分配时间。\n6、不会说不对兄弟部门、上级领导无原则“认怂”\n有理有据，采用“不夸大，不缩小”的策略。\n对于老板的要求，可以问老板问题以获取更多信息。比如，你可以问老板：我们为什么要做这件事？你的具体期待是什么样的？我现在碰到的具体困难是这样的，如果你一定要做A，在不增加人手的情况下，我现在手头的B项目会受影响。\n\n《技术管理实战36讲》1、过程导向，被动执行管理思维：管理看结果，员工看动作。\n没有从“管理者”的视角出发，所以至少带来如下后果\n1、团队方向感缺失\n2、团队做不出有效的业绩\n3、无法带领一个团队\n2、大包大揽，唯我最强包工作、包责任、包功劳\n会带来如下后果：\n1、梯队问题\n2、激励问题\n3、个人发展问题\n3、带头大哥，当家保姆1、不职业的管理风格和文化\n2、团队没有方向\n4、单一视角，固化思维1、习惯性卡住\n2、认知层次低\n3、难堪重任\n5、自扫门前雪，固守边界角色和责任的边界划分，是为了分工和合作，但由于很多大型项目有赖于多个团队一起协作完成，所以双需要有人主动站出来，去承担边界模糊的那部分职责。\n作为员工边界分明无可厚非，但作为一个管理者，需要以全局的目标为己任，才能拿到公司要的业绩结果。\n否则会带来如下问题：\n1、项目推进不畅，从而影响全局的结果 \n2、自我设限，因此个人成长受限\n3、个人影响力无法扩展\n6、患得患失对此详细的解释在《做技术还是做管理》文章中已经描述。\n\n《不确定的危机下，做确定的业绩》管理认知不到位，会出现充当二传手、过度亲力亲为、充当救火队长等管理错位现象\n第一种：充当二传手上级有任务给到管理者，管理者就直接转给下属。\n下属有问题，管理者就让他直接找上级。\n上级和下属都觉得组织当中最没有价值的就是这种管理者。\n第二种：过度亲力亲为这种管理者责任心非常强，他认为自己既然是团队管理者，所有的工作都应该是自己的工作，就应该事事冲在前面，做出榜样给下属看。\n因此经常看到团队管理者玩命干，可他的员工却没事干。管理者的能力再强工作再忙，也不可能靠一己之力完成整个部门的业绩。\n第三种：充当救火队长由于没有事先分工，没有明确职责，没有设立流程，没有奖惩制度，没有充足训练，导致工作到处出问题。\n","tags":["管理"]},{"title":"架构与架构师","url":"/blog/architecture-and-architect.html","content":"究竟什么才是“软件架构”？架构师的工作内容究竟是什么？\n架构“架构”这个词给人的直观感受就充满了权力与神秘感，因此谈论架构总让人有一种正在进行责任重大的决策或者深度技术分析的感觉。毕竟，进阶到软件架构这一层次是我们走技术路线的人的终极目标\n应用程序有两个层面需求，第一类是功能性需求；第二类是非功能性需求\n\n架构的重要性就在于非功能需求，这些非功能需求决定一个应用程序在运行时质量，比如可扩展性和可靠性。它们也决定了开发阶段的质量，包括可维护性、可测试性、可扩展性和可部署性。\n架构设计的主要目标是支撑软件系统的全生命周期，设计良好的架构可以让系统便于理解、易于修改、方便维护、并且能轻松部署。软件架构的终极目标就是最大化程序员的生产力，同时最小化系统的总运营成本。\n\n软件的系统架构应该为该系统的用例提供支持；软件系统的架构设计图也应该非常明确地凸显该应用程序会有哪些用例\n\n\n架构设计不是与框架相关的，不应该是基于框架来完成，框架只是一个可用的工具和手段\n\n\n一个良好的架构设计应该围绕着用例来展开，这样的架构设计可以在脱离框架、工具以及使用环境的情况下完整地描述用例\n\n\n不管什么样的架构，它们都具有同一个设计目标：按照不同关注点对软件进行切割。也就是这些架构都会将软件切割成不同的层，至少有一层是只包含该软件的业务逻辑的，而用户接口、系统接口则属于其他层\n\n\n计算机系统的软件架构是构建这个系统所需要的一组架构，包括软件元素、它们之间的关系以及两者的属性\n\n\n所谓“架构”，是“以组件、组件之间的关系、组件与环境之间的关系为内容的某一系统的基本组织结构，以及指导上述内容设计与演化的原则”。之所以要确定系统的组件、组件关系以及设计与演化的原则，目的是通过不同层面的结构视图来促进团队的交流，为设计与开发提供指导。架构不仅仅是指我们设计产生的输出文档，还包括整个设计分析与讨论的过程，这个过程产生的所有决策、方案都可以视为是架构的一部分\n\n架构这么多定义，怎么描述架构呢？\nPhillip Krutchen在他经典的论文《Architectural Blueprints —The 4+1 View Model of Software Architecture》中提出了软件架构的4+1视图\n\n\n逻辑视图：开发人员创建的软件元素。在面向对象的语言中，这些元素是类和包。它们之间的关系是类和包之间的关系，包括继承、关联和依赖。\n\n实现视图：构建编译系统的输出。此视图由表示打包代码的模块和组件组成，组件是由一个或多个模块组成的可执行或可部署单元。在JAVA中，模块是JAR文件，组件通常是WAR文件或可执行JAR文件。它们之间的关系包括模块之间的依赖关系以及组件和模块之间的组合关系。\n\n进程视图：运行时的组件。每个元素都是一个进程，进程之间的关系代表进程间通信。\n\n部署视图：进程如何映射到机器。此视图中的元素由（物理或虚拟）计算机和进程组成。机器之间的关系代表网络。该视图还描述了进程和机器之间的关系。\n\n\n除了这四个视图以外，4+1中的+1是指场景，它负责把视图串联在一起。每个场景负责描述在一个视图中的多个架构元素如何协作，以完成一个请求。例如，在逻辑视图中的场景，展现了类是如何协作的。同样，在进程视图中的场景，展现了进程是如何协作的\n4+1视图是描述应用程序架构的绝佳方式。每一个视图都描述了架构的一个重要侧面。场景把视图中的元素如何协作串联在一起\n良好的架构有如下特点：\n\n独立于框架\n要被测试\n独立于UI\n独立于数据库\n独立于任何外部机构\n\n\n架构师架构师干什么？画PPT吗？写不写代码？\n首先，软件架构师自身需要是程序员，并且必须一直坚持做一线程序员，绝对不要听从那些说应该让软件架构师从代码中解放出来以专心解决高阶问题的伪建议\n软件架构师应该是能力最强的一群程序员，他们通常会在自身承接编程任务的同时，逐渐引导整个团队向一个能够最大化生产力的系统设计方向前进\n概括一下：\n有人讲【优秀程序员的价值,不在于其所掌握的几招屠龙之术,而是在细节中见真著】，那么架构师则不仅要有屠龙刀，还得有绣花针\n","tags":["架构师","架构"]},{"title":"时也势也","url":"/blog/time-and-potential.html","content":"古人云要成大事，必得天时、地利、人和\n天时是相当重要的，常读历史就知道，这世间太多的事犹如有无形之手，一切都是冥冥中有注定，都是在那些关键节点某人某事发生了\n前几天看到周鸿祎说的一段话：再给他1000万美金也无法复制360，再给李彦宏一亿美金也无法成功从零再做一个百度。很多时候所谓的成功都是马后炮，只不过在正确的时间做了正确的事\n正确的时间就是天时，但什么时候是正确时间，很难讲，可能真是天定。主持人康辉就讲过：其实所有后来被认为，给你带来这种高光时刻，带来肯定的机遇，都是回头看你才能说它是机遇，在此之前你永远无法预知你所谓的这个机遇到底在哪里。当这个所谓的机遇来到的时候，其实你只有去冲上去，把它做到它才会是你的机遇，否则它就是你的失败\n大到历史时刻，中到个人成功，就是小到个人做事，我都觉得时也很重要，时也是一种能量，势气\n去年公司帮TL报名参与了华为老师的一线经理人培训课，一直想整理总结一下，可到最近才腾出时间，不仅想单单总结那次课程，也想梳理一下自己走向管理的历程，想回顾一下几年前自己写的文章，有没有过总结，发现自己还写过一个系列文章《游戏小传》总共十篇\n\n看时间，尽然是在两个月内写完的，而且每一篇都不短，现在回看都感觉不太可能，文章里面的文字，有点不太相信是自己输出的\n我想这也许那时是一种时，造就了能写出这些文字的势\n所以有时，心里想干一件事，哪怕知道自己只有三分钟热度，也要凭着一时冲劲干起来，至少开始了，践行了，不再只是理论的层面\n\n回顾一下自己写博客的过程，也是一时兴起，磨磨蹭蹭坚持到现在\n为什么要写呢？在之前的文章《功夫在诗外》中也提到过\n“形成有效的输入输出系统，以输出倒逼输入”，“写作也记录下学习过程，防止狗咬尾巴”\n基于这么简单的初心，开始写作，把写作变成了一种习惯\n很多事情是想得清楚，但说不出来，说明还是没搞明白；有时说得清楚，但写不出来，说明没有懂透\n对于任何问题的思考，想清楚、讲清楚、写清楚是三个完全不同的维度。\n写作可以把一件事搞透，更重要的是写作也是一种反省，对知、或者自身的一种复盘\n后来不仅维护了自己的个人网站，还搞了公众号\n很多公号大V，在两三个月，甚至一个月就有了几万粉丝，他们也表述了写作的好处：结识了很多志同道合的朋友，增加了影响力\n相比他们，我实在微小得多，粉丝不到他们零头，也没有因此结识各种大佬，平平庸庸\n但也不是一丝丝回报都没有：自我感觉更充实、知识有意识的体系化、更善于总结问题、复盘反省\n自我充实写作起初，制定计划，一周写一篇，后来发现只能一月写一篇，再后来得逼自己，一月写两篇，不然年末总结，发现一年就写了12篇，太少了，如果一月两篇，再拼一拼，可以有30篇的输出，也差不多了,相对大V，数量少了很多，但这也是当前能力的体现，输入速度低于输出速度\n那么这30篇写什么呢？需要思考，需要回顾，需要总结，刚开始写时，会觉得有很多内容可以写，但写着写着就发现没内容可写了，怎么办呢？\n就需要平时多积累，多思考一些问题，不管是突发灵感，还是阶段性目标，都记到to do list中，这样to do list会越来越多，当没有内容时，就说明自己懈怠了，大脑没有思考，倒逼自己成长\n这样就有了很多可选写作主题，也有了很多学习目标\n不单要去温习旧知识，也得学习新知识，还得阶段性整理总结\n先不管这些是不是只是战术勤奋，至少也算是日拱一卒\n体系化这其实是上一个回报的延伸，当温习旧知识时，需要点、线、面、体四维；学习新知识时，得由浅入深，从广度推向深度\n在这两个维度学习的过程中，知识必须体系化，一是为了有东西有写，二是的确需要梳理知识树\n比如近期的《DDD》，对于这方面知识，以前也知道，但是东一块西一块，虽然学习中也发现了问题，但没有体系化解决，通过写作，算是把一些问题思考清楚了\n在《程序员成长体系》中，也提到得复用碎片化时间，体系化学习\n总结复盘对于这一点，还是差了很多，比如写作这件事，并没有常总结复盘，没有去刻意练习，现在写了不少，虽然不追求什么名气，成为大V，但写作能力还是需要成长的\n也写了几年了，回头翻看自己文章的次数很少，更别提去润色文章了，更加没有去刻意练习怎么写好一篇文章，只追求的在自我的世界，成长速度有限\n这不只是文章好不好，还要涉及运营，如果文章是产品，一个好产品不只是本身的质量，营销也是有必要的，推销自我也是一门学问\n就写作本身，什么是好文章？\n优秀的内容 + 清晰的结构 + 标题 &#x3D; 好文章\n什么是优秀内容：内容足够丰富，包含真正有价值的内容，不能含太多水分\n\n如果你写了一篇文章但是觉得内容很单薄，可以先当成一篇笔记存起来，等有了更丰富的积累之后再整理成文章。扩展文章内容的方法，并不是添加无意义的空话套话，而是根据文章探讨的问题延展开来。\n\n\n比如说介绍自己解决的一个老大难 Bug，可能真正修改的代码并没有几行，把过程讲出来也不过寥寥几段。这时候你就可以再分析一下 Bug 存在的原因，为什么一直拖到现在，再思考一下如何避免这类问题，遇到同类 Bug 怎样快速排查。这样自己想问题的角度更全面了，文章内容也更丰富了。\n\n\n比如你想介绍一项自己在学的新技术，发现自己写的东西其实就是官方文档的简化版，去重之后几乎什么都不剩了。这时候不要再继续抄文档了，把自己的思考总结先记下来，继续学习技术，持续记录新的内容，有更全面的了解之后，再写文章。\n\n清晰的结构：\n\n先想好标题，再划分好目录结构，再一段一段的填充内容，最后再润色一下连接部分。文章可以不按顺序看，也可以不按顺序写\n\n\n在平时工作的时候，可以建个文档库，把日常的一些琐碎的想法记录下来，随时写随时存。我是用手机的便签 App 随手记东西，比较喜欢它的语音转汉字功能，工作相关、生活相关，随时随地想起任何话题都可以记录下来。\n\n\n在有了明确话题，准备写文章之前，先把各种碎片化的记录收集起来，形成一份“素材”文档，然后梳理文章脉络，把素材应用进去。操作起来很简单，刚开始的时候会遇到前后不通畅的问题，那就不要直接复制素材的内容，重新换个表达方式写出来。多练习练习就好了\n\n好标题：\n现在太多的标题党，但标题党吸引眼球，这背后也有很多大脑科学\n\n第一个是数字法则，人的大脑和视觉系统在处理数字的时候，要比处理复杂的文字优先得多，如果你的文章里那些比较有亮点的数字、金额、排名、要点什么的，记得一定要把它们往标题上放，会让人感觉信息含量比较高。\n\n\n第二个是尽量通俗易懂地直接给出结论&#x2F;价值感，避免出现生僻、专业的词汇。能让普通人和专业人士都理解的标题，才叫好标题。\n\n\n第三个是建立好奇，要想办法让读者有兴趣、建立内容与受众之间的相关性\n\n\n再回到主题，时也势也，把握天时，在三分钟热度内，充分挖掘，形成一种势能，推动自己养成一种良好习惯\n","tags":["认知","写作"]},{"title":"架构与架构师2","url":"/blog/architecture-and-architect-2.html","content":"最近闲了，看了几次李运华关于架构的视频，不尽再次反问架构是什么？架构师的职责是什么？\n对于这两个问题，之前也总结过一篇《架构和架构师》，再结合他的专栏文章和视频，补充一下\n架构李运华给架构的定义：软件架构指软件系统的顶层结构，缩句成架构指结构，而结构的修饰语蕴含了太多东西，抽象不够直白\n这个定义里面蕴含了作者介绍的系统和子系统、模块与组件、框架与架构三组常见的概念\n\n系统泛指由一群有关联的个体组成，根据某种规则运作，能完成个别元件不能单独完成的工作的群体。它的意思是“总体”“整体”或“联盟”\n\n\n软件模块（Module）是一套一致而互相有紧密关连的软件组织。它分别包含了程序和数据结构两部分。现代软件开发往往利用模块作为合成的单位。模块的接口表达了由该模块提供的功能和调用它时所需的元素。模块是可能分开被编写的单位。这使它们可再用和允许人员同时协作、编写及研究不同的模块。\n\n\n软件组件定义为自包含的、可编程的、可重用的、与语言无关的软件单元，软件组件可以很容易被用于组装应用程序中。\n\n\n从逻辑的角度来拆分系统后，得到的单元就是“模块”；从物理的角度来拆分系统后，得到的单元就是“组件”。\n\n\n划分模块的主要目的是职责分离；划分组件的主要目的是单元复用。其实，“组件”的英文 component 也可翻译成中文的“零件”一词，“零件”更容易理解一些，“零件”是一个物理的概念，并且具备“独立且可替换”的特点。\n\n\n软件框架（Software framework）通常指的是为了实现某个业界标准或完成特定基本任务的软件组件规范，也指为了实现某个软件组件规范时，提供规范所要求之基础功能的软件产品\n\n\n软件架构指软件系统的“基础结构”，创造这些基础结构的准则，以及对这些结构的描述\n\n这么多的概念，在不理解的情况下，最多能记忆一小时吧，其实就算是理解了，最多也就记忆一天。因为这些概念比较虚，离我们具体coding有点远，但学习新知识又都是从定义起始，定义不理解时，就实践，再回看定义，可架构太大了，短时间没能力也没条件去架构设计\n而且这定义可是一位阿里P9级别多年经验总结归纳出来的，得行多少路，抽象了多少回，才有的认知，所以我也不打算靠记忆了，不过对于模块和组件的认知很独到\n虽然架构定义众家纷说，但对于如何描述架构还是有共识的，那就是“4+1视图”，在《架构和架构师》也描述了，也就是说架构的确需要从各角度观察和考虑\n想来还是喜欢ISO&#x2F;IEC 42010:20072 中对架构有如下定义\n\nThe fundamental organization of a system, embodied in its components, their relationships to each other and the environment, and the principles governing its design and evolution.　\n\n\n这里定义了架构的三要素：\n\n职责明确的模块或者组件\n组件间明确的关联关系\n约束和指导原则\n\n即架构是一种结构，是由组件（Components）+ 组件之间的关系 + 指导原则组成的\n在《code review》中也提了，万事要以降低代码复杂度为大计，先Review设计实现思路，然后Review设计模式，接着Review成形的骨干代码，最后Review完成的代码；到了架构设计更是得如此，落地到代码层面，也就是要解决代码要如何被组织的问题，以业务为核心，解耦外部依赖，分离业务复杂度和技术复杂度\n\n架构师架构说清楚了，那架构师呢？在《架构和架构师》中，也说了\n\n【优秀程序员的价值,不在于其所掌握的几招屠龙之术,而是在细节中见真著】，那么架构师则不仅要有屠龙刀，还得有绣花针\n\n但如何拥有屠龙刀和绣花针呢？架构师在国内，大多时候可能不是个岗位，而是个角色。大厂还有架构师一说，小厂难得有专职架构师，所以架构师职能还得多多取经大牛，学习一下大牛\n架构师能力模型\n这三部分好似是任何一个职业的三条腿，要像走向人生巅峰迎娶白富美，这三条腿都得硬，越往上走，尤其管理和业务\n技术只是技术人的最基本敲门砖，初级阶段以技术为重，往上走时，重点就得向后偏移，不能一直安静地码代码\n架构设计过程\n这个过程，回顾最近几个系统设计的确是这样的\n\n业务方提出一个业务，刚开始可能只是个目标，轮廓\n与业务方、产品不停的交流，交流得越深入，需求就越明确\n理解业务并明确需求后，划分模块，不管是传统画ER图，还是4色建模，找出实体以及他们的关系\n模块确定后，就是再深入细节，模块内部的业务流程，模块之间的交互\n最后整理，确定技术选型，输出设计方案\n\n之后，在架构落地过程中，随着业务进化，不停地演化架构，这些像上面说的宏观面的屠龙刀，绣花针就体现在细节，有时细节决定成败，架构师需要去识别哪些细节会影响到架构，以防后面不停地打补丁\n","tags":["架构师","架构"]},{"title":"架构与架构师3","url":"/blog/architecture-and-architect-3.html","content":"最近又看了几本关于架构的书籍，不禁回到原点：架构是什么？架构师职责是什么？\n架构在《架构与架构师2》中引用了1995年David Garlan和Dewayne Perry给出的定义：\n\n系统的组件结构，组件的相互关系，以及管控组件设计和长期演进的原则和指导方针\n\n十几年前，软件架构师只处理架构中的纯技术问题，像上面定义中的组件，可能是类，是包。而现在架构师承担着大量、宽泛的责任，并且范围还在不断扩大。尤其云时代，IT基础设施包括网络、数据中心、计算基础设施、存储，以及其他子系统都得考虑\n贴一张思维导图来说明软件架构涵盖的范围\n\n从图中可以看出，架构师的职责包含技术能力、软技能、运营意识及其他很多方面\n所以定义架构不是件轻松的事，Martin Fowler也都拒绝尝试对架构做出定义，退而引用名言：\n\n“架构是那些重要的东西…………无论它具体是什么”            —-  Ralph Johnson\n\n所以在行业内共识：对软件架构本身并没有一个好的定义。\n虽然架构很难定义，但我们总得尝试着描述它，分解它，进而更好地运用它指导软件开发。如果说软件世界更迭速度过快，组件化定义显得太陈旧，那我们需要一种与时俱进的思考软件架构的方式\nMark Richards与Neal Ford展示了这样的思考方式\n\n如图中所示：软件架构包含系统的结构、系统必须支持的架构特征、架构决策以及设计原则\n系统结构实现该系统的一种或多种架构风格（比如微服务、分层和微内核）\n\n仅仅描述结构并不能完整地诠释架构，还需要了解架构特征、架构决策和设计原则\n架构特征架构特征定义了系统的成功标准，这些标准往往与系统的功能正交\n\n在《架构与架构师》中，指出应用系统需要考虑两方面内容：一是功能性需求，二是非功能性需求。\n但从语言角度来看，将一个东西命名为非功能会带来负面影响：如何说服团队充分注意“非功能性”的东西\n另一个流行术语是质量属性，但它暗示的是事后质量评估而不是设计。\n架构特征描述了对架构以及整个系统的成功至关重要的关注点，同时又不影响其重要性。\n架构特征满足三个标准：\n\n明确非领域设计的某个注意事项\n影响设计的某些结构项\n是否对应用的成功至关重要\n\n\n构架决策架构决策定义了一组关于如何构建系统的规则，构成了系统约束，并指导团队哪些可以做，哪些不可以做\n\n比如在一个分层架构中，架构师可能会规定只有业务层和服务层可以访问数据库，限制表现层直接调用数据库。\n设计原则设计原则与架构决策的不同之处在于，设计原则是指导原则，而不是必须遵守的规则。\n\n在微服务架构中，开发团队应该使用服务间的异步消息传递来提升性能。\n架构定律虽然架构范围已经大到难以置信，但统一元素仍然存在。\n架构第一定律：\n\n软件架构中的一切都是在做权衡\n\n当架构师若认为自己发现了不需要做权衡的东西，很有可能他们只是还没有发现需要舍弃的东西而已\n通过结合架构的原则、特征等，我们对软件架构的定义超越了软件结构脚手架。架构不仅仅是各种要素的组合，还体现了架构第二定律：\n\n原因比方法更重要\n\n架构师面对不了解的系统时，可以探明这个架构是如何工作的，但会很难解释某个选择背后的原因。\n因此架构师需要去详细记录架构决策以及背后权衡的逻辑。\n架构师在之前的两篇文章中指出架构师必须要有屠龙刀还得有绣花针，需要技术+业务+管理三条腿。\n总之一句话，架构师是最牛的人。可一个团队不能人人都是架构师，况且还有资深工程师，技术专家。作为架构师与他们的区别是什么呢？能力模型有什么不同呢？\n决定一个人的强弱，是他的认知水平。对应技术人员就是对技术的认知。架构师的认知有四个阶段：\n\n愚昧之巅（不知道自己不知道）、绝望之谷（知道自己不知道）、开悟之坡（知道自己知道）和持续平衡的高原（不知道自己知道），这也是架构师的认知逐步提升的过程。\n如果人们对开发工程师的期望是把功能需求开发完成，那对架构师的期望就多样了\n一、制定架构决策\n架构师需要制定架构决策和设计原则，以指导团队、部门或者整个企业进行技术决策\n二、持续分析架构\n架构师需要持续分析架构和当前技术环境，然后给出改进建议。从整体上分析技术和问题域的变化，以确定架构的稳健性\n三、掌握最新趋势\n开发人员必须时刻关注技术更新，从而保证与这些技术与时俱进。对架构师来说，掌握最新的技术和行业趋势更为关键\n四、确保决策被遵守\n架构师需要确保架构决策和设计原则被遵守\n五、丰富的经历和经验\n架构师需要涉猎各种各样的技术、框架、平台和环境\n六、具备业务领域知识\n一个称职的软件架构师不仅要了解技术，还要了解问题背后的业务领域。没有业务领域知识，就无法理解业务的问题、目标和需求，也就不可能设计出有效的架构\n七、具备人际交往能力\n架构师需要具备出色的人际交往能力，其中包括团队合作、引导和领导力\n八、了解并驾驭政治\n架构师所做的几乎每个决策都会受到挑战。由于成本或工作量（时间）的增加，架构性决策将受到产品负责人、项目经理和业务利益相关者的挑战\n\n针对以上八点，以及技术+业务+管理三项技术人普实能力，可以更简洁地概述架构师自身定制的三条腿：技能+影响力+领导力\n1.技能是实践架构的基础。它需要知识以及应用知识的能力\n2.影响力用来衡量架构师在项目中应用技能后给项目或公司带来多大的效益\n3.领导力确保了架构实践的状态能稳步向前推进，同时培养更多的架构师\n能力模型论能力模型，与开发人员之间对技术方向的侧重有所不同。开发人员必须拥有很深的技术深度，但软件架构师必须具有非常广的技术广度才能像架构师般思考，并以架构的角度看待事物。\n以知识金字塔展示世界上所有技术知识的类别，事实证明，技术人员应重视的信息类型随职业阶段的不同而不同\n\n“已知”指代技术人员日常工作用到的技术、框架、编程语言和工具\n“已知的未知”指代技术人员稍微了解或听说过，但没有掌握的技术\n“未知的未知”是金字塔中面积最大的部分，指代能够完美解决技术人员面临的问题的技术、工具、框架和编程语言，但是技术人员甚至都不知道它们的存在\n开发人员的早期职业生涯专注于扩展金字塔的顶端，积累经验和专业知识。金字塔顶端的知识需要投入时间才能保持专业。最终，金字塔顶的大小就是个人的技术深度。\n\n而随着开发人员过渡到架构师角色，知识的性质也发生变化。架构师的价值很大一部分是广泛地理解技术，并且知道如何利用技术解决特定的问题。对架构师来说，最重要的部分是金字塔的顶部和中间部分\n\n中间部分与底部交汇处的长度代表了架构师的技术广度\n作为架构师，技术广度比技术深度更重要。因为架构师的职责就是根据功能做出与技术限制相匹配的决策，所以广泛了解了解各种解决方案是非常有价值的\n\n架构师需要“博而不专”，牺牲技术深度来提高技术广度，虽然技术人都想在多个领域保持专业深度，但结果往往事与愿违，甚至无一成功。\n对于能力模型为啥有区别，简单总结一下：\n广度决定能找到的方法+深度决定选择方法的正确性+经验决定找到正确方法的速度\n平衡编码虽然架构师的能力模型与开发工程师有所不同，但还是需要保持动手编写代码，并保持一定水平的技术深度。\n正好之前所说，不仅要有屠龙术，还要会瓷器活。\n因此架构师面临的困难任务之一是如何在动手编码和软件架构之间取得平衡。\n如果参与过多的编码工作，可能会陷入瓶颈陷阱。也就是当架构师在项目的关键部分（通常是基础框架代码）中拥有代码所有权并成为团队的瓶颈时，就会发生瓶颈陷阱。\n避免瓶颈陷阱方法之一是将关键路径和框架代码委托给开发团队其他人员，然后着重于实现业务功能（一个服务），并且在1~3个迭代中完成。\n如何保持编码能力和一定水平的技术深度呢？\n一、频繁进行概念验证（POC），这种做法不仅要求架构师编写源代码，还要求架构师能够通过考虑细节来帮助验证架构决策\n二、处理一些技术债或架构相关的故事问题，使开发团队腾出精力来处理关键的功能性的用户故事；或者在迭代中修复bug，能使架构师识别出存在于代码甚至架构中的问题和弱点\n三、创建简单的命令行工具和分析器进行自动化来帮助开发团队完成日常任务\n四、进行频繁的代码审查，通过代码审查能确保代码符合架构规则，并在团队中进行指导和辅导\n总结架构定义是件不容易的事，软件发展日异月新，架构的范围也日益扩大，进一步加据了定义架构的难度。但无论如何，我们还是有必要通过结构化思维去分析架构，进化古老的组件化定义，从架构结构、架构决策、架构特征以及设计原则四方面描述架构，继而明确架构师的职责，区别与开发工工程师的能力模型，加强“技能+影响力+领导力”三条腿能力成长，更好地服务架构。\n","tags":["架构师","架构"]},{"title":"架构如何迭代演进","url":"/blog/how-does-the-architecture-evolve-iteratively.html","content":"最近看完了一本大佬很早就推荐的书：《演进式架构》\n\n现在看已经算是一本很老的书了，里面的很多概念对架构师来讲已经算是耳熟能详了。\n如果你没有一些常识性思考，那还是可以看看的，如果没有时间，我通过这篇读书笔记梳理了书中的核心知识点，结合最近的一些新书观点，方便你快速获取这些知识。\n\n\n演进式架构架构的定义每一本讲架构的书籍，基本都要先阐述一下，然而很书籍都给出了相同的答案，那就是Ralph Johnson的定义：\n“架构是那些重要的东西…………无论它具体是什么”\n这本书也没有例外。想了解最新架构及架构师解读，可以阅读最新的一本书籍《软件架构》读书笔记\n何为演进式架构架构的第一定律是：架构中的一切都是权衡\n架构师在很多方面和骑独轮车的人一样，不断地平稳以适应环境变化。\n然而架构师无论怎么努力，软件依然出现两个突出的问题：\n架构构建完成后，会出现退化叫架构比特衰减，我们也称为架构腐化。\n软件组成部分随着时间推移变得愈发脆弱和难以变更。\n如何应对，演进式架构应运而生：演进式架构支持跨多个维度的引导性增量变量，主要由三方面构成：增量变更、适应度函数、适当的耦合。\n增量变更增量变量描述了软件架构的两个方面：如何增量地构建软件和如何部署软件\n引导性变更一旦架构师选择了重要的架构特征，他们会把变更引导进入思想史，以保护这些重要特征。\n何为架构特征：在《软件架构》有详细描述，可看上面提到的读书笔记。\n怎么保护这些架构特征，引入“适应度函数”，该函数是一种目标函数，用于计算潜在的解决方案与既定目标的差距。在演化计算中，适应度函数决定一个算法是否在持续提升。\n适应度函数的隐喻涵盖多种机制，包括度量、测试和其他检验工具。为某些架构特征提供了客观的完整性评估。也体现了系统架构特征的保护机制。\n多个维度软件架构师往往关注技术架构，但那只是软件项目的维度之一。\n除了技术，还有可审计性、数据、安全性、性能以及伸缩性等关键特征。我们强调架构整体的重要性，技术架构耦合以及数据耦合都影响架构演进，耦合不仅仅是项目的结构元素，甚至团队结构对架构都有着影响，所以才有了康威定律与逆康威定律。\n适当的耦合很多架构师认为耦合是必然之恶，但如果不依赖其他组件（并与其耦合）又很难构建复杂的软件。因此不能有耦合创伤应激障碍，对耦合有条件反射式恐惧。要客观看待耦合，并且要以最小的开销和成本最大程度地获益。\n谈到耦合，必谈模块化。平台不同，代码复用机制也不同，但它们都支持将相关代码组成模块。模块化描述了相关代码的逻辑分组。可以以不同的物理方式封装模块。组件就是模块的物理封装。模块意味着逻辑分组，而组件意味着物理划分。\n拆分组件有助于一些工程实践，例如构建和部署。库是一类组件，它往往和调用代码在相同的内存地址内运行，通过编程语言的函数调用机制进行通信。别一类组件被称为“服务”，如微服务，运行期依赖。\n所有模块化机制都有助于代码复用，在任何级别尝试复用代码都是明智的选择，无论单一的函数，还是封装好的业务平台。\n量子是物理实体相互作用时所涉及的最小单位。架构量子则是具有高功能内聚并可以独立部署的组件，它包括了支持系统正常工作的所有结构性元素。\n如现在火热的DDD中，其中限界上下文的概念，所有领域相关内容在该领域同可见，但不对其他限界上下文可见。\n构建演进式架构的关键之一在于决定自然组件的粒度以及它们之间的耦合，以此来适应那些通过软件架构支持的能力。\n架构师一直在与耦合斗争，架构一直在演进，最原始的大泥球架构进化到单体分层架构再到微服务架构。\n在重建昂贵的架构之前，提升现有架构的模块程度能让架构师获益。如果已经没有可以提升的地方了，那么这便是开始重建更加复杂的架构好时机。\n实践演进式架构从何开始实践？不仅实践演进式架构，其实实践其他任何架构都有一些通用策略：\n1、容易实现的目标：将风险降至了最低，但可能牺牲价值。\n2、最高价值优先：原因一：选择价值最高的部分表明决心。原因二：能明确演进式架构的长远价值。原因三：用最有价值的部分来审查此架构方法，能够为是否继续提供可行的数据。\n构建可演进的架构会耗费额外的时间和精力，但好处是公司可以应对市场的重大变化，而不需要大量返工。\n总结简而言之，《演进式架构》提供了一种架构迭代的指导方法，就如同重构代码一样。\n首先要有目标，以终为始，知道架构最终形态。也就是引导性变更。\n其次需要模块化，提升扩展性，这是演进式架构的基础，寻找最合适的组件粒度，对于大泥球架构，整体应用就是架构量子，没法迭代式增量变更。\n最后要有适应度函数，才能保障演进的正确与成功。就如同重构，得有UT的保障，不然谁敢重构，并且知道演进的效果。\n","tags":["架构"]},{"title":"架构师如何看待统一语言","url":"/blog/how-do-architects-view-unified-language.html","content":"DDD统一语言统一语言，最早听到这个概念是在学习DDD的时候。\n统一语言在DDD中，是一个很重要的概念。\nDDD中的几个大词：问题域，解决域，战略，战术，统一语言，界限上下文\n\n\n\n对于网上的这个版本，我不太认同，把图修改一下：\n\n因为统一语言是贯穿整个过程的，不仅要有战略高度，也得有具体战术措施。\n\n在实践DDD的过程中，虽然明白统一语言重要性，但似乎更多的还是关注在编码实施。\n引起的行为大致包含：\n\n技术人员使用业务人员的用语作为开发词汇\n技术人员要将这些词汇映射到代码实现中\n业务词汇整理出来，并随着项目发展一点点修正扩展\n\n希望能达到代码既模型，代码既文档。主要还是为了代码。\n通过这些理论的学习，至少可以规避一些问题：\n1、销售订单上可不可以增加是否投诉字段？从客服角度，必须要加上，你作为系统设计者同意这个需求吗？\n2、变更了profile上的买家地址，销售订单上的买家地址怎么也跟着变化了？\n知识消化然而，在《领域驱动设计模式的收益与挑战》中提到，其实代码是次要的，DDD中更核心的是知识消化。\n\n1、业务方与技术方沟通业务需求，在交流中，对部分业务知识达到共识，这部分交流语言被标准化为统一语言；\n2、在不断地交流中，对于双方达成共识部分，凝炼成到模型中，对模型review，以确定描述了业务实际情况，发现缺乏或不适当概念时，进行修正，指取新的统一语言；\n3、当模型确认后，以模型为样本，使用代码实现它；\n4、上面是正向流程，技术方在重构代码时，也会同步修改模型，进来提取出新的统一语言，反哺业务方。\n5、通过正逆流程，达到修改统一语言就是修改模型，修改模型也就是修改代码；修改代码也是修改模型，修改模型也相继修改统一语言。\n6、这样打破了知识壁垒，给予业务方与技术方一种更好的协同方式。这就是DDD的精髓。让分析模型与实现模型融合了，不再像以前的方法一样分裂。\n\n架构统一语义统一语言的认知似乎就这么多了，有没有更高层次的洞见呢？最近学习了《郭东白的架构课》，发现统一语言还真没那么简单。\n正如上面所说，之前更多的还是停留在编码实施层面。虽然整个项目参与方很多，但因为认知层次低，所以眼中只看到了产品经理和研发，因此统一语言的使用范围也被局限在了一个很小的规范内。\n而把视野提升到一个大型项目的架构师角度。统一语言有了更高的价值。\n郭东白讲不是统一语言，应该称为统一语义。我们要的是在语义环境中统一，而不单单是语言环境。\n以实践DDD的经验，可以理解为人的语言和计算机语言的维度，并且语义是相同的。因为希望代码即模型，代码即文档。项目参与者交流的都得体现在代码中。所以姑且称为统一语言涵盖语言和语义，不纠结两者的称谓统一。\n站到整个架构活动的层次上，项目的参与者就不仅仅是产品经理和程序员。事项也只是把代码写好。统一语言也不止存在于需求、模型、代码。\n从整个项目视角看待，架构师需要拉通所有参与者：业务方，主要执行者，其他参与者，时刻对齐目标。让所有人的信息通畅，协作高效。\n1、架构活动的目标，能够清晰传递并分解给每个参与者；\n2、所有参与者的诉求，能够被准确地表达、记录和传递；\n3、架构活动的目标和所有需求，能够反映到整体的架构规划中，并且能够被无损地拆分到多个子领域的任务中；\n4、需求方能得到执行者的真实反馈，从而对整个架构活动的产出有个合理的期望；\n5、每个子领域交付并组装好之后，能够语义契合、相互兼容，最终符合思想史活动的整体目标。\n结合上面的知识消化过程，整合后，如下图所示：\n\n为什么会有语义的分歧？1、语境不同\n如上面提到的为什么销售订单上不能增加投诉字段\n2、认知不同\n一种事物，从一个人的思维中，到表达出来，再由另一个人通过表达理解，并融入到自己的思维中，常常是有损的。\n所以在一个大型的架构活动中，团队内部都会有理解偏差，更何况跨团队，跨业务。\n如何消除语义分歧？1、发现不同的语境\n2、定义概念\n上面知识消化图中，有一个方块叫统一语言提案，原因在于不是某个人直接定义一个语义，让所有人遵循。而是群策群力，深度思考和不断探索的过程。\n3、语义建模\n通过第2步定义概念，需要把不同概念引入到同一个语境中，也就是将两个不同的语境进行合并。\n如上面的销售订单，指的是售中阶段的订单，而非售后阶段，所以不能增加是否投诉字段。\n4、反馈修正\n如第2步一样，自己的认知通常是存在于自己语境中的认知，要与所有人重新确认并多次调整，才能找到基本正确的统一语境。\n5、公布、维护和使用统一的语境\n不断使用和打磨实体定义，为企业带来统一语境。从自然语言到需求描述、到域模型定义过程，延伸到接口定义、模块设计、代码实现等等。\n\n总结最后简单总结一下：\n站高一个层级，提升一个维度，同样的内容就看出的更丰富的内涵。\n从一个兼职架构师提高到大型跨域项目的全职架构师，就不再是产品经理与研发之前围绕着需求的沟通，而应该再往前看，产品经理的前面还有真正的业务方，整个架构的目标。\n使整个项目所有参与者的需求能够无损地表达、记录和传递。促使项目整体架构在一个逻辑完备和语义一致的环境中，确认整个架构的完整性，提升项目的成功率。\n","tags":["DDD","架构师"]},{"title":"架构的本质是业务的正交分解","url":"/blog/the-essence-of-architecture-is-orthogonal-decomposition-of-services.html","content":"七牛CEO许式伟讲：架构的本质是业务的正交分解。\n好独特的见解。\n做架构到底是做什么？在《首席架构师的打怪升级之路》中提到：架构师是具备架构能力的人，架构能力是指为相对复杂的场景设计并引导一个或多个研发团队，来实施结构化软件系统的能力。\n关键信息：复杂场景结构化\n在《软件设计之美》中总结了软件复杂性来自业务复杂性和技术复杂性。应对的办法是通过分而治之，控制规模大小；保持结构清晰与一致性来降低认知负荷。并且要有一定的前瞻性，拥有可扩展性，能应对变化。\n关键信息：规模可控、结构清晰、应对变化\n总结以上两篇的关键信息：做架构就是通过规模可控、结构清晰的小模块去组合成大模块，进而形成更复杂的软件系统。并且拥有足够的扩展性应对未来的变化。\n架构的核心就是【组合与应对变化】；简洁点，三个字：“分、合、变”。\n这些其实与“业务的正交分解”方法是一脉相承的。\n正交分解既然是业务的正交分解，自然得理解正交是什么意思？\n在《应对变化》详细介绍过正交设计。\n简而言之，主要是三个要点：\n1、消除重复\n2、分离关注点\n3、管理依赖：缩小依赖的范围和向稳定的方向依赖\n想要把一个复杂的系统拆解成一个一个可被理解掌控、并且又能被结构化地合并成大模块的小模块。正交设计是必须的。\n这考验了架构的拆解能力，拆解的合理性就是解耦的合理性；并能在合并时每一个模块保持高内聚。\n开闭原则正交设计主要应对的是“分、合”，那么怎么应对“变”？\n就得提到著名的开闭原则。开闭原则是架构治理的根本哲学。\n之前也整理了下OCP原则，《SOLID之OCP》，只要我们面向接口编程，就能大概率的符合开闭原则。当时的理解回头看还是比较肤浅的。\n一些人对开闭原则的错误解读，认为开闭原则不鼓励修改软件的代码来响应新需求。这显然比较极端。\n一个软件产品只要在其生命周期内，就会不断发生变化。变化是一个事实，需要让软件去适应变化。我们应该在设计时尽量适应这些变化，以提高项目的稳定性和灵活性，真正实现“拥抱变化”。\n其实，开闭原则的背后，是推崇模块业务的确定性。可以修改模块代码的缺陷，但不要去随意调整模块的业务范畴，增加功能或减小功能都不鼓励。这意味着模块的业务变更是需要极其谨慎的，需要经得起推敲的。\n开闭原则指出尽量通过扩展软件实体的行为来应对变化，满足新的需求，而不是通过修改现有代码来完成变化，它是为软件实体的未来事件而制定的对现行开发设计进行约束的一个原则。\n总结一下，开闭原则就两点：\n1、模块的业务要稳定。当要修改模块业务时，不如实现一个新业务模块。而实现一个新的业务模块来完成新的业务范畴，是一件轻松的事。这个角度，鼓励写“只读”的业务模块，一经设计不可修改。需要变化不如把它归档，放弃掉。这种模块业务只读的思想，是架构治理的基础哲学。\n2、模块的业务变化点，简单一点，通过回调函数或者接口开放出去，交给其他业务模块。复杂一点，通过引入插件机制把系统分解为“最小化的核心系统+多个彼此正交的周边系统”。\n\n将开闭原则应用到业务系统。业务对外只读，意味着不可变，但不变的业务生命周期是很短暂的，所以要可扩展。要扩展还要不变，就你倒逼着要做兼容，而兼容可能导致现有的功能职责不单一，这又倒逼着要对现有的功能做再抽象，以适应更广的“单一职责”。\n\n\n所以不改是不可能的，只是改的结果应当是让项目往更稳定方向发展，而这很难。无论是新的抽象还是职责范围的扩张，需要强大的分析能力和精湛的设计。\n\n这种不变与变其实也印证了架构第一定律：一切都是权衡\n","tags":["架构"]},{"title":"树概述","url":"/blog/tree-overview.html","content":"树的类型不少，此篇简要对树进行描述，脑中有个整体概念，细节分篇再研究\n树树（Tree）是n（n&gt;&#x3D;0）个结点的有限集。\n在任意一棵非空树中：\n（1）有且仅有一个特定的称为根（Root）的结点；\n（2）当n&gt;1时，其余结点可分为m（m&gt;0）个互不相交的有限集T1，T2，…，Tn，其中每个集合本身又是一棵树，并称为根的子树（SubTree）\n\n术语\n\n\n结点：如上图，每一个圈圈我们就称为树的一个结点\n度: 结点拥有的子树数称为结点的度-(Degree)，树的度取树内各结点的度的最大值\n叶结点(Leaf)或终端结点: 度为0的结点\n内部结点: 度不为0的结点称为分支结点或非终端结点，除根结点外，分支结点也称为内部结点。5. 结点间的关系：结点的子树的根称为结点的孩子(Child)，相应的，该结点称为孩子的双亲(Parent)，同一双亲的孩子之间互称为兄弟(Sibling)。结点的祖先是从根到该结点所经分支上的所有结点\n深度：树中结点的最大层次称为树的深度(Depth)或高度\n结点的层次(Level): 从根开始定一起，根为第一层，根的孩子为第二层。其双亲在同一层的结点互为堂兄弟\n有序树: 如果将树中结点的各子树看成从左至右是有次序的，不能互换的，则称该树为有序树, 否则为无序树\n森林(Forest): 是 m(m&gt;&#x3D;0)棵互不相交的树的集合。对树中每个结点而言，其子树的集合即为森林\n\n二叉树二叉树(Binary Tree)是n(n&gt;&#x3D;0)个结点的有限集合。该集合可能是空的（空二叉树），也可能由一个根结点和该根结点的左子树和右子树组成。左右子树不相交，而且都是二叉树\n特点\n每个结点最多有两棵字树，即每个结点的度和树的度不大于2。\n结点的左子树和右子树是有顺序的，不能颠倒。\n即使结点只有一棵子树，也是有顺序的\n\n\n满二叉树除最后一层无任何子节点外，每一层上的所有结点都有两个子结点。也可以这样理解，除叶子结点外的所有结点均有两个子结点。节点数达到最大值，所有叶子结点必须在同一层上\n完全二叉树若设二叉树的深度为h，除第 h 层外，其它各层 (1～(h-1)层) 的结点数都达到最大个数，第h层所有的结点都连续集中在最左边，这就是完全二叉树\n\n之前讲过的《堆排序》 就是依赖完全二叉树结构\n二叉查找树二叉查找树(Binary Search Tree)，又被称为二叉搜索树\n（1）若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；\n（2） 若任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；\n（3） 任意节点的左、右子树也分别为二叉查找树；\n（4） 没有键值相等的节点\n\n复杂度\n复杂度分析：它和二分查找一样，插入和查找的时间复杂度均为O(logn)，但是在最坏的情况下仍然会有O(n)的时间复杂度。原因在于插入和删除元素的时候，树没有保持平衡\n平衡二叉树平衡二叉搜索树，又被称为AVL树\n由于普通的二叉查找树会容易失去”平衡“，极端情况下，**二叉查找树会退化成线性的链表，导致插入和查找的复杂度下降到 O(n) **，所以，这也是平衡二叉树设计的初衷。\n具有以下性质：\n\n要么是棵空树，要么其根节点左右子树的深度之差的绝对值不超过1；\n其左右子树也都是平衡二叉树；\n二叉树节点的平衡因子定义为该节点的左子树的深度减去右子树的深度。则平衡二叉树的所有节点的平衡因子只可能是-1,0,1\n\n红黑树红黑树是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。它是在1972年由Rudolf Bayer发明的，他称之为”对称二叉B树”，它现代的名字是在 Leo J. Guibas 和 Robert Sedgewick 于1978年写的一篇论文中获得的。它是复杂的，但它的操作有着良好的最坏情况运行时间，并且在实践中是高效的: 它可以在O(log n)时间内做查找，插入和删除，这里的n是树中元素的数目\n特性\n每个节点要么是红色，要么是黑色。\n根节点永远是黑色的。\n所有的叶节点都是空节点（即 null），并且是黑色的。\n每个红色节点的两个子节点都是黑色。（从每个叶子到根的路径上不会有两个连续的红色节点）\n从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点。\n\n\n为什么需要红黑树平衡二叉树的插入&#x2F;删除操作带来的旋转操作可能会达到logn次\n红黑树的插入操作最多进行两次旋转、删除操作最多进行三次旋转\nB树B树是一种平衡的多路查找树，结点最大的孩子数目称为B树的阶（Order），是为磁盘存储而专门设计的一类平衡搜索树\nb-tree分为用“阶”的定义和用“度”的定义，度和阶都是描述子节点的数量的\n特性\n定义任意非叶子结点最多只有M个儿子；且M&gt;2；\n根结点的儿子数为[2, M]；\n除根结点以外的非叶子结点的儿子数为[M&#x2F;2, M]；\n每个结点存放至少M&#x2F;2-1（取上整）和至多M-1个关键字；（至少2个关键字）\n非叶子结点的关键字个数&#x3D;指向儿子的指针个数-1；\n非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]；\n非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树；\n所有叶子结点位于同一层；\n\n\n这是B树存储在硬盘的逻辑结构图。\n其中根节点中17，35在称为关键字(key) ，实际中往往附带更多复杂类型数据。\n可以看出一个节点包含 keys  ChildNotePointer  2部分信息\n为什么需要B树\n当数据量大的时候，树的高度会比较高，数据量大的时候，查询会比较慢\n树每个节点只存储一个记录，可能导致一次查询有很多次磁盘IO\n\n\n这是个典型的b树结构，初始因子为1000，高度仅为3的b树，就可以存储1002001000的数据了\n假设要查询最后一个数据:\n\n从硬盘加载根节点搜索，IO一次。\n根据根节点的指针信息，去加载第二层的节点， IO一次。\n重复2，IO一次。IO只用了3次，就查询了需要的数据，所以说B树效率是非常高的。\n\nB树的节点，在硬盘里表现为：柱面里的页(page)或盘块(block)，如果把索引持久化到内存，只需要一次就够了\nB+树B+树是B-树的变体，也是一种多路搜索树：\n\n其定义基本与B-树相同\n非叶子结点的子树指针与关键字个数相同（B树中是k-1个元素）\n非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）；\n为所有叶子结点增加一个链指针\n所有关键字都在叶子结点出现\n\n\nB+的搜索与B-树也基本相同，区别是B+树只有达到叶子结点才命中（B-树可以在非叶子结点命中），其性能也等价于在关键字全集做一次二分查找\nB树：有序数组+平衡多叉树\nB+树：有序数组链表+平衡多叉树\nB+树的关键字全部存放在叶子节点中，非叶子节点用来做索引，而叶子节点中有一个指针指向一下个叶子节点。做这个优化的目的是为了提高区间访问的性能。而正是这个特性决定了B+树更适合用来存储外部数据\n为什么需要B+树\nb+树的中间节点不保存数据，所以磁盘页能容纳更多节点元素，更“矮胖”；\nb+树查询必须查找到叶子节点，b树只要匹配到即可不用管元素位置，因此b+树查找更稳定（并不慢）；\n对于范围查找来说，b+树只需遍历叶子节点链表即可，b树却需要重复地中序遍历\n\nB*树B*树是对B+树进行的又一次的升级。在B+树的非根和非叶子结点再增加指向兄弟的指针\n\n在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1&#x2F;2提高到2&#x2F;3；\n在这比如说当你进行插入节点的时候，它首先是放到兄弟节点里面。如果兄弟节点满了的话，进行分裂的时候从兄弟节点和这个节点各取出1&#x2F;3，放入新建的节点当中，这样也就实现了空间利用率从1&#x2F;2到1&#x2F;3。\n总结B树：二叉树，每个结点只存储一个关键字，等于则命中，小于走左结点，大于走右结点\nB-树：多路搜索树，每个结点存储M&#x2F;2到M个关键字，非叶子结点存储指向关键字范围的子结点；所有关键字在整颗树中出现，且只出现一次，非叶子结点可以命中；\nB+树：在B-树基础上，为叶子结点增加链表指针，所有关键字都在叶子结点中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中；\nB*树：在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1&#x2F;2提高到2&#x2F;3；\n参考资料B-树学习笔记\n","tags":["DataStructure"]},{"title":"架构师眼中的正交设计","url":"/blog/orthogonal-design-in-the-eyes-of-architects.html","content":"正交设计，什么是正交设计，在之前的几篇文章中，《架构的本质是业务的正交分解》、《应用对变化》都有学习记录。\n这两篇文章越看越感觉有道理：\n1、系统应该被分解为“最小化核心系统 + 多个彼此正交的周边系统”\n2、消除重复\n3、分离关注点\n4、管理依赖：最小化依赖、向稳定方向依赖\n对于这四个策略的理解，感觉自己的认知层次还是太低了。更多的时候还是在作为编码原则。而非架构原则。\n在《架构师的自我拯救》提出了技术人员的商业价值，包括两部分：快速试错和快速规模化。\n那么我们能在企业的竞争中做些什么，同时也自己创造增量价值呢？其实也被包含在这两方面。\n比如快速试错。为什么需要快速试错？为了验证商业想法是否能得到市场认同，从而获得商业价值。必然需要高速响应业务和技术的需求。\n这面临的挑战就是交付时间压力。市场不等人，竞争对手也不等人。\n除了战略层面的尝试方向对不对，如果有人承诺方向一定对，那自然不用试错，直接火力全开，饱和式攻击就行。\n绝大多数情况是没人担保的，只能尝试。对应到技术人员，挑战在于只是很小的一次尝试，不要把系统改得面目全非。\n对应到架构，就是我们系统的得符合“开闭原则”。能稳住核心系统的不变性，又能保持系统有序的增量。把大多数的尝试尽量封装到一个小的领域内。不会因为多次的业务尝试，导致系统随着时间变得混乱。\n想要做到这些，需要如下架构原则：\n1、单一职责，把每个业务尝试封装到一个单一模块中。一旦尝试失败，就可以迅速把业务逻辑下线，避免影响整体的复杂性。\n2、最小依赖，整体架构设计要保障大多数业务尝试可以在业务层完成。如果每个业务方的需求都会侵入到底层的逻辑，那么每次尝试都会变成跨模块，甚至跨团队合作，这种架构会大幅降低业务尝试的速度\n3、最小暴露，相当于最小被依赖，在业务尝试期接口不对部门或企业外部暴露，包括API、数据共享、事件、消息等一切对外界造成影响的通信机制。尤其是输出，这样才能最小化它的爆炸半径。否则该业务尝试的数据模型会污染到其他业务，在尝试失败之后对其他业务的影响也会很难剥离。\n原则很简单，但怎么落地这些原则，最大的挑战来于短视疸。如互联网火热时，人员更替很频繁，导致技术人员的稳定性差，想要快速拿到结果就会设计短视。还有企业组织结构，像康威定律一样，组织间的利益争夺，造成组织内最优设计，但企业整体设计熵增。\n作为架构师，可以：\n1、提升对封装能力重要性的认知。这是一个技术人员的基本功，从写代码的第一天就需要。只不过随着职业发展，从封装代码架构，到封装业务逻辑，最后到封装业务尝试。\n2、建设复杂度控制机制。这里设计评审很关键。业务尝试也要有设计评审，而评审的一个固定环节就是逻辑、数据和接口的最小爆炸半径的设计。\n3、推行最小必要架构原则。任何增加功能、引入复杂性的设计，都要做一个正式的评审，而简化的行为则不需要。\n\n当然，这些内容，是在郭东白架构课程里面看到的，他提出这是一个架构师提升企业架构设计对外部的适应能力。我理解这就是应对变化的能力。怎么能更好的应对变化，最佳原则就是“开闭原则”。而这些内容我更感觉是正交设计的另一种表述。这些原则与正交设计是一脉相承的。\n如果整个系统的各个功能模块是正交设计的，那自然能灵活应对变化。一个庞大系统无法适应变化时，主要是架构僵化以及各个模块之间的关系错综复杂，导致牵一发而动全身。不能改不敢改。\n应对变化时，不要饱和式攻击取胜，需要对阶段性精确目标最大投入取得成果。怎么才能做到不饱和式攻击，在架构层面就是要做到正交分解。\n\n总结一下：架构师主要职责就是为了抵制熵增。而抵制熵增不管从战术还是战略，正交设计都是一种很好的实践方式和指导原则。\n","tags":["架构"]},{"title":"架构师的自我拯救","url":"/blog/the-architects-self-rescue.html","content":"年前老板跟我讲了句话，“兄弟们得自我拯救”。\n感觉十分在理。\n这几年，行情很差，以肉眼可见的速度一步步衰退。大厂裁员，小厂倒闭，与互联网相关的行业，哀鸿遍野，各个公司都在进行降本增效。\n辛辛苦苦一年，年末了，年终还得来个折上折。但从公司角度，长久生存是第一要务。的确很是无奈。\n战略这种词太大，我这种底层也不太明白。但回首公司几年，有几句口号，回荡在耳边，加上老板这句，串联在一起，还蛮有意思：\n躬身入局、往前走一步、自我拯救！\n躬身入局，记得当时说的是高管要躬身入局。我跟一位CTO朋友分享，他立刻反应那你这底层要躬身出局。感叹人家能当CTO也不是白来的，这敏捷的思维，机智的身形。\n对于我这底层，就是躬身出局、往前走一步、自我拯救。\n\n\n\n这几句的核心意思就是不要埋头赶路，还得抬头看路。\n研发人员，不要盯着自己的那点技术三亩地，看看商务，看看销售，看看客户。写的那点代码，开发的那些功能，是不是实实在在的给客户带来价值，给公司带来了利益。\n想一想，我们的工资是从哪里来的？公司凭什么会在明天、明年甚至十年后还会给我发工资？\n技术人为什么那么高傲？技术人自己常讲我们能驱动业务。是真的吗？说实在的，能跟随业务，交付业务就不错了。\n技术给业务带来什么价值，达到共识的有两点：\n1、快速试错商业想法。老板有一个想法，通过技术手段快速上线，快速验证想法的正确性。\n2、快速扩张。一个商业想法被验证是能运作的，那通过技术快速的扩张，以点带面，形成规模效应。\n更进一步的问题就是：我们自己的商业模式是什么？\n\n商业模式：一个企业是以什么样的方式赚钱的，如电商，京东和淘宝是两种不同的商业模式。\n商业价值：从现金收入的视角看价值创造的过程。简单来说，商业价值就是帮助公司获取商业收。每天忙碌的工作，从企业的收上来说，是为公司带来什么样的短期和长期现金和其他收入，那么对这部分收入的量化，就是创造的商业价值。\n细化一下上面技术给业务带来的价值。作为一个技术人员，写代码做架构设计，从创造商业价值视角来看，代码和设计有三个作用：\n1、实现一个商业模式：如写代码实现一个功能\n2、提升一个商业模式的效率：如实现一个算法，提升转换率\n3、加速一个商业模式的收敛速度：如通过A&#x2F;B test，加速收敛速度\n这也是一个程序员，主要通过这三个路径为公司赚钱。\n那么如何更好的落地这三个路径呢？\n1、理解你所在企业或团队的商业模式为什么需要理解自己开发的模块和所在领域的商业模式是什么？\n不知道商业模式，就没法主动创造商业价值，你的日常工作很可能只是不断被动实现需求。\n作为技术人，可以把自己领域的商业模式用一个公式来表达；然后学会这个公式中，寻找并创造自己的价值。这个公式，其实就是对所在行业的商业逻辑的数学表达，也就是我们常说的KPI的逻辑\n如电商平台，像天猫。收入来自于交易抽成：\n\n总收入 &#x3D; GMV * Commission\n\n平台交易额越大，抽成越多。平台规模越大，总收入就越多。\n大家即使在同一家公司工作，但如果各自所在领域不同，那么为公司创造商业价值的方法也有所不同。\n比如负责平台的一个由算法驱动的购物频道，那商业模式是这样的：\n\nGMV &#x3D; 流量 * 转化率 * 平均订单金额\n\n在流量是一定的情况下，那就可以通过优化算法，获得更高转化率和更高的平均订单金额\n比如负责平台某个垂直行业的招商团队，那商业式是这样的：\n\nGMV &#x3D; 日均动销店铺数 * 店铺日均销售额\n\n假设每个店铺的销售额差不多，那目标就是让平台上有越来越多的店铺。\n对于一个架构师而言，必须深入理解自己所在公司和团队的商业模式，并且想尽一切办法去最化这个商业模式的成功概率。这样才能通过工作为公司创造商业价值，同时也为自己创造长期的商业价值。\n2、理解你在自己所处环境中创造的商业价值我们研究一家公司的商业模式，就是希望你认真理解自己所处的工作环境。\n“良禽择木而栖”就是你要选择能够最大化自身成长的工作环境。对于一个业务部门而言，存在不一定合理，只有提供稳定商业价值的存在才是合理的。\n3、保障架构活动的长期商业价值每个人都要有自己的商业模式。也就是你必须在工作环境中找到创造价值的方式，这样才能保障自己一直被需要，也能保障未来的收入。\n具体需要你为公司、部门或团队提供可量化的增量价值。\n第一是增量价值，就是你通过工作所创造的价值，是在社会提供的平均价值之上的。\n为什么技术人要不停地学习新技术？十年前懂分布式与现在懂分布式的价值完全不同。虽然工作没有变，但社会提供的开源解决方案的价值增加了，那你的增量价值相应地就会减少，甚至不存在。\n第二是可度量性。\n很多做技术的人秉持这样一种态度，似乎他创造的价值极其普适，普适到像空气一样，以至于不能量化成商业价值，甚至谈度量就是对工作的一种侮辱。我自己也是。\n对于软件行业的从业者来说，价值创造永远是个衰减的过程，因为我们的经验会在信息扩散中迅速贬值。\n如果不度量自己的增量价值，那就无法确保自己处在价值创造的前沿。你也不知道应该朝什么方向努力，才能最大化未来的增量价值，更不能在一个相对未知的环境下扩大你的增值空间。\n其实就是不管干什么都得计算ROI，去年公司搞了很多专项，前提就是必须要计算出ROI，而且是以具体人民币的量化数据计算出来。看看整个项目的价值，是否值得去投入。\n作为架构师如何创造自己的增量价值？架构师需要在一个相对复杂的问题上引导实施一个结构化的解决方案。这个方案的参与者是一群人，所以架构师的产出不完全靠自己，需要靠一群人来完成架构目标。在这种情况下，一个架构师想要创建长期的商业价值，就必须同时满足三个条件：\n一、确保最终架构方案的可行性\n二、确保参与方达成一个合理的实施路径，最终能够完成实施\n三、确保设计方案可以最大化解决方案的结构性\n事实上这三个条件很难被同时满足。架构师之所以参与一个方案，往往有这么几个原因：已经有现成方案，但比较复杂；参与团队众多，但各个团队的优先级不一样；公司压力大，能够投入到现存方案的人力资源有限。这就意味着作为一个架构师，需要在资源有限的条件下做取舍。\n所以架构师在这个过程中，创造的增量价值就在于能够审时度势，在企业内部各种资源限制和现实条件下，找到合理可行，并且能够最大化企业长期价值的架构方案。做架构和做业务一样，都不能靠饱和攻击取胜，而是靠对阶段性精确目标的最大化投入来取得进步。\n4、在架构规划中寻找扩大收入的机会技术人不在关注软件之外的事情，比如很少关心公司或部门的收入。这种性格虽然可以让他专注于软件工作，但长期来看，如果不去思考如何通过技术为公司创造商业价值，那就很难保持或扩大自己在团队的影响力，职业发展也可能受挫。\n“在小数据里看大机会，在大数据里看小机会”，适用于我们所有技术人。\n前半句指的是从个性需求中抽象出共性的机会。也就是从解决一个具体问题的过程中得到启发，并从中找到一个可以规模化应用的机会。\n后半句指的是靠数据来打磨用户体验。也就是通过数据分析找到机会点，然后通过产品和技术的改进，不断提升转化减少损失。\n5、在架构规划中寻找减少成本的机会成本观念公司上下每个人都要有。对于一个公司而言，一切有限资源上的消耗都是公司在架构活动中要付出成本，比如时间成本、人力成本、机会成本、计算成本等。\n在一个企业中，追求完美必须以成本可控为前提。\n总结一下必须要创造足够的商业价值，这样才能保障你在企业长期存在意义。\n第一、你作为一个架构师，在架构设计中要追求商业价值比如做性能优化，不是单纯地性能指标的优化，而是一上来就以提升商业价值为目标。因此我们的优化目标是订单数，而不是一个技术指标。\n第二、想要创造商业价值，就必须不断度量你创造的增量价值，这样才能确保自己处在价值创造的前沿。并且能够在一个相对未知的环境下，不断寻找自己的增值空间第三、作为一个架构师，要最小化整个架构活动的成本1、确保最终方案的可行性\n2、寻找最优的实施路径，确保最终能够完成实施\n3、试图最大化最终解决方案的结构性，以最小成本放大你的产出\n第四、做架构和做业务一样，都不能饱和攻击取胜，而要靠对阶段性精确目标的最大化投入来取得进步第五、不断寻找通过技术手段扩大收的机会第六、不断寻找通过技术手段缩减成本Refrence《郭东白的架构课》\n","tags":["架构师"]},{"title":"死锁分析","url":"/blog/deadlock-analysis.html","content":"最近新项目上线，在压测和发布生产都出现了好几种死锁情况，分析一二\n死锁日志日志一：\n日志二：\n日志三：\n这三个死锁日志特别的有意思，都是同一条SQL，但各种组合样的死锁都齐活了\n日志一的两条sql，where里面的条件不同；\n日志二和日志三sql完全一样，其实是两次调用(同一时刻并发调用)，调用条件不同，但在程序处理时这条SQL的where条件一样而已\n分析隔离级别RC\n日志一，where里面的条件不同第一个事务在等待RECORD LOCKS，锁模式为X model;位置在space id 428 page no 178\n第二个事务持有RECORD LOCKS，锁模式为X model;位置也在space id 428 page no 178；等待的锁也是RECORD LOCKS，锁模式为X model，也在space id 428 page no 178\n这个死锁很是奇怪，同一条sql，都是在索引【idx_tenant_user】上加锁，完全不符合死锁的循环等待特征\n这张表上的索引\nKEY `idx_collection_no` (`collection_no`) USING BTREE,KEY `idx_uniflag` (`invoice_uiq_flag`) USING BTREE,KEY `idx_tenant_user` (`tenant_id`,`user_id`) USING BTREE\n\n通过explain查看此语句\n\n索引上看使用idx_tenant_user,也与死锁日志一致，但怎么就死锁了呢？\n【SHOW ENGINE INNODB STATUS;】只能显示最终发生死锁时的sql,并不能显示全部的sql，从程序上下文中寻找，发现点蛛丝马迹\n\n事务2在T1时刻执行了一条根据id更新数据的sql，这条sql会在id聚簇索引上加X锁，还会在二级索引上加X锁，所以先获得了(user_id,tenant_id)锁，\n事务1在T2时刻只能等待\n事务2在T3时刻形成了循环等待，deadlock\n日志二,sql完全一样与前面解释，两个并发请求，入参不同，但到这个方法时，sql的条件是一样的\n\n日志三，sql也完全一样虽然与日志二的SQL一样，但死锁日志却不同\n\n\n为什么同样的SQL，却得出各样的结果？时而collection_no索引在前，时而组合索引在前\n苦思几日，在线上跑了下explain，发现了些问题\n\n原来线上使用的index merge\n有官网上有介绍：https://dev.mysql.com/doc/refman/5.6/en/index-merge-optimization.html\n\nMySQL在分析执行计划时发现走单个索引的过滤效果都不是很好，于是对多个索引分别进行条件扫描，然后将多个索引单独扫描的结果进行合并的一种优化操作。合并的方式分为三种：intersection、union和sort_union\n\n\nindex merge 之 intersect,简单而言，index intersect merge就是多个索引条件扫描得到的结果进行交集运算。显然在多个索引提交之间是 AND 运算时，才会出现 index intersect merge. \n\n正因为index merge,所以索引的真正执行顺序是不一样的，也就造成了各种表象\n解决建立联合索引\n都使用主键更新\n关掉参数index_merge_intersection&#x3D;off，禁用index_merge功能\n参照MySQL 优化之 index_merge\n一个 MySQL 死锁案例分析\n","tags":["mysql"]},{"title":"正交性是什么","url":"/blog/what-is-orthogonality.html","content":"重读经典–《程序员修炼之道》\n大多数开发人员对设计正交系统的必要性都很熟悉。只不过他们可能会使用其他一些词来描述这个过程，例如模块化、基于组件和分层，等等。\n正交性是什么“正交性”是从几何学中借用来的术语。\n若两条直线相交后构成直角，它们就是正交的。\n\n例如，图表中的坐标轴就是正交的。对于向量而言，这两条线相互独立。图示中的向量1指向北，完全不影响东西朝向。向量2指向东，完全不影响南北朝向。\n在计算科学中，这个术语象征着独立性或解耦性。\n对于两个或多个事务，其中一个的改变不影响其他任何一个，则这些事物是正交的。\n在良好设计的系统中，数据库相关代码应该和用户界面保持正交：你可以变更界面但不应影响数据库，切换数据库而不必要更换界面。\n正交的好处编写正交的系统，就能获得两个主要的收益：提高生产力及降低风险\n提高生产力1、将变更限制在局部后，开发时间和测试时间都会减少。\n2、正交的方法同时促进了重用。\n3、组合正交组件能获得相当微妙的生产力提升。\n假设一个组件能做M件独特的事情，另一个能做N件。如果它们是正交的，组合起来就能做M*N件事。如果两个组件不正交，有重叠之处，结果就少一些。\n在正交组件的组合过程中，单个单元的性价比提高了。\n降低风险1、代码中病变的部分被隔离开。\n如果一个模块生病了，不太可能将症状传播到系统的其他部分。把它切下来并移植一个新的健康器官进去，也更加容易\n2、这样获得的系统不那么脆弱。\n对特定区域进行小的变更和修复后，因此而产生的任何问题都将局限于该区域。\n3、你不会被特定的供应商、产品或平台紧紧束缚。\n因为这些第三方组件的接口所关联的，仅仅是整个开发中相对很小的一部分。\n4、正交系统可能更利于测试，因为为其组件设计和运行测试更加容易\n正交的方法设计系统应该由一组相互协作的模块构成，每个模块实现的功能应独立于其他模块。\n有时这些模块组件被组织到不同的层次上，每一层都做了一级抽象。\n这种分层的实现是设计正交系统的有力途径。\n因为每一层只使用它下面一层提供的抽象，所以可以在不影响代码的情况下极其灵活地更改底层实现。\n工具包和程序库在引入第三方工具包和程序库时，请注意保持系统的正交性。技术选择要明智。\n当你拿出一个工具包时，问问自己，它是否会将一些不应该有的变化强加给你代码。\n编码每当你写下代码时，就有降低软件的正交性的风险。\n不仅需要盯着正做的事情，还要监控软件的大环境。\n养成不断质疑代码的习惯。只要有机会就重新组织、改善其结构和正交性。这个过程被称为重构。\n保持代码解耦\n编写害羞的代码–模块不会向其他模块透露任何不必要的信息，也不依赖于其他模块的实现。\n试试最少知识原则。如果你需要改变一个对象的状态，让该对象替你来完成。这样做能让你的代码和其他代码实现隔离，更有可能保持正交性。\n避免全局数据\n只要代码引用全局数据，就会将自己绑定到共享该数据的其他组件上。\n即使只打算对全局数据进行读操作，也可能引发问题。\n避免相似的函数\n重复代码是结构问题的症状。\n测试基于正交性设计和实现的系统更容易测试。\n由于系统组件之间的交互是形式化的，且交互有限，因此可以在单个模块级别上执行更多的系统测试。\n文档正交性也适用于文档。其涉及的两个独立维度是内容和呈现。\n真正符合正交性的文档，应该能够在不改变内容的情况下显著地改变外观。\n","tags":["读书"]},{"title":"死锁分析延续","url":"/blog/deadlock-analysis-continuation.html","content":"根据上一篇【死锁分析】，又重新梳理了一下，画图表示更形象一些\n\n\n\n\n事务 1\n事务 2\n\n\n\n-\nbegin\n\n\nbegin\ndelete id&#x3D;1;(1)id加锁、(2)A加锁\n\n\ndelete id&#x3D;2;(3)id加锁、(4)A加锁\n-\n\n\n\n| update ? where user_id&#x3D;? and tenant_id&#x3D;? and no&#x3D;?;\n| 如果先走no索引，已经持有B锁，再去持D锁时等待update ? where user_id&#x3D;? and tenant_id&#x3D;? and no&#x3D;?; | -先走no索引，持B锁时等待；deadlock |-\n\nupdate ? where user_id&#x3D;? and tenant_id&#x3D;? and no&#x3D;?;如果先走（tenant_id,user_id） 则是日志一\n先走no，则是日志二\n索引交叉，则是日志三\n\n最近借着死锁事项，又温习了部分数据库的理论知识，后面有时间再整理。现在的程序员真难，得上知天文，下知地理；这应该是DBA的专长，作为开发也得去深究，真难\n在追查死锁的过程中，对照理论有一些实践，总结一下：\n查看事务自动提交选项\nshow session variables like &#x27;autocommit&#x27;;show global variables like &#x27;autocommit’;set session autocommit=0;set global autocommit=0;\n\n\n查看事务隔离级别\nselect @@tx_isolation\n\n查看锁信息，想查看一条sql使用了什么锁，需要打开锁监听\nshow session variables like &#x27;%output%&#x27;;#开启InnoDB锁监控set global innodb_status_output_locks=on;set global innodb_status_output=on;#上面的语句可定期写入到标准错误输出（stderr，即error log，大概每15s写一次），你也可以使用 SHOW ENGINE INNODB STATUS 语句直接在客户端获取innodb信息show session variables like &#x27;%output%&#x27;;\n\n要启用InnoDB锁定监视器的 SHOW ENGINE INNODB STATUS输出，只需启用innodb_status_output_locks\n打开监控开关后，在mysql日志文件中会出现\n=====================================2020-06-30 15:44:46 7fdc8a76e700 INNODB MONITOR OUTPUT=====================================----------------------------END OF INNODB MONITOR OUTPUT============================\n\n\n打开锁监控，可以确定一下常用语句的锁信息\n执行完一条SQL，使用SHOW ENGINE INNODB STATUS打印出锁信息\ndelete from invoice_collection_info where id=1275244823997059072TABLE LOCK table `assist`.`invoice_collection_info` trx id 1636893 lock mode IXRECORD LOCKS space id 18491 page no 211 n bits 104 index `PRIMARY` of table `assist`.`invoice_collection_info` trx id 1636893 lock_mode X locks rec but not gap\ndelete语句，根据主键删除操作；可以明显看出上了表锁IX model,还有一个主键索引锁\n其实如果有二级索引，还会有二级索引锁，但那是隐式锁，所以没有显示出来，后面会有试验让隐式锁显示化\n\n使用二级索引删除操作\ndelete FROM invoice_item WHERE ( collection_id = 1275244823997059072 );TABLE LOCK table `assist`.`invoice_item` trx id 1636964 lock mode IXRECORD LOCKS space id 18493 page no 4 n bits 784 index `idx_collection_id` of table `assist`.`invoice_item` trx id 1636964 lock_mode X locks rec but not gapRecord lock, heap no 563 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 8; hex 91b2946930001000; asc    i0   ;; 1: len 8; hex 91b2ae5d61401000; asc    ]a@  ;;RECORD LOCKS space id 18493 page no 12 n bits 96 index `PRIMARY` of table `assist`.`invoice_item` trx id 1636964 lock_mode X locks rec but not gapRecord lock, heap no 28 PHYSICAL RECORD: n_fields 23; compact format; info bits 0\n\n先在二级索引上加锁，再在对应的主键索引上加锁\n\n使用二级索引查询\nselect * from invoice_collection_info where invoice_uiq_flag = &#x27;031001900104-62079412&#x27; for updateTABLE LOCK table `assist`.`invoice_collection_info` trx id 1636947 lock mode IXRECORD LOCKS space id 18491 page no 642 n bits 344 index `idx_uniflag` of table `assist`.`invoice_collection_info` trx id 1636947 lock_mode X locks rec but not gapRECORD LOCKS space id 18491 page no 496 n bits 96 index `PRIMARY` of table `assist`.`invoice_collection_info` trx id 1636947 lock_mode X locks rec but not gap\n\n从日志中看出，先在invoice_uiq_flg二级索引上加锁，再在主键索引加锁\n\n使用主键更新操作\nupdate invoice_collection_info set invoice_uiq_flag = &#x27;031200190010-62079412&#x27; WHERE (  id = 1275244823997059072 ); TABLE LOCK table `assist`.`invoice_collection_info` trx id 1636958 lock mode IXRECORD LOCKS space id 18491 page no 741 n bits 88 index `PRIMARY` of table `assist`.`invoice_collection_info` trx id 1636958 lock_mode X locks rec but not gap\n\n其实不仅会在主键加X，还会在二级索引上也加X，但没有显示出来；这儿跟delete一样，其实也是个隐式锁\n\n模拟测试了一下，两条sql，一条根据二级索引删除操作、另一条使用主键更新记录模拟并发死锁，把update中的二级索引锁显示出来了\n\n\n上面的操作都是在RC级别下进行的，对于select操作，快照读都不会加锁，实验结果也与理论一致\n","tags":["mysql"]},{"title":"游戏小传序","url":"/blog/game-introduction.html","content":"序言在游戏行业足足待了八年了。从大学毕业就开始开发游戏。一直到现在还在一线岗位。\n从小小的开发，到掌握后端全局的主程；从胎死腹中的产品，到月流水过亿的大作。\n游戏人太苦，996工作制是正常的，凌晨下班也是常有的，为什么可以坚持，可能是心中都有个游戏梦，要大成，要大作。但每次都是充满期待，结果却无声奈何。想想那些从别的行业转来做游戏的同事，一个一个期望变成失落，坚持了几年，又都失望地离开了游戏行业，而我是幸运的，至少经历了大作，经过了一款月流水过亿的产品。\n人常说七年就是一辈子，那我这算在工作经历上过完了一辈子，下辈子怎么过呢？不清楚。但至少不能再重复上辈子\n对于一辈子想有个总结，开始想写本书，至少是个系列《游戏开发实战》，写的过程又是重学的过程，而之前定的一周一篇技术文章的目标总是不能执行，因为时间不够，工作很忙，要写一篇好的技术文章很废时间。所以不想再以技术文章为系列去写，写技术文章太枯燥，由浅入深，面面俱到，太累！\n所以这次就以时间为轴线，以技术内容为补充，记录一下我从小鸟变成一个老兵的成长过程，在此过程中遇到的一些问题，思考心得。\n","tags":["游戏小传"]},{"title":"深入浅出索引","url":"/blog/easy-to-understand-index.html","content":"前言索引，一种强大的存在；不管是什么行业，数据都是根基，终将落盘固化，提供各方检索查询，之前整理了一篇《深入浅出spring事务》，你可以推脱不使用事务，但索引是不可或缺的必备知识点\n知识点比较多，有些会分篇细化，整体会从以下几方面整理\n\n索引是什么,人人都在讲，但他的定义到底是什么？\n索引作用，创建表时，都要考虑索引，能带什么好处？\n索引负作用，索引那么好，为什么不在每个字段上都加上索引？\n索引实现原理，那么多数据结构，索引为什么非要使用B+Tree？\n索引应用，加了索引也不一定能发挥作用，使用时注意哪些？\n\n索引是什么MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。\n数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。\n最基本的查询算法当然是顺序查找（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法\n例如二分查找（binary search）、二叉树查找（binary tree search）等。\n如果稍微分析一下会发现，每种查找算法都只能应用于特定的数据结构之上\n例如二分查找要求被检索数据有序，而二叉树查找只能应用于二叉查找树上，但是数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织）\n所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引\n索引意义通过索引定义，作用基本已经明确，再细化一下\n作用\n大大加快数据的检索速度;   \n创建唯一性索引，保证数据库表中每一行数据的唯一性;   \n加速表和表之间的连接;   \n在使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间\n\n反作用索引有这么多的好处，哪是不是每一列都给建上索引相当好呢？\n过犹不及\n\n索引需要占用数据表以外的物理存储空间\n创建索引和维护索引要花费一定的时间\n当对表进行更新操作时，索引需要被重建，这样降低了数据的维护速度\n\n索引分类分类有两种角度：\n\n1.物理存储\n\n1.1 聚簇索引(Clustered Index)：将数据存储与索引放到了一块，找到索引也就找到了数据，一个表只能有一个聚集索引\n1.2 非聚簇索引(Non- Clustered Index)：将数据存储于索引分开结构，搜索索引，然后通过索引找到磁盘相应数据\n\n\n2.逻辑功能\n\n2.1.主键索引：它是一种特殊的唯一索引，不允许有空值  primary key (id)\n2.2. 普通索引：这是最基本的索引，它没有任何限制\n\n  create index idx_name on user(name(20)); \n\n2.3. 唯一索引：它与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值\n\n  CREATE UNIQUE INDEX idx_email ON user(email);\n\n2.4. 组合索引\n\n  INDEX name (last_name,first_name)\n\nInnodb使用的是聚簇索引，MyISam使用的是非聚簇索引\nInnodb中的主键索引是一种聚簇索引，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引\n在Innodb中，Mysql中的数据是按照主键的顺序来存放的。那么聚簇索引就是按照每张表的主键来构造一颗B+树，叶子节点存放的就是整张表的行数据。由于表里的数据只能按照一颗B+树排序，因此一张表只能有一个聚簇索引\n在Innodb中，聚簇索引默认就是主键索引\n索引实现一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I&#x2F;O消耗，相对于内存存取，I&#x2F;O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I&#x2F;O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I&#x2F;O的存取次数\n存储原理在了解索引的数据结构之前了解一下硬件存储原理，毕竟一切都是基于硬件\n计算机存储设备一般分为两种：内存储器(main memory)和外存储器(external memory) \n\n内存存取速度快，但容量小，价格昂贵，而且不能长期保存数据(在不通电情况下数据会消失)。\n外存储器—磁盘是一种直接存取的存储设备(DASD)。它是以存取时间变化不大为特征的。可以直接存取任何字符组，且容量大、速度较其它外存设备更快。\n\n磁盘结构\n如上图，磁盘由盘片构成,每个盘片有两面，又称为盘面(Surface)，这些盘面覆盖有磁性材料。\n盘片中央有一个可以旋转的主轴(spindle)，他使得盘片以固定的旋转速率旋转，通常是5400转每分钟(Revolution Per Minute,RPM)或者是7200RPM\n磁盘包含一个多个这样的盘片并封装在一个密封的容器内。\n上图左，展示了一个典型的磁盘表面结构。每个表面是由一组成为磁道(track)的同心圆组成的，每个磁道被划分为了一组扇区(sector).每个扇区包含相等数量的数据位，通常是（512）子节。\n扇区之间由一些间隔(gap)隔开,不存储数据。\n磁盘读写\n如上图，磁盘用读&#x2F;写头来读写存储在磁性表面的位，而读写头连接到一个传动臂的一端\n磁盘上数据必须用一个三维地址唯一标示：柱面号、盘面号、块号(磁道上的盘块)\n读&#x2F;写磁盘上某一指定数据需要下面3个步骤：\n\n首先移动臂根据柱面号使磁头移动到所需要的柱面上，这一过程被称为定位或查找 。\n所有磁头都定位到第10盘面的10条磁道上(磁头都是双向的)。这时根据盘面号来确定指定盘面上的磁道。\n盘面确定以后，盘片开始旋转，将指定块号的磁道段移动至磁头下\n\n经过上面三个步骤，指定数据的存储位置就被找到。这时就可以开始读&#x2F;写操作了。访问某一具体信息，由3部分时间组成：\n\n查找时间(seek time) Ts: 完成上述步骤(1)所需要的时间。这部分时间代价最高，最大可达到0.1s左右。\n等待时间(latency time) Tl: 完成上述步骤(3)所需要的时间。由于盘片绕主轴旋转速度很快，一般为7200转&#x2F;分(电脑硬盘的性能指标之一, 家用的普通硬盘的转速一般有5400rpm(笔记本)、7200rpm几种)。因此一般旋转一圈大约0.0083s。\n传输时间(transmission time) Tt: 数据通过系统总线传送到内存的时间，一般传输一个字节(byte)大概0.02us&#x3D;2*10^(-8)s\n\n磁盘读取数据是以盘块(block)为基本单位的。位于同一盘块中的所有数据都能被一次性全部读取出来。而磁盘IO代价主要花费在查找时间Ts上\n因此我们应该尽量将相关信息存放在同一盘块，同一磁道中。或者至少放在同一柱面或相邻柱面上，以求在读&#x2F;写信息时尽量减少磁头来回移动的次数，避免过多的查找时间Ts\n在大规模数据存储方面，大量数据存储在外存磁盘中，而在外存磁盘中读取&#x2F;写入块(block)中某数据时，首先需要定位到磁盘中的某块，如何有效地查找磁盘中的数据，需要一种合理高效的外存数据结构\n局部性原理与磁盘预读由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I&#x2F;O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。\n这样做的理论依据是计算机科学中著名的局部性原理：\n当一个数据被用到时，其附近的数据也通常会马上被使用。\n程序运行期间所需要的数据通常比较集中。\n由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I&#x2F;O效率。\n预读的长度一般为页（page）的整倍数\n页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。\n当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行\n数据结构根据索引定义，索引就是一种数据结构，来看下此数据结构是什么样的，能在当前硬件条件下，高效地查找磁盘数据,这种数据结构需要满足两个条件：\n\n快速，快速查找到数据\n局部性原理，满足局部性原理，减小IO次数，减小硬件磁头移动\n\n根据之前温习的各种算法，可以找一种适合的查找算法与数据结构吗？\n\n1.顺序查找：这种复杂度为O(n)的算法在数据量很大时显然是糟糕的\n\n2.数组+二分查找：效率是O(logn),但是数组的插入元素以及删除元素的效率很低\n\n3.hash:检索效率非常高，索引的检索可以一次定位,在Hashmap源码解析中有过详细分析\n\n3.1Hash 索引仅仅能满足”&#x3D;”,”IN”和”&lt;&#x3D;&gt;”查询，不能使用范围查询\n\n  由于 Hash 索引比较的是进行 Hash 运算之后的 Hash值，  所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样\n\n3.2Hash 索引无法被用来避免数据的排序操作\n\n  由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算\n\n3.3Hash索引不能利用部分索引键查询\n\n  对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用\n\n3.4Hash索引在任何时候都不能避免表扫描\n\n  Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果\n\n3.5Hash索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高\n\n  对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下\n\n\n在mysql中，只有memory引擎显式支持哈希索引，这也是memory引擎表的默认索引类型，memory也支持btree，值得一提的是，memory引擎是支持非唯一哈希索引的。在数据库世界里是比较与众不同，如果多个列的哈希值相同，索引会以链表的方式存放多个记录指针到同一个哈希条目中\nB树为磁盘存储而专门设计的一类平衡搜索树，细节可以阅读《树概述》\n先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I&#x2F;O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：\n每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I&#x2F;O\nB-Tree中一次检索最多需要h-1次I&#x2F;O（根节点常驻内存），渐进复杂度为\n一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。\n综上所述，用B-Tree作为索引结构效率是非常高的\nmysql实现在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的，主要讨论MyISAM和InnoDB两个存储引擎的索引实现方式。\nMyISAM索引实现MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图：\n\n这里设表一共有三列，假设我们以Col1为主键，上图是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：\n\n同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。\nMyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分\nInnoDB索引实现虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同\n第一个重大区别是InnoDB的数据文件本身就是索引文件,MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。\n而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引\n\n这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录\n主键索引是聚集索引还是非聚集索引？\n在Innodb下主键索引是聚集索引，在Myisam下主键索引是非聚集索引\n\nMyisAM索引 VS InnoDB索引\nMyisAM支持全文索引（FULLTEXT）、压缩索引，InnoDB不支持；\nInnoDB支持事务，MyisAM不支持；\nMyisAM顺序储存数据，索引叶子节点保存对应数据行地址，辅助索引很主键索引相差无几；InnoDB主键节点同时保存数据行，其他辅助索引保存的是主键索引的值；\nMyisAM键值分离，索引载入内存（key_buffer_size），数据缓存依赖操作系统；InnoDB键值一起保存，索引与数据一起载入InnoDB缓冲池；MyisAM主键（唯一）索引按升序来存储存储，InnoDB则不一定\nMyisAM索引的基数值（Cardinality，show index 命令可以看见）是精确的，InnoDB则是估计值。这里涉及到信息统计的知识，MyisAM统计信息是保存磁盘中，在alter表或Analyze table操作更新此信息，而InnoDB则是在表第一次打开的时候估计值保存在缓存区内；\nMyisAM处理字符串索引时用增量保存的方式，如第一个索引是‘preform’，第二个是‘preformence’，则第二个保存是‘7，ance’，这个明显的好处是缩短索引，但是缺陷就是不支持倒序提取索引，必须顺序遍历获取索引\n\n查询查询过程在收到一个查询的时候，Mysql的架构中的各个组件是如此工作的：\n\n客户端同数据库服务层建立TCP连接，连接管理模块会建立连接，并请求一个连接线程。如果连接池中有空闲的连接线程，则分配给这个连接，如果没有，在没有超过最大连接数的情况下，创建新的连接线程负责这个客户端。\n在真正的操作之前，还需要调用用户模块进行授权检查，来验证用户是否有权限。通过后，方才提供服务，连接线程开始接收并处理来自客户端的SQL语句。\n连接线程接收到SQL语句之后，将语句交给SQL语句解析模块进行语法分析和语义分析。\n如果是一个查询语句，则可以先看查询缓存中是否有结果，如果有结果可以直接返回给客户端。\n如果查询缓存中没有结果，就需要真的查询数据库引擎层了，于是发给SQL优化器，进行查询的优化。如果是表变更，则分别交给insert, update, delete, create，alter处理模块进行处理。\n接下来就是请求数据库引擎层，打开表，如果需要的话获取相应的锁。\n接下来的处理过程就到了数据库引擎层，例如InnoDB。\n在数据库引擎层，要先查询缓存页中有没有相应的数据，如果有则可以直接返回，如果没有就要从磁盘上去读取。\n当在磁盘中找到相应的数据之后，则会加载到缓存中来，从而使得后面的查询更加高效，由于内存有限，多采用变通的LRU表来管理缓存页，保证缓存的都是经常访问的数据。\n获取数据后返回给客户端，关闭连接，释放连接线程，过程结束。\n结构先来一张带主键的表，如下所示，pId是主键\n\n\n\npId\nname\nbirthday\n\n\n\n5\nzhangsan\n2016-10-02\n\n\n8\nlisi\n2015-10-04\n\n\n11\nwangwu\n2016-09-02\n\n\n13\nzhaoliu\n2015-10-07\n\n\n\n如上图所示，分为上下两个部分，上半部分是由主键形成的B+树，下半部分就是磁盘上真实的数据！那么，当我们， 执行下面的语句\nselect * from table where pId=&#x27;11&#x27;\n查询过程：\n\n如上图所示，从根开始，经过3次查找，就可以找到真实数据。如果不使用索引，那就要在磁盘上，进行逐行扫描，直到找到数据位置。显然，使用索引速度会快。但是在写入数据的时候，需要维护这颗B+树的结构，因此写入性能会下降！\n再创建一个非聚簇索引：\ncreate index index_name on table(name);\n\n结构图如下所示\n\n会根据你的索引字段生成一颗新的B+树。因此， 我们每加一个索引，就会增加表的体积， 占用磁盘存储空间。然而，注意看叶子节点，非聚簇索引的叶子节点并不是真实数据，它的叶子节点依然是索引节点，存放的是该索引字段的值以及对应的主键索引(聚簇索引)\nselect * from table where name=&#x27;lisi&#x27;\n查询过程：\n\n通过上图红线可以看出，先从非聚簇索引树开始查找，然后找到聚簇索引后。根据聚簇索引，在聚簇索引的B+树上，找到完整的数据！\n什么情况不去聚簇索引树上查询呢？\n还记得我们的非聚簇索引树上存着该索引字段的值么。如果，此时我们执行下面的语句\nselect name from table where name=&#x27;lisi&#x27;\n\n查询过程\n\n如上图红线所示，如果在非聚簇索引树上找到了想要的值，就不会去聚簇索引树上查询\n再创建一个非聚簇索引：\ncreate index index_birthday on table(birthday);\n\n多加一个索引，就会多生成一颗非聚簇索引树。因此，很多文章才说，索引不能乱加。因为，有几个索引，就有几颗非聚簇索引树！你在做插入操作的时候，需要同时维护这几颗树的变化！因此，如果索引太多，插入性能就会下降\n最左原则最左原则，并不是指 SQL 语句的 where 顺序要和联合索引一致\n当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，\n比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向\n如果name相同再依次比较age和sex，最后得到检索的数据；\n但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询\n比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了\n参考资料mysql索引最左匹配原则的理解?\nMySQL索引背后的数据结构及算法原理\nB树、B-树、B+树、B*树【转】,mysql索引\n索引原理与慢查询优化\nMySQL(Innodb)索引的原理\n","tags":["db"]},{"title":"游戏灰度发布","url":"/blog/game-gray-release.html","content":"背景快速可以说是互联网的最大特点了，唯快不破，快速响应，快速发布，快速部署，快速上线\n但上线，毕竟还是有风险的，怎么能又快速响应，又能降低风险范围呢\n前人，现人，后人们都在寻找着银弹\n部署方式就进化了有很多次，蓝绿部署、滚动部署、灰度发布、金丝雀发布。。。\n这些都是为了应对互联网的快速响应需求\n游戏的发布现在还是比较粗暴的，对开发，运维也比较简单。\n制定一个版本计划，开发，与运营沟通，确定版本内容，到了时间，所有游戏区全部关闭入口，停止服务器，发布，部署，重启，开放入口，一气呵成，快哉！\n等等，理想很丰满，现实很骨感\n在版本发布最后一天，开发人员在凌晨1、 2点时，还在开发，修复bug，好不容易打包，回家睡觉\n第二天运维在8点开始停机发布新版本；\nduang,怎么游戏服起不来了，开发请起床，查问题\n迷迷糊糊的开发在梦境中惊醒，终于搞定，打包，发版本，启动服务(有时可能要一上午查问题，通知运营方，延长维护时间)\nduang,玩家反馈，新功能有问题…\n此时，回滚？还是。。。；好汉不回头，哪来的回滚\n紧急停机，再寻找问题，修复，上线…\n…\n整个游戏的链条上，似乎大家都已经习惯，开发习惯，玩家也习惯\n习惯麻痹了一切，没有提出更好的策略，大家都这么玩啊，无所谓啦~\n方案细思极恐，我们应该，也需要做得更好\n灰度发布／金丝雀发布灰度发布是在原有版本可用的情况下，同时部署一个新版本应用作为“金丝雀”（金丝雀对瓦斯极敏感，矿井工人携带金丝雀，以便及时发发现危险），测试新版本的性能和表现，以保障整体系统稳定的情况下，尽早发现、调整问题。\n\n灰度发布／金丝雀发布由以下几个步骤组成：\n\n准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。\n从负载均衡列表中移除掉“金丝雀”服务器。\n升级“金丝雀”应用（排掉原有流量并进行部署）。\n对应用进行自动化测试。\n将“金丝雀”服务器重新添加到负载均衡列表中（连通性和健康检查）。\n如果“金丝雀”在线使用测试成功，升级剩余的其他服务器。（否则就回滚）\n\n游戏架构\n这个架构图比现实丰满不少，真实情况组件可能是单点的，数据层也就是单个mysql，一切都是那么脆弱。\n流程图\n玩家首先登陆游戏运营平台，鉴权完毕，选择区服，通过网关服务器获取到真实game-server信息，通过TCP，玩家与game-server建立起长连接。\n通过这个流程，就知道玩家与game-server直接牵手，强依赖的，如果gameserver重启，tcp连接是一定会断的，虽然前端可能尝试重新连接，但对玩家是有感的，不可能对玩家透明。\n改进怎么才能对玩家无感，切换版本呢？\n\n在之前的架构图中，稍作修改，在玩家与Gameserver之间增加一层ha-proxy，这样就有了灰度发布的基础\n玩家不再直接与game-server直连，而是与ha-proxy\n透明性对玩家来说，发版本就是透明的，发版本时，不再需要停机，入口也不需要关闭，7*24玩耍\n流量灵活切换灰度百分比，可以灵活控制，这里面又涉及到路由规则，复杂了，可以先百分百切换\n快速迭代玩家无感，出现bug，可以快速修复，快速上线\n快速回滚一旦新版本有问题，可以马上切回老版本，版本之间无逢切换\n难点加了ha-proxy，多了更多的灵活性\nha-proxy的难点，高可用，高可靠，高性能\n高可用最重要的一点，不能单点；\n如果ha-proxy挂了，怎么办？就算game-server正常运行，也不能再提供服务，自己坑了自己\n所以ha-proxy不能单点，哪是集群，还是主从？\n每台物理机上都部署，还是集中几台部署？\n高可靠在新旧版本同时在线时，流量是否平滑过渡？ 玩家操作是否保持完整性？\n一个玩家操作横跨新旧版本时，数据一致性如何保障？\n高性能游戏服都是尽量压榨单台服务的能力，现在多了一层通讯，IO会不会影响性能？\n结论对于以上方案，不论是哪一种实现方式，仁者见仁，条条大路通罗马。\n也可能你觉得这种想法本身就是个多余。\n能卖1块钱的豆腐，为什么要卖5毛？\n"},{"title":"百万QPS系统的缓存实践","url":"/blog/cache-practice-of-million-qps-system.html","content":"标题有些吸引眼球了，但并不浮夸，甚至还会远远超过百万，现在的平均响应时间在1ms内，0.08ms左右\n如此高的QPS，如此低的AVG,为什么会有如此效果，关键点还是在多级缓存上\n\n在开发高并发系统时有三把利器用来保护系统:缓存、降级和限流\n\n概述\n上图基本上就是查询的通用方案，缓存中是否存在，存在就返回，不存在再查询Db,查询到的结果load进缓存\n实践缓存，逃不过三种操作，创建、查询、删除\n此实践可能不保证全场景通用，但满足当前系统各项指标，当然没有完美的方案，只有适合的方案。\n下面的时序图中，cache lv1是指本地缓存，cache lv2是cache cluster\n查询\n查询过程：\n从一级缓存开始查，如果没有，再向下一级查询，直到db\n注意点：\n\n一直查到db时，需要回源各级cache\n防止击穿，需要在cache中填充value\n\n创建\n创建过程：\n\n创建cacheObject\n放入Db(为了性能，以及db的降级，这儿可以引入异步开关)\n放入cache lv2\n放入cache lv1\npublish创建成功消息\n消息监听服务会通知其它服务更新本地缓存\n\n注意点：\n\n到底是先放入Db,还是先放入cache\ndb与cache的一致性保障\n\n删除\n删除过程：\n\n通过key查询cacheobject\n清除db\n清除各级cache\npublish消除成功消息\n监听服务清除其它服务的本地缓存\n\n注意点：\n\n先清除db还是cache\nDb与cache的一致性保障\n\n缓存操作模式除了创建，查询，删除，还有更新操作；但我们业务场景没有。\n对于我们的实践是不是放之四海而皆准，肯定是不行的。不以业务为基础的设计都是无根之木\n先看下业界常见的操作缓存模式\n更新缓存的的Design Pattern有四种：Cache aside, Read through, Write through, Write behind caching\nCache aside\n失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。\n命中：应用程序从cache中取数据，取到后返回。\n更新：先把数据存到数据库中，成功后，再让缓存失效。\n\n\n\n这是标准的design pattern，包括Facebook的论文《Scaling Memcache at Facebook》也使用了这个策略。为什么不是写完数据库后更新缓存？你可以看一下Quora上的这个问答《Why does Facebook use delete to remove the key-value pair in Memcached instead of updating the Memcached during write request to the backend?》，主要是怕两个并发的写操作导致脏数据。\n那么，是不是Cache Aside这个就不会有并发问题了？不是的，比如，一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。\n但，这个case理论上会出现，不过，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必须在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。\nCache Aside，我们的应用代码需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。所以，应用程序比较啰嗦。而Read&#x2F;Write Through套路是把更新数据库（Repository）的操作由缓存自己代理了，所以，对于应用层来说，就简单很多了。可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。\nRead ThroughRead Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。\n这似乎很像guave的LoadCache\nWrite ThroughWrite Through 套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）\nWrite Back在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I&#x2F;O操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。\n在wikipedia上有一张write back的流程图，基本逻辑如下：\n\n在游戏开发中基本上都是使用这种模式\n但他也有缺点：\n\n数据不是强一致性\n数据可能会丢失\n逻辑比较复杂\n\n争论\n一致性问题  这儿的一致性是说强一致性，在分布式环境下，保证强一致性促使系统复杂性增加，或者性能有所下降。所以现在一般对非强制性业务场景都使用最终一致性解决。一致性的解读可以看看《zookeeper-paxos》，在我们实践时，在删除操作时，在清理失败时也通过补偿操作去尝试清除。\n到底是update cache,还是delete cache其实任务技术手段都是看业务场景的，不能一概而论\nupdate cache 这个在并发写时，A1写db，B1写db，B2写cache，A2写cache；这时就出现db与Cache不一致的问题 主动更新缓存，如果cacheobject复杂，需要Db与cache的多次交互，虽然减少了一次cache miss，但却增加了系统复杂度，得不偿失\ndelete cache 这个不会有不一致问题了，但会造成cache miss，会不会造成热key穿透？\n\n\n是先操作Db,还是cache 假设先操作cache，再操作db;A B并发操作，A1 delete cache； B1 get cache –&gt; miss –&gt; select db –&gt; load cache；A2 delete db; 此种情况就出现此key一直有效状态，如果没有设置超时时间，那会长期在缓存中。这是不是得先操作db呢？ 一个操作先update db,再delte cache时失败了；那会数据库里是新数据，而缓存里是旧数据，业务无法接受。那是不是该先操作缓存呢？\n\n是不是已经晕头了呢？\n再有db主从架构中，主从不一致的情况，是不是没法玩了\n所以还是开篇讲的没有放之四海而皆准的方案，只能寻找最适合的方案\n在各种业务场景下，还是需要去寻找一些最佳实践，比如关注一下缓存过期策略、设置缓存过期时间\n参考资料缓存更新的套路\nA beginner’s guide to Cache synchronization strategies\n","tags":["高性能","缓存"]},{"title":"监控之traceid","url":"/blog/monitored-traceid.html","content":"监控之前只总结了一篇《微服务-监控》，比较宏观。其中很多细节没有过深关注到，主要还是没有实践过，更没有去深度思考，所以很多有意思的技术点都错过了，比如traceid的生成，传递\n大牛圈总的大作《微服务系统架构之分布式traceId追踪参考实现》已经给出解决方案，但还是再主动总结一下\n意义为什么需要traceid，为了查看完整的调用链，一旦调用过程中出现问题，可以第一时间定位到问题现场\n整个调用链是一棵树形结构，traceid的传递涉及到主干与支干，进程内与进程外\n生成原则是唯一不重复，比如现成的UUID\n但UUID一是丑、无意义，二是string；\n从字面意义以及未来落盘都不能说是最佳方案，比如想让traceid包含信息更丰富一些，能一眼看出此traceid是主干还是分支\n此traceid有没有最终落盘(这儿涉及到落盘抽样率，每天服务处理海量请求，总不能每个traceid都落盘)\nRandom这儿引申到如何更好地获取一个随机数又是一个课题，另开篇吧\n传递在《熔断机制》中提过，服务调用是一个1-&gt;N扇出，调用链展现出对应的树形结构，但调用嵌套都不会深，一般两层就差不多了\n\ntraceId1\ntraceId1.1\ntraceId1.1.1\n\n\ntraceId2.1\ntraceId3.1\n\n\n\n进程外服务之间的传递\nserverA –&gt; serverB – serverC\n这儿在设计传输协议时，在协议头里面带上traceid\n进程内主干这种场景ThreadLocal是最佳手法\n支干比如serviceA – &gt; remote.serviceB\ntrace是个树形结构，可以将remote.serviceB的traceId.parentId &#x3D; serviceA.traceId\n异步子任务子线程可以通过InheritableThreadLocal传递traceid\n顺带一下，InheritableThreadLocal的详细实现，先可补习一下ThreadLocal《解析ThreadLocal》\n在创建Thread时，会从父线程的inheritableThreadLocals复制到子线程中去，这样在子线程中就能拿到在父线程中的赋值\n/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null;/* * InheritableThreadLocal values pertaining to this thread. This map is * maintained by the InheritableThreadLocal class. */ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;\n\nif (parent.inheritableThreadLocals != null)        this.inheritableThreadLocals =            ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);\n\n线程池如果没有线程池，以上就算是解决所有问题了，可实现毕竟是实现\n/** * 子线程从父线程中取值 * @throws InterruptedException */private static void testThreadpool() throws InterruptedException &#123;    ExecutorService executorService = Executors.newFixedThreadPool(1);    final ThreadLocal&lt;String&gt;  threadLocal = threadLocal();//new InheritableThreadLocal&lt;&gt;()    threadLocal.set(&quot;parent&quot;);    for(int i=0;i&lt;1;i++) &#123;        Runnable runnable = new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(Thread.currentThread().getName() +&quot; get parent value:&quot; + threadLocal.get());                threadLocal.set(&quot;sun&quot;);                System.out.println(Thread.currentThread().getId() + &quot;==&quot; + threadLocal.get());            &#125;        &#125;;        executorService.execute(runnable);        Thread.sleep(100);        executorService.execute(runnable);        Thread.sleep(100);        System.out.println(&quot;main:&quot; + threadLocal.get());    &#125;    executorService.shutdown();&#125;\n\n为了好重现问题，线程池大小为1，但会连续跑两次任务\npool-1-thread-1 get parent value:parent11==sunpool-1-thread-1 get parent value:sun11==sunmain:parent\n在第二次取父线程值时，却是第一次任务线程中的赋值，在线程池中子线程不能正常获取父线程值\n线程池中，线程会复用，线程中的inheritableThreadLocals没有被清空\n解决方法一是：池中线程数大于任务线程，让线程没有重用机会\nExecutorService executor = Executors.newFixedThreadPool(&gt;=[任务线程数])\n但在多线程应用中，明显不能解决问题，任务数肯定远远超过线程数\n解决方法二是：自定义实现在使用完线程主动清空inheritableThreadLocals\n阿里开源transmittable-thread-local就实现这样的功能\n整体思路也是从主线程复制，使用，再清理\n\nTtlRunnable 构造方法中，调用了 TransmittableThreadLocal.Transmitter.capture() 获取当前线程中所有的上下文，并储存在 AtomicReference 中\n\n\n当线程执行时，调用 TtlRunnable run 方法，TtlRunnable 会从 AtomicReference 中获取出调用线程中所有的上下文，并把上下文给 TransmittableThreadLocal.Transmitter.replay 方法把上下文复制到当前线程。并把上下文备份\n\n\n当线程执行完，调用 TransmittableThreadLocal.Transmitter.restore 并把备份的上下文传入，恢复备份的上下文，把后面新增的上下文删除，并重新把上下文复制到当前线程\n\ntransmittable-thread-local代码不多，但有很多亮点，可以自行膜拜\n在此场景，transmittable-thread-local还是太重了，其实可以简单借鉴一下transmittable-thread-local的思路，自定义Runnable\npublic TransRunnable(Runnable runnable)&#123;    this.runnable = runnable;    //在创建时，获取父traceId    this.parentId = TranceContext.getParentTrace();&#125;@Overridepublic void run() &#123;    //    String old = TranceContext.getParentTrace();    //设置父traceid    TranceContext.setParentTrace(parentId);    runnable.run();    //还原    TranceContext.setParentTrace(old);&#125;\n在创建子线程时，把父traceId带进去，就能在子线程业务方法中拿到父traceId,这样整个调用链也不会断\nscheduletraceid生成，有主动请求时，会生成，但如果是个系统的定时任务呢？\n\n让taskService调用一下入口，类似模拟用户行为\n主动生成一个parent traceId\n\n总结到此，对于traceid的知识结构丰满了很多\n","tags":["ThreadLocal","链路追踪"]},{"title":"程序员得懂点马斯洛理论","url":"/blog/programmers-need-to-understand-maslow-theory.html","content":"马斯洛需求层次理论是管理心理学中人际关系理论、群体动力理论、权威理论、需要层次理论、社会测量理论的五大理论支柱之一。\n\n以往对马斯洛需求层次理论的理解很肤浅：人对需求是有层次的，层次间都有依赖关系。当低层次的需求被满足后，才会去考虑更高一层次的需求。\n而且好像也没什么用处。知道之后既不能提升硬技能，也不能升职加薪。\n马斯洛理论定义通过《郭东白的架构课》的学习，了解到马斯洛理论的本意是：我们可能同时并行存在着多个需求，这些需求之间并不存在依赖或层次关系。\n包含两个重点：\n第一点：不是需求有层次，而是动机有优先级\n如果这些需求得不到满足，那么它们各自会诱发动机。但动机有优先级，且具备抢占性质。所以任何时候，只有一个动机在主导着整个人的意识和行为。\n第二点：动机跃迁模型\n人有且只有一个主导动机。这个动机由人的内在需求所驱动，并独占且主导你当前的一切意识和行为，你整个人，包括你的视觉、听觉、嗅觉，你的思考、记忆、行为等。直到这个动机背后的需求被完全满足之后，更高层次的动机才可能进入主导位置。\n学习了理论本意后，由于理论抽象度高，需要更具象的事才能更好地理解，经过反复思考，找到了一些日常工作中的常见的场景，可以用为进一步理解此理论的抓手。\n指导架构郭东白讲架构活动需要尊重和顺应人性，架构师必须洞察研发人员的人性，在方案设计和架构活动组织中充分考虑研发的人性，才能保障方案的正确性，以及方案的高效实施。\n什么样的架构才算是尊重和顺应人性呢？不得不再次搬出当下两个流行的事物：中台和微服务\n中台对于中台概念，可以温习之前写的中台是什么。定义中台为企业级能力复用平台。\n在做企业级业务架构时，做出来的模型，需要考虑两点：\n1、凡是公用的部分，应该照顾到所有利益相关方的需求；\n2、凡是已实现的功能都应该对新的需求方开放并支持必要的扩展。\n部门利益是做企业级的最大障碍，跨越这个障碍是对业务架构师设计能力的最高挑战。\n\n中台建设虽然需要兼顾各方的利益，但更多主要还是解决企业管理层对于公司长期生存与可持续发展的恐惧与焦虑问题\n\n中台建设的这两个考虑点，似乎是郭东白架构课程中重要价值输出的浓缩版本。\n前半段结合马斯洛理论，中台的建设通常都会伴随企业内的组织重构以及利益和职责的再分配，中台必然会触碰到前端业务团队利益，这自然威胁到了业务团队。\n尤其很多公司建设中台是跟风式的，本身就没有明确的战略意图，相当于架构活动没有正确目标，甚至没有目标，更没有清晰的构建路径，冒然简单粗暴地下沉前端业务功能，让原本根错综复杂的前端业务团队缺失了安全感，按马斯洛理论，业务团队满足安全需求的动机占据主导位置，可以想象，整个中台的推进速度。\n后半段则是任何企业活动的目标，都是为企业带来长期生存的优势。管理层、架构师都得考虑当下的活动是否真的带来生存优势。生存优势我简单理解为降本增效，ROI越高越有优势。\n微服务之前谈到微服务常会提到《康威定律与反康威定律》，随着近些年互联网行业的不景色，从以前的拆掉中台到现在的《拆掉微服务》。\n康威定律有个常用示例：如果有四个小组合作开发一个编译器，那么你将得到一款具有四个步骤的编辑器。\n结合马斯洛理论，每个小组都有了自己的一亩三分地，也就有了归属感和安全感，从人性角度，团队会更有活力、进取心和责任感。\n技术管理作为TL，在《码而优则仕》中提出三件重要事情。尤其激活团队。\nTL如何激励团队？\n都说现在00后是来整顿职场的，所以不能再像过去，员工以生存为目的，无条件接受资本主义压榨。\n现在生活条件大大改善，对应马斯洛最底层需求已经完全满足。管理者怎么办呢？会通过内部激励机制，如晋升职级；和红线制度，明确惩罚事项。\n有没有更高阶的方式方法呢？脱离上述的靠外部驱动。\n马斯洛理论给出指导方针：让员工有更多的归属和尊重。激发他们内部需求。\n\n总结一个看似无用的理论，经过高人的讲解，可以感知到原来这个理论贯穿在每日生活的细节中。\n马斯洛理论就是这样，不管是做架构还是做管理，只要有人参与的活动，都渗透着它的威力。\n","tags":["认知"]},{"title":"码而优则仕的3个底层认知","url":"/blog/three-underlying-cognition-of-code-and-excellence.html","content":"“学而优则仕”的传统文化渗透在各行各业。\n那么”码而优则仕”则是这种文化的延伸，自然而然的结果。\n当然很多程序员对做管理不感兴趣，想很纯粹的研究技术，成为一名技术专家。人各有志，但客观讲，技术专家与技术管理相比较，成为技术专家比技术管理难度大得多，只有做到在一个区域，一个行业屈指可数的顶尖专家，才有更加广阔的前景。尤其在国内的环境大多数都是业务型公司，技术本身没有直接价值，没有太高的壁垒，有太多能取代你位置的人。\n当然，技术管理也有难度，尤其对于程序员群体。但只要做到一个团队内的最佳，则拿到了敲门砖，随时准备幸运之神的降临。跨越技术纯粹性的舒适性，技术管理之路就开启了。\n\n\n\n当被首次提拔为技术管理时，会本能地做些什么呢？\n“我要让他们这样写代码”“以后这种事的流程这么走”“以后每周我们进行一次code review”“大家high起来”···\n这些很笼统，作为一名非管理专业且刚入门的管理新手，如何华丽转身？\n唯一驱动自我成长的帮助，就是寻找各种管理资料。\n各门各派的管理学说：\n1、 管理没那么复杂，只要做好四件事：把管、理、人、事组成四象限\n\n2、 管理第一件事就是招聘\n招聘第一原则：宁缺毋滥\n基本要求：\n\ncoding能力\n对技术的热情\n能简明扼要地沟通\n积极乐观\n对团队目标的认同\n\n3、 打造团队是日常工作首当其冲的任务\n作为团队Leader，都要走在团队前面，为团队规划方向、定义技术路线和架构模型、建立与之匹配的团队组织结构、团队骨干和backup\n4、 Leader的基本要求 \n不仅基本功要扎实，还得有架构能力、抽象能力、设计能力，包括前瞻性技术规划的能力\n5、 设计规范与制定流程\n如开发规范：命名规范、代码模板、maven规范、comment规范、统一API规范、异常规范、分支规范、日志规范\n制定流程：需求管理、架构评审、代码评审、发布评审\n6、 技术管理能力\n技术视野和技术格局，以及诸如交付能力、运行保障能力、带团队能力等等，真正落在具体工作场景中的核心技术能力，团队规划、绩效考核、团队建设\n7、 研发Leader的职责\n\n团队任务管理：开发工作量评估、开发任务分配\n团队生产质量提升：代码审核、开发风险识别&#x2F;报告&#x2F;协调解决\n团队生产力提升：代码模板研发与推广、最佳实践规范总结与推广、自动化研发生产工具研发与推广\n团队专业力提升：招聘面试、新人指导、领导复盘总结改进\n\n···\n···\n···\n\n看了上面的各个流派，是不是蒙圈了，没法干了，不知道到底要干什么？\n后面我去查找了管理的学术资料，管理的定义很简单：通过他人完成工作。\n明确不要再务实了，天天跟下属抢活干。\n并参加了一些管理培训，管理的4个任务\n\n达成目标：承接上级意图，带领团队追求卓越成果\n带好团队：明确方向，建立运作规则，奖罚公正\n发展自我：提升岗位能力，面向未来追求进步\n传承文化：身体力行，树立榜样\n\n根据所学，把管理定义进行一下扩句：\n\n让他人完成工作\n让他人高效完成工作\n让他人高效高质量完成工作\n让他人愉快高效高质量完成工作\n让他人主动愉快高效高质量完成工作\n\n\n虽然流派众多，干法万千，然而这些都是别人的，管理是艺术，终究需要结合自身特点，汇融众派集一身，形成自己的管理特色。\n在如此众多纷繁的方法论面前，怎么才能寻找到自己的特色，刘润说在快速变化的环境里面，我们要寻找底层逻辑，在乔新亮的CTO复盘中，发现了三个底层认知。\n第一个：组织调整到位\n乔老师讲的是职能型团队与产品型团队。\n对于一线管理者，组织调整，我想更多的是人才梯队。一个团队不可能都是强者，强强联合不如强弱组合。\n第二个：加强协同效率\n为什么要搞一堆开发规范，开会章程？不也是为了书同文，车同轨，让协作更流畅。\n为什么要建立坦诚透明的文化？也是为了减少信息差，上下同心，避免相互推诿。\n第三个：激活团队活力\n为什么要团建？公司是钱多请客吃饭？\n为什么搞考评淘汰，晋升制度？\n在招聘时，都要考察价值观？\n这些手段都是为了激活团队活力。\n当团队中越来越多的自律、自驱的同路人。先管，向管理要效益；然后慢慢不管，团队自律、自驱，管理达到无为状态。\n这三个底层认知是所有方法论的抽象，而在落地做事时，又得具象化。\n然而我想最根本的一条管理解法：业务持续高速发展，就如同个人一样：“何以解优，唯有暴富”。\n当公司业务在高速发展，野蛮扩张时，谁会关心管理细则，业务推着每个人前进，心中有成就感，财富也源源而来。心满意，钱到位。员工全火力猛干，老板也没空来看考勤记录，人员成本管控。\n但高速发展不会是常态，也就是管理不能永远缺席。管理是公司风险控制的重要保障。\n老子曾说：太上，不知有之；其次，亲而誉之；其次，畏之；其次，侮之。信不足焉，有不信焉。所以管理终极目标是不管。管理的目的是为了将不那么自我驱动的人，变得更主动、更积极，而不是当个监工，越管越严。\n而且管理者的职责不是保证每个人的成功，而是保证组织以及留 在组织中成员成功。如果管理者只做好人，最后大家短期开心，长期组织死掉了，最终把所有人都害了。\n","tags":["管理"]},{"title":"程序员成长职级","url":"/blog/programmer-growth-rank.html","content":"之前与老同事叙旧，一同事讲起现在公司在压缩人员，另一同事马上讲谁让你们把系统搞得那么好，几年都出不了个二级Bug，想想真是悲壮\n有时想程序员这群可爱的人，自命清高，但不过是群工具人而已；技术人特别像古时的武将，君主开疆拓土时，那真是座上宾，可一旦休战，杯酒释兵权都是佳话\n习武之人有三重境界，见自己，见天地，见众生；这三重境界很适合技术人\n对于程序员，很多人都梦想成长一名架构师，程序员怎么成长，在成长的途径中，要打哪些怪，经验值怎么分布，知道这些后，就能有的放矢\n最近听了阿里P9关于架构师成长之路，我特地记录一下，对照一下自己的成长\n职级整体打怪升级路径：工程师 - 高级工程师 - 技术专家 - 初级架构师 - 中级架构师 - 高级架构师\n工程师P5（1~3年）特点：求指导\n重点：基础（环境、工具、流程）\n技巧与误区：\n\n碎片化时间，系统化学习\n经典书籍系统学习：运行环境、编程语言、网络基础\n三大坑：编译原理，XXX内核代码、XX算法代码\n\n要想打好基础能力，首先要明确什么才是真正的“基础能力”。我的观点是“基础能力是指工作任务相关的基础能力，不是整个计算机技术的基础能力”，核心就是“工作相关”，千万不要单纯照搬别人口中的基础能力\n高级工程师P6（2~5年）特点：独挡一面（从需求设计到设计，编码完成整个流程）\n重点：积累经验（业务、套路【缓存，分库分表】、原理【redis,netty,看源码主要是了解怎么实现】）\n技巧与误区：\n\n掌握基础原理：JVM，开源软件等\n学习套路：分库分表、缓存、SOLID、设计模式、MVP等\n贪大求全，看了很多，但都是蜻蜓点水\n\n技术专家P7（4~8年）特点：领域专家\n重点：技术深度+宽度(深度【不仅知道reactor,还得知道怎么实现，redis与netty的reactor有什么区别】、全面、业界)\n技巧与误区：\n\n熟悉核心源码：成熟的开源软件，Memcache、Redis、Nginx、Netty等\n业界交流：参加技术大会，关注大厂技术\n生搬硬套，直接拷贝大厂技术，以防水土不服\n\n初级架构师P8（5~10年）特点：构建普通系统【指导20人内开发的系统】\n重点：方法论(复杂度驱动，风险驱动，领域驱动)\n技巧与误区：\n\n架构对比：Redis vs Memcache,Nginx vs Apache,Vue vs React等\n架构重构：尝试去重构已有的系统\n过分依赖以往成功经验\n\n中级架构师P9（8+年）特点：构建复杂系统【100人开发的系统】\n重点：技术本质\n\n理论：CAP\n算法：如Flink算法原理\n原理：cpu cache line\n\n技巧与误区：\n\n技术理论：CAP、BASE\\分布式快照算法等\n技术原理：磁盘(kaffa)、CPU和内存(Disruptor)等\n好大喜功，过度设计，炫技式设计\n\n高级架构师P10（10+年）特点：可以创建架构模式，如google大数据三大论文\n重点：创造\n\n业务\n技术\n文化\n\n\n从这个职级年限看，我这天赋太一般，职场规划也不行，现在大厂已经壮大，量级巨大，获取知识途径也更方便更多，所以对于当今程序员需要了解的知识面也更广更深，如果说以前北大青岛之类拉低了java程序员的门槛，那现在一些知识平台拉大程序员间的差距，不学则退\n晋升了解程序员进阶title之后，后面就是了解怎么能晋升，最好能快速晋升\n三大原则一、主动原则：主动做事主动规划工作任务，不能一味服从命令听指挥，领导指哪打哪，成为职场工具人\n主动跟别人了解更信息，不只是做好自己本职工作，还了解业务上下游，业务价值、上线后效果、没有达到预期的原因、机房部署\n二、成长原则：不断挖掘成长点误区：以为事情做得多，自然就能晋升；以为事情做得好，自然就晋升，把任务做完，保证效率和质量，拿到好绩效，但不一定晋升，因为不同级别的能力要求是有本质的区别的，而不仅仅是熟练度的区别，把事情做好，只能说明你已经熟练掌握当前级别所要求的能力，但并不一定意味着你的能力就自动达到下一职级的要求\n不管事情做好了还是没有做好，都应该多做复盘总结，找到可以提升优化的点\n三、价值原则：学习为公司产出价值的技能公司设计职级体系的初衷，是为了衡量不同员工的能力级别，然后根据级别来制定相应的薪酬、福利、管理等制度，同时鼓励员工尽量提升自己的能力，为公司产出更大的价值\n让能力为公司产出价值的人，比空有一身能力的人更容易晋升，优先学能为公司产出价值的技能\n晋升逻辑绩效关注的是业务结果，晋升关注的是能力提升；除了达到上述每个职级的技能要求，还有以下两条晋升逻辑\n第一条逻辑：提前做下一级别的事其实职级与本身能力是否匹配，有很多条件，就像你的薪资是否匹配当前能力一样，很难完美匹配，大多时候都是能力超过应有的福利；很多时候你的能力回报通常在下一份工作中兑现\n职级也一样，当你做了下一次职级的事情，就更有机会晋升\n第二条逻辑：做好当前级别的事由第一条逻辑引出捷径：晋升通过之后，立刻跟主管要求安排下一级别的工作来快速晋升，但在能胜任下一级别工作前，必须先做好当前级别的事\n任何级别都有三层水平：基础、熟练和精通\n基础意味着会做，标志是能够独立完成；熟练意味着做好，标志是掌握最佳实践；精通意味着优化，标志是创造新的经验\n晋升步骤\n按照晋升原则的指导，在当前级别拿到好结果，为公司创造价值，同时把当前级别要求的能力提升到精通程度，成为晋升备选人\n到了精通程度，对照下一级别要求提升自己能力，为可能的晋升做好准备\n主动寻找工作机会，尝试做下一级别事情，继续拿到好的结果，向主管证明具备下一级的能力\n拿到工作结果申请晋升，介绍做过的事情，展示相关能力和结果，证明自己具备了下一级别要求能力\n\n\n现在都讲究终身学习，学习为了什么？不是为了学习而学习，更多的是为了成长，如果只是一味地完成职场岗位本职工作，只能永远是棵随时被替换的螺丝钉，我们最根本的目标是成长，通过职场工作提升自己，成长自己。也许你很不屑晋升，认为那有很多厚黑学，但它是成长的催化剂，更与自己身利益息息相关，以终为始，事半功倍\n\n","tags":["职场"]},{"title":"程序员都不喜欢做项目管理","url":"/blog/programmers-dont-like-to-do-project-management.html","content":"《技术为径：带领公司走向卓越的工程师》–管理项目\n制定一份项目计划，需要搞清楚各部分之间的相互依赖关系。所有依赖关系都必须详加考虑，一个一个地反复讨论每个子任务的描述信息、时间安排、以及如何拆分。\n领导能帮助我解决一些问题，但是更多的问题需要我自己去解决。\n我一点都不喜欢这样的工作。这种体验给我留下了极为深刻的印象。我清晰地记得自己对任何一点疏忽的恐惧，对计划中的任何一点不确定性的反复斟酌。\n而这一切都是为了制订一份能让领导看上的计划表。接下来我们又需要将这份计划表转化为可以展示给公司管理层的格式，说服他们接受这一计划。感觉自己简直要烦死了。但是，这也是我职业我生涯中最重要的学习经历。\n现在都是敏捷开发，是不是不再需要项目管理了？\n敏捷开发只是一种拆分工作的好方式，它让你将注意力集中在小型目标上，从而不停地持续交付这些目标。\n但是，这不能取代项目管理。大型项目不可能在一个或两个冲刺周期内完成。你还需要向管理层预估项目的完成时间，同时附带对项目所需时间的解释信息。\n另外，某些项目，比如基础设施项目、平台项目、系统设计项目，通常需要详细的系统设计，或者非常超前的项目计划。\n在面对这样的项目时，存在大量的未知信息和刚性很强的时间节点，敏捷模式根本不适用。\n随着职业生涯的不断进步，学会如何将超出个人能力的复杂项目进行拆分是不可或缺的。\n对于一个时间周期很长、多人参加的项目进行项目管理，并不是每个人都会喜欢的工作。\n这项工作过于烦琐，同时还有点可怕。我喜欢构建系统、交付功能，而不太喜欢每天思考一个细节模糊的系统如何进行拆分。\n同时，我很怕自己在项目计划中某个疏忽导致项目最终失败。但是，如果我不亲自参与的话，项目也不会自己完成，而且有很大概率会浪费大家的更多时间。\n项目管理不能事无巨细地进行，这一点很多组织都意识不到。\n不要招专门的项目经理，因为他们往往会成为工程师推卸责任的“挡箭牌”，而非一起合作的的伙伴。专门的项目经理往往导致项目以瀑布流的方式进行，而非采用敏捷的方式推进。然而，一定程度的项目管理是不可避免的，技术小组长对技术性强的项目应该根据需要进行合理的项目计划。\n于项目提前规划的意义并不在于你是否事先想到了每一个细节，对未来考虑得是否周全，或者项目进度是否完美推进。\n其真正的意义在于，制订项目计划这个过程强迫工程师在动手实干之前，先对项目进行一些深度考量。\n++制订项目计划的真正目标在于，推动工程师在合适的进行合理的预测，并制订针对意外的应对计划。++\n至于这个计划到底有多么准确，并不一定真的那么重要。\n我们提前确定了想要达成的目标，同时也提前识别出一些可能导致项目失败的问题，并且为此提前做了准备。\n项目管理，让每个人认真地花时间去面对这些非技术性、无法提前预测的难题。这些困难的工作帮助每个人完成自己的复杂项目，并且帮助成长。让每个人都能带领更大的团队，更好地拆分任务，以构建更复杂的系统。\n作为技术人员，我们往往假设管理层十分这解我们的所做所想。“有问题就看看代码吧”作为技术领域内沉浸多年的技术人员，我们很容易假设别人和我们一样对这些问题了如指掌。\n但是，这是错误的。技术管理者竭尽全力地去招募精兵良将，是为了让这些人才来解决非常棘手的技术问题的。但是，这不意味着技术管理者全知全能。在我的职业生涯中，每次我们向一些非常资深的技术管理者耐心解释诸如“NoSQL是什么”这种问题时，他们都很由衷地感激我。\n现在，我一点都不觉得向其他人（不论他们是资深经理，还是新人）介绍基础技术概念及相关技术的优势对比是浪费自己的时间。\n如果以平等的方式与他们进行对话，他们就会慢慢地培养起对我的建议和决策能力的信任，而这终将有利于推动我想推动的变革。花时间向别人解释自己的想法是非常重要和值得的。\n","tags":["管理"]},{"title":"深入浅出spring事务","url":"/blog/spring-transactions-in-simple-terms.html","content":"前言这篇其实也要归纳到《常识》系列中，但这重点又是spring的介绍，故归档在spring系列中。\n工作很多年，除了学生时代学过，事务还真没有用过。过去开发游戏时，完全不用事务；现在互联网开发，也没有使用事务的场景，不要见怪。\n概念对于事务(Transaction)的概念，网上有各种版本，大同小异，\n事务就是是由一系列对系统中数据进行读写的操作组成的一个程序执行单元，狭义上的事务特指数据库事务。\n事务是一系列的动作，它们综合在一起才是一个完整的工作单元，这些动作必须全部完成，如果有一个失败的话，那么事务就会回滚到最开始的状态，仿佛什么都没发生过一样。 \n在企业级应用程序开发中，事务管理必不可少的技术，用来确保数据的完整性和一致性。 \n比如你去ATM机取1000块钱，大体有两个步骤：首先输入密码金额，银行卡扣掉1000元钱；然后ATM出1000元钱。这两个步骤必须是要么都执行要么都不执行。如果银行卡扣除了1000块但是ATM出钱失败的话，你将会损失1000元；如果银行卡扣钱失败但是ATM却出了1000块，那么银行将损失1000元。所以，如果一个步骤成功另一个步骤失败对双方都不是好事，如果不管哪一个步骤失败了以后，整个取钱过程都能回滚，也就是完全取消所有操作的话，这对双方都是极好的。 \n事务的特性大名鼎鼎的ACID\n\n原子性（Atomicity），事务必须是一个原子的操作序列单元，一次事务只允许存在两种状态，全部成功或全部失败，任何一个操作失败都将导致整个事务失败\n一致性（Consistency），事务的执行不能破坏系统数据的完整性和一致性，如果未完成的事务对系统数据的修改有一部分已经写入物理数据库，这时系统数据就处于不一致状态\n隔离性（Isolation），在并发环境中，不同的事务操作相同的数据时，虚相互隔离不能相互干扰\n持久性（Durability），事务一旦提交，对系统数据的变更就应该是永久的，必须被永久保存下来，即使服务器宕机了，只要数据库能够重新启动，就一定能够恢复到事务成功结束时的状态\n\n事务并发处理问题如果没有锁定且多个用户同时访问一个数据库，则当他们的事务同时使用相同的数据时可能会发生问题。由于并发操作带来的数据不一致性包括：丢失数据修改、读”脏”数据（脏读）、不可重复读、产生幽灵数据：\n假设数据库中有如下一张表：\n\n第一类丢失更新(lost update)回滚丢失\n在完全未隔离事务的情况下，两个事物更新同一条数据资源，某一事物异常终止，回滚造成第一个完成的更新也同时丢失。\n在T1时刻开启了事务1，T2时刻开启了事务2，\n在T3时刻事务1从数据库中取出了id&#x3D;”402881e535194b8f0135194b91310001”的数据，\nT4时刻事务2取出了同一条数据，\nT5时刻事务1将age字段值更新为30，\nT6时刻事务2更新age为35并提交了数据，\n但是T7事务1回滚了事务age最后的值依然为20，事务2的更新丢失了，\n这种情况就叫做”第一类丢失更新(lost update)”。\n脏读(dirty read)事务没提交，提前读取\n如果第二个事务查询到第一个事务还未提交的更新数据，形成脏读\n在T1时刻开启了事务1，T2时刻开启了事务2，\n在T3时刻事务1从数据库中取出了id&#x3D;”402881e535194b8f0135194b91310001”的数据，\n在T5时刻事务1将age的值更新为30，但是事务还未提交，\nT6时刻事务2读取同一条记录，获得age的值为30，但是事务1还未提交，\n若在T7时刻事务1回滚了事务2的数据就是错误的数据(脏数据)，\n这种情况叫做” 脏读(dirty read)”。\n虚读(phantom read)一个事务执行两次查询，第二次结果集包含第一次中没有或者某些行已被删除，造成两次结果不一致，只是另一个事务在这两次查询中间插入或者删除了数据造成的\n\n在T1时刻开启了事务1，T2时刻开启了事务2，\nT3时刻事务1从数据库中查询所有记录，记录总共有一条，\nT4时刻事务2向数据库中插入一条记录，T6时刻事务2提交事务。\nT7事务1再次查询数据数据时，记录变成两条了。\n这种情况是”虚读(phantom read)”。\n不可重复读(unrepeated read)一个事务两次读取同一行数据，结果得到不同状态结果，如中间正好另一个事务更新了该数据，两次结果相异，不可信任\n在T1时刻开启了事务1，T2时刻开启了事务2，\n在T3时刻事务1从数据库中取出了id&#x3D;”402881e535194b8f0135194b91310001”的数据，此时age&#x3D;20，\nT4时刻事务2查询同一条数据，\nT5事务2更新数据age&#x3D;30，T6时刻事务2提交事务，\nT7事务1查询同一条数据，发现数据与第一次不一致。\n这种情况就是”不可重复读(unrepeated read)”\n第二类丢失更新(second lost updates)覆盖丢失\n不可重复读的特殊情况，如果两个事务都读取同一行，然后两个都进行写操作，并提交，第一个事务所做的改变就会丢失。\n\n在T1时刻开启了事务1，T2时刻开启了事务2，\nT3时刻事务1更新数据age&#x3D;25，\nT5时刻事务2更新数据age&#x3D;30，\nT6时刻提交事务，\nT7时刻事务2提交事务，把事务1的更新覆盖了。\n这种情况就是”第二类丢失更新(second lost updates)”。\n并发问题总结不可重复读的重点是修改 : \n同样的条件 ,   你读取过的数据 ,   再次读取出来发现值不一样了 \n幻读的重点在于新增或者删除 \n同样的条件 ,   第 1 次和第 2 次读出来的记录数不一样 \n第一类更新丢失(回滚丢失)\n第二类更新丢失(覆盖丢失)\n隔离级别解决并发问题的途径是什么?答案是：采取有效的隔离机制。怎样实现事务的隔离呢？隔离机制的实现必须使用锁\n一般在编程的时候只需要设置隔离等级\n数据库系统提供四种事务隔离级别：\n\n未提交读（READ UNCOMMITTED ）\n\n最低隔离级别，一个事务能读取到别的事务未提交的更新数据，很不安全，可能出现丢失更新、脏读、不可重复读、幻读；\n\n提交读（READ COMMITTED）\n\n一个事务能读取到别的事务提交的更新数据，不能看到未提交的更新数据，不会出现丢失更新、脏读，但可能出现不可重复读、幻读；3. 可重复读（REPEATABLE READ）\n保证同一事务中先后执行的多次查询将返回同一结果，不受其他事务影响，不可能出现丢失更新、脏读、不可重复读，但可能出现幻读；\n\n序列化（SERIALIZABLE）\n\n最高隔离级别，不允许事务并发执行，而必须串行化执行，最安全，不可能出现更新、脏读、不可重复读、幻读，但是效率最低。\n\n隔离级别越高，数据库事务并发执行性能越差，能处理的操作越少。所以一般地，推荐使用REPEATABLE READ级别保证数据的读一致性。对于幻读的问题，可以通过加锁来防止\n\nMySQL支持这四种事务等级，默认事务隔离级别是REPEATABLE READ。\nOracle数据库支持READ COMMITTED 和 SERIALIZABLE这两种事务隔离级别，所以Oracle数据库不支持脏读\nOracle数据库默认的事务隔离级别是READ COMMITTED\n不可重复读和幻读的区别是，不可重复读对应的表的操作是更改(UPDATE)，而幻读对应的表的操作是插入(INSERT)，两种的应对策略不一样。对于不可重复读，只需要采用行级锁防止该记录被更新即可，而对于幻读必须加个表级锁，防止在表中插入数据\n锁乐观锁(Optimistic Lock)和悲观锁(Pessimistic Lock)最重要的分类就是乐观锁(Optimistic Lock)和悲观锁(Pessimistic Lock)，这实际上是两种锁策略\n乐观锁，顾名思义就是非常乐观，非常相信真善美，每次去读数据都认为其它事务没有在写数据，所以就不上锁，快乐的读取数据，而只在提交数据的时候判断其它事务是否搞过这个数据了，如果搞过就rollback。乐观锁相当于一种检测冲突的手段，可通过为记录添加版本或添加时间戳来实现。\n悲观锁，对其它事务抱有保守的态度，每次去读数据都认为其它事务想要作祟，所以每次读数据的时候都会上锁，直到取出数据。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性，但随之而来的是各种开销。悲观锁相当于一种避免冲突的手段。\n选择标准：如果并发量不大，或数据冲突的后果不严重，则可以使用乐观锁；而如果并发量大或数据冲突后果比较严重（对用户不友好），那么就使用悲观锁。\n分共享锁（S锁，Shared Lock）和排他锁（X锁，Exclusive Lock）从读写角度，分共享锁（S锁，Shared Lock）和排他锁（X锁，Exclusive Lock），也叫读锁（Read Lock）和写锁（Write Lock）。理解：\n持有S锁的事务只读不可写。\n如果事务A对数据D加上S锁后，其它事务只能对D加上S锁而不能加X锁。\n持有X锁的事务可读可写。\n如果事务A对数据D加上X锁后，其它事务不能再对D加锁，直到A对D的锁解除。\n表级锁（Table Lock）和行级锁（Row Lock）从锁的粒度角度，主要分为表级锁（Table Lock）和行级锁（Row Lock）。\n表级锁将整个表加锁，性能开销最小\n用户可以同时进行读操作。当一个用户对表进行写操作时，用户可以获得一个写锁，写锁禁止其他的用户读写操作。写锁比读锁的优先级更高，即使有读操作已排在队列中，一个被申请的写锁仍可以排在所队列的前列。\n行级锁仅对指定的记录进行加锁\n这样其它进程可以对同一个表中的其它记录进行读写操作。行级锁粒度最小，开销大，能够支持高并发，可能会出现死锁。\nMySQL的MyISAM引擎使用表级锁，而InnoDB支持表级锁和行级锁，默认是行级锁。还有BDB引擎使用页级锁，即一次锁定一组记录，并发性介于行级锁和表级锁之间。\n三级锁协议三级加锁协议是为了保证正确的事务并发操作，事务在读、写数据库对象是需要遵循的加锁规则。\n一级封锁协议：事务T在修改数据R之前必须对它加X锁，直到事务结束方可释放。而若事务T只是读数据，不进行修改，则不需加锁，因此一级加锁协议下可能会出现脏读和不可重复读。\n二级加锁协议：在一级加锁协议的基础上，加上这样一条规则——事务T在读取数据R之前必须对它加S锁，直到读取完毕以后释放。二级加锁协议下可能会出现不可重复读。\n三级加锁协议：在一级加锁协议的基础上，加上这样一条规则——事务T在读取数据R之前必须对它加S锁，直到事务结束方可释放。三级加锁协议避免了脏读和不可重复读的问题\nSpring事务Spring事务管理的实现有许多细节，如果对整个接口框架有个大体了解会非常有利于我们理解事务\n\n\nSpring事务管理器Spring事务管理涉及的接口的联系如下：\nSpring并不直接管理事务，而是提供了多种事务管理器，他们将事务管理的职责委托给Hibernate或者JTA等持久化机制所提供的相关平台框架的事务来实现。 \nSpring事务管理器的接口是org.springframework.transaction.PlatformTransactionManager，通过这个接口，Spring为各个平台如JDBC、Hibernate等都提供了对应的事务管理器，\n但是具体的实现就是各个平台自己的事情了\n/** * This is the central interface in Spring&#x27;s transaction infrastructure. * Applications can use this directly, but it is not primarily meant as API: * Typically, applications will work with either TransactionTemplate or * declarative transaction demarcation through AOP. */public interface PlatformTransactionManager &#123;    TransactionStatus getTransaction(TransactionDefinition definition)        throws TransactionException;    void commit(TransactionStatus status) throws TransactionException;    void rollback(TransactionStatus status) throws TransactionException;&#125;\n\n标准的jdbc处理事务代码\nConnection conn = DataSourceUtils.getConnection(); //开启事务conn.setAutoCommit(false);try &#123;    Object retVal = callback.doInConnection(conn);    conn.commit(); //提交事务    return retVal;&#125;catch (Exception e) &#123;    conn.rollback();//回滚事务    throw e;&#125;finally &#123;    conn.close();&#125;\n\nspring对应的TranstactionTemplate处理\npublic class TransactionTemplate extends DefaultTransactionDefinition\t\timplements TransactionOperations, InitializingBean &#123;\t\t    @Override\tpublic &lt;T&gt; T execute(TransactionCallback&lt;T&gt; action) throws TransactionException &#123;\t\tif (this.transactionManager instanceof CallbackPreferringPlatformTransactionManager) &#123;\t\t\treturn ((CallbackPreferringPlatformTransactionManager) this.transactionManager).execute(this, action);\t\t&#125;\t\telse &#123;\t\t\tTransactionStatus status = this.transactionManager.getTransaction(this);\t\t\tT result;\t\t\ttry &#123;\t\t\t\tresult = action.doInTransaction(status);\t\t\t&#125;\t\t\tcatch (RuntimeException ex) &#123;\t\t\t\t// Transactional code threw application exception -&gt; rollback\t\t\t\trollbackOnException(status, ex);\t\t\t\tthrow ex;\t\t\t&#125;\t\t\tcatch (Error err) &#123;\t\t\t\t// Transactional code threw error -&gt; rollback\t\t\t\trollbackOnException(status, err);\t\t\t\tthrow err;\t\t\t&#125;\t\t\tcatch (Exception ex) &#123;\t\t\t\t// Transactional code threw unexpected exception -&gt; rollback\t\t\t\trollbackOnException(status, ex);\t\t\t\tthrow new UndeclaredThrowableException(ex, &quot;TransactionCallback threw undeclared checked exception&quot;);\t\t\t&#125;\t\t\tthis.transactionManager.commit(status);\t\t\treturn result;\t\t&#125;\t&#125;\t&#125;\n具体的事务管理机制对Spring来说是透明的，它并不关心那些，那些是对应各个平台需要关心的，所以Spring事务管理的一个优点就是为不同的事务API提供一致的编程模型，如JTA、JDBC、Hibernate、JPA。下面分别介绍各个平台框架实现事务管理的机制。\n\nJDBC事务如果应用程序中直接使用JDBC来进行持久化，DataSourceTransactionManager会为你处理事务边界。为了使用DataSourceTransactionManager，你需要使用如下的XML将其装配到应用程序的上下文定义中：\n&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;    &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt;\n实际上，DataSourceTransactionManager是通过调用java.sql.Connection来管理事务，而后者是通过DataSource获取到的。通过调用连接的commit()方法来提交事务，同样，事务失败则通过调用rollback()方法进行回滚。\nHibernate事务如果应用程序的持久化是通过Hibernate实习的，那么你需要使用HibernateTransactionManager。对于Hibernate3，需要在Spring上下文定义中添加如下的声明：\n&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.orm.hibernate3.HibernateTransactionManager&quot;&gt;    &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot; /&gt;&lt;/bean&gt;\nsessionFactory属性需要装配一个Hibernate的session工厂，HibernateTransactionManager的实现细节是它将事务管理的职责委托给org.hibernate.Transaction对象，而后者是从Hibernate Session中获取到的。当事务成功完成时，HibernateTransactionManager将会调用Transaction对象的commit()方法，反之，将会调用rollback()方法。\n事务属性事务管理器接口PlatformTransactionManager通过getTransaction(TransactionDefinition definition)方法来得到事务，这个方法里面的参数是TransactionDefinition类，这个类就定义了一些基本的事务属性。\npublic interface TransactionDefinition &#123;    int getPropagationBehavior(); // 返回事务的传播行为    int getIsolationLevel(); // 返回事务的隔离级别，事务管理器根据它来控制另外一个事务可以看到本事务内的哪些数据    int getTimeout();  // 返回事务必须在多少秒内完成    boolean isReadOnly(); // 事务是否只读，事务管理器能够根据这个返回值进行优化，确保事务是只读的&#125; \n\n那么什么是事务属性呢？事务属性可以理解成事务的一些基本配置，描述了事务策略如何应用到方法上。事务属性包含了5个方面\n\n传播行为事务的第一个方面是传播行为（propagation behavior）。当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。\n为什么需要定义传播？\n\n在我们用SSH开发项目的时候，我们一般都是将事务设置在Service层 那么当我们调用Service层的一个方法的时候它能够保证我们的这个方法中执行的所有的对数据库的更新操作保持在一个事务中，在事务层里面调用的这些方法要么全部成功，要么全部失败。那么事务的传播特性也是从这里说起的。如果你在你的Service层的这个方法中，除了调用了Dao层的方法之外，还调用了本类的其他的Service方法，那么在调用其他的Service方法的时候，这个事务是怎么规定的呢，我必须保证我在我方法里掉用的这个方法与我本身的方法处在同一个事务中，否则如果保证事物的一致性。事务的传播特性就是解决这个问题的，“事务是会传播的”在Spring中有针对传播特性的多种配置我们大多数情况下只用其中的一种:PROPGATION_REQUIRED：这个配置项的意思是说当我调用service层的方法的时候开启一个事务(具体调用那一层的方法开始创建事务，要看你的aop的配置),那么在调用这个service层里面的其他的方法的时候,如果当前方法产生了事务就用当前方法产生的事务，否则就创建一个新的事务。这个工作使由Spring来帮助我们完成的。以前没有Spring帮助我们完成事务的时候我们必须自己手动的控制事务，例如当我们项目中仅仅使用hibernate，而没有集成进spring的时候，我们在一个service层中调用其他的业务逻辑方法，为了保证事物必须也要把当前的hibernate session传递到下一个方法中，或者采用ThreadLocal的方法，将session传递给下一个方法，其实都是一个目的。现在这个工作由spring来帮助我们完成，就可以让我们更加的专注于我们的业务逻辑。而不用去关心事务的问题。\n\nSpring定义了七种传播行为：\nPROPAGATION_REQUIRED\n如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。\nPROPAGATION_SUPPORTS\n支持当前事务，如果当前没有事务，就以非事务方式执行。\nPROPAGATION_MANDATORY\n使用当前的事务，如果当前没有事务，就抛出异常。\nPROPAGATION_REQUIRES_NEW\n新建事务，如果当前存在事务，把当前事务挂起。\nPROPAGATION_NOT_SUPPORTED\n以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。\nPROPAGATION_NEVER\n以非事务方式执行，如果当前存在事务，则抛出异常。\nPROPAGATION_NESTED\n如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。\n传播行为详细通过实例尝试一下各个传播属性\nServiceA &#123;            void methodA() &#123;         ServiceB.methodB();     &#125;&#125;  ServiceB &#123;            void methodB() &#123;     &#125;&#125;\n\n\nPROPAGATION_REQUIRED如果存在一个事务，则支持当前事务。如果没有事务则开启一个新的事务\n//事务属性 PROPAGATION_REQUIREDmethodA&#123;    ……    methodB();    ……&#125;//事务属性 PROPAGATION_REQUIREDmethodB&#123;   ……&#125;\n\n单独调用methodB方法：\nmain&#123;     metodB(); &#125;\n相当于\nMain&#123;     Connection con=null;     try&#123;         con = getConnection();         con.setAutoCommit(false);         //方法调用        methodB();         //提交事务        con.commit();     &#125; Catch(RuntimeException ex) &#123;         //回滚事务        con.rollback();       &#125; finally &#123;         //释放资源        closeCon();     &#125; &#125; \nSpring保证在methodB方法中所有的调用都获得到一个相同的连接。在调用methodB时，没有一个存在的事务，所以获得一个新的连接，开启了一个新的事务。 \n只是在ServiceB.methodB内的任何地方出现异常，ServiceB.methodB将会被回滚，不会引起ServiceA.methodA的回滚\n单独调用MethodA时，在MethodA内又会调用MethodB.\n执行效果相当于：\nmain&#123;     Connection con = null;     try&#123;         con = getConnection();         methodA();         con.commit();     &#125; catch(RuntimeException ex) &#123;         con.rollback();     &#125; finally &#123;            closeCon();     &#125;  &#125; \n调用MethodA时，环境中没有事务，所以开启一个新的事务.\n当在MethodA中调用MethodB时，环境中已经有了一个事务，所以methodB就加入当前事务\nServiceA.methodA或者ServiceB.methodB无论哪个发生异常methodA和methodB作为一个整体都将一起回滚\nPROPAGATION_SUPPORTS如果存在一个事务，支持当前事务。如果没有事务，则非事务的执行。但是对于事务同步的事务管理器，PROPAGATION_SUPPORTS与不使用事务有少许不同\n//事务属性 PROPAGATION_REQUIREDmethodA()&#123;  methodB();&#125;//事务属性 PROPAGATION_SUPPORTSmethodB()&#123;  ……&#125;\n单纯的调用methodB时，methodB方法是非事务的执行的。当调用methdA时,methodB则加入了methodA的事务中,事务地执行\nPROPAGATION_MANDATORY如果已经存在一个事务，支持当前事务。如果没有一个活动的事务，则抛出异常\n//事务属性 PROPAGATION_REQUIREDmethodA()&#123;    methodB();&#125;//事务属性 PROPAGATION_MANDATORY    methodB()&#123;    ……&#125;\n当单独调用methodB时，因为当前没有一个活动的事务，则会抛出异常throw new IllegalTransactionStateException(“Transaction propagation ‘mandatory’ but no existing transaction found”);\n当调用methodA时，methodB则加入到methodA的事务中，事务地执行\nPROPAGATION_REQUIRES_NEW总是开启一个新的事务。如果一个事务已经存在，则将这个存在的事务挂起。\n//事务属性 PROPAGATION_REQUIREDmethodA()&#123;    doSomeThingA();    methodB();    doSomeThingB();&#125;//事务属性 PROPAGATION_REQUIRES_NEWmethodB()&#123;    ……&#125;\n调用A方法：\nmain()&#123;    methodA();&#125;\n相当于\nmain()&#123;    TransactionManager tm = null;    try&#123;        //获得一个JTA事务管理器        tm = getTransactionManager();        tm.begin();//开启一个新的事务        Transaction ts1 = tm.getTransaction();        doSomeThing();        tm.suspend();//挂起当前事务        try&#123;            tm.begin();//重新开启第二个事务            Transaction ts2 = tm.getTransaction();            methodB();            ts2.commit();//提交第二个事务        &#125; Catch(RunTimeException ex) &#123;            ts2.rollback();//回滚第二个事务        &#125; finally &#123;            //释放资源        &#125;        //methodB执行完后，恢复第一个事务        tm.resume(ts1);        doSomeThingB();        ts1.commit();//提交第一个事务    &#125; catch(RunTimeException ex) &#123;        ts1.rollback();//回滚第一个事务    &#125; finally &#123;        //释放资源    &#125;&#125;\n在这里，我把ts1称为外层事务，ts2称为内层事务。从上面的代码可以看出，ts2与ts1是两个独立的事务，互不相干。\nTs2是否成功并不依赖于ts1\n如果methodA方法在调用methodB方法后的doSomeThingB方法失败了，而methodB方法所做的结果依然被提交。\n而除了 methodB之外的其它代码导致的结果却被回滚了\nPROPAGATION_NOT_SUPPORTED以非事务方式执行操作，如果当前存在事务，就把当前事务挂起,\n//事务属性 PROPAGATION_REQUIREDmethodA()&#123;    doSomeThingA();    methodB();    doSomeThingB();&#125;//事务属性 PROPAGATION_NOT_SUPPORTEDmethodB()&#123;    ……&#125;\n当前不支持事务。比如ServiceA.methodA的事务级别是PROPAGATION_REQUIRED ，而ServiceB.methodB的事务级别是PROPAGATION_NOT_SUPPORTED ，那么当执行到ServiceB.methodB时，ServiceA.methodA的事务挂起，而他以非事务的状态运行完，再继续ServiceA.methodA的事务\nPROPAGATION_NEVER不能在事务中运行。假设ServiceA.methodA的事务级别是PROPAGATION_REQUIRED，而ServiceB.methodB的事务级别是PROPAGATION_NEVER ，那么ServiceB.methodB就要抛出异常了。\nPROPAGATION_NESTED开始一个 “嵌套的” 事务,  它是已经存在事务的一个真正的子事务. 潜套事务开始执行时,  它将取得一个 savepoint. 如果这个嵌套事务失败, 我们将回滚到此 savepoint. 潜套事务是外部事务的一部分, 只有外部事务结束后它才会被提交. \n比如我们设计ServiceA.methodA的事务级别为PROPAGATION_REQUIRED，ServiceB.methodB的事务级别为PROPAGATION_NESTED，那么当执行到ServiceB.methodB的时候，ServiceA.methodA所在的事务就会挂起，ServiceB.methodB会起一个新的子事务并设置savepoint，等待ServiceB.methodB的事务完成以后，他才继续执行\n因为ServiceB.methodB是外部事务的子事务，那么\n\n如果ServiceB.methodB已经提交，那么ServiceA.methodA失败回滚，ServiceB.methodB也将回滚。\n如果ServiceB.methodB失败回滚，如果他抛出的异常被ServiceA.methodA的try..catch捕获并处理，ServiceA.methodA事务仍然可能提交；如果他抛出的异常未被ServiceA.methodA捕获处理，ServiceA.methodA事务将回滚。\n\n理解Nested的关键是savepoint。\n与PROPAGATION_REQUIRES_NEW的区别：\n\nRequiresNew每次都创建新的独立的物理事务，而Nested只有一个物理事务；\nNested嵌套事务回滚或提交不会导致外部事务回滚或提交，但外部事务回滚将导致嵌套事务回滚，而 RequiresNew由于都是全新的事务，所以之间是无关联的；\nNested使用JDBC 3的保存点实现，即如果使用低版本驱动将导致不支持嵌套事务。使用嵌套事务，必须确保具体事务管理器实现的nestedTransactionAllowed属性为true，否则不支持嵌套事务，如DataSourceTransactionManager默认支持，而HibernateTransactionManager默认不支持，需要我们来开启。\n\n在 spring 中使用 PROPAGATION_NESTED的前提：\n\n我们要设置 transactionManager 的 nestedTransactionAllowed 属性为 true, 注意, 此属性默认为 false!!! \njava.sql.Savepoint 必须存在, 即 jdk 版本要 1.4+ \nConnection.getMetaData().supportsSavepoints() 必须为 true, 即 jdbc drive 必须支持 JDBC 3.0\n\n\n隔离规则用来解决并发事务时出现的问题，其使用TransactionDefinition中的静态变量来指定\n\nISOLATION_DEFAULT\t使用后端数据库默认的隔离级别\nISOLATION_READ_UNCOMMITTED\t最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读\nISOLATION_READ_COMMITTED\t允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生\nISOLATION_REPEATABLE_READ\t对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生\nISOLATION_SERIALIZABLE\t最高的隔离级别，完全服从ACID的隔离级别，确保阻止脏读、不可重复读以及幻读，也是最慢的事务隔离级别，因为它通常是通过完全锁定事务相关的数据库表来实现的\n\n可以使用DefaultTransactionDefinition类的setIsolationLevel(TransactionDefinition. ISOLATION_READ_COMMITTED)来指定隔离级别，其中此处表示隔离级别为提交读\n也可以使用或setIsolationLevelName(“ISOLATION_READ_COMMITTED”)方式指定，其中参数就是隔离级别静态变量的名字，但不推荐这种方式\n事务只读将事务标识为只读，只读事务不修改任何数据；\n对于JDBC只是简单的将连接设置为只读模式，对于更新将抛出异常；\n对于一些其他ORM框架有一些优化作用，如在Hibernate中，Spring事务管理器将执行“session.setFlushMode(FlushMode.MANUAL)”即指定Hibernate会话在只读事务模式下不用尝试检测和同步持久对象的状态的更新。\n如果使用设置具体事务管理的validateExistingTransaction属性为true（默认false），将确保整个事务传播链都是只读或都不是只读\n第二个addressService.save()不能设置成false\n对于错误的事务只读设置将抛出IllegalTransactionStateException异常，并伴随“Participating transaction with definition [……] is not marked as read-only……”信息，表示参与的事务只读属性设置错误\n事务超时设置事务的超时时间，单位为秒，默认为-1表示使用底层事务的超时时间\n使用如setTimeout(100)来设置超时时间，如果事务超时将抛出org.springframework.transaction.TransactionTimedOutException异常并将当前事务标记为应该回滚，即超时后事务被自动回滚\n可以使用具体事务管理器实现的defaultTimeout属性设置默认的事务超时时间，如DataSourceTransactionManager. setDefaultTimeout(10)\n回滚规则spring事务管理器会捕捉任何未处理的异常，然后依据规则决定是否回滚抛出异常的事务\n默认配置下，Spring只有在抛出的异常为运行时unchecked异常时才回滚该事务，也就是抛出的异常为RuntimeException的子类(Errors也会导致事务回滚)，而抛出checked异常则不会导致事务回滚。可以明确的配置在抛出那些异常时回滚事务，包括checked异常。也可以明确定义那些异常抛出时不回滚事务\n如何改变默认规则：\n\n让checked例外也回滚：在整个方法前加上 @Transactional(rollbackFor&#x3D;Exception.class)\n让unchecked例外不回滚： @Transactional(notRollbackFor&#x3D;RunTimeException.class)\n不需要事务管理的(只查询的)方法：@Transactional(propagation&#x3D;Propagation.NOT_SUPPORTED)\n\n事务状态上面讲到的调用PlatformTransactionManager接口的getTransaction()的方法得到的是TransactionStatus接口的一个实现，这个接口的内容如下：\npublic interface TransactionStatus&#123;    boolean isNewTransaction(); // 是否是新的事物    boolean hasSavepoint(); // 是否有恢复点    void setRollbackOnly();  // 设置为只回滚    boolean isRollbackOnly(); // 是否为只回滚    boolean isCompleted; // 是否已完成&#125; \n可以发现这个接口描述的是一些处理事务提供简单的控制事务执行和查询事务状态的方法，在回滚或提交的时候需要应用对应的事务状态\n编程式和声明式事务Spring提供了对编程式事务和声明式事务的支持，编程式事务允许用户在代码中精确定义事务的边界\n而声明式事务（基于AOP）有助于用户将操作与事务规则进行解耦。 \n简单地说，编程式事务侵入到了业务代码里面，但是提供了更加详细的事务管理；而声明式事务由于基于AOP，所以既能起到事务管理的作用，又可以不影响业务代码的具体实现。\n编程式Spring提供两种方式的编程式事务管理，分别是：使用TransactionTemplate和直接使用PlatformTransactionManager\n使用TransactionTemplate采用TransactionTemplate和采用其他Spring模板，如JdbcTempalte和HibernateTemplate是一样的方法。它使用回调方法，把应用程序从处理取得和释放资源中解脱出来。如同其他模板，TransactionTemplate是线程安全的。代码片段：\nTransactionTemplate tt = new TransactionTemplate(); // 新建一个TransactionTemplateObject result = tt.execute(    new TransactionCallback()&#123;          public Object doTransaction(TransactionStatus status)&#123;              updateOperation();              return resultOfUpdateOperation();          &#125;  &#125;); // 执行execute方法进行事务管理\n\n使用TransactionCallback()可以返回一个值。如果使用TransactionCallbackWithoutResult则没有返回值\n使用PlatformTransactionManager示例代码如下：\nDataSourceTransactionManager dataSourceTransactionManager = new DataSourceTransactionManager();//定义一个某个框架平台的TransactionManager，如JDBC、HibernatedataSourceTransactionManager.setDataSource(this.getJdbcTemplate().getDataSource()); // 设置数据源    DefaultTransactionDefinition transDef = new DefaultTransactionDefinition(); // 定义事务属性    transDef.setPropagationBehavior(DefaultTransactionDefinition.PROPAGATION_REQUIRED); // 设置传播行为属性    TransactionStatus status = dataSourceTransactionManager.getTransaction(transDef); // 获得事务状态    try &#123;        // 数据库操作        dataSourceTransactionManager.commit(status);// 提交    &#125; catch (Exception e) &#123;        dataSourceTransactionManager.rollback(status);// 回滚    &#125;\n\n声明式有几种实现方式，不一一罗列了\n使用tx拦截器     &lt;bean id=&quot;transactionManager&quot;        class=&quot;org.springframework.orm.hibernate3.HibernateTransactionManager&quot;&gt;        &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot; /&gt;    &lt;/bean&gt;    &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt;        &lt;tx:attributes&gt;            &lt;tx:method name=&quot;*&quot; propagation=&quot;REQUIRED&quot; /&gt;        &lt;/tx:attributes&gt;    &lt;/tx:advice&gt;    &lt;aop:config&gt;        &lt;aop:pointcut id=&quot;interceptorPointCuts&quot;            expression=&quot;execution(* com.bluesky.spring.dao.*.*(..))&quot; /&gt;        &lt;aop:advisor advice-ref=&quot;txAdvice&quot;            pointcut-ref=&quot;interceptorPointCuts&quot; /&gt;           &lt;/aop:config&gt; \n全注解&lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot; /&gt;    &lt;bean id=&quot;transactionManager&quot;          class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager &quot;&gt;        &lt;property name=&quot;dataSource&quot;&gt;            &lt;ref bean=&quot;basicDataSource&quot; /&gt;        &lt;/property&gt;&lt;/bean&gt;\n\nSpring源码片段在《BeanPostProcessor学习》中提到了AOP的实现方式，声明式事务实现是基于AOP\n首先得解析xml配置，TxNamespaceHandler\n@Override\tpublic void init() &#123;\t\tregisterBeanDefinitionParser(&quot;advice&quot;, new TxAdviceBeanDefinitionParser());\t\tregisterBeanDefinitionParser(&quot;annotation-driven&quot;, new AnnotationDrivenBeanDefinitionParser());\t\tregisterBeanDefinitionParser(&quot;jta-transaction-manager&quot;, new JtaTransactionManagerBeanDefinitionParser());\t&#125;\n\n主要是TransactionInterceptor类\npublic Object invoke(final MethodInvocation invocation) throws Throwable &#123;\t\t// Work out the target class: may be &#123;@code null&#125;.\t\t// The TransactionAttributeSource should be passed the target class\t\t// as well as the method, which may be from an interface.\t\tClass&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null);\t\t// Adapt to TransactionAspectSupport&#x27;s invokeWithinTransaction...\t\t//主要逻辑在父类\t\treturn invokeWithinTransaction(invocation.getMethod(), targetClass, new InvocationCallback() &#123;\t\t\t@Override\t\t\tpublic Object proceedWithInvocation() throws Throwable &#123;\t\t\t\treturn invocation.proceed();\t\t\t&#125;\t\t&#125;);\t&#125;\n\n核心逻辑，还得看父类TransactionAspectSupport#invokeWithinTransaction\n逻辑主干很清晰\nif (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) &#123;\t\t\t// Standard transaction demarcation with getTransaction and commit/rollback calls.\t\t\t// 判断创建Transaction\t\t\tTransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification);\t\t\tObject retVal = null;\t\t\ttry &#123;\t\t\t\t// This is an around advice: Invoke the next interceptor in the chain.\t\t\t\t// This will normally result in a target object being invoked.\t\t\t\t//执行业务逻辑\t\t\t\tretVal = invocation.proceedWithInvocation();\t\t\t&#125;\t\t\tcatch (Throwable ex) &#123;\t\t\t\t// target invocation exception\t\t\t\t// 出现异常，回滚\t\t\t\tcompleteTransactionAfterThrowing(txInfo, ex);\t\t\t\tthrow ex;\t\t\t&#125;\t\t\tfinally &#123;\t\t\t\t//清除当前事务状态\t\t\t\tcleanupTransactionInfo(txInfo);\t\t\t&#125;\t\t\t//提交事务\t\t\tcommitTransactionAfterReturning(txInfo);\t\t\treturn retVal;\t\t&#125;\n\n创建事务createTransactionIfNecessary主要逻辑在PlatformTransactionManager#getTransaction()\npublic final TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException &#123;\t\t//得到各个不同数据源的事务对象，spring尽然没有把transaction对象抽象出来，很是奇怪\t\tObject transaction = doGetTransaction();\t\t// Cache debug flag to avoid repeated checks.\t\tboolean debugEnabled = logger.isDebugEnabled();\t\tif (definition == null) &#123;\t\t\t// Use defaults if no transaction definition given.\t\t\tdefinition = new DefaultTransactionDefinition();\t\t&#125;\t\t//此事务是否已经存在\t\tif (isExistingTransaction(transaction)) &#123;\t\t\t// Existing transaction found -&gt; check propagation behavior to find out how to behave.\t\t\treturn handleExistingTransaction(definition, transaction, debugEnabled);\t\t&#125;\t\t// Check definition settings for new transaction.\t\tif (definition.getTimeout() &lt; TransactionDefinition.TIMEOUT_DEFAULT) &#123;\t\t\tthrow new InvalidTimeoutException(&quot;Invalid transaction timeout&quot;, definition.getTimeout());\t\t&#125;\t\t// No existing transaction found -&gt; check propagation behavior to find out how to proceed.\t\tif (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) &#123;\t\t\tthrow new IllegalTransactionStateException(\t\t\t\t\t&quot;No existing transaction found for transaction marked with propagation &#x27;mandatory&#x27;&quot;);\t\t&#125;\t\t//这三种都是新建事务\t\telse if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED ||\t\t\t\tdefinition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW ||\t\t\t\tdefinition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) &#123;\t\t\tSuspendedResourcesHolder suspendedResources = suspend(null);\t\t\tif (debugEnabled) &#123;\t\t\t\tlogger.debug(&quot;Creating new transaction with name [&quot; + definition.getName() + &quot;]: &quot; + definition);\t\t\t&#125;\t\t\ttry &#123;\t\t\t\tboolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER);\t\t\t\tDefaultTransactionStatus status = newTransactionStatus(\t\t\t\t\t\tdefinition, transaction, true, newSynchronization, debugEnabled, suspendedResources);\t\t\t\t//开始获取链接，开启事务，绑定资源到当前线程\t\t\t\tdoBegin(transaction, definition);\t\t\t\tprepareSynchronization(status, definition);\t\t\t\treturn status;\t\t\t&#125;\t\t\tcatch (RuntimeException | Error ex) &#123;\t\t\t\tresume(null, suspendedResources);\t\t\t\tthrow ex;\t\t\t&#125;\t\t&#125;\t\telse &#123;\t\t\t// Create &quot;empty&quot; transaction: no actual transaction, but potentially synchronization.\t\t\tif (definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT &amp;&amp; logger.isWarnEnabled()) &#123;\t\t\t\tlogger.warn(&quot;Custom isolation level specified but no actual transaction initiated; &quot; +\t\t\t\t\t\t&quot;isolation level will effectively be ignored: &quot; + definition);\t\t\t&#125;\t\t\tboolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS);\t\t\treturn prepareTransactionStatus(definition, null, true, newSynchronization, debugEnabled, null);\t\t&#125;\t&#125;\n\nTransactionStatus这儿返回的是TransactionStatus\npublic interface TransactionStatus extends SavepointManager, Flushable &#123;\tboolean isNewTransaction();\tboolean hasSavepoint();\tvoid setRollbackOnly();\tboolean isRollbackOnly();\tvoid flush();\tboolean isCompleted();\n\nTransactionInfo事务信息\nprotected final class TransactionInfo &#123;\t\tprivate final PlatformTransactionManager transactionManager;\t\tprivate final TransactionAttribute transactionAttribute;\t\tprivate final String joinpointIdentification;\t\tprivate TransactionStatus transactionStatus;\t\tprivate TransactionInfo oldTransactionInfo;\t&#125;\t\t\ncommitTransactionAfterReturning提交事务逻辑到了AbstractPlatformTransactionManager#processRollback\nprivate void processRollback(DefaultTransactionStatus status, boolean unexpected) &#123;\t\ttry &#123;\t\t\tboolean unexpectedRollback = unexpected;\t\t\ttry &#123;\t\t\t\ttriggerBeforeCompletion(status);\t\t\t\t//有savepoint，\t\t\t\tif (status.hasSavepoint()) &#123;\t\t\t\t\tif (status.isDebug()) &#123;\t\t\t\t\t\tlogger.debug(&quot;Rolling back transaction to savepoint&quot;);\t\t\t\t\t&#125;\t\t\t\t\tstatus.rollbackToHeldSavepoint();\t\t\t\t&#125;\t\t\t\telse if (status.isNewTransaction()) &#123;\t\t\t\t\tif (status.isDebug()) &#123;\t\t\t\t\t\tlogger.debug(&quot;Initiating transaction rollback&quot;);\t\t\t\t\t&#125;\t\t\t\t\t//回滚事务\t\t\t\t\tdoRollback(status);\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\t// Participating in larger transaction\t\t\t\t\t//在一个事务中，就先设置回滚标识,等父事务一起回滚\t\t\t\t\tif (status.hasTransaction()) &#123;\t\t\t\t\t\tif (status.isLocalRollbackOnly() || isGlobalRollbackOnParticipationFailure()) &#123;\t\t\t\t\t\t\tif (status.isDebug()) &#123;\t\t\t\t\t\t\t\tlogger.debug(&quot;Participating transaction failed - marking existing transaction as rollback-only&quot;);\t\t\t\t\t\t\t&#125;\t\t\t\t\t\t\tdoSetRollbackOnly(status);\t\t\t\t\t\t&#125;\t\t\t\t\t\telse &#123;\t\t\t\t\t\t\tif (status.isDebug()) &#123;\t\t\t\t\t\t\t\tlogger.debug(&quot;Participating transaction failed - letting transaction originator decide on rollback&quot;);\t\t\t\t\t\t\t&#125;\t\t\t\t\t\t&#125;\t\t\t\t\t&#125;\t\t\t\t\telse &#123;\t\t\t\t\t\tlogger.debug(&quot;Should roll back transaction but cannot - no transaction available&quot;);\t\t\t\t\t&#125;\t\t\t\t\t// Unexpected rollback only matters here if we&#x27;re asked to fail early\t\t\t\t\tif (!isFailEarlyOnGlobalRollbackOnly()) &#123;\t\t\t\t\t\tunexpectedRollback = false;\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;\t\t\tcatch (RuntimeException | Error ex) &#123;\t\t\t\ttriggerAfterCompletion(status, TransactionSynchronization.STATUS_UNKNOWN);\t\t\t\tthrow ex;\t\t\t&#125;\t\t\ttriggerAfterCompletion(status, TransactionSynchronization.STATUS_ROLLED_BACK);\t\t\t// Raise UnexpectedRollbackException if we had a global rollback-only marker\t\t\tif (unexpectedRollback) &#123;\t\t\t\tthrow new UnexpectedRollbackException(\t\t\t\t\t\t&quot;Transaction rolled back because it has been marked as rollback-only&quot;);\t\t\t&#125;\t\t&#125;\t\tfinally &#123;\t\t\tcleanupAfterCompletion(status);\t\t&#125;\ncompleteTransactionAfterThrowing回滚事务protected void completeTransactionAfterThrowing(TransactionInfo txInfo, Throwable ex) &#123;\t\t//有事务才能回滚\t\tif (txInfo != null &amp;&amp; txInfo.hasTransaction()) &#123;\t\t\tif (logger.isTraceEnabled()) &#123;\t\t\t\tlogger.trace(&quot;Completing transaction for [&quot; + txInfo.getJoinpointIdentification() +\t\t\t\t\t\t&quot;] after exception: &quot; + ex);\t\t\t&#125;\t\t\t//回滚在 (ex instanceof RuntimeException || ex instanceof Error)\t\t\tif (txInfo.transactionAttribute.rollbackOn(ex)) &#123;\t\t\t\ttry &#123;\t\t\t\t\ttxInfo.getTransactionManager().rollback(txInfo.getTransactionStatus());\t\t\t\t&#125;\t\t\t\tcatch (TransactionSystemException ex2) &#123;\t\t\t\t\tlogger.error(&quot;Application exception overridden by rollback exception&quot;, ex);\t\t\t\t\tex2.initApplicationException(ex);\t\t\t\t\tthrow ex2;\t\t\t\t&#125;\t\t\t\tcatch (RuntimeException ex2) &#123;\t\t\t\t\tlogger.error(&quot;Application exception overridden by rollback exception&quot;, ex);\t\t\t\t\tthrow ex2;\t\t\t\t&#125;\t\t\t\tcatch (Error err) &#123;\t\t\t\t\tlogger.error(&quot;Application exception overridden by rollback error&quot;, ex);\t\t\t\t\tthrow err;\t\t\t\t&#125;\t\t\t&#125;\t\t\telse &#123;\t\t\t\t// We don&#x27;t roll back on this exception.\t\t\t\t// Will still roll back if TransactionStatus.isRollbackOnly() is true.\t\t\t\ttry &#123;\t\t\t\t\ttxInfo.getTransactionManager().commit(txInfo.getTransactionStatus());\t\t\t\t&#125;\t\t\t\tcatch (TransactionSystemException ex2) &#123;\t\t\t\t\tlogger.error(&quot;Application exception overridden by commit exception&quot;, ex);\t\t\t\t\tex2.initApplicationException(ex);\t\t\t\t\tthrow ex2;\t\t\t\t&#125;\t\t\t\tcatch (RuntimeException ex2) &#123;\t\t\t\t\tlogger.error(&quot;Application exception overridden by commit exception&quot;, ex);\t\t\t\t\tthrow ex2;\t\t\t\t&#125;\t\t\t\tcatch (Error err) &#123;\t\t\t\t\tlogger.error(&quot;Application exception overridden by commit error&quot;, ex);\t\t\t\t\tthrow err;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t&#125;\n\n\n总结一个完整的事务介绍结束了。框架就是封装一切，透明一切，简化一切。本质的流程不会变\n参考资料http://blog.sina.com.cn/s/blog_7ed8b1e90101mgas.html\nhttps://my.oschina.net/wanyuxiang000/blog/277568\nhttp://www.mamicode.com/info-detail-1248286.html\nhttp://jinnianshilongnian.iteye.com/blog/1496953\nhttp://www.cnblogs.com/yldIndex/p/spring_Transactional.html\nhttp://jinnianshilongnian.iteye.com/blog/1441271\nhttp://www.cnblogs.com/chihirotan/p/6739748.html\n","categories":["源码解读"],"tags":["spring","事务"]},{"title":"算法概要","url":"/blog/algorithm-overview.html","content":"\n算法虐我千万遍，我待算法如初恋；IT人永远逃脱不了的算法\n\n概念算法是特定问题求解步骤的描述，在计算机中表现为指令的有限序列\n算法是独立存在的一种解决问题的方法和思想\n对于算法而言，实现的语言并不重要，重要的是思想\n特性\n输入: 算法具有0个或多个输入\n输出: 算法至少有1个或多个输出\n有穷性: 算法在有限的步骤之后会自动结束而不会无限循环，并且每一个步骤可以在可接受的时间内完成\n确定性：算法中的每一步都有确定的含义，不会出现二义性\n可行性：算法的每一步都是可行的，也就是说每一步都能够执行有限的次数完成\n\n复杂度一个算法的优劣主要从算法的执行时间和所需要占用的存储空间两个方面衡量\n时间复杂度定义：如果一个问题的规模是n，解这一问题的某一算法所需要的时间为T(n)，它是n的某一函数T(n)称为这一算法的“时间复杂性”\nT(n) = O(f(n))\n\n当输入量n逐渐加大时，时间复杂性的极限情形称为算法的“渐近时间复杂性”。\n比如排序算法：可用算法执行中的数据比较次数与数据移动次数来衡量\n空间复杂度对一个算法在运行过程中临时占用存储空间大小的量度，记做S(n)&#x3D;O(f(n))。\n比如直接插入排序，需一个监视哨兵，空间复杂度是O(1) ，而一般的递归算法就要有O(n)的空间复杂度了，因为每次递归都要存储返回信息。\n大O表示法大O表示法被用来描述一个算法的性能或复杂度。大O表示法可以用来描述一个算法的最差情况，或者一个算法执行的耗时或占用空间（例如内存或磁盘占用）\n假设一个算法的时间复杂度是 O(n)，n在这里代表的意思就是数据的个数。\n举个例子，如果你的代码用一个循环遍历 100 个元素，那么这个算法就是 O(n)，n 为 100，所以这里的算法在执行时就要做 100 次工作\n大O表示法就是将算法的所有步骤转换为代数项，然后排除不会对问题的整体复杂度产生较大影响的较低阶常数和系数,只关心复杂度最重要的部分\n规律       Big-O2             O(1)   --&gt; 就是一个常数2n + 10       O(n)   --&gt; n 对整体结果会产生最大影响5n^2         O(n^2) --&gt; n^2 具有最大影响\n\nO(log n)，即对数复杂度（logarithmic complexity）。对数可以是ln(底数为e)，log10，log2 或者以其它为底数，这无关紧要，它仍然是O(log n)，正如O(2n^2) 和 O(100n^2) 都记为 O(n^2)。\n示例O(1)O(1)表示该算法的执行时间（或执行时占用空间）总是为一个常量，不论输入的数据集是大是小\nbool IsFirstElementNull(IList&lt;string&gt; elements)&#123;    return elements[0] == null;&#125;\n\nO(N)O(N)表示一个算法的性能会随着输入数据的大小变化而线性变化。下面的例子同时也表明了大O表示法其实是用来描述一个算法的最差情况的：在for循环中，一旦程序找到了输入数据中与第二个传入的string匹配时，程序就会提前退出，然而大O表示法却总是假定程序会运行到最差情况（在这个例子中，意味着大O会表示程序全部循环完成时的性能）\nbool ContainsValue(IList&lt;string&gt; elements, string value)&#123;    foreach (var element in elements)    &#123;        if (element == value) return true;    &#125;    return false;&#125;\n\nO(n²)for循环嵌套的复杂度就是二次方的，因为你在一个线性操作里执行另外一个线性操作（或者说： n*n &#x3D;n² ）\n如果嵌套层级不断深入的话，算法的性能将会变为O(N^3)，O(N^4)，以此类推\nfor (var outer = 0; outer &lt; elements.Count; outer++)    &#123;        for (var inner = 0; inner &lt; elements.Count; inner++)        &#123;            // Don&#x27;t compare with self            if (outer == inner) continue;            if (elements[outer] == elements[inner]) return true;        &#125;    &#125;\n\nO(2^N)O(2^N)表示一个算法的性能将会随着输入数据的每次增加而增大两倍。O(2^N)的增长曲线是一条爆炸式增长曲线——开始时较为平滑，但数据增长后曲线增长非常陡峭。一个典型的O(2^N)方法就是裴波那契数列的递归计算实现\nint Fibonacci(int number)&#123;    if (number &lt;= 1) return number;    return Fibonacci(number - 2) + Fibonacci(number - 1);&#125;\n(logn)i=1;       while (i&lt;=n)    i=i*2;\n\n比较O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n^2)&lt;O(n^3)&lt;O(2^n)&lt;O(n!)&lt;O(n^n)\n\n\n引申阅读算法渣-排序-冒泡\n算法渣-排序-快速排序\n算法渣-排序-插入\n算法渣-排序-希尔\n","tags":["算法"]},{"title":"算法渣-排序-基数排序","url":"/blog/algorithm---sort---cardinal-sort.html","content":"\n没有一身好内功，招式再多都是空;算法绝对是防身必备，面试时更是不可或缺；跟着算法渣一起从零学算法\n\n线性排序常见的三种以线性时间运行的算法：计数排序、基数排序和桶排序；\n需要注意的是线性排序算法是非基于比较的排序算法，都有使用限制才能达到线性排序的效果\n定义基数排序的发明可以追溯到1887年赫尔曼·何乐礼在打孔卡片制表机（Tabulation Machine）, 排序器每次只能看到一个列。它是基于元素值的每个位上的字符来排序的。 对于数字而言就是分别基于个位，十位， 百位或千位等等数字来排序。\n基数排序（Radix sort）是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数\n算法原理是将整数按位数切割成不同的数字，然后按每个位数分别比较\n基数排序可以采用两种方式：\nLSD（Least Significant Digital）：从待排序元素的最右边开始计算（如果是数字类型，即从最低位个位开始）\nMSD（Most Significant Digital）：从待排序元素的最左边开始计算（如果是数字类型，即从最高位开始）\n基数排序又称为“桶子法”，从低位开始将待排序的数按照这一位的值放到相应的编号为0~9的桶中。\n等到低位排完得到一个子序列，再将这个序列按照次低位的大小进入相应的桶中，一直排到最高位为止，数组排序完成\n演示通过基数排序对数组{53, 3, 542, 748, 14, 214, 154, 63, 616}，它的示意图如下：\n\n在上图中，从最低位开始，依次进行排序。\n\n按照个位数进行排序。\n按照十位数进行排序。\n按照百位数进行排序。排序后，数列就变成了一个有序序列\n\n\n伪代码\nRadix-Sort(A, d)// 每个在数组A[1...n] 中的元素都是d-位数的正整数// 位数是从右到左标记上1到d 的//A[]-- 初始的待排序的数组   // 创建一个for 循环，从1 到d   for j = 1 to d do       int count[10] = &#123;0&#125;;       // 将键的计数放在数组count[] 中       // 键key - 是在位数j 上的数字       for i = 0 to n do          count[key of(A[i]) in pass j]++       for k = 1 to 10 do          count[k] = count[k] + count[k-1]       // 创建一个结果数组，通过从count[k] 中检查A[i] 中的新位置      for i = n-1 downto 0 do          result[ count[key of(A[i])] ] = A[j]          count[key of(A[i])]--      //现在主数组A[] 包含了根据现在位数位置排好序的数字     for i=0 to n do         A[i] = result[i]    end for(j)end func \n\n实现使用桶排序，把各位上的数分别桶排序，再依次输出\nprivate static void radixSort(int []array)&#123;\t//取最大值，好计算位数\tint max = Integer.MIN_VALUE;\tfor (int a:array) &#123;\t\tif(a&gt; max) &#123;\t\t\tmax = a;\t\t&#125;\t&#125;\t//(0~9)10个桶\tint [][]buckets = new int[10][];\t//初始化桶\tfor(int b=0;b&lt;10;b++) &#123;\t\tbuckets[b] = new int[array.length];\t&#125;\t//每个桶的元素数量\tint [] index = new int[10];\t//按每一位数排序\tfor (int radix = 1;max/radix&gt;0;radix*=10)&#123;\t\t//把元素放到各自的桶内\t\tfor (int a:array) &#123;\t\t\t//得到每位数\t\t\tint per = a/radix%10;\t\t\tbuckets[per][index[per]] = a;\t\t\tindex[per]++;\t\t&#125;\t\t//各个桶的数据依次放回数组\t\tint j = 0;\t\tfor (int b=0;b&lt;10;b++) &#123;\t\t\t//去掉桶中别的元素\t\t\tfor (int i = 0;i&lt;index[b];i++)&#123;\t\t\t\tarray[j++] = buckets[b][i];\t\t\t&#125;\t\t&#125;\t\tSystem.err.println(&quot;按第&quot;+radix+&quot;位,排序：&quot; + Arrays.toString(array));\t\t//清空计数器\t\tindex = new int[10];\t&#125;&#125;\n\n对数组{53, 3, 542, 748, 14, 214, 154, 63, 616}进行基数排序\n通过程序可以看出每位数排序的结果\n按第1位,排序：[542, 53, 3, 63, 14, 214, 154, 616, 748]按第10位,排序：[3, 14, 214, 616, 542, 748, 53, 154, 63]按第100位,排序：[3, 14, 53, 63, 154, 214, 542, 616, 748]\n百倍排序完，整个数组也就排序好了\n复杂度时间复杂度假设在基数排序中，r为基数，d为位数。则基数排序的时间复杂度为O(d(n+r))。\n空间复杂度在基数排序过程中，对于任何位数上的基数进行“装桶”操作时，都需要n+r个临时空间\n","tags":["算法"]},{"title":"算法渣-排序-冒泡","url":"/blog/algorithm---sorting---bubbling.html","content":"\n没有一身好内功，招式再多都是空;算法绝对是防身必备，面试时更是不可或缺；跟着算法渣一起从零学算法\n\n定义冒泡排序（Bubble Sort），是一种计算机科学领域的较简单的排序算法。\n这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端（升序或降序排列），就如同碳酸饮料中二氧化碳的气泡最终会上浮到顶端一样，故名“冒泡排序”\n算法它重复地走访过要排序的元素列，依次比较两个相邻的元素，如果他们的顺序（如从大到小、首字母从A到Z）错误就把他们交换过来。走访元素的工作是重复地进行直到没有相邻元素需要交换，也就是说该元素已经排序完成。\n演示对数组[5,6,3,1,8,7,2,4]进行冒泡排序\n\n/** * 传统写法 * @param sorts */private static void bubbleSort(int [] sorts)&#123;    for (int i=0;i&lt;sorts.length-1;i++) &#123;        for (int j= 0;j&lt;sorts.length-1-i;j++) &#123;            if(sorts[j] &lt; sorts[j+1]) &#123;                swap(sorts,j,j+1);            &#125;        &#125;    &#125;&#125;private static void swap(int []sorts,int i,int j)&#123;        int tmp = sorts[i];        sorts[i] = sorts[j];        sorts[j] = tmp;    &#125;\n\n改进有序如果一个数组本身就是有序的，或者部分已经有序\n比如:[8,7,6,5,4,3,1,2]\n假如现在有一个长度10000的数组，前1000无序，后9000有序并且大于前1000数据。用上面这种方法，数据交换次数在1000之内，但是剩下9000的数据虽然没有交换，但是每次循环都会进行比较。剩下9000数据已经有序了，我们不要对它们去进行判断浪费不必要的时间\n/** * 如果部分已经排序,设置一个flag,有序就跳出循环 * @param sorts */private static void bubbleSort1(int [] sorts)&#123;    for (int i=0;i&lt;sorts.length-1;i++) &#123;        boolean flag = false;        for (int j= 0;j&lt;sorts.length-1-i;j++) &#123;            if(sorts[j] &lt; sorts[j+1]) &#123;                swap(sorts,j,j+1);                flag = true;            &#125;        &#125;        if(!flag) &#123;            break;        &#125;    &#125;&#125;\n\n鸡尾酒排序鸡尾酒排序等于是冒泡排序的轻微变形。不同的地方在于从低到高然后从高到低，而冒泡排序则仅从低到高去比较序列里的每个元素。他可以得到比冒泡排序稍微好一点的效能，原因是冒泡排序只从一个方向进行比对(由低到高)，每次循环只移动一个项目。\n算法\n/** * 鸡尾酒排序，定向冒泡排序 * @param sorts */private static void bubbleSort2(int [] sorts)&#123;    int i = 0;    int j = sorts.length-1;    while (i &lt;= j) &#123;        for(int s = i;s&lt;j;s++) &#123;//从左往右            if(sorts[s] &lt; sorts[s+1]) &#123;                swap(sorts, s, s + 1);            &#125;        &#125;        System.out.println(JSON.toJSONString(sorts));        for(int e = j;e&gt;i;e--) &#123;//从右往左            if(sorts[e] &gt; sorts[e-1]) &#123;                swap(sorts, e, e - 1);            &#125;        &#125;        j--;i++;        System.out.println(JSON.toJSONString(sorts));    &#125;&#125;\n\n总体上，鸡尾酒排序可以获得比冒泡排序稍好的性能。但是完全逆序时，鸡尾酒排序与冒泡排序的效率都非常差\n时间复杂度\n如果我们的数据正序，只需要走一趟即可完成排序。所需的比较次数C和记录移动次数M均达到最小值，即：Cmin&#x3D;n-1;Mmin&#x3D;0;所以，冒泡排序最好的时间复杂度为O(n)。\n\n如果很不幸我们的数据是反序的，则需要进行n-1趟排序。每趟排序要进行n-i次比较(1≤i≤n-1)，且每次比较都必须移动记录三次来达到交换记录位置。在这种情况下，比较和移动次数均达到最大值：\n\n\n\nBest| Average| Worst|Memory|Stable — | —| —|——| :–: |—n |  n^2 |n^2| 1 | Stable\n","tags":["算法"]},{"title":"算法渣-排序-希尔","url":"/blog/algorithm---sorting---hill.html","content":"\n没有一身好内功，招式再多都是空;算法绝对是防身必备，面试时更是不可或缺；跟着算法渣一起从零学算法\n\n定义希尔排序是希尔（Donald Shell）于1959年提出的一种排序算法。希尔排序也是一种插入排序，它是简单插入排序经过改进之后的一个更高效的版本，也称为缩小增量排序，同时该算法是冲破O(n2）的第一批算法之一\n算法直接插入排序很循规蹈矩，不管数组分布是怎么样的，依然一步一步的对元素进行比较，移动，插入，比如[5,4,3,2,1,0]这种倒序序列，数组末端的0要回到首位置很是费劲，比较和移动元素均需n-1次\n是否能够减少这样的移位呢？不希望是一步一步的移动，而是大步大步的移动。\n希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止\n初始时,有一个大小为 10 的无序序列\n在第一趟排序中,我们不妨设 gap1 &#x3D; N &#x2F; 2 &#x3D; 5,即相隔距离为 5 的元素组成一组,可以分为 5 组\n接下来,按照直接插入排序的方法对每个组进行排序\n在第二趟排序中,我们把上次的 gap 缩小一半,即 gap2 &#x3D; gap1 &#x2F; 2 &#x3D; 2 (取整数)。这样每相隔距离为 2 的元素组成一组,可以分为 2 组\n按照直接插入排序的方法对每个组进行排序\n在第三趟排序中,再次把 gap 缩小一半,即gap3 &#x3D; gap2 &#x2F; 2 &#x3D; 1。 这样相隔距离为 1 的元素组成一组,即只有一组\n按照直接插入排序的方法对每个组进行排序。此时,排序已经结束\n演示\n1.增量N&#x2F;2&#x3D;4分组\n\n\n{35, 14}, {33, 19}, {42, 27} , {10, 44}\n排序完：\n\n\n2.增量N&#x2F;2&#x2F;2&#x3D;2分组\n\n\n{14, 27, 35, 42}, {19, 10, 33, 44}\n排序完：\n\n\n3.增量N&#x2F;2&#x2F;2&#x2F;2&#x3D;1分组排序\n\n\n也可以通过动画更清晰了解整个排序过程\n动画：http://www.zhuxingsheng.com/tools/sort/sort.html\n分组排序后，他们的索引还是保留在原始索引中，来两个更加直观的动画演示\n\n\n实现static void shellSort(int []array) &#123;        //以length/2为增量        for (int gap=array.length/2;gap&gt;0;gap= gap/2) &#123;            //以gap分组，进行排序           for(int i = gap;i&lt;array.length;i++)&#123;               int tmp = array[i];               int j = i - gap;               //相对直接插入，步长从1变成了gap               while ( j&gt;=0 &amp;&amp; tmp&lt;array[j] ) &#123;                   array[j+gap] = array[j];                   j=j-gap;               &#125;               array[j+gap] = tmp;           &#125;        &#125;    &#125;\n\n复杂度希尔排序的时间复杂度与增量(即，步长gap)的选取有关\n{1,2,4,8,…}这种序列并不是很好的增量序列，使用这个增量序列的时间复杂度（最坏情形）是O(n²)\nHibbard提出了另一个增量序列{1,3,7，…,2^k-1}，这种序列的时间复杂度(最坏情形)为O(n^1.5)\nSedgewick提出了几种增量序列，其最坏情形运行时间为O（n^1.3）,其中最好的一个序列是{1,5,19,41,109,…}\n9×4^i−9×2i+1  和 4^i−3×2^i+1  这两个算式\n其中， i&#x3D;0,1,2,⋯ 时，第一个式子计算出的值分别为1，19，109，……； i&#x3D;2,3,⋯ 时，第二个式子算出的值分别为5，41，……\nBest| Average| Worst|Memory|Stable — | —| —|——| :–: |—n log(n)\t|depends on gap sequenc|\tn²\t| 1 |\tNo\n","tags":["算法"]},{"title":"算法渣-排序-堆排序","url":"/blog/algorithm-slag-sort-heap-sort.html","content":"\n没有一身好内功，招式再多都是空;算法绝对是防身必备，面试时更是不可或缺；跟着算法渣一起从零学算法\n\n定义堆排序（英语：Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。\n堆堆是一棵顺序存储的完全二叉树\n\n其中每个结点的关键字都不大于其孩子结点的关键字，这样的堆称为小根堆。\n其中每个结点的关键字都不小于其孩子结点的关键字，这样的堆称为大根堆。\n举例来说，对于n个元素的序列{R0, R1, … , Rn}当且仅当满足下列关系之一时，称之为堆：\n(1) Ri &lt;&#x3D; R2i+1 且 Ri &lt;&#x3D; R2i+2 (小根堆)\n(2) Ri &gt;&#x3D; R2i+1 且 Ri &gt;&#x3D; R2i+2 (大根堆)\n其中i&#x3D;1,2,…,n&#x2F;2向下取整; \n\n同时，我们对堆中的结点按层进行编号，将这种逻辑结构映射到数组中就是下面这个样子\n\n完全二叉树完全二叉树的定义是建立在满二叉树定义的基础上的，而满二叉树又是建立在二叉树的基础上的。\n二叉树二叉树是树的特殊一种，具有如下特点：\n\n每个结点最多有两颗子树，结点的度最大为2。\n左子树和右子树是有顺序的，次序不能颠倒。\n即使某结点只有一个子树，也要区分左右子树。\n\n满二叉树所有的分支结点都存在左子树和右子树，并且所有的叶子结点都在同一层上，这样就是满二叉树。就是完美圆满的意思，关键在于树的平衡\n\n根据满二叉树的定义，得到其特点为：\n\n叶子只能出现在最下一层。\n非叶子结点度一定是2.\n在同样深度的二叉树中，满二叉树的结点个数最多，叶子树最多。\n\n完全二叉树对于一个树高为h的二叉树，如果其第0层至第h-1层的节点都满。如果最下面一层节点不满，则所有的节点在左边的连续排列，空位都在右边。这样的二叉树就是一棵完全二叉树\n\n在上图中，树1，按层次编号5结点没有左子树，有右子树，10结点缺失。树2由于3结点没有字数，是的6,7位置空挡了。树3中结点5没有子树。\n\n上图就是一个完全二叉树\n算法利用堆顶记录的是最大(以大顶堆为例)关键字这一特性，每一轮取堆顶元素放入有序区，就类似选择排序每一轮选择一个最大值放入有序区，可以把堆排序看成是选择排序的改进。\n\n将初始待排序关键字序列(R0,R1,R2….Rn)构建成大顶堆，此堆为初始的无序区；\n\n将堆顶元素R[0]与最后一个元素R[n]交换，此时得到新的无序区(R0,R1,R2,……Rn-1)和新的有序区(Rn)；\n\n由于交换后新的堆顶R[0]可能违反堆的性质，因此需要对当前无序区(R0,R1,R2,……Rn-1)调整为新堆\n\n\n不断重复此2、3步骤直到有序区的元素个数为n-1，则整个排序过程完成\n演示\n由一个无序序列建成一个堆\n输出堆顶元素之后，调整剩余元素成为一个新的堆\n\n1.构造堆构造初始堆,将给定无序序列构造成一个大顶堆（一般升序采用大顶堆，降序采用小顶堆)\n数组是一个无序结构\n\n因为(n&#x2F;2-1)~0的节点才有子节点，n&#x3D;5,(n&#x2F;2-1) &#x3D; 1  即1 0节点才有子节点\n所以将1 0节点从下到上，从右到左的与它自己的子节点比较并调整最终形成大顶堆\n1. 节点1和它的子节点3 4的元素进行比较，最大者作为父节点\n\n2. 将节点0和它的子节点1 2的元素进行比较，最大者为父节点\n\n3. 交换导致了子根[4,5,6]结构混乱，继续调整，[4,5,6]中6最大，交换4和6\n\n构造完成将一个无需序列构造成了一个大顶堆\n2. 调整堆将堆顶元素与末尾元素进行交换，使末尾元素最大。然后继续调整堆，再将堆顶元素与末尾元素交换，得到第二大元素。如此反复进行交换、重建、交换。\n1. 将堆顶元素9和末尾元素4进行交换\n\n2. 重新调整结构，使其继续满足堆定义\n\n3. 再将堆顶元素8与末尾元素5进行交换，得到第二大元素8\n\n4. 继续进行调整，交换，如此反复进行，最终使得整个序列有序\n\n实现 /** * * a.将无需序列构建成一个堆，根据升序降序需求选择大顶堆或小顶堆; 　b.将堆顶元素与末尾元素交换，将最大元素&quot;沉&quot;到数组末端; 　c.重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整+交换步骤，直到整个序列有序。 * 整个排序过程，就是构造堆的过程 * * 这儿写得利于理解一点，把最后一步改掉，循环从数组中把第一位取出来放到新数组，剩余的再去构造堆 * @param array */static void heapSort(int []array) &#123;    //原始数组    int [] oriental = Arrays.copyOf(array,array.length);    //最终排序好的数组    int [] result = new int[array.length];    int length = array.length;    for ( int i = 0;i&lt; length;i++) &#123;        //1.构造堆        buildHeap(array);        //构建完array[0]就是最大的元素,取出来放到排序好的数组        result[i] = array[0];        //[0]取走之后，一个新数组，再去构造堆        array = Arrays.copyOfRange(array, 1,length-i);    &#125;    System.out.println(&quot;finish:&quot;+ Arrays.toString(result));&#125;/** * 构造椎 * @param array */static void buildHeap(int []array) &#123;    //(n/2-1)~0的节点才有子节点    for (int i= array.length/2 -1 ;i&gt;=0;i--) &#123;//            System.out.println(&quot;i:&quot;+i);//            System.out.println(&quot;start:&quot;+ Arrays.toString(array));        int k = i;        for (int left = k * 2 + 1; left &lt; array.length; left = k * 2 + 1) &#123;           // System.out.println(&quot;build:&quot;+ Arrays.toString(array));            int max = left;            int right = left + 1;            //有右节点            if (right &lt; array.length) &#123;                if (array[right] &gt; array[left]) &#123;                    max = right;                &#125;            &#125;            //max是left子节点,那就交换左子节点与k            if (array[max] &gt; array[k]) &#123;                swap(array, max, k);                // 下面就是非常关键的一步了                // 如果子节点更换了，那么，以子节点为根的子树会不会受到影响呢？                // 所以，循环对子节点所在的树继续进行判断                k = left;            &#125; else &#123;                break;            &#125;        &#125;    &#125;    //System.out.println(&quot;  end:&quot;+ Arrays.toString(array));&#125;\n\n详细代码：https://github.com/zhuxingsheng/javastudy/tree/master/src/main/java/com/jack/algorithms/sort\n复杂度\n\n\nBest\nAverage\nWorst\nMemory\nStable\n\n\n\nn log(n)\nn log(n)\nn log(n)\n1\nNo\n\n\n参考资料图解排序算法(三)之堆排序\n图解堆排序\n","tags":["算法"]},{"title":"算法渣-排序-归并排序","url":"/blog/algorithm---sort---merge-sort.html","content":"\n没有一身好内功，招式再多都是空;算法绝对是防身必备，面试时更是不可或缺；跟着算法渣一起从零学算法\n\n定义归并排序（MERGE-SORT）是建立在归并操作上的一种有效的排序算法,该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并。\n算法归并排序(Merge Sort)就是利用归并思想对数列进行排序。根据具体的实现，归并排序包括”从上往下“和”从下往上“2种方式\n从上往下的归并排序：\n\n分解 – 将当前区间一分为二，即求分裂点 mid &#x3D; (low + high)&#x2F;2\n求解 – 递归地对两个子区间a[low…mid] 和 a[mid+1…high]进行归并排序。递归的终结条件是子区间长度为1\n合并 – 将已排序的两个子区间a[low…mid]和 a[mid+1…high]归并为一个有序的区间a[low…high]\n\n\n 从下往上的归并排序：\n\n将待排序的数列分成若干个长度为1的子数列，然后将这些数列两两合并；\n得到若干个长度为2的有序数列，再将这些数列两两合并；得到若干个长度为4的有序数列，再将它们两两合并；\n直接合并成一个数列为止。这样就得到了我们想要的排序结果。\n\n\n归并步骤\n第一步：申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列\n第二步：设定两个指针，最初位置分别为两个已经排序序列的起始位置\n第三步：比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置\n重复步骤3直到某一指针超出序列尾，将另一序列剩下的所有元素直接复制到合并序列尾\n\n比如合并，要将[4,5,7,8]和[1,2,3,6]两个已经有序的子序列，合并为最终序列[1,2,3,4,5,6,7,8]，来看下实现步骤\n\n\n演示\n实现/** * 归并排序 * @param array * @param left * @param right */private static void mergeSort(int []array,int left,int right)&#123;    if(left &lt; right) &#123;        //分解        int mid = (left + right) / 2;        mergeSort(array,left,mid);        mergeSort(array,mid + 1,right);        //合并        merge(array,left,mid,right);    &#125;&#125;static void merge(int []array,int left,int mid,int right) &#123;    System.out.println(&quot;merge-&gt;left:&quot;+left+&quot; mid:&quot;+mid+&quot; rgiht:&quot;+right);    int i = left;    int j = mid +1;    int tmp[] = new int[right-left+1];//构建tmp数组    int t = 0;//tmp数组索引    //填充tmp数组    for (;i&lt;=mid &amp;&amp; j&lt;=right;) &#123;        if(array[i] &lt; array[j]) &#123;            tmp[t++] = array[i++];        &#125; else &#123;            tmp[t++] = array[j++];        &#125;    &#125;    while (i&lt;=mid) &#123;        tmp[t++] = array[i++];    &#125;    while (j&lt;=right) &#123;        tmp[t++] = array[j++];    &#125;    //再把tmp复制到array    t = 0;    while (left&lt;=right) &#123;        array[left++] = tmp[t++];    &#125;    System.out.println(&quot;  tmp:&quot;+ Arrays.toString(tmp));    System.out.println(&quot;merge:&quot;+ Arrays.toString(array));&#125;\n\n复杂度归并排序的时间复杂度是O(N*lgN)\n假设被排序的数列中有N个数。遍历一趟的时间复杂度是O(N)，需要遍历多少次呢？\n归并排序的形式就是一棵二叉树，它需要遍历的次数就是二叉树的深度，而根据完全二叉树的可以得出它的时间复杂度是O(N*lgN)\n\n\n\nBest\nAverage\nWorst\nMemory\nStable\n\n\n\nn log(n)\nn log(n)\nn log(n)\nn\nYes\n\n\nVS 快速排序归并排序（MergeSort）和快速排序(QuickSort)都是用了分治算法思想。\n所谓分治算法，顾名思义，就是分而治之，就是将原问题分割成同等结构的子问题，之后将子问题逐一解决后，原问题也就得到了解决。\n同时，归并排序（MergeSort）和快速排序(QuickSort)也代表了两类分治算法的思想。\n对于归并排序，我们对于待处理序列怎么分的问题上并没有太多关注，仅仅是简单地一刀切，将整个序列分成近乎均匀的两份，然后将子序列进行同样处理。但是，我们更多的关注点在于怎么把分开的部分合起来，也就是merge的过程。\n对于快速排序来说，我们则是花了很大的功夫放在了怎么分这个问题上，我们设定了枢轴（标定点），然后通过partition的过程将这个枢轴放在合适的位置，这样我们就不用特别关心合起来的过程，只需要一步一步地递归下去即可。\n归并排序是由下向上的，先处理子数组然后再合并。而快速排序正好相反，它的过程是由上向下的，先分出两个子区间，再对子区间进行排序。归并排序是稳定的时间复杂度为 O(n)O(n)，但它是非原地算法，在进行子数组合并的时候，我们需要临时申请一个数组来暂时存放排好序的数据。因为这个临时空间是可以重复利用的，因此归并排序的空间复杂度为 O(n)，最多需要存放 n 个数据；而快排则是原地排序算法\n\n","tags":["算法"]},{"title":"算法渣-排序-快速","url":"/blog/algorithmic-slag-sorting-fast.html","content":"\n没有一身好内功，招式再多都是空;算法绝对是防身必备，面试时更是不可或缺；跟着算法渣一起从零学算法\n\n定义快速排序（Quicksort）是对冒泡排序的一种改进\n快速排序由C. A. R. Hoare在1962年提出。\n它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列\n算法设要排序的数组是A[0]……A[N-1]，首先任意选取一个数据（通常选用数组的第一个数）作为关键数据，然后将所有比它小的数都放到它前面，所有比它大的数都放到它后面，这个过程称为一趟快速排序。值得注意的是，快速排序不是一种稳定的排序算法，也就是说，多个相同的值的相对位置也许会在算法结束时产生变动\n一趟快速排序的算法是：\n\n设置两个变量i、j，排序开始的时候：i&#x3D;0，j&#x3D;N-1；\n以第一个数组元素作为关键数据，赋值给key，即key&#x3D;A[0]；\n从j开始向前搜索，即由后开始向前搜索(j–)，找到第一个小于key的值A[j]，将A[j]和A[i]互换；\n从i开始向后搜索，即由前开始向后搜索(i++)，找到第一个大于key的A[i]，将A[i]和A[j]互换；\n重复第3、4步，直到i&#x3D;j； (3,4步中，没找到符合条件的值，即3中A[j]不小于key,4中A[i]不大于key的时候改变j、i的值，使得j&#x3D;j-1，i&#x3D;i+1，直至找到为止。找到符合条件的值，进行交换的时候i， j指针位置不变。另外，i&#x3D;&#x3D;j这一过程一定正好是i+或j-完成的时候，此时令循环结束）。\n\n演示上面的定义，算法都是很学术的表达，看得有点晕了，看一个示例：\n对数组[2,10,8,22,34,5,12,28,21,11]进行快速排序\n\n也可以通过动画更清晰了解整个排序过程\n动画：http://www.zhuxingsheng.com/tools/sort/sort.html\n实现快速排序有好些实现手法，左右指针法、挖坑法、前后指针(快慢指针)法\n左右指针法算法过程与上面的演示图差不多\n\n先从数列中取出一个数作为中轴基数。 \n分区过程，将比这个数大的数全放到它的右边，小于或等于它的数全放到它的左边。 \n再对左右区间重复第二步，直到各区间只有一个数\n\n/** * 分治法,从小到大排序 * @param array */public static int partition(int []array,int start,int end) &#123;    //取一位做为基数    int pivot = array[end];//这儿取最后一位作为基数了    int left = start;    int right = end-1;//从倒数第二位开始比较    //从两头向中间搜索,从小到大排序    while (left &lt; right) &#123;        //从left端开始搜索        while(left &lt; right &amp;&amp; array[left] &lt;= pivot) &#123;            left ++;        &#125;        //从right端开始搜索        while (left &lt; right &amp;&amp; array[right] &gt;= pivot) &#123;            right -- ;        &#125;        //两数交换,大的放到右边，小的放到左边        if(left &lt; right) &#123;            swap(array,left,right);            left++;            right--;        &#125;    &#125;    //    if(left != end &amp;&amp; array[left] &gt; array[end] ) &#123;        swap(array,left,end);        return left;    &#125;    //right == left    return left+1;&#125;/** * 分治法,从小到大排序 * @param array * @param start * @param end */private static void quicSort(int []array,int start,int end)&#123;    if( start &lt; end )&#123;        int partition = partition(array,start,end);        print(array);        quicSort(array,start,partition-1);        quicSort(array,partition+1,end);    &#125;&#125;\n\n挖坑法挖坑填坑，也可以叫拆东墙补西墙\n先演示一番,对[22,12,28,21,14]进行排序\n\n\n\nindex:\n0\n1\n2\n3\n4\n\n\n\ndata:\n22\n12\n28\n21\n14\n\n\n第一步:挖最右边的数为坑\n坑: pit&#x3D;array[right]&#x3D;14;左索引: left&#x3D;0,右索引: right&#x3D;3, \n\n\n\nindex:\n0\n1\n2\n3\n4\n\n\n\ndata:\n22\n12\n28\n21\nX\n\n\n从left开始搜索，寻找比坑大的数，发现array[left&#x3D;0]&gt;14,那就用left&#x3D;0 填 right&#x3D;4的坑\narray[right&#x3D;4]&#x3D;array[left&#x3D;0];left++;\n此时数组：\n\n\n\nindex:\n0\n1\n2\n3\n4\n\n\n\ndata:\nX\n12\n28\n21\n22\n\n\nleft&#x3D;1,right&#x3D;3\n第二步: 从right端开始找比pit小的数，发现array[1] &lt; 14,那就用right&#x3D;1 填 left&#x3D;0的坑\narray[left&#x3D;0]&#x3D; array[right&#x3D;1];\n此时数组：\n\n\n\nindex:\n0\n1\n2\n3\n4\n\n\n\ndata:\n12\nX\n28\n21\n22\n\n\nleft&#x3D;1,right&#x3D;0; left&gt;right,那此回合结束,用pit填回坑array[left&#x3D;1]\n结束时：\n\n\n\nindex:\n0\n1\n2\n3\n4\n\n\n\ndata:\n12\n14\n28\n21\n22\n\n\n发现14左都是小于它的数，右边都是大于它的数\n以14为分界，两边数组进行递归下去，就行了\nint partion(int arr[], int begin, int end)&#123;    int pit = arr[end];//挖最右数，留一个坑    int left = begin;    int right = end;    while (left &lt; right)    &#123;        //从最左开始搜索比坑大的数        while (left &lt; right &amp;&amp; arr[left] &lt;= pit)            left++;        if (left&lt;right) &#123;            arr[right] = arr[left];//拿left去填坑，left成为新坑        &#125;        while (left &lt; right &amp;&amp; arr[right] &gt;= pit)            right--;        if (left &lt; right) &#123;            arr[left] = arr[right];//right去填left坑，left成为新坑        &#125;    &#125;    arr[left] = pit;//用key填坑    return left;&#125;void QuickSort(int arr[], int left, int right)&#123;    if (left &lt; right)    &#123;        int mid = partion(arr, left, right);        print(arr);        QuickSort(arr, left, mid - 1);        QuickSort(arr, mid + 1, right);    &#125;&#125;\n\n前后指针法大体思路：\n\n定义两个指针，一前一后，cur（前）指向起始位置，prev（后）指向cur的前一个位置；选择数组最后一个元素作为key（right）\ncur找比key小的数，prev在cur没有找到的情况下，一直不动（即保证prev一直指向比key大的数）；直到cur找到比key小的数（+ +prev &amp;&amp; prev !&#x3D; cur时）然后++cur,prev仍然不动\n直到cur走到right前一个位置，终止循环。最后++prev，交换prev和right的值。返回中间位置prev。最后再继续递归\n\n\nint partion(int arr[], int left, int right)&#123;    int key = arr[right];//取最后一位为key    int cur = left;//当前指针    int prev = left - 1;//前一个指针    while (cur &lt; right)    &#123;        if(arr[cur] &lt; key &amp;&amp; ++prev != cur)&#123;//发现比key小的数            swap(arr,cur,prev);        &#125;        cur++;    &#125;    //最后++prev交换    swap(arr,++prev,cur);    return prev;&#125;void QuickSort(int arr[], int left, int right)&#123;    if (left &lt; right)    &#123;        int mid = partion(arr, left, right);        print(arr);        QuickSort(arr, left, mid - 1);        QuickSort(arr, mid + 1, right);    &#125;&#125;\n\n分治以上几个方法，不管怎样的思路，都是寻找一个标准数,让它成为一个分界，大于所有左边的数，小于所有右边的数，进行分而治之\n复杂度最好情况：最在最好的情况下，每次的划分都会恰好从中间将序列划分开来，那么只需要lgn次划分即可划分完成，是一个标准的分治算法Cn&#x3D;2Cn&#x2F;2+N，每一次划分都需要比较N次。时间复杂度O(nlogn)\n最坏情况：在最坏的情况下，即序列已经排好序的情况下，每次划分都恰好把数组划分成了0，n两部分，那么需要n次划分，但是比较的次数则变成了n, n-1, n-2,….1, 所以整个比较次数约为n(n-1)&#x2F;2~n2&#x2F;2\n比较和移动次数最少时间复杂度表示为O(nlogn);\n比较和移动次数最多的时间复杂度表示为O(n^2);\n使用的辅助存储空间最少为logn，最多为n^2；是不稳定的排序；\nBest| Average| Worst|Memory|Stable — | —| —|——| :–: |—nlog(n)\t|nlog(n)|\tn^2\t| log(n) |\tNo\n","tags":["算法"]},{"title":"算法渣-排序-插入","url":"/blog/algorithm---sort---insert.html","content":"\n没有一身好内功，招式再多都是空;算法绝对是防身必备，面试时更是不可或缺；跟着算法渣一起从零学算法\n\n定义插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的、个数加一的有序数据，算法适用于少量数据的排序\n它的基本思想是：每步将一个待排序的记录，按其关键码值的大小插入前面已经排序的文件中适当位置上，直到全部插入完为止\n联想打扑克牌时理顺手中牌的时候，你从左往右依次检查你的牌，并将其和前面的牌进行比较，然后将其插入正确的位置\n\n理解起来，比《快速排序》容易多了\n算法\n设置监视哨r[0]，将待插入记录的值赋值给r[0]；\n设置开始查找的位置j；\n在数组中进行搜索，搜索中将第j个记录后移，直至r[0].key≥r[j].key为止；\n将r[0]插入r[j+1]的位置上。\n\n演示\n也可以通过动画更清晰了解整个排序过程\n动画：http://www.zhuxingsheng.com/tools/sort/sort.html\n实现插入排序包括：直接插入排序，二分插入排序（又称折半插入排序），链表插入排序，希尔排序（又称缩小增量排序）\nstatic void insertSort1(int []sorts) &#123;    for(int i = 1;i&lt;sorts.length;i++) &#123;        int tmp = sorts[i];//哨兵        int j= i-1;        while(j &gt;=0 &amp;&amp; tmp &lt; sorts[j]) &#123;            sorts[j+1] = sorts[j];//比tmp大的全部往右移动            j--;        &#125;        //别的移完位置，把哨兵放到正确的位置        sorts[++j] = tmp;    &#125;&#125;\n\n复杂度当问题规模为n时\n最好情况（原本就是有序的）\n比较次数：Cmin&#x3D;n-1\n移动次数：Mmin&#x3D;0\n最差情况（逆序）\n比较次数：Cmax&#x3D;2+3+4+……+n&#x3D;(n+2)n&#x2F;2\n移动次数：Mmax&#x3D;1+2+3+……+n-1&#x3D;n*n&#x2F;2\nBest| Average| Worst|Memory|Stable — | —| —|——| :–: |—n\t|n^2|\tn^2\t| 1 |\tYes\n","tags":["算法"]},{"title":"算法渣-排序-总结","url":"/blog/algorithm---sorting---summary.html","content":"\n从第一篇《算法概要》开始，到此篇已经经历了将近四个月时间，常见的基础排序已经温习完成\n内外排序内部排序：待排序记录存放在计算机随机存储器中（说简单点，就是内存）进行的排序过程\n外部排序：待排序记录的数量很大，以致于内存不能一次容纳全部记录，所以在排序过程中需要对外存进行访问的排序过程\n衡量效率内部排序：比较次数，也就是时间复杂度\n外部排序：IO次数，也就是读写外存的次数\nIO对排序的影响可以阅读《深入浅出索引》体会\n算法\n详细介绍算法渣-排序-冒泡\n冒泡排序，应该是很多人会且只会的算法；两两比较交换\n为了减小比较与交换的次数，通过双向比较(鸡尾酒排序)、设定是否交换位实现\n算法渣-排序-快速排序\n快速排序，相对冒泡又改进了，都是交换，但引入了分治思想\n\n算法渣-排序-插入\n插入排序，像打牌时，整理牌一样，通过比较、移动来达到排序\n算法渣-排序-希尔\n希尔，相对插入做了改进，不是一步一步的移动，而是大步大步的移动\n\n算法渣-排序-选择\n选择，类似插入的反向操作；插入排序是边读边排，每当读入一个新的数时，目前的数组一定是排好序的。而选择排序不同，它必须是读完所有的数据之后才能开始排序的\n算法渣-排序-堆排序\n堆排序，借助堆数据结构，构造堆结构，选取堆顶元素，不再需要遍历所有元素选择\n\n算法渣-排序-归并排序\n归并排序，也是分治思想，但与快速有些区别；归并排序是由下向上的，先处理子数组然后再合并。而快速排序正好相反，它的过程是由上向下的，先分出两个子区间，再对子区间进行排序\n\n算法渣-排序-基数排序\n算法渣-排序-桶排序\n算法渣-排序-计数排序\n线性排序算法,非基于比较的排序算法，性能很高，但都有限制才能达到线性排序的效果\n\n场景对于排序算法选择，不能单从时间复杂上看，简单算法都是O(n^2),就不考虑，只选择改进算法\n插入排序  vs 快速排序 vs 归并排序由下图可以看出，在输入规模小于100时，插入排序要好于归并和快速排序。在输入规模小于200时，插入排序优于归并排序。规模在30以下时，插入排序效率要比快速排序高50%以上，规模在50以下时，插入排序比归并排序效率高90%以上\n\n改进算法在数据量大时，使用改进算法\n\n\n就时间性能而言， 希尔排序、快速排序、树形选择排序、堆排序和归并排序都是较为先进的排序方法。耗时远小于O(N^2)级别的算法。\n先进算法之中，快排的效率是最高的。 但其缺点十分明显：在待排序列基本有序的情况下，会蜕化成起泡排序，时间复杂度接近 O(N^2)。\n希尔排序的性能让人有点意外，这种增量插入排序的高效性完全说明了：在基本有序序列中，直接插入排序绝对能达到令人吃惊的效率。但是希尔排序对增量的选择标准依然没有较为满意的答案，要知道增量的选取直接影响排序的效率。\n归并排序的效率非常不错，在数据规模较大的情况下，它比希尔排序和堆排序都要好。\n堆排序在数据规模较小的情况下还是表现不错的，但是随着规模的增大，时间代价也开始和上面两种排序拉开的距离。\n\n总结总的来说，并不存在“最佳”的排序算法。必须针对待排序列自身的特点来选择“良好”的算法。下面有一些指导性的意见：\n\n数据规模很小，而且待排序列基本有序的情况下，选择直接插入排序绝对是上策。不要小看它O(N^2)级别\n数据规模不是很大，完全可以使用内存空间。而且待排序列杂乱无序(越乱越开心)，快排永远是不错的选择，当然付出log(N)的额外空间是值得的。\n海量级别的数据，必须按块存放在外存(磁盘)中。此时的归并排序是一个比较优秀的算法\n\n试题【京东】假设你只有100Mb的内存，需要对1Gb的数据进行排序，最合适的算法是（ ）\nA. 归并排序　　B. 插入排序　　C. 快速排序　　D. 冒泡排序\n\n根据题目，我们可以知道，我们现有的内存限制使得我们无法把数据一次性加载到内存中，所以我们只能先加载一部分数据，对其排序后存入磁盘中。然后再加载一些数据，把它们“合并”到已排序的数据集中去，重复这个过程直到排序完成，显然最能胜任这个工作的是归并排序。\n\n【2016阿里巴巴校招笔试题】现有1GB数据进行排序，计算资源只有1GB内存可用，下列排序方法中最可能出现性能问题的是（ ）\nA. 堆排序　　B. 插入排序　　C. 归并排序　　D. 快速排序　　E. 选择排序　　F. 冒泡排序\n\n根据题目的描述，我们能够很明确的知道这道题考察我们的是原地排序的概念，这里我们只需要选择非原地排序的占用额外空间最大的算法，显然答案是”C. 归并排序”。\n\n【2015阿里巴巴研发工程师笔试题】个数约为50K的数列需要进行从小到大排序，数列特征是基本逆序(多数数字从大大小，个别乱序)，以下哪种排序算法在事先不了解数列特征的情况下性能最优\nA. 冒泡排序　　B. 改进冒泡排序　　C. 选择排序　　D. 快速排序　　E. 堆排序　　F.插入排序\n\n根据题目中的描述，首先我们可以排除A、B、C，因为它们的时间复杂度都是O(n^2)。接下来我们看下D选项，我们前面提到过，快速排序在最坏情况下的时间复杂度会退化至O(n^2)，F选项的插入排序在逆序数很大时性能也很差（O(n^2)）。而堆排序在最坏情况下的复杂度也为O(logn)，所以这里我们应该选择堆排序\n\n参考资料基于比较的内部排序总结\n常见比较排序算法的耗时测试\n","tags":["算法"]},{"title":"算法渣-排序-桶排序","url":"/blog/algorithm-slag-sorting-bucket-sorting.html","content":"\n没有一身好内功，招式再多都是空;算法绝对是防身必备，面试时更是不可或缺；跟着算法渣一起从零学算法\n\n线性排序常见的三种以线性时间运行的算法：计数排序、基数排序和桶排序；网上教程不少，但三者经常混淆，称桶排序但实质可能是计数排序，为了保证原味性，主要参考《算法导论》\n需要注意的是线性排序算法是非基于比较的排序算法，都有使用限制才能达到线性排序的效果\n定义桶排序 (Bucket sort)或所谓的箱排序，是一个排序算法，工作的原理是将数组分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。桶排序是鸽巢排序的一种归纳结果。当要被排序的数组内的数值是均匀分配的时候，桶排序使用线性时间（Θ（n））\n算法桶排序的思想：其实就是先分配再收集的这个一个过程\n假设输入是一个随机过程产生的[0,1)区间上均匀分布的实数\n把区间划分成n个大小相同的子区间，或称为桶。然后将n个输入元素分布的各个桶中去。先对各个桶中的数进行排序，然后按次序把各桶中的数据列出来即可\n     （因为输入元素均匀而独立的分布在区间 [0,1)上，所以不会出现很多数落在一个桶中的情况）\n在桶排序算法中，假设输入的是一个含n个元素的数组A，且每个元素满足0≤A[i]&lt;1。另外，还需要一个辅助数组B[0…n-1]来存放链表（桶），并假设可以用某种机制来维护这些表\n\n【刚开始按照示例图的方式理解了桶排序，桶分10个，以十分位为桶号放入各个桶，也算是桶排序一种实现方式，但还是狭隘了】\n\n在实际应用时，其实并不然必须元素范围为[0,1)，整数，小数都是可以的，只要分布均匀就能最大发挥桶排序优势\n优质的桶排序需要考虑几个因素：\n\n桶的数量：桶越多，占用空间越大 \n区间跨度：桶与桶之间的跨度\n桶内元素的排序\n\n一般区间跨度：\n除了最后一个桶只包含一个最大值之外，其余各桶之间的区间跨度&#x3D;(最大值-最小值)&#x2F;(桶数量-1)\n\n//伪代码BUCKET_SORT(A)  n = length(A)   for i= 1 to n           do insert A[i] into list B    for i=0 to n-1           do sort list B[i] with insertion sort concatenate the list B[0]、B[1]，，，B[n-1] together in order\n\n实现private static void bucketSort(double [] array)&#123;\tint bucketNum = 10;//10个桶\tdouble max = Double.MIN_VALUE;\tdouble min = Double.MIN_VALUE;\tfor (double a:array) &#123;\t\tif(a&gt; max) &#123;\t\t\tmax = a;\t\t&#125;\t\tif(a&lt;min) &#123;\t\t\tmin = a;\t\t&#125;\t&#125;\t//区间跨度\tdouble span  = (max - min) / (bucketNum - 1);\tdouble [][]buckets = new double[bucketNum][];\t//初始化桶\tfor (int b = 0; b&lt;bucketNum;b++) &#123;\t\t//以排序元素个数初始化每个桶，以防极端情况\t\tbuckets[b] = new double[array.length];\t&#125;\t//每个桶的元素数量\tint [] index = new int[10];\tfor (int d = 0;d&lt;array.length;d++) &#123;\t\tint bucket =  (int)((array[d] - min)/span);\t\tbuckets[bucket][index[bucket]] = array[d];\t\tindex[bucket]++;\t&#125;\t//每个桶排序，直接使用sort函数了\tfor(int b = 0; b&lt;10; b++) &#123;\t\tArrays.sort(buckets[b]);\t&#125;\tint j = 0;\tfor(int b = 0; b&lt;10; b++) &#123;\t\tif(index[b] == 0) &#123;\t\t\tcontinue;\t\t&#125;\t\t//这儿需要特殊处理一下，主要是因为每个桶初始化了array.length，\t\t// 经过sort排序，比如第一个桶数组变成了[0.0,0.0,......0.002]\t\t//需要剔掉数组中的0\t\tfor (int bi = array.length-index[b];bi&lt;array.length;bi++) &#123;\t\t\tarray[j++] = buckets[b][bi];\t\t&#125;\t&#125;&#125;\n\n复杂度时间复杂度：\n假设有m个桶，则每个桶的元素为n&#x2F;m;\n当辅助函数为冒泡排序O(n^2)时,桶排序为 O(n)+mO((n&#x2F;m)2);\n当辅助函数为快速排序时O(nlgn)时,桶排序为 O(n)+m*O(n&#x2F;m log(n&#x2F;m))\n空间复杂度：　\nO(M+N)  \n通常桶越多，执行效率越快，即省时间，但是桶越多，空间消耗就越大，是一种通过空间换时间的方式\n","tags":["算法"]},{"title":"算法渣-排序-选择","url":"/blog/algorithm---sort---select.html","content":"\n没有一身好内功，招式再多都是空;算法绝对是防身必备，面试时更是不可或缺；跟着算法渣一起从零学算法\n\n定义选择排序（Selection sort）是一种简单直观的排序算法。它的工作原理是每一次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到全部待排序的数据元素排完。 选择排序是不稳定的排序方法。\n算法n个记录的文件的直接选择排序可经过n-1趟直接选择排序得到有序结果：\n\n初始状态：无序区为R[1..n]，有序区为空\n第1趟排序在无序区R[1..n]中选出关键字最小的记录R[k]，将它与无序区的第1个记录R[1]交换，使R[1..1]和R[2..n]分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区。……\n第i趟排序第i趟排序开始时，当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区。\n\n演示\n实现static void selectSort(int []array) &#123;    for (int i=0;i&lt;array.length-1;i++) &#123;        int min  = i;        for (int j = i+1;j&lt;array.length;j++)&#123;            if(array[min] &gt; array[j]) &#123;                min = j;            &#125;        &#125;        if( min != i) &#123;            int tmp = array[i];            array[i] = array[min];            array[min] = tmp;        &#125;    &#125;&#125;\n\n复杂度比较次数：T &#x3D; （n-1)）+ （n -2）+（n - 3）…. + 1; T &#x3D; [n*(n-1) ] &#x2F; 2；\n交换次数：\n最好的情况全部元素已经有序，则交换次数为0；\n最差的情况，全部元素逆序，就要交换 n-1 次；\n空间复杂度\n最优的情况下（已经有顺序）复杂度为：O(0) \n最差的情况下（全部元素都要重新排序）复杂度为：O(n );\n平均的时间复杂度：O(1)\nBest| Average| Worst|Memory|Stable — | —   | —  |——| :–: |—n²   |  n²   |\tn²\t| 1 |\tNo\nVS 插入排序插入排序特别的相似\n复杂度一样，但是插入排序和读入（初始）的数据有关，最优情况只有O(n)；而选择排序不论如何，永远都是O(n^2)\n插入排序是边读边排，每当读入一个新的数时，目前的数组一定是排好序的。而选择排序不同，它必须是读完所有的数据之后才能开始排序的。\n那么选择排序的缺点就是，万一数据量很大，比方说一百万个，光读就慢了，还要排序，那就更慢了。如果这两个耗时的步骤可以并行一起做的话，显然插入排序肯定就会快一些。\n","tags":["算法"]},{"title":"算法渣-排序-计数排序","url":"/blog/algorithm---sorting---counting-sorting.html","content":"\n没有一身好内功，招式再多都是空;算法绝对是防身必备，面试时更是不可或缺；跟着算法渣一起从零学算法\n\n线性排序常见的三种以线性时间运行的算法：计数排序、基数排序和桶排序\n需要注意的是线性排序算法是非基于比较的排序算法，都有使用限制才能达到线性排序的效果\n线性排序是个神奇的算法，比基数排序及桶排序神奇得多\n定义计数排序是一个非基于比较的排序算法，该算法于1954年由 Harold H. Seward 提出。它的优势在于在对一定范围内的整数排序时，它的复杂度为Ο(n+k)（其中k是整数的范围），快于任何比较排序算法\n算法计数排序的基本思想是对于给定的输入序列中的每一个元素x，确定该序列中值小于x的元素的个数（此处并非比较各元素的大小，而是通过对元素值的计数和计数值的累加来确定）。一旦有了这个信息，就可以将x直接存放到最终的输出序列的正确位置上\n首先需要三个数组，第一个数组记录A要排序的数列大小为n，第二个数组B要记录比某个数小的其他数字的个数所以第二个数组的大小应当为K（数列中最大数的大小），第三个数组C为记录排序好了的数列的数组，大小应当为n。\n接着需要确定数组最大值并确定B数组的大小。并对每个数由小到大的记录数列中每个数的出现次数。因为是有小到大通过出现次数可以通过前面的所有数的出现次数来确定比这个数小的数的个数，从而确定其位置\n假定20个随机整数的值，也就是第一个数组A：\n9，3，5，4，9，1，2，7，8，1，3，6，5，3，4，0，10，9 ，7，9\n数组A中最大数为10，数组B需要0~10索引\n\n比如第一个整数是9，那么数组下标为9的元素加1：\n\n第二个整数是3，那么数组下标为3的元素加1：\n\n最终，数列遍历完毕时，数组的状态如下：\n\n数组每一个下标位置的值，代表了数列中对应整数出现的次数。\n有了这个“统计结果”，排序就很简单了。直接遍历数组，输出数组元素的下标值，元素的值是几，就输出几次：\n0，1，1，2，3，3，3，4，4，5，5，6，7，7，8，9，9，9，9，10\n实现/** * 计数排序 * @param array */public static void countSort(int []array)&#123;    //最大最小数    int min = Integer.MAX_VALUE;    int max = Integer.MIN_VALUE;    for ( int a:array) &#123;        if(min &gt; a) &#123;            min = a;        &#125;        if(max &lt; a) &#123;            max = a;        &#125;    &#125;    //数组索引数量,统计数组计数    // max-min 主要是考虑到像[90,99,93,95]不是从很小数开始的数组排序，减小空间消耗    int indexCount = max - min + 1;    System.err.println(&quot;统计数组长度&quot;+indexCount);    int []countArray = new int[indexCount];    for (int i=0;i&lt;array.length;i++)&#123;        System.err.println(array[i]-min);        countArray[array[i]-min]++;    &#125;    System.err.println(&quot;countArray:&quot;+Arrays.toString(countArray));    //排好序的数组    int [] sortArray = new int[array.length];    int index = 0;    for (int i=0;i&lt;indexCount;i++) &#123;        for (int j=0;j&lt;countArray[i];j++)&#123;            sortArray[index++] = min + i;        &#125;    &#125;    //输出就是有序    System.err.println(Arrays.toString(sortArray));&#125;\n\n改进上面的实现为什么要改进，主要是当两个元素相同时，算法的稳定性问题\n改进之前，数组B存放的是元素出现的次数\n改进之后，会引入一个新数组(也可以共用数组B)，存放的是元素的位置号(这个纯粹是个人理解，之前数组B是存放元素出现的次数，新数组存放每一个元素都加上前面所有元素出现次数之和，当找到对应排序数组元素时，新数组元素就是位置号)\n语言比较空洞，直接来个示例(转自小灰程序员)\n将数组arr中的数据当作是学生的成绩，要求不但要按照顺序从低到高排序，成绩相同时，按原有顺序显示：\n\n\n统计数组从第二个元素开始，每一个元素都加上前面所有元素之和\n\n第一步，我们遍历成绩表最后一行的小绿：\n小绿是95分，我们找到countArray下标是5的元素，值是4，代表小绿的成绩排名位置在第4位。\n同时，我们给countArray下标是5的元素值减1，从4变成3,，代表着下次再遇到95分的成绩时，最终排名是第3。\n\n第二步，我们遍历成绩表倒数第二行的小白：\n小白是94分，我们找到countArray下标是4的元素，值是2，代表小白的成绩排名位置在第2位。\n同时，我们给countArray下标是4的元素值减1，从2变成1,，代表着下次再遇到94分的成绩时（实际上已经遇不到了），最终排名是第1。\n\n第三步，我们遍历成绩表倒数第三行的小红：\n小红是95分，我们找到countArray下标是5的元素，值是3（最初是4，减1变成了3），代表小红的成绩排名位置在第3位。\n同时，我们给countArray下标是5的元素值减1，从3变成2,，代表着下次再遇到95分的成绩时（实际上已经遇不到了），最终排名是第2。\n\n这样一来，同样是95分的小红和小绿就能够清楚地排出顺序了，也正因此，优化版本的计数排序属于稳定排序。\n/** * 稳定计数排序 * @param array */public static void countSort1(int []array) &#123;    //最大最小数    int min = Integer.MAX_VALUE;    int max = Integer.MIN_VALUE;    for ( int a:array) &#123;        if(min &gt; a) &#123;            min = a;        &#125;        if(max &lt; a) &#123;            max = a;        &#125;    &#125;    //数组索引数量,统计数组计数    // max-min 主要是考虑到像[90,99,93,95]不是从很小数开始的数组排序，减小空间消耗    int indexCount = max - min + 1;    System.err.println(&quot;统计数组长度&quot;+indexCount);    int []countArray = new int[indexCount];    for (int i=0;i&lt;array.length;i++)&#123;        System.err.println(array[i]-min);        countArray[array[i]-min]++;    &#125;    System.err.println(&quot;countArray:&quot;+Arrays.toString(countArray));    //位置数组    int []pointArray = new int[indexCount];    int sum =0;    for (int i = 0;i&lt;indexCount;i++)&#123;        sum += countArray[i];        pointArray[i] = sum;    &#125;    System.err.println(&quot;pointArray:&quot;+Arrays.toString(pointArray));    System.err.println(&quot;aaaaaArray:&quot;+Arrays.toString(array));    //排好序的数组    int [] sortArray = new int[array.length];    for (int i=array.length-1;i&gt;=0;i--) &#123;            sortArray[pointArray[array[i]-min] -1 ] = array[i];            pointArray[array[i]-min]--;    &#125;    //输出就是有序    System.err.println(Arrays.toString(sortArray));&#125;\n\n总结复杂度假设array元素有N个，取值范围是M。\n时间复杂度：3N(计算最大最小数、计数、排好序的数组) + M(位置数组)，去掉系数，时间复杂度是O(N+M)\n空间复杂度：只考虑统计数组，那就是M\n局限性1.当数列最大最小值差距过大时，并不适用计数排序。\n比如给定20个随机整数，范围在0到1亿之间，这时候如果使用计数排序，需要创建长度1亿的数组。不但严重浪费空间，而且时间复杂度也随之升高。\n2.当数列元素不是整数，并不适用计数排序。\n如果数列中的元素都是小数，比如25.213，或是0.00000001这样子，则无法创建对应的统计数组。这样显然无法进行计数排序。\n引申阅读算法渣-排序-基数排序\n算法渣-排序-桶排序\n参考资料漫画：什么是计数排序\n","tags":["算法"]},{"title":"算法渣-递归算法","url":"/blog/algorithm---recursive-algorithm.html","content":"前言之前的排序算法 《快速排序》 与 《归并排序》 都使用了递归手法，如果不能理解递归，那分治思想类算法实现就难以理解\n递归To iterate is human,to recurse divine. — L. Peter Deutsch\n迭代的是人，递归的是神\n递归思想递归的基本思想是把规模大的问题转化为规模小的相似的子问题来解决。在函数实现时，因为解决大问题的方法和解决小问题的方法往往是同一个方法，所以就产生了函数调用它自身的情况。另外这个解决问题的函数必须有明显的结束条件，这样就不会产生无限递归的情况了。\n递归中的“递”就是入栈，递进；“归”就是出栈，回归\n规模大转化为规模小是核心思想，但递归并非是只做这步转化，而是把规模大的问题分解为规模小的子问题和可以在子问题解决的基础上剩余的可以自行解决的部分。而后者就是归的精髓所在，是在实际解决问题的过程\n\n为什么我老是有递归没有真的在解决问题的感觉？\n\n\n因为递是描述问题，归是解决问题。而我的大脑容易被递占据，只往远方去了，连尽头都没走到，何谈回的来\n\n递归就是有去（递去）有回（归来）\n为什么可以”有去“？\n\n这要求递归的问题需要是可以用同样的解题思路来回答除了规模大小不同其他完全一样的问题\n\n为什么可以”有回“？\n\n这要求这些问题不断从大到小，从近及远的过程中，会有一个终点，一个临界点，一个baseline，一个你到了那个点就不用再往更小，更远的地方走下去的点，然后从那个点开始，原路返回到原点\n递归三要素用程序表达出来，确定了三个要素：递 + 结束条件 + 归\nfunction recursion(大规模)&#123;    if (end_condition)    &#123;        end;         &#125; else &#123;     //先将问题全部描述展开，再由尽头“返回”依次解决每步中剩余部分的问题        recursion(小规模);     //go;        solve;                //back;    &#125;&#125;\n\n另一种递归情况，比如递归遍历的二叉树的先序\nfunction recursion(大规模)&#123;    if (end_condition)&#123;        end;         &#125;else&#123;     //在将问题转换为子问题描述的每一步，都解决该步中剩余部分的问题。        solve;                //back;        recursion(小规模);     //go;    &#125;&#125;\n\n示例阶乘求一个数的阶乘是练习简单而典型的例子，阶乘的递推公式为：factorial(n)&#x3D;n*factorial(n-1)，其中n为非负整数,且0!&#x3D;1,1!&#x3D;1\n我们根据递推公式可以轻松的写出其递归函数：\npublic static long factorial(int n) throws Exception &#123;    if (n &lt; 0)        throw new Exception(&quot;参数不能为负！&quot;);    else if (n == 1 || n == 0)        return 1;    else        return n * factorial(n - 1);&#125;\n\n在求解6的阶乘时，递归过程:\n\n斐波那契数列斐波那契数列的递推公式:Fib(n)&#x3D;Fib(n-1)+Fib(n-2)，指的是如下所示的数列：\n1、1、2、3、5、8、13、21…..\n按照其递推公式写出的递归函数如下：\npublic static int fib(int n) throws Exception &#123;    if (n &lt; 0)        throw new Exception(&quot;参数不能为负！&quot;);    else if (n == 0 || n == 1)        return n;    else        return fib(n - 1) + fib(n - 2);&#125;\n\n\nVS迭代递归算法与迭代算法的设计思路区别在于：函数或算法是否具备收敛性，当且仅当一个算法存在预期的收敛效果时，采用递归算法才是可行的，否则，就不能使用递归算法\n参考资料怎么更好地终极理解递归算法\n","tags":["算法"]},{"title":"缓存是个面子工程","url":"/blog/caching-is-a-face-project.html","content":"使用缓存来加速应用程序的访问速度，是几乎所有高性能系统都会采用的方法。\n但缓存真的那么好吗？架构师在构建高性能系统时，是不是必须增加缓存组件？缓存是不是多多益善？\n《一代宗师》里本山大叔说过这样的一段话：\n“一门里，有人当面子，就得有人当里子。面子不能沾一点儿灰尘。流了血，里子得收着，收不住，漏到了面子上，就是毁派灭门的大事。”\n\n如果缓存是里面的角色，那么绝对是面子。\n虽然缓存带来了性能的提升，但给系统带来的多少复杂性。缓存穿透，缓存击穿，缓存雪崩，缓存污染这些问题不绝于耳。这些问题不是操作系统兜着，就是程序员。所以缓存是24K纯金的面子。人人都好面子，还得有个能轻松应对的里子。\n\n\n历史悠久看现在软件世界里面，尤其互联网系统，处处都有缓存。但其实缓存的历史很久远。在硬件时代就已经出现了。\n且看存储金字塔结构：\n\n受限于存储介质的存取速率和成本，现代计算机的存储结构呈现为金字塔型。越往塔顶，存取效率越高、但成本也越高，所以容量也就越小。得益于程序访问的局部性原理，这种节省成本的做法也能取得不俗的运行效率。从存储器的层次结构以及计算机对数据的处理方式来看，上层一般作为下层的Cache层来使用（广义上的Cache）。比如寄存器缓存CPU Cache的数据，CPU Cache L1~L3层视具体实现彼此缓存或直接缓存内存的数据，而内存往往缓存来自本地磁盘的数据。\n在Linux的IO体系里面也有它的身影：\n\n如图中的PageCache,应用程序在写文件的时候，操作系统会先把数据写入到 PageCache 中，数据在成功写到 PageCache 之后，对于用户代码来说，写入就结束了。\n然后，操作系统再异步地把数据更新到磁盘的文件中。应用程序在读文件的时候，操作系统也是先尝试从 PageCache 中寻找数据，如果找到就直接返回数据，找不到会触发一个缺页中断，然后操作系统把数据从文件读取到 PageCache 中，再返回给应用程序。\n在数据写到 PageCache 中后，它并不是同时就写到磁盘上了，这中间是有一个延迟的。操作系统可以保证，即使是应用程序意外退出了，操作系统也会把这部分数据同步到磁盘上。但是，如果服务器突然掉电了，这部分数据就丢失了。\nCache的同步方式有两种，即Write Through（写穿）和Write back（写回）。 从名字上就能看出这两种方式都是从写操作的不同处理方式引出的概念。\n对应到Linux的PageCache上所谓Write Through就是指write操作将数据拷贝到Page Cache后立即和下层进行同步的写操作，完成下层的更新后才返回。\n而Write back正好相反，指的是写完Page Cache就可以返回了。Page Cache到下层的更新操作是异步进行的。\nLinux下Buffered IO默认使用的是Write back机制，即文件操作的写只写到Page Cache就返回，之后Page Cache到磁盘的更新操作是异步进行的。因此才会出现数据丢失问题。\n可以看出读写缓存的这种设计，它天然就是不可靠的，是一种牺牲数据一致性取性能的设计。\n但在硬件时代，相对程序员的好处是，自己不用考虑，操作系统已经实现这些机制了。\n为什么需要缓存回到开篇的问题，缓存真的是必不可少的组件吗？缓存带来的系统复杂性与提升的系统性能投入产出比合理吗？\n如果CPU强劲，IO没有开销，还需要缓存吗？反过来，引入缓存到底是为了提升性能，还只是为了补齐CPU与IO的短板。是主攻还是防守？是不是个面子工程。\n所以综观一下，引入缓存，主要是两方面的理由：\n\n缓解CPU压力：把运算结果存储起来，节省CPU算力\n缓解IO压力：把原本对网络、磁盘等慢介质的读写访问变为对内存等快介质的访问。\n\n而这两方面，核心不是为了性能，性能的提升只是个副作用。\n也就是如果能通过提升硬件，增强CPU和IO本身性能，是更好的解决方案。\n譬如云，如果不是硬件受工艺与成本的限制，谁会花大成本搞云呢。加机器多省事。\n在互联网场景下，大多数时候是读缓存，但也有像消息队列，读写量几乎是均衡的，如何应对缓存带来复杂性，是每一次系统架构时引入缓存组件时都需要考虑的问题。\n数据一致性使用缓存组件，我们需要重点关注一些技术指标，如“吞吐量”和“命中率”。而在使用过程中面对的问题，相对缓存穿透、击穿、雪崩，还是更关注一下缓存污染，也就是数据一致性问题。之前写过《百万QPS系统的缓存实践》，但里面还有一些场景没有详细阐述。尤其在当前标配的分布式架构下，CAP理论大棒肆无忌惮的挥舞。时时都要考虑数据一致性。\n当然，虽然我们通过一些手段解决缓存的一致性问题，但也仅仅是缓解，并没法根治，它是个面子工程，不然也不会有像Paxos、Raft等一系列强一致性算法出现。\n缓存数据一致性的问题，主要是两方面：\n一是并发：并发操作引起的数据不一致\n二是原子性：操作DB与操作缓存要么都成功，要么都失败\n在《百万QPS系统的缓存实践》中已经指出，Cache-Aside pattern是通识，也就是先操作数据库，再删除缓存。\n并发在理论上，会有一种并发问题：\n\n缓存中 X 不存在（数据库 X &#x3D; 1）\n线程 A 读取数据库，得到旧值（X &#x3D; 1）\n线程 B 更新数据库（X &#x3D; 2)\n线程 B 删除缓存\n线程 A 将旧值写入缓存（X &#x3D; 1）\n\n\n这个场景需要cache miss、读请求 + 写请求并发、更新数据库 + 删除缓存的时间（步骤 3-4），要比读数据库 + 写缓存时间短（步骤 2 和 5）\n但这种现象的概率太低了，数据库写操作时长远远大于读操作的。\n原子性原子性是指，与数据库事务原子性语义相同，数据库与缓存操作怎么捆绑在一起，要么都成功，要么都失败。\n如果要强一致，那就需要像二阶段提交协议，还有近年出现的Paxos、Raft。但那就更复杂了，简单的方案可以有几种选择：\n\n操作缓存失败，直接回滚数据库，返回失败：想想真如果这么干，首先系统可用性大大降低，其次代码是什么样，挑战极大。\n重试：用户无感，系统重试。可失败后马上重试大概率也是失败，重试多少次，重试过程中，一直占用资源。\n异步重试：类似于Write Back 模式。\n\n但此处的Write Back不能限于内存，一旦重试过程中，服务重启，必然造成数据丢失。因此需要第三方服务来支撑。显然消息队列很适合这种场景\n消息队列可靠保障：只要成功写入，不会丢失；并且能成功投递，直到消费成功。\n有没有简单点的方案，毕竟引入消息队列有点重。\n也有，就是『订阅数据库变更日志，再操作缓存』\n通过监听binglog，当数据库变更时，去删除对应的缓存。这样应用程序无需再去主动操作缓存。\n怎么订阅binglog呢？也有现成的开源组件，如canal。\n\n到目前为止，还算完美解决了一致性问题。但在互联网行业中，数据库大多采用一主多从的部署方案。也就是在引入缓存前，能增加硬件方式解决时优先考虑增加硬件。\n在系统中只要采用数据库主从架构，就有主从本身一致性问题，引入缓存又增加了复杂性。\n\n\n线程 A 更新主库 X &#x3D; 2（原值 X &#x3D; 1）\n线程 A 删除缓存\n线程 B 查询缓存，没有命中，查询「从库」得到旧值（从库 X &#x3D; 1）\n从库「同步」完成（主从库 X &#x3D; 2）\n线程 B 将「旧值」写入缓存（X &#x3D; 1）\n\n怎么解决呢？类似于解决主从本身问题，可以等待slave同步完数据，延迟再删除一次缓存。\n\n只是这个延迟间隔，需要依据master slave同步的间隔。\n总结总结一下本文的重点：\n1、引入缓存会带来复杂性，甚至负面作用。尽量通过升级硬件来避免不必要的风险。\n2、缓存需要考虑“吞吐量”、“命中率”等属性，还需要应对穿透、击穿、雪崩、不致性等问题。\n3、Cache-Aside模式可以几乎完美解决单体架构下并发带来的问题。\n4、在主从数据库模式下，Cacahe-Aside模式需要延迟双删方案，解决一致性问题。\n5、CAP时时在发威，性能与一致性需要权衡。\n参考资料聊聊Linux IO\n","tags":["架构","缓存"]},{"title":"耦合必然性","url":"/blog/coupling-inevitability.html","content":"最近学到一个词“耦合创伤应激障碍”，讲的是程序员对耦合条件反射式恐惧，对于这个新词，我再重新理解一篇\n对于一名程序员，从入行开始，就听到前辈们对“高内聚低耦合”的谆谆教诲，所以对于低耦合的意识深入骨髓。知行合一，看看是怎么践行的，打开任何一个项目工程，可以看到，每一个service都有一个interface和impl，代码看起来整整齐齐，所有变化点都考虑到了，但其实没有降低问题复杂度，只是自己看着舒服\n在《SOLID总结》中提到过面向接口编程中接口到底是什么含义，并不是所有实现类都得需要一个接口，才是面向接口编程\n而现在实践中对实现依赖心理恐惧，成了一种行业通病，见不得对实现的依赖，这是典型的耦合创伤应激障碍，像“猴子实验”\n\n五只猴子被关进笼子里，笼子一角挂着一串香蕉，如果有猴子试图摘取香蕉，就会被开水泼到。猴子们吃了几次苦头之后，就再也不想摘香蕉了。此时用一只新猴子替换老猴子，新猴子看到有香蕉刚想去摘，就被老猴子们拉住一顿暴打。新猴子挨了几次打之后，也不再去摘香蕉了。此时再换进一只新猴子，它也看到香蕉想去摘，也被老猴子们一顿暴打，下手最狠的恰恰是那一只没被开水烫到过的。最后老猴子们都被换干净了，仍然没有猴子去碰那串香蕉，因为它们知道——碰香蕉意味着被打，而为什么会被打，没有猴子知道。\n\n当参与一个新项目，不再创建interface时，肯定会变成那只被打的“猴子”\n然而现实并不是这样的，真的加个interface就减少耦合了吗？耦合少得了吗？比如，需要使用支付宝或微信支付，那么这就是业务需求，与支付宝和微信就必然会耦合，才能达到业务要求。不管怎么组织代码结构，是明显直接调用，还是隐晦地抛出支付事件，终将需要调用支付宝微信的支付接口；再比如现在很多应用需要推送消息，短信、邮件亦或微信，那么与支付类似，不管如何，必将调用第三方接口才能实现这些功能，这也就是耦合的必然性\n代码大致是这样的：\n先来一个接口：\npackage com.zhuxingsheng.infrastructure.portpublic interface AlipayService &#123;        public PayResult pay(AliInfo aliInfo,decimal payAmount);&#125;\n\n再来对接口的具体实现，调用支付宝SDK\npackage com.zhuxingsheng.infrastructure.apapterpublic class AlipayServiceImpl implements AlipayService &#123;        public PayResult pay(AliInfo aliInfo,decimal payAmount) &#123;        AlipaySdk.pay();        return result;    &#125;&#125;\n\n微信支付代码结构类似，对于这些代码味道是不是相当熟悉，有service必有interface和impl，但看看接口的意义在哪儿？\n机智的你，肯定发现这样不对，我们需要的应该是在线支付能力，而支付宝支付或微信支付只是具体的实现而已，也就是与支付宝和微信耦合其实不是必然的，必然的是在线支付能力\n这儿其实有两种演变过程：\n第一种：先实现了支付宝支付功能，当再实现微信支付时，此时发现要抽象出在线支付接口，策略模式\n第二种：从业务需求用户故事：作为用户需要完成订单线上支付，完成订单的全流程\n第一种从技术入手，而第二种从最原始的业务入手，这两种演变虽然第二种方是大道，可技术人却喜欢第一种，这也就回到篇首所说，代码看起来整整齐齐，却没有简化问题，甚至只因为技术风格的强统一，带来了业务语义的更加隐晦\n技术其实是解决业务的工具，需要从业务本源着手，挖掘业务背后隐藏的业务能力，构建出对应的技术模型，达到模型即代码的统一，也就知道了必然性耦合，怎么降低耦合\n所以再看上面的接口，package com.zhuxingsheng.infrastructure.port，是在基础设施层，只是技术上单纯的一个接口，在《DDD》专栏中，提到过的接口在领域层，实现在基础设施层，因为maven模块循环依赖或者DIP的需要，所以必需要把接口放在领域层，从业务角度分析，线上支付能力是构建模型的必要能力，是领域模型必不可少的部分，需要在线支付能力，也是业务必然性耦合的体现，应该在领域层\n可从代码形式上看，你是不是觉得不管是对业务的深刻理解，还是单纯技术抽象，不都是一个接口吗？无非是叫接口还是叫业务能力而已吗？\n再看一个接口\npackage com.zhuxingsheng.infrastructure.portpublic interface UserService &#123;        public User getUser(long userId);&#125;\n从命名就知道，获取用户信息，不管是业务系统自身处理用户信息，还是从用户中心式外部服务获取用户信息，这是整个系统的基本能力，而不会再需要去抽象一个深奥的业务能力，当业务需求故事阐述用户下订单业务行为时，业务方已然抽象了整个用户体系，只有研究用户上下文子域问题时，才去深入用户领域模型，但从当前业务上下文看，业务系统与这些基础服务是深度绑定，并在系统架构初始已经确定了整体架构\n因此在业务系统中去定义一个userservice接口，是没啥意义的，除非系统大动，否则是不会变动的\n延伸一下，此时领域层如何依赖基础设施层呢？怎么DIP呢？有没有丝毫感受到分层有问题呢。对此下会分解\n总结一下，我们需要正确看待耦合必然性，不是从技术实现的角度去硬生抽象，而需要从业务角度，挖掘出业务真正耦合的能力，坦然接受这样的耦合，清晰化表达业务语义\n","tags":["SOLID"]},{"title":"类加载器","url":"/blog/class-loader.html","content":"java执行过程先回顾一下要执行java程序，需要经过哪些步骤\n\n\n编写java代码\n通过javac把源代码编译成class\n把class载入JVM\n\n1、2两步是需要开发人员参与的，而第3步是JVM的行为，对开发人员透明\nJVM类加载详细看下第三点，class载入JVM过程\n从内存空间视角,会分配到各个空间：\n\n每个内存空间详情可参考：《GC及JVM参数》\n从类生命周期角度，分阶段：\n\n其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。\n1.加载类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口\n在加载阶段，虚拟机需要完成以下3件事情：\n\n通过一个类的全限定名来获取定义此类的二进制字节流\n将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。\n在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口\n\n加载.class文件的方式\n\n从本地系统中直接加载\n通过网络下载.class文件\n从zip，jar等归档文件中加载.class文件\n从专有数据库中提取.class文件\n将Java源文件动态编译为.class文件\n\n相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载\n加载阶段完成后，虚拟机外部的 二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据\n加载时机\n当应用程序启动的时候，所有的类不会被一次性加载，因为如果一次性加载，内存资源有限，可能会影响应用程序的正常运行。例如，A a&#x3D;new A()，一个类真正被加载的时机是在创建对象的时候，才会去执行以上过程，加载类。当我们测试的时候，最先加载拥有main方法的主线程所在类\n\nJava虚拟机有预加载功能。类加载器并不需要等到某个类被”首次主动使用”时再加载它,JVM规范规定JVM可以预测加载某一个类，如果这个类出错，但是应用程序没有调用这个类， JVM也不会报错；如果调用这个类的话，JVM才会报错，（LinkAgeError错误)\n\n\n加载方式隐式加载\n创建类对象\n使用类的静态域\n创建子类对象\n使用子类的静态域\n在JVM启动时，BootStrapLoader会加载一些JVM自身运行所需的class\n在JVM启动时，ExtClassLoader会加载指定目录下一些特殊的class\n在JVM启动时，AppClassLoader会加载classpath路径下的class，以及main函数所在的类的class文件\n\n显式加载\nClassLoader.loadClass(className)，不会进行初始化\nClass.forName(String name, boolean initialize,ClassLoader loader);  借助当前调用者的class的ClassLoader完成class的加载,加载class的同时根据initialize是否初始化\n\n2.连接2.1.验证：确保被加载的类的正确性验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作：\n文件格式验证：验证字节流是否符合Class文件格式的规范；例如：是否以0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。\n元数据验证：对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了java.lang.Object之外。\n字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。\n符号引用验证：确保解析动作能正确执行。\n验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用**-Xverify:none**参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间\n2.2. 准备：为类的静态变量分配内存，并将其初始化为默认值准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：\n\n2.2.1、这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。\n\n2.2.2、这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。假设一个类变量的定义为：public static int value &#x3D; 3； 那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的putstatic指令是在程序编译后，存放于类构造器方法之中的，所以把value赋值为3的动作将在初始化阶段才会执行\n\n2.2.3、如果类字段的字段属性表中存在ConstantValue属性，即同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值。\n 假设上面的类变量value被定义为： public static final int value &#x3D; 3；\n 编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为3\n\n\n2.3. 解析：虚拟机将常量池中的符号引用替换为直接引用（内存地址）的过程解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。符号引用就是一组符号来描述目标，可以是任何字面量。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄\n常量池\n字面量：比较接近Java语言层面，如String字符串,声明final的常量等\n符号引用：属于编译原理方面的概念:1、包括类和接口的全限定名 2、字段的名称和描述符3.方法的名称和描述符\n\n常量项结构\n这些内容，需要再去分析class文件详细结构，后续再学习了\n3.初始化，为类的静态变量赋予正确的初始值类加载的最后一个阶段，除了加载阶段我们可以通过自定义类加载器参与之外，其余完全又JVM主导。到了初始化阶段，才真正开始执行程序，也就是由java转换成的class\nJVM负责对类进行初始化，主要对类变量进行初始化。\n在Java中对类变量进行初始值设定有两种方式：\n\n声明类变量是指定初始值\n\n使用静态代码块为类变量指定初始值\n\n\nJVM初始化规则类初始化时机：只有当对类的主动使用的时候才会导致类的初始化\nJava程序对类的使用方式可以分为两种： \n\n主动使用：会执行加载、连接、初始化静态域\n被动使用：只执行加载、连接，不执行类的初始化静态域\n\n类的主动使用包括以下六种：\n创建类的实例，如（1）new （2）反射newInstance （3）序列化生成obj;遇到new、getstatic、putstatic、invokestatic这四条字节码指令\n访问某个类或接口的静态变量，或者对该静态变量赋值 （注意static 与static final的区别）\n调用类的静态方法\n反射（如Class.forName(“Test”)）\n初始化某个类的子类，则其父类也会被初始化；接口初始化不会导致父接口的初始化(这其实也是static final的原因)；对于静态字段，\n只有直接定义这个字段的类才会被初始化，因此，通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化\n\n\nJava虚拟机启动时被标明为启动类的类（Java Test），直接使用java.exe命令来运行某个主类\n\n被动使用，不在主动使用的六种以内都是被动的\n1.如通过子类引用父类的静态字段，为子类的被动使用，不会导致子类初始化\n2.通过数组定义类引用类，为类的被动使用，不会触发此类的初始化\n2.1 原因：其实数组已经不是E类型了，E的数组jvm在运行期，会动态生成一个新的类型，新类型为：      如果是一维数组，则为：[L+元素的类全名；二维数组，则为[[L+元素的类全名      如果是基础类型（int&#x2F;float等），则为[I（int类型）、[F（float类型）等\n\n\n3.常量在编译阶段会存入调用方法所在的类的常量池中，本质上没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化\n\n/** * 主动 被动使用问题测试 * Created by Jack on 2018/9/28. */public class ClassInitTest3 &#123;    public static void main(String[] args) &#123;        String x = F.s;    &#125;&#125;class F &#123;    //因为UUID.randomUUID().toString()这个方法，是运行期确认的，所以，这不是被动使用    static final String s = UUID.randomUUID().toString();    static &#123;        //这儿会被输出        System.out.println(&quot;Initialize class F&quot;);    &#125;&#125;\n\nclinit 与 init在编译生成class文件时，编译器会产生两个方法加于class文件中，一个是类的初始化方法clinit, 另一个是实例的初始化方法init\nclinit：clinit指的是类构造器，这个构造器是jvm自动合并生成的，在jvm第一次加载class文件时调用，包括静态变量初始化语句和静态块的执行\n它合并static变量的赋值操作\n\n注意是赋值操作，**(仅声明，或者final static)**不会触发，毕竟前面准备阶段已经默认赋过值为0了\nstatic{}语句块生成，且虚拟机保证执行前，父类的已经执行完毕，所以说父类如果定义static块的话，一定比子类先执行\n如果一个类或接口中没有static变量的赋值操作和static{}语句块，那么不会被JVM生成\nstatic变量的赋值操作和static{}语句块合并的顺序是由语句在源文件中出现的顺序所决定的。\n\ninit:在实例创建出来的时候调用，也就是构造函数，包括:\n\nnew操作符\n普通代码块\n调用Class或java.lang.reflect.Constructor对象的newInstance()方法；\n调用任何现有对象的clone()方法；\n通过java.io.ObjectInputStream类的getObject()方法反序列化。\n\n/** * &lt;clinit&gt; 与 &lt;init&gt; 区别 */public class ClassInitTest2 &#123;    static &#123;        System.out.println(&quot;cinit&quot;);        i = 3;//可以赋值        //System.out.println(i);//但不能使用，语法错误    &#125;    private static int i = 1;    &#123;        System.out.println(&quot;init&quot;);//实例化构造器，    &#125;    public static void main(String [] args)\t&#123;        new ClassInitTest2();        new ClassInitTest2();        String str = &quot;str&quot;;        System.out.println(str);    &#125;&#125;// 输出cinitinitinitstr\n\nstatic 与 static final 对初始化的区别\n/** * static 与 static final 对初始化的区别 */public class ClassInitFinalTest &#123;    public static  int age = 20;    static &#123;        //如果age定义为static final，这儿就不会执行        System.out.println(&quot;静态初始化！&quot;);    &#125;    public static void main(String args[])&#123;        System.out.println(ClassInitFinalTest.age);    &#125;&#125;\n\n不会执行类初始化的几种情况\n通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。\n定义对象数组，不会触发该类的初始化\n类A引用类B的static final常量不会导致类B初始化 (看上面的ClassInitFinalTest)\n通过类名获取Class对象，不会触发类的初始化。如\nSystem.out.println(Person.class);\n通过Class.forName加载指定类时，如果指定参数initialize为false时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。\n通过ClassLoader默认的loadClass方法，也不会触发初始化动作\n\n结束生命周期在如下几种情况下，Java虚拟机将结束生命周期\n\n执行了System.exit()方法\n程序正常执行结束\n程序在执行过程中遇到了异常或错误而异常终止\n由于操作系统出现错误而导致Java虚拟机进程终止\n\n类加载测试看到一段代码，很有意思\n/** * 测试类加载及初始化顺序问题 * Created by jack01.zhu on 2018/9/28. */public class ClassInit &#123;        private static ClassInit singleton = new ClassInit();        public static int counter1;        public static int counter2 = 0;        private ClassInit() &#123;            counter1++;            counter2++;        &#125;        public static ClassInit getSingleton() &#123;            return singleton;        &#125;&#125;/** * 通过输出结果，推测类加载过程 * Created by jack01.zhu on 2018/9/28. */public class ClassInitTestMain &#123;    public static void main(String []args) &#123;        ClassInit classInitTest = ClassInit.getSingleton();        System.out.println(&quot;counter1=&quot;+classInitTest.counter1);        System.out.println(&quot;counter2=&quot;+classInitTest.counter2);    &#125;&#125;\n这段代码输出的结果是什么？\ncounter1=1counter2=0\n\n\n入口肯定是ClassInitTestMain.main()，从这儿开始加载，初始化\nClassInit.getSingleton()，首次使用化，所以从加载部分开始执行，执行到准备阶段所有static变量都被设置为初始值。此时\n\npublic static int counter1 = 0;public static int counter2 = 0;private static ClassInit singleton = null;\n\nClassInit执行到初始化阶段，生成类构造器，类构造器会合并 static变量的赋值操作和 static语句块。合并后执行\n\npublic static int counter1 ; // 由于 counter1没被赋值，所以不会被合并进去public void clinit() &#123;// 伪代码：&lt;clinit&gt;方法体内容  ClassInit singleton = new ClassInit();//（1）  int counter2 = 0;// （2）&#125;\n\n初始化阶段 执行clinit内代码，执行到（1）处，此时counter1和counter2都变为1。\n初始化阶段 执行clinit内代码，执行到（2）处，counter2又被设置为0。\n初始化结束 ，回到Main方法的ClassInit.getSingleton();继续执行main方法，最后输出结束。\n\n\n以上，就是一个类的生命周期，这篇重点就是加载部分，如上面所说，加载阶段相对别的阶段，对开发人员而言有更强的可控性;下面学习一下类加载器相关知识\n类加载器\n\n\nBootstrapClassLoader:加载路径: System.getProperty(“java.class.path”) 或直接通过 -Xbootclasspath 指定\n\n  特性: 用C语言写的\n  手动获取加载路径: sun.misc.Launcher.getBootstrapClassPath().getURLs()\n\nExtClassLoader:加载路径: System.getProperty(“java.ext.dirs”) 或直接通过 -Djava.ext.dirs 指定\n\n  特性: 继承 URLClassLoader\n  手动获取加载路径:((URLClassLoader)App.class.getClassLoader().getParent()).getURLs()\n\nAppClassLoader:加载路径: System.getProperty(“sun.boot.class.path”) 或直接通过 -cp, -classpath 指定\n\n  特性: 继承 URLClassLoader\n  手动获取加载路径: ((URLClassLoader)App.class.getClassLoader()).getURLs()  通过 ClassLoader.getSystemClassLoader() 就可以获取 AppClassLoader, 自己写的程序中写的 ClassLoader(继承 URLClassLoader), 若不指定 parent, 默认的parent就是 AppClassLoader\n\n同一个class在JVM中，如何确定一个类型实例:\n同一个Class &#x3D; 相同的 ClassName + PackageName + ClassLoader\n在JVM中，类型被定义在一个叫SystemDictionary 的数据结构中，该数据结构接受类加载器和全类名作为参数，返回类型实例。\nSystemDictionary 如图所示：\n\n加载机制\n全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入\n双亲委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类\n缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效\n\n双亲委托模型双亲委托的工作过程：如果一个类加载器收到了一个类加载请求，它首先不会自己去加载这个类，而是把这个请求委托给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父类加载器反馈自己无法完成加载请求(它管理的范围之中没有这个类)时，子加载器才会尝试着自己去加载\n\n\n当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。\n\n当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。\n\n如果BootStrapClassLoader加载失败（例如在$JAVA_HOME&#x2F;jre&#x2F;lib里未查找到该class），会使用ExtClassLoader来尝试加载；\n\n若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。\n\n\njavac –verbose查看运行类是加载了jar文件 \n\nprotected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123;\t// 首先检查，jvm中是否已经加载了对应名称的类，findLoadedClass(String )方法实际上是findLoadedClass0方法的wrapped方法，做了检查类名的工       //作，而findLoadedClass0则是一个native方法，通过底层来查看jvm中的对象。\tClass c = findLoadedClass(name);\tif (c == null) &#123;//类还未加载\t    try &#123;\t\tif (parent != null) &#123;            //在类还未加载的情况下，我们首先应该将加载工作交由父classloader来处理。\t\t    c = parent.loadClass(name, false);\t\t&#125; else &#123;                    //返回一个由bootstrap class loader加载的类，如果不存在就返回null\t\t    c = findBootstrapClassOrNull(name);\t\t&#125;\t    &#125; catch (ClassNotFoundException e) &#123;                // ClassNotFoundException thrown if class not found                // from the non-null parent class loader            &#125;            if (c == null) &#123;\t        // If still not found, then invoke findClass in order\t        // to find the class.\t        c = findClass(name);//这里是我们的入手点，也就是指定我们自己的类加载实现\t    &#125;\t&#125;\tif (resolve) &#123;\t    resolveClass(c);//用来做类链接操作\t&#125;\treturn c;    &#125;\n从上面的方法也看出我们在实现自己的加载器的时候，不要覆盖locaClass方法，而是重写findClass()，这样能保证双亲委派模型，同时也实现了自己的方法\n为什么要使用双亲委托这种模型呢？\n节约系统资源： 因为这样可以避免重复加载，当父亲已经加载了该类的时候，就没有必要子ClassLoader再加载一次\n保证Java核心库的类型安全: 我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义的类型，这样会存在非常大的安全隐患，而双亲委托的方式，就可以避免这种情况，因为String已经在启动时就被引导类加载器（Bootstrcp ClassLoader）加载，所以用户自定义的ClassLoader永远也无法加载一个自己写的String，除非你改变JDK中ClassLoader搜索类的默认算法。\n\n自定义加载器既然JVM已经提供了默认的类加载器，为什么还要定义自已的类加载器呢？\n因为Java中提供的默认ClassLoader，只加载指定目录下的jar和class，如果我们想加载其它位置的类或jar时，比如：我要加载网络上的一个class文件，通过动态加载到内存之后，要调用这个类中的方法实现业务逻辑。在这样的情况下，默认的ClassLoader就不能满足我们的需求了，所以需要定义自己的ClassLoader\n定义自已的类加载器分为两步：\n继承java.lang.ClassLoader\n重写父类的findClass方法\n\n示例很简单的两个类，方法中打印出各自的类加载器\npublic class LoaderClass &#123;    public void loader()&#123;        System.out.println(&quot;LoaderClass:&quot;+this.getClass().getClassLoader());        LoaderClass1 class1 = new LoaderClass1();        class1.loader();    &#125;&#125;public class LoaderClass1 &#123;    public void loader() &#123;        System.out.println(this.getClass().getName() + &quot; loader:&quot;+this.getClass().getClassLoader());    &#125;&#125;\n\n自定义加载器\n\n重写findClass方法，从class文件加载\n通过defineClass从bytes构建class\n\npublic class MyClassLoader extends ClassLoader &#123;    protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123;        String root = &quot;d:/&quot;;        byte[] bytes = null;        try &#123;            //路径改到根目录下            String file = root + name.substring(name.lastIndexOf(&quot;.&quot;)+1) + &quot;.class&quot;;            InputStream ins = new FileInputStream(file);            ByteArrayOutputStream baos = new ByteArrayOutputStream();            int bufferSize = 1024;            byte[] buffer = new byte[bufferSize];            int length = 0;            while ((length = ins.read(buffer)) != -1) &#123;                baos.write(buffer, 0, length);            &#125;            bytes = baos.toByteArray();            ins.close();        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;        return defineClass(name, bytes, 0, bytes.length);    &#125;&#125;\n\n测试类\npublic class ClassLoaderTest &#123;    public static void main(String[]args) throws Exception &#123;        ClassLoaderTest test = new ClassLoaderTest();        System.out.println(test.getClass().getClassLoader());//输出sun.misc.Launcher$AppClassLoader        System.out.println(test.getClass().getClassLoader().getParent());//输出sun.misc.Launcher$ExtClassLoader        System.out.println(test.getClass().getClassLoader().getParent().getParent());//输出null        //=====测试重复加载，类路径中LoaderClass.class存在=================        //======虽然指定了classloader，但依然输出的是LoaderClass:sun.misc.Launcher$AppClassLoader        //==删除类路径下的LoaderClass.class,才会输出LoaderClass:com.jack.classloader.MyClassLoader        //并且loaderclass中创建的对象类加载器也是MyClassLoader        MyClassLoader classLoader = new MyClassLoader();        Class&lt;?&gt; loadClass = Class.forName(&quot;com.jack.classloader.LoaderClass&quot;, true, classLoader);        Method startMethod = loadClass.getMethod(&quot;loader&quot;);        startMethod.invoke(loadClass.newInstance());        //===当类加载器不一样时，两个class不相等        MyClassLoader classLoader1 = new MyClassLoader();        Class&lt;?&gt; loadClass1 = Class.forName(&quot;com.jack.classloader.LoaderClass&quot;, true, classLoader1);        System.out.println(loadClass.equals(loadClass1));//输出false    &#125;&#125;\n\n参考资料class加载时机及两种显示加载的区别\nJVM类加载机制—类加载的过程\n&lt;init&gt;和&lt;clinit&gt;\n类加载原理分析&amp;动态加载Jar&#x2F;Dex\njava类的主动使用&#x2F;被动使用\n","categories":["java"],"tags":["classloader"]},{"title":"自定义类加载器","url":"/blog/custom-class-loader.html","content":"1、为什么需要自定义类加载器\n在《类加载器》中讲的，默认类加载器只能加载固定路径下的class，如果有特定路径下的class，需要自定义\n安全性：系统自身需要一些jar，class，如果业务类代码中也有相同的class，破坏系统，类似双亲委托安全性\n\n可以看看tomcat自定义类加载器的原因，别的就大同小异了\na)、要保证部署在tomcat上的每个应用依赖的类库相互独立，不受影响。b)、由于tomcat是采用java语言编写的，它自身也有类库依赖，为了安全考虑，tomcat使用的类库要与部署的应用的类库相互独立。c)、有些类库tomcat与部署的应用可以共享，比如说servlet-api，使用maven编写web程序时，servlet-api的范围是provided，表示打包时不打包这个依赖，因为我们都知道服务器已经有这个依赖了。d)、部署的应用之间的类库可以共享。这听起来好像与第一点相互矛盾，但其实这很合理，类被类加载器加载到虚拟机后，会生成代表该类的class对象存放在永久代区域，这时候如果有大量的应用使用spring来管理，如果spring类库不能共享，那每个应用的spring类库都会被加载一次，将会是很大的资源浪费。\n\n2、自定义加载器这儿主要说下我司的自定义类加载器；更复杂点的可以看看tomcat的类加载机制\n为什么需要自定义类加载器？这可以参考章节1的答案\n主要在于应用与基础平台的隔离，相对应用:可以有更大技术选型自由度,不用考虑基础平台的jar包版本、相对平台：更可靠安全，不被应用class影响\n类加载器结构虽然JAVA使用了类加载的委派机制，但并没严格要求开发者必须遵守该机制，我们可以打破这种”双亲委派”机制\n目录结构\n\n\n目录\n说明\n\n\n\n&#x2F;servicesdir\n业务实现jar包\n\n\n&#x2F;thirddir\n业务依赖jar包\n\n\n&#x2F;platformdir\n平台依赖jar包\n\n\n类加载器\n1.PlatformClassLoader平台加载器\n1.1.加载&#x2F;platformdir下的jar包\n1.2.在加载时，采用了默认的“双亲委派”\n\n\n2.AppClassLoader应用加载器\n2.1.加载&#x2F;servicesdir,&#x2F;thirddir下的jar\n2.2.该类加载器一定程度上打破了默认的“双亲委派”\n2.2.0.loadClass方法中，如果本加载器没有load到对应的类，则会检查该类是否处于平台类加载器白名单中：\n2.2.1.如果处于白名单中，则委派PlatformClassLoader加载\n2.2.2.否则，通过super.loadClass(String,boolean)走默认的双亲委派\n\n\n\n\n\n此处白名单类：平台核心类，不能被同名业务类干扰\n预加载《类加载器》中说过，程序启动后，并不会加载所有类，在运行中实现到时，才会去加载。这儿就有性能损耗。\n按类加载规则，一个类只加载一次\n可以测试一下，加载需要的损耗\n/** * 类加载时间性能测试 * * 看一下类加载需要消耗的时间 * Created by Jack on 2018/10/8. */public class ClassLoaderTest1 &#123;    public static void main(String[] args) throws SQLException &#123;        long s = System.nanoTime();        LoaderClass loaderClass = new LoaderClass();        long e = System.nanoTime();        //第一次时间        System.out.println(e - s);        e = System.nanoTime();        //第二次实例，但已经加载过，不再需要加载        LoaderClass loaderClass1 = new LoaderClass();        long e1 = System.nanoTime();        //第二次时间        System.out.println(e1 - e);    &#125;&#125;//输出2409737396\n可以从输出看到性能损耗是不小的，这部分损耗可以通过预加载来消除\n随着程序运行时间越久，被触发的业务越多，那加载到的业务类越多。\n预加载类的逻辑ClassWarmUp\n\n1.在classloader中loadClass时，把className加入到LinkedBlockingDeque中\n2.为了性能，异步把deque中的class写入到文件中，需要起一个后台线程\n2.1 后台线程，从deque中取出class，写入到文件中\n\n\n3.下次从文件中预先加载class\n\n打包对于&#x2F;servicesdir 与 &#x2F;thirddir 都好处理，但对于platformdir是怎么打包的呢？毕竟在开发时，只是引入一个平台基础jar就行\n使用有了自定义类加载器，在应用主函数中，就不能直接new了，不然就会使用AppClassLoader\n所以需要使用反射机制\nClass&lt;?&gt; loadClass = platformClassLoader.loadClass(&quot;com.jack.Start&quot;);Method startMethod = loadClass.getMethod(&quot;startUp&quot;);startMethod.invoke(loadClass);\n这样，通过Start加载的类也会通过platformClassLoader去加载\n创建springcontext也一样,这儿还需使用到Thread.currentThread().getContextClassLoader()【下面有详解】\nClassLoader currentThreadLoader = Thread.currentThread().getContextClassLoader();Thread.currentThread().setContextClassLoader(appClassLoader);Class&lt;?&gt; contextClass = appClassLoader\t\t\t\t.loadClass(&quot;org.springframework.context.support.FileSystemXmlApplicationContext&quot;);Class&lt;?&gt;[] parameterTypes = new Class[] &#123; String[].class &#125;;Constructor&lt;?&gt; constructor = contextClass.getConstructor(parameterTypes);return constructor.newInstance(new Object[] &#123; xmlPaths.toArray(new String[0]) &#125;);// switch back the thread context classloaderThread.currentThread().setContextClassLoader(currentThreadLoader);\n\n3、反常“双亲委派”模型有优点，也有力不从心的地方\n\nJava 提供了很多服务提供者接口（Service Provider Interface，SPI），允许第三方为这些接口提供实现。常见的 SPI 有 JDBC、JCE、JNDI、JAXP 和 JBI 等。\n\n\n这些 SPI 的接口由 Java 核心库来提供，而这些 SPI 的实现代码则是作为 Java 应用所依赖的 jar 包被包含进类路径（CLASSPATH）里。SPI接口中的代码经常需要加载具体的实现类。那么问题来了，SPI的接口是Java核心库的一部分，是由启动类加载器(Bootstrap Classloader)来加载的；SPI的实现类是由系统类加载器(System ClassLoader)来加载的。引导类加载器是无法找到 SPI 的实现类的，因为依照双亲委派模型，BootstrapClassloader无法委派AppClassLoader来加载类。而线程上下文类加载器破坏了“双亲委派模型”，可以在执行线程中抛弃双亲委派加载链模式，使程序可以逆向使用类加载器。\n\n场景：\n当高层提供了统一的接口让低层去实现，同时又要在高层加载（或者实例化）低层的类时，就必须要通过线程上下文类加载器来帮助高层的ClassLoader找到并加载该类\n当使用本类托管类加载，然而加载本类的ClassLoader未知时，为了隔离不同的调用者，可以取调用者各自的线程上下文类加载器代为托管\n\n解决方案：从jdk1.2开始引入的，类Thread中的getContextClassLoader()与setContextClassLoader(ClassLoader c1)，分别用来获取和设置类加载器\n一般使用模式：获取-使用-还原\nClassLoader classLoader = Thread.currentThread().getContextClassLoader(); try&#123;        Thread.currentThread().setContextClassLoader(targetTccl);        excute(); &#125; finally &#123;     Thread.currentThread().setContextClassLoader(classLoader); &#125;\njdbc以jdbc看下场景1的情况\nClass.forName(&quot;com.mysql.jdbc.Driver&quot;)String url = &quot;jdbc:mysql://localhost:3306/testdb&quot;;    // 通过java库获取数据库连接Connection conn = java.sql.DriverManager.getConnection(url, &quot;name&quot;, &quot;password&quot;);\n\n\n1.Class.forName(“com.mysql.jdbc.Driver”); 在com.mysql.jdbc.Driver中\n\npublic class Driver extends NonRegisteringDriver implements java.sql.Driver &#123;\tstatic &#123;\t\ttry &#123;\t\t\tjava.sql.DriverManager.registerDriver(new Driver());\t\t&#125; catch (SQLException E) &#123;\t\t\tthrow new RuntimeException(&quot;Can&#x27;t register driver!&quot;);\t\t&#125;\t&#125; \tpublic Driver() throws SQLException &#123;\t\t// Required for Class.forName().newInstance()\t&#125;&#125;\n通过Class.forName()，主要就是执行初始化static代码块，也就是向DriverManager注册Driver\n此时：应用类、Driver是由AppClassLoader加载，但由于双亲委派java.sql.DriverManager是由BootstrapClassLoader加载\n\n2.java.sql.DriverManager.getConnection 获取连接\n\nprivate static Connection getConnection(\tString url, java.util.Properties info, ClassLoader callerCL) throws SQLException &#123;\tjava.util.Vector drivers = null;        \tsynchronized(DriverManager.class) &#123;\t \t  if(callerCL == null) &#123;\t      callerCL = Thread.currentThread().getContextClassLoader();\t   &#125;    \t&#125; \t \tif(url == null) &#123;\t    throw new SQLException(&quot;The url cannot be null&quot;, &quot;08001&quot;);\t&#125;    \tprintln(&quot;DriverManager.getConnection(\\&quot;&quot; + url + &quot;\\&quot;)&quot;);    \tif (!initialized) &#123;\t    initialize();\t&#125; \tsynchronized (DriverManager.class)&#123; \t    drivers = readDrivers;          &#125; \tSQLException reason = null;\tfor (int i = 0; i &lt; drivers.size(); i++) &#123;\t    DriverInfo di = (DriverInfo)drivers.elementAt(i);  \t    if ( getCallerClass(callerCL, di.driverClassName ) != di.driverClass ) &#123;\t\tprintln(&quot;    skipping: &quot; + di);\t\tcontinue;\t    &#125;\t    try &#123;\t\tprintln(&quot;    trying &quot; + di);\t\tConnection result = di.driver.connect(url, info);\t\tif (result != null) &#123;\t\t    // Success!\t\t    println(&quot;getConnection returning &quot; + di);\t\t    return (result);\t\t&#125;\t    &#125; catch (SQLException ex) &#123;\t\tif (reason == null) &#123;\t\t    reason = ex;\t\t&#125;\t    &#125;\t&#125; \tif (reason != null)    &#123;\t    println(&quot;getConnection failed: &quot; + reason);\t    throw reason;\t&#125;    \tprintln(&quot;getConnection: no suitable driver found for &quot;+ url);\tthrow new SQLException(&quot;No suitable driver found for &quot;+ url, &quot;08001&quot;);    &#125;private static Class getCallerClass(ClassLoader callerClassLoader, \t\t\t\t\tString driverClassName) &#123;\tClass callerC = null; \ttry &#123;\t    callerC = Class.forName(driverClassName, true, callerClassLoader);\t&#125;\tcatch (Exception ex) &#123;\t    callerC = null;           // being very careful \t&#125; \treturn callerC;    &#125;\n\n这其中有两行代码：\ncallerCL = Thread.currentThread().getContextClassLoader();callerC = Class.forName(driverClassName, true, callerClassLoader);\n这儿是取线程上下文中的classloader，也就是AppClassLoader；如果不取此classloader，那么Class.forName(driverClassName)就是使用DriverManager的BootstrapClassLoader加载，那必然是加载不到，这也就是父层类加载器加载不了低层类。\n还有个问题，为什么在应用程序中已经加载过Driver，到了getConnection()又要再加载，还得通过Thread.currentThread().getContextClassLoader()？\n其实在getConnection()中，只是对比class是否是同一个，像tomcat那样，各个应用都有自己的mysql-driver的jar包，就只能通过classloader来区分，因为class是不是相同需要classname+classloader组合鉴别\nspring对于场景2的问题\n\n如果有 10 个 Web 应用程序都用到了spring的话，可以把Spring的jar包放到 common 或 shared 目录下让这些程序共享。Spring 的作用是管理每个web应用程序的bean，getBean时自然要能访问到应用程序的类，而用户的程序显然是放在 &#x2F;WebApp&#x2F;WEB-INF 目录中的（由 WebAppClassLoader 加载），那么在 CommonClassLoader 或 SharedClassLoader 中的 Spring 容器如何去加载并不在其加载范围的用户程序（&#x2F;WebApp&#x2F;WEB-INF&#x2F;）中的Class呢？\n\n\n答案呼之欲出：spring根本不会去管自己被放在哪里，它统统使用线程上下文加载器来加载类，而线程上下文加载器默认设置为了WebAppClassLoader，也就是说哪个WebApp应用调用了spring，spring就去取该应用自己的WebAppClassLoader来加载bean\n\norg.springframework.web.context.ContextLoader类\npublic WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123;\t\tif (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123;\t\t\tthrow new IllegalStateException(\t\t\t\t\t&quot;Cannot initialize context because there is already a root application context present - &quot; +\t\t\t\t\t&quot;check whether you have multiple ContextLoader* definitions in your web.xml!&quot;);\t\t&#125;\t\tLog logger = LogFactory.getLog(ContextLoader.class);\t\tservletContext.log(&quot;Initializing Spring root WebApplicationContext&quot;);\t\tif (logger.isInfoEnabled()) &#123;\t\t\tlogger.info(&quot;Root WebApplicationContext: initialization started&quot;);\t\t&#125;\t\tlong startTime = System.currentTimeMillis();\t\ttry &#123;\t\t\t// Determine parent for root web application context, if any.\t\t\tApplicationContext parent = loadParentContext(servletContext);\t\t\t// Store context in local instance variable, to guarantee that\t\t\t// it is available on ServletContext shutdown.\t\t\tthis.context = createWebApplicationContext(servletContext, parent);\t\t\tservletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context);\t\t\tClassLoader ccl = Thread.currentThread().getContextClassLoader();\t\t\tif (ccl == ContextLoader.class.getClassLoader()) &#123;\t\t\t\tcurrentContext = this.context;\t\t\t&#125;\t\t\telse if (ccl != null) &#123;\t\t\t\tcurrentContextPerThread.put(ccl, this.context);\t\t\t&#125;\t\t\tif (logger.isDebugEnabled()) &#123;\t\t\t\tlogger.debug(&quot;Published root WebApplicationContext as ServletContext attribute with name [&quot; +\t\t\t\t\t\tWebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE + &quot;]&quot;);\t\t\t&#125;\t\t\tif (logger.isInfoEnabled()) &#123;\t\t\t\tlong elapsedTime = System.currentTimeMillis() - startTime;\t\t\t\tlogger.info(&quot;Root WebApplicationContext: initialization completed in &quot; + elapsedTime + &quot; ms&quot;);\t\t\t&#125;\t\t\treturn this.context;\t\t&#125;\t\tcatch (RuntimeException ex) &#123;\t\t\tlogger.error(&quot;Context initialization failed&quot;, ex);\t\t\tservletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex);\t\t\tthrow ex;\t\t&#125;\t\tcatch (Error err) &#123;\t\t\tlogger.error(&quot;Context initialization failed&quot;, err);\t\t\tservletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, err);\t\t\tthrow err;\t\t&#125;\t&#125;\n关键代码：\n// 获取线程上下文类加载器，默认为WebAppClassLoaderClassLoader ccl = Thread.currentThread().getContextClassLoader();// 如果spring的jar包放在每个webapp自己的目录中// 此时线程上下文类加载器会与本类的类加载器（加载spring的）相同，都是WebAppClassLoaderif (ccl == ContextLoader.class.getClassLoader()) &#123;    currentContext = this.context;&#125;else if (ccl != null) &#123;    // 如果不同，也就是上面说的那个问题的情况，那么用一个map把刚才创建的WebApplicationContext及对应的WebAppClassLoader存下来    // 一个webapp对应一个记录，后续调用时直接根据WebAppClassLoader来取出    currentContextPerThread.put(ccl, this.context);&#125;\n这样做的目的在于当通过ConetxtLoader的静态方法获取context的时候，能保证获取的是当前web application的context.实际上就是对于tomcat下面的任何一个线程，我们都能很方便的找出这个线程对应的webapplicationContext.于是在一些不能方便获取servletContext的场合，我们可以通过当前线程获取webapplicationContext.\npublic static WebApplicationContext getCurrentWebApplicationContext() &#123;\t\tClassLoader ccl = Thread.currentThread().getContextClassLoader();\t\tif (ccl != null) &#123;\t\t\tWebApplicationContext ccpt = currentContextPerThread.get(ccl);\t\t\tif (ccpt != null) &#123;\t\t\t\treturn ccpt;\t\t\t&#125;\t\t&#125;\t\treturn currentContext;\t&#125;\n\n总结简而言之就是ContextClassLoader默认存放了AppClassLoader的引用，由于它是在运行时被放在了线程中，所以不管当前程序处于何处（BootstrapClassLoader或是ExtClassLoader等），在任何需要的时候都可以用Thread.currentThread().getContextClassLoader()取出应用程序类加载器来完成需要的操作\n4、参考资料以jdbc为例搞清contextClassLoader\n","categories":["java"],"tags":["classloader"]},{"title":"莫道君行早","url":"/blog/mo-daojun-goes-early.html","content":"前一段时间，脑子短路了，出现点思维障碍，突然特别想推广一下公众号，增长一下粉丝数量。\n所以呢，就去各大技术网站，同步一些文章，想引流到公众号，现在写作技术网站真不少，也可能因为各个能写的技术人都要打造自己的个人品牌，从这些大型平台上搬迁到个人网站了，造成了一些流量流失，所以现在这些平台也在大力推广，吸引作者回归平台，比如搞更文活动，有赏写文，用户体检也上去了，可以很方便地从别的平台把文章搬迁过来\n时间巧得很，7月底去看了各大平台，发现掘金在8月搞更文活动，连续更文多少天，就有相应的奖品。虽然奖品不是很值钱，但我借此机会，把文章搬过去，即能引些流量，又能得到奖品，两全其美。要得到最大奖项的要求是连续31天，心里想，这应该很难有多少人做到，每天写一篇，真是神人，除非像我这种人，已经有一大堆文章，只是手动搬迁一下\n虽然就每天机械地选篇文章复制过去，但坚持了一周，还是有些烦，一是每天都有这么一件事在心里挂着，二是越来越发现意义不大，不应该把时间浪费在此，哪怕只有2分钟。 同时也发现能挑选的系列文章不多，好文章也不多，几年的积累，战不过一个月的考验，悲哉\n一整月，终于过去了，平台发布了中奖名单，我根据人数，做了个统计\n\n横轴是更文天数，纵轴是人数\n个人感觉应该是金字塔结构，结果是头尾两波人数量差不多，中间人数反而比较少，这有些违背常识，难道跟我类似的人很多？\n连续更文31天的人，如此之多，单单是为了这些奖品，我是不太相信，更多的应该是内驱力的驱动。莫道君行早，更有早行人。这个世界勤奋的人远超出想象，这估计也是为什么各行各业都充斥着内卷的气息\n这也说明在当下时代，相对过去想要成功，不仅需要付出更多的勤奋，还需要有智慧的勤奋，也就是战术勤奋，战略更不能不努力。需要更加剖析自我，找出个人特色，有的放矢。\n努力决定下限，运气决定上限；除了单单个人努力，在这样一个时代，还需要其他因素，而且因他因素的占比会越来越重，也越来越多元。\n在此环境下，我们首先需要提高自己的底层认知水平\n最近听好几位大佬提到一本书《跃迁》，摘抄几句：\n\n获得百倍收益的关键，并不是百倍努力。每个时代的高手都在利用社会和科技的底层逻辑撬动自己，实现跨越式的成长。\n\n\n长江商学院的校训是“取势、明道、优术”，个人方法论被放到了第三位，更重要的是把握趋势（取势）、理解系统运行之道（明道）\n\n\n没有一个人是仅凭努力、天赋、机遇而获得巨大成功的，跃迁式成功都是利用了更底层规律，激发了个体的跨越式成长。\n\n\n暂时还在消化中，有些认识值得多看几遍，希望你也有所收获\n","tags":["认知"]},{"title":"解决技术债的5个步骤","url":"/blog/5-steps-to-solve-technical-debt.html","content":"《管好技术债》- 第13章 与技术债务共存\n解决技术债务的通用路径\n1、感知\n确保所有相关人员都对什么是技术债务以及它如何影响项目有共同的认识\n2、评估信息\n了解项目的状态，你目前面临的债务，什么原因，以及它的后果是什么\n3、建立一个登记表\n建立某种形式的技术债务清单\n4、决定要解决的问题\n当你计划发布时，查看技术债务登记表，力求该发布可以减少技术债务并且可实际解决技术债务问题\n5、采取行动\n把技术债务的识别和管理纳入所有软件开发和业务治理实践中\n重复这个过程，因为不太可能一下子完全摆脱技术债务。\n如果你想要明确地管理组织中的技术债务，不要将债务处理作为一个单独的过程，将其集成到流程中，以补充当前的实践。\n循序渐进，而不是大幅度地修改。第一步，选择能带来最直接利益的修改。\n感知给你的技术债务起个名字。确保所有参与项目或接近项目的人员对技术债务有共同的理解：什么是技术债务，什么不是技术债务，以及它如何影响项目。\n提高感知能力的一些方法：\n1、为项目提供一个清晰、简单的技术债务定义。\n2、向团队讲解什么是技术债务及其产生的原因\n3、直接在项目环境中给大家（管理人员、分析师和产品经理）讲解关于技术债务的知识\n4、在问题跟踪系统中创建技术债务类别，使技术债务与缺陷或新功能有所区别\n5、将已知的技术债务作为长期技术路线图的一部分\n6、将感知活动扩展到作为项目一部分的任何外部供应商\n使用能够帮助团队沟通的方法，帮助每个人在概念上都达成一致。\n评估信息在尝试补救技术责备之前，客观评估项目的状态。根据你在技术债务时间线上的位置，考虑以下行动：\n1、确定评估技术债务的目标和标准\n2、通过分析代码、架构和生产基础设施来监控你的产品，以了解导致团队经历种种症状的技术债务\n3、纳入轻量检查 ，以持续监控技术债务\n建立技术债务登记表1、将你的问题跟踪工具中的“技术债务”分类细化为技术债务描述，并将其指向所涉及的特定软件工件：代码、架构或生产基础设施\n2、至少包括最常见的两类技术债务：\n2.1、简单的、本地化的、代码级的债务\n2.2、广泛的、结构化的、架构债务，并指向所涉及的软件工件：代码、架构或生产基础设施\n3、分析包含非故意的技术债务的代码和架构，并在技术债务登记表中描述结果\n4、在你的迭代审查和回顾会中包括对技术债务的讨论，并对其加以特别的重视。将它作为一个待办事项参与优先排序\n在收集信息以获得一些具体示例和评估用的数据时，可能需要做一些清点工作。\n决定修复什么如果你面对的是一个庞大的、有点繁杂的技术债务登记表，则需要确定修复什么以及什么时候修复。\n应该根据你对情况的评估来做出决定，包括下一步软件产品的发展方向。要做出决定，需要收集有关补救策略、成本和权衡的其他信息。\n审查技术债务登记表中的各项，确保其中包含适当的项目，并确定处理它们的优先顺序，从而决定下一步交付什么：\n1、不仅要估计偿还技术债务的成本，还要估计不偿还技术债务项的成本：延迟偿还会在多大程度上减缓当前的进度？如果你无法提供实际成本，请使用“T恤尺码”策略\n2、分配时间以偿还技术债务\n3、制订一个与上下文相关的偿还计划。\n采取行动根据你的特定情况，并结合项目上下文来综合实施技术债务管理方法。这样做能更加积极主动地了解技术债务产生的原因，并控制新债务的引入 。\n采取一些行动来识别和管理软件开发和业务治理实践中的技术债务\n1、通过将一些技术债务项添加到迭代待办事项列表中，以保持技术债务处于较低水平，从而减少每个开发周期的技术债务。\n2、将技术债务纳入有关延迟功能交付和降低作为短期或长期投资，并计划对其进行管理。\n3、收集与技术债务相关的工作或成本的关键指标，以协助未来的决策。\n从最简单的情况开始并迭代这些活动，在每次迭代中逐步改进流程。\n","tags":["读书","技术债"]},{"title":"自我管理","url":"/blog/self-management.html","content":"最近在温习之前管理课程时，在“自我发展”这一章节看到一篇文章彼得·德鲁克的《自我管理》，作者：彼得·德鲁克(Peter F．Drucker，1909年－2005年)被誉为“现代管理学之父”与“管理大师中的大师”。德鲁克以他建立于广泛实验基础之上的30余部著作，奠定了其现代管理学开创者的地位。他在《哈佛商业评论》发表了近30篇文章，本文《自我管理》是《哈佛商业评论》创刊以来重印次数最多的文章之一。\n特别不错，专门做了个思维导图，应该可以指引每一位知识工作者\n\n\n\n自我管理\n为什么需要自我管理\n公司并不怎么管员工的职业发展\n知识工作者必须成为自己的首席执行官\n我们必须学会自我发展，必须知道把自己放在什么样的位置上，才能做出最大的贡献，而且还必须在长达50年的职业生涯中保持着高度的警觉和投入\n从一切听从别人吩咐的体力劳动者到不得不自我管理的知识工作者\n\n\n我的长处是什么\n回馈分析法\n每当做出重要决定或采取重要行动时，你都可以事先记录下自己对结果的预期。9到12个月后，再将采取实际结果与自己预期比较\n\n\n根据回馈分析启示，采取行动\n专注于自己的长处，把自己放到那些能发挥长处的地方\n加强你的长处\n发现任何由于恃才傲物而造成的偏见和无知，并且加以克服\n要让自己的长处得到充分发挥，就应该努力学习新技能、汲取新知识\n\n\n纠正不良习惯\n不良习惯–那些会影响工作成效和工作表现的事情\n\n\n礼貌是一个组织的润滑剂\n\n\n\n\n我的工作方式是怎样的\n很少有人知道自己平时是怎么把事情做成的\n对于知识工作者来说，这个问题比“我的长处是什么”更加重要\n读者型，听者型？\n\n\n我如何学习\n学习方式\n邱吉尔靠写学习\n\n\n我能与别人合作？还是单干\n在怎么关系下与他人共事\n当部属\n当教练\n当导师\n\n\n如何才能取得成果\n决策者\n顾问\n\n\n在压力下的表现，还是适应按部就班、可预测工作环境\n大公司，还是小公司\n不要试图改变自我，因为这样你不大可能成功，应该努力改进工作方式，另外不要从事干不了或干不好的工作\n\n\n我的价值观是什么\n镜子测试\n每天早晨在镜子里想看到一个什么样的人？\n\n\n一个组织的价值体系不为自己所接受或自己价值观不相容，人们备感沮丧，工作效力低下\n价值观是并且应该是最终的试金石\n\n\n我属于何处\n知道了“我的长处是什么”、“我的工作方式是怎样的”、“我的价值观是什么”就应该决定自己该向何处投入精力\n成功的事业不是预先规划的，而是在人们知道自己的长处、工作方式和价值观后，准备把握机遇时水到渠成的\n知道自己属于何处，可使一个勤奋、有能力但原本表现平平的普通人，变成出类拔萃的工作者\n\n\n我该做出什么贡献\n考虑三因素\n当前形势要求是佬\n鉴于我的长处、工作方式及价值观，怎样才能做出最大贡献\n必须取得什么结果才产生重要影响\n\n\n我在哪些方面能取得将在今后一年半内见效的结果？如何取得这样的结果？\n结果应该比较难实现，有“张力”，但也就应该是能力所及\n这些结果富有意义\n结果应该明显可见，能够衡量\n\n\n\n\n对人际关负责\n接受别人是和你一样的个体这个事实\n“管理”上司秘诀\n老板不是组织结构图上的一个头衔，也不是一个“职能”\n他们是有个性的人，有权以自己最得心应手的方式来工作\n有责任观察他们，了解他们的工作方式，并做出自我调整，适应老板最有效的工作方式\n\n\n工作方式，人各有别\n提高效力第一秘诀是了解跟你合作和你要依赖的人，以利用他们的长处、工作方式和价值观\n工作关系应当既以工作为基础，也以人为基础\n\n\n\n\n沟通责任\n与个性冲突有关：不知道别人在做什么，在采取什么工作方式\n不去问明情况，是历史使然\n怕别人把自己看成是一个冒昧、愚蠢、爱打听的人\n谢谢你来问我，但是，你为什么不早点来问我？\n组织不再建立在强权基础上，而是建立在信任基础上\n人与人相互信任，不一定意味他们彼此喜欢对方，而是意味彼此了解\n\n\n\n\n管理后半生\n发展第二职业原因\n厌倦\n遭遇严重挫折\n\n\n发展第二职业方式\n完全投身新工作\n发展一个平行职业\n社会创业\n\n\n先决条件：进入后半生之前就开始行动\n在一个崇尚成功的社会里，拥有各种选择变得越来越重要\n\n\n\n\n\n总结知识工作者必须在思想和行为上成为自己的首席执行官，在《领导梯队》中也看到同样的话，每个人都是自己的领导者，在《软技能-代码之外的生存技能》中作者也指出要把软件开发事业当成一门生意，要像企业一样思考，每个人都是CEO，领导自己，成就自己，那就得早日管理自己\n","tags":["管理"]},{"title":"计数器算法","url":"/blog/counter-algorithm.html","content":"《微服务-熔断机制》中提到了计数器，这篇详细学习一下计数器算法\n之前的有次面试，碰到了计数器的的题目\nQ：线上服务，设计一个拦截器，一个IP如果短时间内请求次数过多，就屏蔽\nA：使用map，key为ip，值为次数与时间\nQ：请求相当大，会直接冲垮内存,怎么办？\nA：使用redis，像redis cluster，绝对可以满足\nQ: 写下伪代码\nA：bbbbbbb\n其实计数器在互联网开发中很常见，当时刚转互联网比较无知，面试得很烂。\n计数器法计数器法是限流算法里最简单也是最容易实现的一种算法。比如我们规定，对于A接口来说，我们1分钟的访问次数不能超过100个。那么我们可以这么做：在一开 始的时候，我们可以设置一个计数器counter，每当一个请求过来的时候，counter就加1，如果counter的值大于100并且该请求与第一个 请求的间隔时间还在1分钟之内，那么说明请求数过多；如果该请求与第一个请求的间隔时间大于1分钟，且counter的值还在限流范围内，那么就重置 counter，具体算法的示意图如下：\n\npublic class Counter &#123;    public long timeStamp = getNowTime();    public int reqCount = 0;    public final int limit = 100; // 时间窗口内最大请求数    public final long interval = 1000; // 时间窗口ms    public boolean grant() &#123;        long now = getNowTime();        if (now &lt; timeStamp + interval) &#123;            // 在时间窗口内            reqCount++;            // 判断当前时间窗口内是否超过最大请求控制数            return reqCount &lt;= limit;        &#125;        else &#123;            timeStamp = now;            // 超时后重置            reqCount = 1;            return true;        &#125;    &#125;&#125;\n以上是示意代码，先忽视其中的并发问题，最大的问题是临界问题\n\n从上图中我们可以看到，假设有一个恶意用户，他在0:59时，瞬间发送了100个请求，并且1:00又瞬间发送了100个请求，那么其实这个用户在 1秒里面，瞬间发送了200个请求。我们刚才规定的是1分钟最多100个请求，也就是每秒钟最多1.7个请求，用户通过在时间窗口的重置节点处突发请求， 可以瞬间超过我们的速率限制。用户有可能通过算法的这个漏洞，瞬间压垮我们的应用。\n滑动窗口滑动窗口，又称rolling window\n\n在上图中，整个红色的矩形框表示一个时间窗口，在我们的例子中，一个时间窗口就是一分钟。然后我们将时间窗口进行划分，比如图中，我们就将滑动窗口 划成了6格，所以每格代表的是10秒钟。每过10秒钟，我们的时间窗口就会往右滑动一格。每一个格子都有自己独立的计数器counter，比如当一个请求 在0:35秒的时候到达，那么0:30~0:39对应的counter就会加1。\n那么滑动窗口怎么解决刚才的临界问题的呢？我们可以看上图，0:59到达的100个请求会落在灰色的格子中，而1:00到达的请求会落在橘黄色的格 子中。当时间到达1:00时，我们的窗口会往右移动一格，那么此时时间窗口内的总请求数量一共是200个，超过了限定的100个，所以此时能够检测出来触 发了限流。\n我再来回顾一下刚才的计数器算法，我们可以发现，计数器算法其实就是滑动窗口算法。只是它没有对时间窗口做进一步地划分，所以只有1格。\n由此可见，当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。\n实现一根据上面滑动窗口的定义，实现很简单了\n\n需要一个map,当然是并发安全的，key为时间\n统计窗口内的请求总数\n\n这儿有个以这种方式实现的https://github.com/zhuxingsheng/yammer-metrics/blob/master/metrics-core/src/main/java/com/codahale/metrics/SlidingTimeWindowReservoir.java\n摘点核心的片段：\n//一个并发安全map,skip list有序this.measurements = new ConcurrentSkipListMap&lt;Long, Long&gt;();\n\n/** * 获取map的key,以时间纳秒值为key * @return */private long getTick() &#123;    for (; ; ) &#123;        final long oldTick = lastTick.get();        //每纳秒处理的请求很多，减少compareAndSet的失败次数，这儿*COLLISION_BUFFER        final long tick = clock.getTick() * COLLISION_BUFFER;        // ensure the tick is strictly incrementing even if there are duplicate ticks        final long newTick = tick &gt; oldTick ? tick : oldTick + 1;        if (lastTick.compareAndSet(oldTick, newTick)) &#123;            return newTick;        &#125;    &#125;&#125;\n\n\nprivate void trim() &#123;        //清除window之前的计数        measurements.headMap(getTick() - window).clear();    &#125;\n\n缺点实现简单，但有个问题，map的key是在不停的增加，删除，给GC带来了压力\n实现二考虑key的复用，使用环形结构\n\n通过取模来达到这个效果\n初始化：\nprivate int window; //计算窗口//整个循环数组窗口private int ringWindow=window+30; requestCounter = new AtomicInteger[ringWindow];failedCounter = new AtomicInteger[ringWindow];for (int i = 0; i &lt; ringWindow; i++) &#123;\trequestCounter[i] = new AtomicInteger(0);\tfailedCounter[i] = new AtomicInteger(0);&#125;initCounterTimeInSecond =TimeUnit.NANOSECONDS.toSeconds(System.nanoTime());\n\n计算窗口内的次数\nprivate long countTotal(AtomicInteger[] caculateCounter)&#123;\t\tint currentIndex = getIndex();\t\t\t\tlong sum = 0;\t\t\t\tfor (int i = 0; i &lt; window; i++) &#123;\t\t\t//这儿并不是直接计算window中的所有counter，\t\t\t//而是从currentIndex向前倒取window个\t\t\tint index = ((currentIndex + ringWindow) -i) \t\t\t% this.ringWindow;\t\t\tsum += caculateCounter[index].get();\t\t&#125;\t\treturn sum;\t&#125;\n\n为什么需要ringWindow，直接window就可以？这儿有个奇技淫巧。\nCLEAN_UP_BUFFER=10;public void cleanupFutureCounter() &#123;\t\tint currentIndex = getIndex();\t\t\t\tfor (int i = 1 ; i &lt;= CLEAN_UP_BUFFER; i++) &#123;\t\t\tint index = (currentIndex + i) % this.ringWindow;\t\t\trequestCounter[index].set(0);\t\t\tfailedCounter[index].set(0);\t\t&#125;\t&#125;\n这儿会有个定时任务，每5秒会去清空未来10秒的数据\n因为在一环数组全部填充完成后，下一轮开始时，需要清空，哪个地方是起点，无法区分，所以ringwindow预留点位置用来清空\n实现三还有一些是加锁，当然会是轻量的CAS；每一个轮回完成后，都需要标记开始位置，并清空环。\n漏桶算法漏桶(Leaky Bucket)算法思路很简单,水(请求)先进入到漏桶里,漏桶以一定的速度出水(接口有响应速率),当水流入速度过大会直接溢出(访问频率超过接口响应速率),然后就拒绝请求,可以看出漏桶算法能强行限制数据的传输速率.示意图如下:\n\n我们将算法中的水换成实际应用中的请求，我们可以看到漏桶算法天生就限制了请求的速度。当使用了漏桶算法，我们可以保证接口会以一个常速速率来处理请求。所以漏桶算法天生不会出现临界问题\npublic class LeakyDemo &#123;public long timeStamp = getNowTime();public int capacity; // 桶的容量public int rate; // 水漏出的速度public int water; // 当前水量(当前累积请求数)public boolean grant() &#123;    long now = getNowTime();    water = max(0, water - (now - timeStamp) * rate); // 先执行漏水，计算剩余水量    timeStamp = now;    if ((water + 1) &lt; capacity) &#123;    // 尝试加水,并且水还未满    water += 1;    return true;    &#125;    else &#123;    // 水满，拒绝加水    return false;    &#125;    &#125;&#125;\n\n令牌桶算法（Token Bucket）令牌桶算法(Token Bucket)和 Leaky Bucket 效果一样但方向相反的算法,更加容易理解.随着时间流逝,系统会按恒定1&#x2F;QPS时间间隔(如果QPS&#x3D;100,则间隔是10ms)往桶里加入Token(想象和漏洞漏水相反,有个水龙头在不断的加水),如果桶已经满了就不再加了.新请求来临时,会各自拿走一个Token,如果没有Token可拿了就阻塞或者拒绝服务\n\n令牌桶的另外一个好处是可以方便的改变速度. 一旦需要提高速率,则按需提高放入桶中的令牌的速率. 一般会定时(比如100毫秒)往桶中增加一定数量的令牌, 有些变种算法则实时的计算应该增加的令牌的数量.\npublic class TokenBucketDemo &#123;public long timeStamp = getNowTime();public int capacity; // 桶的容量public int rate; // 令牌放入速度public int tokens; // 当前令牌数量public boolean grant() &#123;    long now = getNowTime();    // 先添加令牌    tokens = min(capacity, tokens + (now - timeStamp) * rate);    timeStamp = now;    if (tokens &lt; 1) &#123;    // 若不到1个令牌,则拒绝    return false;    &#125;    else &#123;    // 还有令牌，领取令牌    tokens -= 1;    return true;    &#125;    &#125;&#125;\n\n临界问题我 们再来考虑一下临界问题的场景。在0:59秒的时候，由于桶内积满了100个token，所以这100个请求可以瞬间通过。但是由于token是以较低的 速率填充的，所以在1:00的时候，桶内的token数量不可能达到100个，那么此时不可能再有100个请求通过。所以令牌桶算法可以很好地解决临界问 题。\n下图比较了计数器（左）和令牌桶算法（右）在临界点的速率变化。我们可以看到虽然令牌桶算法允许突发速率，但是下一个突发速率必须要等桶内有足够的 token后才能发生：\n\nGuava RateLimiter在guava中，有现成的实现\nRateLimiter使用的是一种叫令牌桶的流控算法，RateLimiter会按照一定的频率往桶里扔令牌，线程拿到令牌才能执行，比如你希望自己的应用程序QPS不要超过1000，那么RateLimiter设置1000的速率后，就会每秒往桶里扔1000个令牌。\n有两种方式，SmoothBursty和SmoothWarmingUp\ncreate(double permitsPerSecond)根据指定的稳定吞吐率创建RateLimiter这里的吞吐率是指每秒多少许可数（通常是指QPS，每秒多少查询）create(double permitsPerSecond, long warmupPeriod, TimeUnit unit)根据指定的稳定吞吐率和预热期来创建RateLimiter这里的吞吐率是指每秒多少许可数（通常是指QPS，每秒多少个请求量），在这段预热时间内，RateLimiter每秒分配的许可数会平稳地增长直到预热期结束时达到其最大速率。（只要存在足够请求数来使其饱和）\n\nSmoothBursty通过平均速率和最后一次新增令牌的时间计算出下次新增令牌的时间的，另外需要一个桶暂存一段时间内没有使用的令牌（即可以突发的令牌数）。另外RateLimiter还提供了tryAcquire方法来进行无阻塞或可超时的令牌消费。\n因为SmoothBursty允许一定程度的突发，会有人担心如果允许这种突发，假设突然间来了很大的流量，那么系统很可能扛不住这种突发。因此需要SmoothWarmingUp一种平滑速率的限流工具，从而系统冷启动后慢慢的趋于平均固定速率（即刚开始速率小一些，然后慢慢趋于我们设置的固定速率）\npublic static void testSmoothWarmingUp()&#123;        //每秒5个，1500ms后达到正常速率        RateLimiter rateLimiter = RateLimiter.create(5,1500, TimeUnit.MILLISECONDS);        List&lt;Runnable&gt; tasks = new ArrayList&lt;Runnable&gt;();        for (int i = 0; i &lt; 10; i++) &#123;            tasks.add(new Request(i));        &#125;        ExecutorService executorService = Executors.newCachedThreadPool();        for(Runnable task:tasks) &#123;            System.out.println(&quot;等待时间：&quot; + rateLimiter.acquire());            executorService.execute(task);        &#125;        executorService.shutdown();    &#125;\n\n运行结果:\n等待时间：0.00 handle request 1528693920502等待时间：0.543111 handle request 1528693921052等待时间：0.4335312 handle request 1528693921486等待时间：0.3326793 handle request 1528693921819等待时间：0.2297854 handle request 1528693922049等待时间：0.1996685 handle request 1528693922249等待时间：0.1998456 handle request 1528693922449等待时间：0.1997577 handle request 1528693922649等待时间：0.199818 handle request 1528693922849等待时间：0.1997329 handle request 1528693923049\n\n可以看出前面几个等待时间长，速度慢；1500ms后，速率达到正常的每秒5的速度\n其实这算是一种漏桶算法的变异，在令牌桶中控制一个移除令牌的速度就是个漏桶了。\n总结计数器 VS 滑动窗口计数器算法是最简单的算法，可以看成是滑动窗口的低精度实现。滑动窗口由于需要存储多份的计数器（每一个格子存一份），所以滑动窗口在实现上需要更多的存储空间。也就是说，如果滑动窗口的精度越高，需要的存储空间就越大。\n漏桶算法 VS 令牌桶算法漏桶算法和令牌桶算法最明显的区别是令牌桶算法允许流量一定程度的突发。因为默认的令牌桶算法，取走token是不需要耗费时间的，也就是说，假设桶内有100个token时，那么可以瞬间允许100个请求通过。\n令牌桶算法由于实现简单，且允许某些流量的突发，对用户友好，所以被业界采用地较多。当然我们需要具体情况具体分析，只有最合适的算法，没有最优的算法\n参考接口限流算法总结\n","tags":["微服务"]},{"title":"谁不服打到他服","url":"/blog/who-doesnt-agree-hit-him.html","content":"对于新晋升管理者常见的困惑中，“不自信”也是普遍存在的一种现象。\n如何克服这种“不自信”，大家服不服我？套用江湖人的话，“谁不服，那就打到他服”。\n当然，如果在普升管理者之前，你就是团队中最强的技术骨干，其他成员的战斗指数以及综合实力都在你之下，那对这个困惑估计体会不深。\n但在普升管理者之前，团队内有跟你级别一样的，能力差不多甚至专业能力在你之上的成员，那将经历一个痛苦的适应过程。\n不自信其实归结起来，新普升管理者不自信的来源，主要有三点：\n第一，管理经验不足和能力欠缺\n很多对管理事务不知道该怎么着手，在摸索前行中磕磕绊绊，于是怀疑自己没有能力做好管理。\n这是每位管理者的必经阶段，其实也是学习所有新事物的必经阶段。就像刚接触技术时一样，也经常会碰到一些不知所措的问题。\n只不过，技术问题往往有比较标准的答案，通过查资料就能解决大部分问题；而管理问题刚很少有标准答案，很多经验和技巧是在不断实践的过程中积累起来的，掌握起来不像技术问题那样可以查查资料就能快速解决。这也是管理有挑战的地方。\n第二，和团队成员对立比较\n由于资历或能力不是团队里最突出的，担心团队里资历老或能力强的团队成员会不服自己，尤其当这些人提出不同意见的时候，常常会引起新晋管理者的挫败和颓丧。\n要解决这个问题，关键是转变认知。\n你现在是团队的负责人，需要把自己从和任何团队成员的比较和竞争中抽离，把目光投向远方，去看看你将带一个什么样的团队，以及在这个过程中，你能为公司、团队和团队成员带来什么样的成绩和成长。\n当你不把团队成员放在你的对立面的时候，你和他们就没有任何竞争关系，因为所有的比较和竞争都是在同一个层次上才会发生，就好像你可能会和你的同学、同事比财富，但不会和马云去比较一样。\n你要做的，不是和团队成员竞争、比较，也不是比团队每个人都强，而是要考虑如何让大家把自己的才智发挥出来，去达成一个共同的团队目标。总之，你要做的不是管束和控制大家，而是引导和支持大家。\n你要做的，就是用大家的力量，去做出更好的成果，而不是单单因为你的职位让大家服气。\n因此，当团队中有老资格和高能力员工的时候，转换一下思维，得到两个结论：\n1、你真的是非常优秀，以至于你能被公司赏识来负责这样一个团队\n2、因为这些老资格和高能力员工的存在，你有机会做出更好的业绩\n第三，背负着沉重的包袱\n因为担心管理工作做不好会辜负上级的期望，所以带着很大的压力去工作。\n前两类自信来源于自我能力和角色认知的提升，那么第三类自信的增强来源于外部反馈，尤其是上级。\n事实上，自信心的建立的确需要外部的正向反馈，这些正向反馈可以极大地提升你的自我认可度。\n如何才能得到外部持续的正向反馈？首先要把反馈通道建立起来，尤其是和上级的沟通通道。可以和上级约好一个例行的沟通机制，定期汇报团队工作，并就已经完成的一些重要工作征求上级的看法和评价。这其中，改进建议固然很宝贵，但是你还需要寻求一些肯定性的反馈。\n\n怎么服人虽然文章开头戏称：谁不服，就打到他服。这显然是受武侠剧的深度影响。看看武侠剧里面，有哪一帮派的帮主或掌门人不是武术最高的？\n可管理者终究不是武侠剧里面的掌门人。看看武林第一的少林寺方丈，功夫深还得看扫地僧。再说还有梅长苏呢。\n所以首先需要确立一个认知：管理者在技术实现能力上并不一定比团队的技术骨干强。管理者比下属技术能力强又如何呢？技术更强就能服人吗？如果你沉浸在“让自己最强”的表象中，就会导致一个问题–你的水平会成为整个团队的瓶颈，这可不是公司希望看到的。\n级别越高的管理者，越应该明确一点，管理者的目标是让团队的成员更强，凝聚力是多高，从而可以一起去攻克更艰难的目标，而不是证明你比你的下属或者平级更强。\n有了认知，如何赢得骨干的尊重呢？三步走：“给干将搭台子”，“克服心理障碍”，“提升自身能力”\n给干将搭台子第一、给充分的资源支持\n给资源支持，分对内、对外两个方面\n对外，平时你要多找一些需求点，然后把你的员工推出去，让他们去负责解决这个强需求点，并且要持续地推出去。\n对内，为了团队的核心骨干能有更好的发展，你需要给他们提供充足的支持，努力去找需求、要资源、要认可，让他们获得真正的成长。\n第二、让员工有被需要的感觉，让他感觉自己在这个团队里“独一无二”\n不耍语言技巧，陈述事实。说出每一句话都是真诚的。\n“这件事很有意义，但是也很难，就我们组织目前的人员配置，只有你最有可能搞定这件事，我没有别的选择，只能靠你”\n克服心理屏障你有没有遇到过这样的情况，你明明觉得你的平级或者团队的高级别员工有些事情做得让你不满意，但是因为他们级别高，或者你觉得他是个硬茬，而你没有足够的感情强度去把他们的问题指出来？\n当你没有了解具体的细节，或者对事情的认识不够深刻时，就去给员工提意见，那效果一定会很差。所以，你给员工提意见和建议的时候不要空谈，要不绕弯子地谈具体的细节。了解得越详细，你提意见的时候也就越有底气。\n提升自己的能力如何提升自己的能力呢？没有捷径，最有效的方法就是去经历挫折，主动去走出舒适区，把每一次办砸的事情都看成“天将降大任于是人也，必先苦其心志，饿其体肤”。犯错比不犯错好，人从失败中汲取营养的效果远好于从成功中汲取营养的效果。\n\n总结当你知道了这些认知，自信心也不是一两天就能建立，但得相信你的上级，你被提拔为管理者，绝不是他的一时冲动。就好比你现在需要从团队中提拔一个新管理者一样，当他需要像你现在的情况，你会怎么鼓励他？“你也许不是那个最强的人，但是你得相信，你是此时此刻做这事儿最合适的人”\n所以相信自己，既然你被认命为这个团队的负责人，你就是此时此刻带领这个团队最合适的人。\n","tags":["管理"]},{"title":"遥远的救世主","url":"/blog/the-distant-savior.html","content":"\n这本小说有改编的电视剧《天道》，不论是电视剧还是原著小说都看过多次，已经不记得是何缘起结识了这部书籍。\n最近有个朋友又提到这部影剧，说影响了他的人生轨迹；使他看到并大概率得到波动命运琴弦的关键及能力\n实在是惭愧，读了那么多次，尽然没有如此感悟，收获。再次翻书阅读\n以我的学识、阅历，要读懂可能很难，甚至短时间没有可能性。但想想，那又怎么样呢？\n如肖亚文所说\n\n认识这个人就是开了一扇窗户，就能看到不一样的东西，听到不一样的声音，能让你思考，觉悟，这已经够了\n\n能有这样一本，让你时时回味，时时思考，有所悟，或有所得的书籍，这已经很好了\n文化属性此书中的故事 皆有“文化属性”而来，那么吸引人的也大体是这个词了。\n\n透视社会依次有三个层面：技术、制度和文化。小到一个人，大到一个国家一个民族，任何一种命运归根到底都是那种文化属性的产物。强势文化造就强者，弱势文化造就弱者，这是规律，也可以理解为天道，不以人的意志为转移\n\n\n强势文化就是遵循事物规律的文化，弱势文化就是依赖强者的道德期望破格获取的文化，也是期望救主的文化。强势文化在武学上被称为“秘笈”，而弱势文化由于易学、易懂、易用，成了流行品种。\n\n知道又如何？怎么用呢？\n\n无所用，无所不用；比如文化产业，文学、影视是扒拉灵魂的艺术，如果文学、影视的创作能破解更高思维空间的文化密码，那么它的功效就是启迪人的觉悟，震撼人的灵魂，这就是众生所需，就是功德、市场、名利，精神拯救的暴利与毒品麻醉的暴利完全等值，而且不必像贩毒那样耍花招，没有心理成本和法律风险\n\n\n中国的传统文化是皇恩浩大的文化，它的实用是以皇天在上为先决条件。中国为什么穷？穷就穷在幼稚的思维，穷在期望救主、期望救恩的文化上，这是渗透到民族骨子里的价值判断体系\n\n神话芮小丹让丁元英在王庙村写个神话\n\n这个世上原本就没有什么神话，神话不过是常人的思维所不易理解的平常事\n\n\n无论做什么，市场都不是一块无限大的蛋糕。神话的实质就是强力作用的杀富济贫，这就可能产生两个问题，一是杀富是不是破坏性开采市场资源？ 二是让井底的人扒着井沿看了一眼再掉下去是不是让他患上精神绝症？\n\n后面的故事，的确如丁所说，乐圣林雨峰自杀了，三个股东之一的刘冰也自杀了。仁人志士一片讨伐之声。\n但这事真的神了吗？\n\n从整个事件里，她没有看到丁元英有任何能让人感到“神”的招式，每一件具体的事都是普通人都能做到的普通事\n\n\n他的确是在公开，公平的条件下合理合法的竞争，一切都是公开的，没有任何秘密和违法可言，所谓的“神话”竟是这么平淡，简单。实事求是就是神话，说老实话，办老实事的人就是神！\n\n\n神就是道，道就是规律，规律如来，容不得你思议，按规律办事的人就是神\n\n在小说开篇，其实就有实事求是，客观规律的论述\n\n马克思主义的道理归根到底就是一句话：客观规律不以人的意志为转移。什么是客观规律？归根到底也是一句话：一切以时间，地点和条件为转移\n\n造血功能整本书貌似都在讲述文化属性，以及各种人潜意识里的文化属性结成了整个故事该有的结局\n\n不是说谁本该成为哪种人是规律，而是说谁本该成为哪种人的条件的可能，因果不虚，因果是规、是律，不可思议\n\n但如何解决造血功能呢？这可能是作者留给读者思考的内容，也就是人人都和各自的条件可能。\n但如何才能做到事实求是呢？\n本质的道作者已经说了很多很次，就是要事实求是，遵循规律，有道无术，术尚可求也，有术无道，止于术\n\n不可思议一词不是众生道里的对神秘事物的描述，而是如是、本来、就是如此，容不得你思议。也是一种告诫、提示，是告诉你不可以思议，由不得你思议。从数学逻辑上说，一加一等于二，容得了你思议吗？不容，这就是告诉你了，一加一等于二是规律，规律是不以人的意志为转移，你只能认识、遵循，不可思议\n\n如果你生活在一个虚妄的世界里，事实求是就很难，就如三个股东一样\n\n观念，传统观念。一是传统的“事实胜于雄辩”的观念，二是传统的疑罪从有的观念，三是传统的青天大老爷的观念。中国人一直接受简单的文化思维教育，他们相信法律是神圣的，决不冤枉一个好人，也决不放过一个坏人\n\n也如芮小丹说讲\n\n只要不是我觉到，悟到的，你给不了我，给了我也拿不住。只有我自己觉到，悟到的我才有可能做到，我能做到的才是我的。\n\n\n你的知道是自觉，现在是让你觉他。知道这个道理的人很多，但多是呈道理和知识存在。不是自觉。道理和知识是没用的，只是有用的一个条件。用才有用。让你觉他什么？觉他的无明，觉他的道理和知识的没用\n\n通过否定法，至少要去掉两种思维，才可能性拥有造血功能\n靠   等\n\n传统观念的死结就在一个“靠”字上，在家靠父母，出门靠朋友，靠上帝、靠菩萨、靠皇恩… 总之靠什么都行，就是别靠自己。这是一个沉积了几千年的文化属性问题，非几次新文化运动就能开悟。\n\n\n咱们翻开历史看看，你从哪一行哪一页能找到救世主救世的记录？没有，从来就没有，从来都是救人的被救了，被救的救了人。如果一定要讲救世主的话，那么符合和代表客观规律的文化就是救世主。扶贫的本质在一个扶字，如果你根本就没打算自己站起来，老天爷来了都没用。\n\n","tags":["读书"]},{"title":"限流","url":"/blog/current-limiting.html","content":"\n为什么需要限流\n如何限流\n\n限流主要就是考虑这两点\n为什么需要限流之前已经介绍了熔断，降级，为什么还需要一个限流呢？是不是多此一举呢？\n先来个结论：\n熔断是为了防止雪崩，明哲保身；而限流则是在已有条件下，最大限制发挥系统效能\n根据《熔断机制》可以知道，熔断有三种状态，[熔断关闭],[半熔断],[熔断开启]三种状态，如果系统压力过大，一个服务就会在三种状态来回切换\n会出现一种情况，就像一辆开在崎岖山路上的法拉利，不管车的性能多好，都需要不停的加速减速\n\n要想速度达到最佳，就得让车开在一条笔直的高速公路上\n系统就是一条河，服务就像行驶在河里的船，岸的两边，一边是熔断，另一边就是限流；一个保障系统安全，一个保持最大限度运转，让系统达到高可用\n如何限流限流如何实施？\n\n量化限流阀值\n确定限流策略、算法\n被限制流量的处理\n\n限流阀值，这个其实就是通过系统压力测试来确定\n这个工作其实在系统开发之初就需要有初步的估量，涉及到业务规模，增长速度，架构选择等等，根据现有资源及其服务能力，给出上限值\n在《计数器算法》中已经说明了几种限流算法：固定窗口、滑动窗口、漏桶、令牌桶\n有人总结为【两窗两桶】，很形象\n固定窗口：临界问题，一旦流量波动，计数器提前计满，剩余时间都会被限流\n滑动窗口：固定窗口的「固定周期」已经很小，那么使用滑动窗口也就没有意义，虽然大大减小临界问题，但总归需要预估一个窗口量，很难把握，过小引起性能和资源损耗\n漏桶：不管进来多少量，出去的速率是恒定的，“出口”速度固定；当桶容量满时，就会被限流\n令牌桶：“进口”速度固定；只要令牌的生成速度大于等于请求被处理的速度,系统就能正常处理\n有了限流策略，那制定在服务端还是客户端呢？\n从效果上讲，肯定是客户端，限制越靠入口，系统就越安全，可以防止不必要的无效流量进入服务端系统\n你也可能想到对网络资源的浪费，但一般各个服务都是在同一IDC机房，因此这点不必考虑\n但成本相对在服务端过高，放在客户端，客户端的数量与扩张速度也是动态的，无法评估，对每个端的限流阀值分配与下发都很复杂\n因此一般都是在服务端进行限流\n至于被限制的流量如何处理？大多数情况是直接抛弃，在系统之初，就有了对流量预判，从设计到资源准备都很充足，会有合理的限流阀值；如果有突发流量，可能配合监控及时增加机器，横向扩展\n总结限流与熔断，一个让系统保持最大活跃性，一个保障安全，两者技术手段有重叠，但意义完全不同，所以两者都是微服务中不可少的两个服务治理手段\n","tags":["微服务"]},{"title":"阿里DDD四弹拜读","url":"/blog/ali-ddd-four-bombs-reading.html","content":"阿里殷浩大牛写了DDD系统文章，现在已经更新到每四篇，有很多异于常规的地方，收获良多，总结一下\nDomain primitive对于DDD第一讲，作者介绍的Domain primitive,开始有些反感的，对DDD理论也深知一二，但从没听过有这概念，所以觉得作者是挂羊头卖狗肉的，但读完发现原来是对Value object的升华，牛人就是不一样\nDomain Primitive的概念和命名来自于Dan Bergh Johnsson &amp; Daniel Deogun的书 Secure by Design，特意找到了这本书的章节，https://livebook.manning.com/book/secure-by-design/chapter-5/1，有兴趣可以看看\n对于DP，在《代码大全》中指出过类似概念：ADT\n抽象数据类型ADT是指一些数据以及对这些数据所进行的操作的集合\n关于使用ADT的建议：\n\n把常见的底层数据类型创建为ADT并且使用这些ADT，而不再使用底层数据类型\n把像文件这样的常用对象当成ADT\n简单的事物也可以当做ADT：这样可以提高代码的自我说明能力，让代码更容易修改。\n不要让ADT依赖于其存储介质\n\nADT就是业务上的最小类型，不要去使用编程语言提供的基础类型\n在之前的DDD文章中，也指出很多时候的重构不过是大方法拆分成小方法，更SRP一些，其实也什么意义，DDD带来的好处是业务语义显现化，而DP就是一种手段\n使用DP后代码遵循了 DRY 原则和单一性原则，作者从四个维度提出DP带来的好处：接口的清晰度（可阅读性）、数据验证和错误处理、业务逻辑代码的清晰度、和可测试性\n在实际项目中碰到一个有意义的问题，我们通过OCR接受识别的增值税发票信息\n之前的接口是receiveInvoice(String invoiceCode,String invoiceNo,String checkCode,…),接受OCR给的发票结构化信息\n发票号码和发票代码是有业务语义，是业务的最小类型，invoiceCode可以从String升级为InvoiceCode\n接口变成：receiveInvoice(InvoiceCode invoiceCode,InvoiceNo invoiceNo,CheckCode checkCode),把业务最小单元提取出来了，接口清晰度，业务语义也显现了。可有个有意思的地方，OCR会出错的，一个正常的发票号码是8位，但会被识别成9位，业务上不能是InvoiceNo,可得固化存储这个识别结果，因此这个入口不能过于语义，总不能来一个WrongInvoiceNo\n这儿我可能有个误区，把DP作为有语义的数据验证工具类使用了，可DP应该是Value object的升华，得在domain层使用，参数校验还得用Validate\n定义Domain Primitive 是一个在特定领域里，拥有精准定义的、可自我验证的、拥有行为的 Value Object 。\n\nDP是一个传统意义上的Value Object，拥有Immutable的特性\nDP是一个完整的概念整体，拥有精准定义\nDP使用业务域中的原生语言\nDP可以是业务域的最小组成部分、也可以构建复杂组合\n\n原则\n将隐性的概念显性化(Make Implicit Concepts Explicit)\n将隐性的上下文显性化(Make Implicit Context Explicit)\n封装多对象行为(Encapsulate Multi-Object Behavior)\n\nVS Value Object在 Evans 的 DDD 蓝皮书中，Value Object 更多的是一个非 Entity 的值对象\n在Vernon 的 DDD红皮书中，作者更多的关注了Value Object的Immutability、Equals方法、Factory方法等\nDomain Primitive 是 Value Object 的进阶版，在原始 VO 的基础上要求每个 DP 拥有概念的整体，而不仅仅是值对象。在 VO 的 Immutable 基础上增加了 Validity 和行为。当然同样的要求无副作用（side-effect free）\nVS DTO\n\n应用架构这一篇算是正常篇，很多文章都是这样的,也是以银行转账为例，但分析得更特彻\n应用架构，意指软件系统中固定不变的代码结构、设计模式、规范和组件间的通信方式\n一个好的架构应该需要实现以下几个目标：\n\n独立于框架：架构不应该依赖某个外部的库或框架，不应该被框架的结构所束缚\n独立于UI：前台展示的样式可能会随时发生变化\n独立于底层数据源：无论使用什么数据库，软件架构不应该因不同的底层数据储存方式而产生巨大改变\n独立于外部依赖：无论外部依赖如何变更、升级，业务的核心逻辑不应该随之而大幅变化\n可测试：无论外部依赖什么样的数据库、硬件、UI或服务，业务的逻辑应该都能够快速被验证正确性\n\n这是很多架构的目标，但想想，一个架构是这样，那还剩下什么，框架没了，数据库没了，对于习惯了CRUD的程序员，什么都没了，我们的架构为了什么。真的就是那个模型，一个软件之所以是这个软件的核心模型，也就是domain\n\nDDD是一种设计范式，主张以领域模型为中心驱动整个软件的设计。在DDD中，业务分析和领域建模是软件开发的关键活动。它不关心软件的架构是怎样的。随着技术的发展，我们可能在新版本中更换软件的架构，但是只要业务没有变更，领域模型就是稳定的，无需改动。\n\n事务脚本弊端一、可维护性能差\n可维护性 &#x3D; 当依赖变化时，有多少代码需要随之改变\n二、可拓展性差\n可扩展性 &#x3D; 做新需求或改逻辑时，需要新增&#x2F;修改多少代码\n三、可测试性能差\n可测试性 &#x3D; 运行每个测试用例所花费的时间 * 每个需求所需要增加的测试用例数量\n破坏原则一、单一原则\n二、依赖反转原则\n三、开放封闭原则\nDDD\n如果今天能够重新写这段代码，考虑到最终的依赖关系，我们可能先写Domain层的业务逻辑，然后再写Application层的组件编排，最后才写每个外部依赖的具体实现。这种架构思路和代码组织结构就叫做Domain-Driven Design（领域驱动设计，或DDD）。所以DDD不是一个特殊的架构设计，而是所有Transction Script代码经过合理重构后一定会抵达的终点\n\n这段话一针见血，很多时候在讨论DDD时，只是学习战术，什么实体、值对象、聚合，可在做项目时，引入了这些器，其他还不是CRUD，谁真正想过domain,并且以此驱动开发\nDDD架构能有效解决传统架构中问题：\n\n高可维护性：当外部依赖变更时，内部代码只用变更跟外部对接的模块，其他业务逻辑不变\n高可扩展性：做新功能时，绝大部分代码都能利用，仅需要增加核心业务逻辑即可\n高可测试性：每个拆分出来的模块都符合单一性原则，绝大部分不依赖框架，可以快速的单元测试，做到100%覆盖\n代码结构清晰：通过POM module可以解决模块间的依赖关系，所有外接模块都可以单独独立成jar包被复用。当团队形成规范后，可以快速的定位到相关代码\n\n\n作者的模块划分和依赖关系，细分析之后发现了些妙处\n\nInfrastructure模块包含了Persistence、Messaging、External等模块。比如：Persistence模块包含数据库DAO的实现，包含Data Object、ORM Mapper、Entity到DO的转化类等。Persistence模块要依赖具体的ORM类库，比如MyBatis。如果需要用Spring-Mybatis提供的注解方案，则需要依赖Spring\n\nPersistence从infrastructure剥离出来，解决了之前碰到的循环依赖问题(repository接口在domain层，但现实在infra层，可从maven module依赖讲，domain又是依赖infra模块的)\n对于为什么拆分得这么细，是不是也解决这个问题，特意请教了作者,作者回复：\n\n这块儿可拆可不拆，拆的好处是每个模块职责比较简单，但不拆问题也不大的domain没必要依赖infra啊？domain里自带Repository接口，所以从maven角度来看，infra是依赖domaininfra只依赖application、domain即可。这里面还有一个Start的模块，把infra依赖进来，然后Spring的DI会自动注入的这里，domain或app依赖的外部的接口而已，这个一般是独立的jar包这个也可以是ACL里面的Facade，但是具体的调用实现还是infra\n\n之前也思考过，的确得DIP，domain在最下层，infra在上面，但有个问题，把对外部依赖的接口都是放在infra里面的，所以倒置不了，以及之前在《DDD分层》里面提到的\n\nDDD引入repository放在了领域层，一是对应聚合根的概念，二是抽象了数据库访问，，但DDD限界上下文可能不仅限于访问数据库，还可能访问同样属于外部设备的文件、网络与消息队列。为了隔离领域模型与外部设备，同样需要为它们定义抽象的出口端口，这些出口端口该放在哪里呢？如果依然放在领域层，就很难自圆其说。例如，出口端口EventPublisher支持将事件消息发布到消息队列，要将这样的接口放在领域层，就显得不伦不类了。倘若不放在位于内部核心的领域层，就只能放在领域层外部，这又违背了整洁架构思想\n\n对于这段话，发给作者，让他点评了一下，作者回复：\n\nEventPublisher接口就是放在Domain层，只不过namespace不是xxx.domain，而是xxx.messaging之类的这里面2个概念，一个是maven module怎么搞，一个是什么是Domain层。这两个不是同一件事Repository、eventpublisher接口再Domain这个module里，但是他们从理论上是infra层的。\n\n\n我一般的理解：从外部收到的，属于interface层，比如RPC接口、HTTP接口、消息里面的消费者、定时任务等，这些需要转化为Command、Query、Event，然后给到App层。App主动能去调用到的，比如DB、Message的Publisher、缓存、文件、搜索这些，属于infra层\n\n\n所以消息相关代码可能会同时存在2层里。这个主要还是看信息的流转方式，都是从interface-》Application-〉infra\n\n\nRepository模式这一篇对repository有了更深的了解，之前对repository的认知和实践都太浮浅\n\nrepository只能操作聚合根\nrepository类似dao,当作dao使用\nrepository是领域层，但从菱形架构中得知，保持领域层的纯洁，放到南向网关\n\n对repository的认知和实践也就这些了，在实践时基本当成dao使用，当然也碰到了想不通的问题\n第一点：数据加载与性能平衡问题\nrepository操作的对象是聚合根，因此加载一个聚合根，就得是一个完整的聚合根，可是有时我们只想加载部分数据，怎么办？很多人指出依赖懒加载方式来解决，但也有人指出这是通过技术解决设计问题，我也迷茫，到底怎么办呢？写两个方法吧\nfindOrder(OrderId id);//获取完整的order聚合findOrderWithoutItems(OrderId id);//只取order不取明细\n\n特别的别扭吧\n第二点：更新数据时，只从聚合根操作，那到了repository怎么知道具体操作哪个对象\n可能又需要类似第一点，写多个方法了\n这些都是很麻烦很现实的问题，为了domain纯洁性，为了DIP而特意加上不合格的repository，是不是更麻烦了呢？\n很多时候，其实技术、框架、依赖三方都不怎么变，变得恰恰是domain，产品需求一日三变，难道我们努力的方向有问题？\nrepository价值对于这个问题，就是为了DIP吧，作者又重新对比了DAO\nDAO的核心价值是封装了拼接SQL、维护数据库连接、事务等琐碎的底层逻辑，让业务开发可以专注于写代码，但是在本质上，DAO的操作还是数据库操作，DAO的某个方法还是在直接操作数据库和数据模型，只是少写了部分代码\n在Uncle Bob的《代码整洁之道》一书里，作者用了一个非常形象的描述：\n\n硬件（Hardware）：指创造了之后不可（或者很难）变更的东西。数据库对于开发来说，就属于”硬件“，数据库选型后基本上后面不会再变，比如：用了MySQL就很难再改为MongoDB，改造成本过高。\n软件（Software）：指创造了之后可以随时修改的东西。对于开发来说，业务代码应该追求做”软件“，因为业务流程、规则在不停的变化，我们的代码也应该能随时变化。\n固件（Firmware）：即那些强烈依赖了硬件的软件。我们常见的是路由器里的固件或安卓的固件等等。固件的特点是对硬件做了抽象，但仅能适配某款硬件，不能通用。所以今天不存在所谓的通用安卓固件，而是每个手机都需要有自己的固件\n\n从上面的描述我们能看出来，数据库在本质上属于“硬件”，DAO 在本质上属于“固件”，而我们自己的代码希望是属于“软件”。但是，固件有个非常不好的特性，那就是会传播，也就是说当一个软件强依赖了固件时，由于固件的限制，会导致软件也变得难以变更，最终让软件变得跟固件一样难以变更\n比如我们使用的mybaties,有各种mapper,原来放在dao中，现在放在repository，换汤不换药\n我们需要一个模式，能够隔离我们的软件（业务逻辑）和固件&#x2F;硬件（DAO、DB），让我们的软件变得更加健壮，而这个就是Repository的核心价值\n此刻，对菱形架构有点反思，是不是repository就应该是领域层，就是与外界数据来源的隔离，不关心具体是不是数据库，io,都是repository\n\n作者把DTOAssembler放在了application层，是不是有点不太合理，至少不太符合分层架构，应该放在controller中呢？\n\n从使用复杂度角度来看，区分了DO、Entity、DTO带来了代码量的膨胀（从1个变成了3+2+N个）。但是在实际复杂业务场景下，通过功能来区分模型带来的价值是功能性的单一和可测试、可预期，最终反而是逻辑复杂性的降低。\nrepository规范传统Data Mapper（DAO）属于“固件”，和底层实现（DB、Cache、文件系统等）强绑定，如果直接使用会导致代码“固化”。所以为了在Repository的设计上体现出“软件”的特性，主要需要注意以下三点：\n\n接口名称不应该使用底层实现的语法，insert,select,update,delete是sql语法\n出入参不应该使用底层数据格式，操作的是Aggregate Root,避免底层实现逻辑渗透到业务代码中的强保障\n应该避免所谓的“通用”repository模式\n\nChange-Tracking 变更追踪这是很多文章没提过的，这也解决了上面的第二点问题\n对于第一点问题，也特意请教了作者，作者这样回复：\n\n在业务系统里，最核心的目标就是要确保数据的一致性，而性能（包括2次数据库查询、序列化的成本）通常不是大问题。如果为了性能而牺牲一致性，就是捡了芝麻漏了西瓜，未来基本上必然会触发bug。\n\n\n如果性能实在是瓶颈，说明你的设计出了问题，说明你的查询目标（主订单信息）和写入目标（主子订单集合）是不一致的。这个时候一个通常的建议是用CQRS的方式，Read侧读取的可能是另一个存储（可能是搜索、缓存等），然后写侧是用完整的Aggregate来做变更操作，然后通过消息或binlog同步的方式做读写数据同步。\n\n\n领域层设计规范这一讲，对领域层讲解得很充分，大牛就是大牛，DDD只是一个外衣，遮挡不了牛人内涵的韵美，这个系列如果不与DDD联系，就取名牛人叫你怎么写代码，也是相当优秀\n一直以来我也认为DDD的基础是面向对象思想，我相对认为DDD与面向对象两者交集很大，重合度很高，结果作者这篇让我认知更深刻了，尤其以游戏为示例，让我更加佩服了，毕竟我在游戏业混了很久，一直自认写的代码还不错，也碰到文章指出的一些问题，可没再深入思考更优解决方案\n继承为什么Composition-over-inheritance？以前只知道继承是强耦合，我们的道是高内聚低耦合，所以不要多过使用继承。之前同事讲过行为要多Composition，但数据层面还得inheritance\n作者从OCP角度再次解释这个问题\n继承虽然可以通过子类扩展新的行为，但因为子类可能直接依赖父类的实现，导致一个变更可能会影响所有对象\n继承虽然能Open for extension，但很难做到Closed for modification。所以今天解决OCP的主要方法是通过Composition-over-inheritance，即通过组合来做到扩展性，而不是通过继承\n领域服务作者讲了三种场景的领域服务\n单对象策略型这个示例，很有新意，实在的，没见过这样写的，有点不理解，特地请教了作者\n为什么通过Double Dispatch来反转调用领域服务的方法\n\n这里的问题就是你作为服务提供方，没办法保证Weapon入参一定是合法的。在这里依赖了另一个服务的提前校验，就说明Player没有做校验，那如果因为忘记或者bug没有提前校验呢？在这里Entity的设计理念是要强保证一致性，这也是为什么要让服务通过参数注入\n\n可能这是事务脚本思维的原因，先判断再执行，而作者的意思是执行本身就应该包含判断，是个整体，不能分两步\n跨对象事务型这个常见，领域服务就是这样来的\nPlayer.attack(monster) 还是 Monster.receiveDamage(Weapon, Player)？放在领域服务就行了\n通用组件型这个平常大多被Utils类给取代了\n但如果再增加一个跳跃能力Jumpable呢？一个跑步能力Runnable呢？如果Player可以Move和Jump，Monster可以Move和Run，怎么处理继承关系？要知道Java（以及绝大部分语言）是不支持多父类继承的，所以只能通过重复代码来实现\n这个问题，最近在项目正好又碰到了，java继承没法处理，只能接口化处理\n但在实体上都得实现相应接口，有些重复，对此也特地请教了作者：\n\nMovementSystem可以共用，但这些实体类都实现Movable，也得重复实现，这个情况是不是没法避免\n\n这个是很正常的，Movable本来就应该是说“我能够Move”，然后要Move就必须要有Position和Velocity。所以在Entity层面重复实现是必须的。只要是接口编程就必然需要这样（除非走mixin，但那个Java不支持）。没办法走Base类就是因为要避免继承，同时base类也没办法实现多父继承。在有Mixin的语言里理论上是可以避免这种，但是Mixin有自己的问题，同时我们主流编程语言都没有mixin\n\nOOP、ECS、DDD三者的比较：\n\n基于继承关系的OOP代码：OOP的代码最好写，也最容易理解，所有的规则代码都写在对象里，但是当领域规则变得越来越复杂时，其结构会限制它的发展。新的规则有可能会导致代码的整体重构。\n基于组件化的ECS代码：ECS代码有最高的灵活性、可复用性、及性能，但极具弱化了实体类的内聚，所有的业务逻辑都写在了服务里，会导致业务的一致性无法保障，对商业系统会有较大的影响。\n基于领域对象 + 领域服务的DDD架构：DDD的规则其实最复杂，同时要考虑到实体类的内聚和保证不变性（Invariants），也要考虑跨对象规则代码的归属，甚至要考虑到具体领域服务的调用方式，理解成本比较高。\n\n实体类在这个过程中，作者也随带说了些实体的规范\n\n因为 Weapon 是实体类，但是Weapon能独立存在，Player不是聚合根，所以Player只能保存WeaponId，而不能直接指向Weapon;这是对象之间关系的处理，都是这样推荐的，不要对象对联，使用ID关联。但聚合根可以直接对象关联\n\n\nEntity只能保留自己的状态（或非聚合根的对象）。任何其他的对象，无论是否通过依赖注入的方式弄进来，都会破坏Entity的Invariance，并且还难以单测\n\n对于为什么实体都特地加一个业务实体ID，之前学习有介绍：\n\n身份标识（Identity，或简称为 ID）是实体对象的必要标志，换言之，没有身份标识的领域对象就不是实体。实体的身份标识就好像每个公民的身份证号，用以判断相同类型的不同对象是否代表同一个实体。身份标识除了帮助我们识别实体的同一性之外，主要的目的还是为了管理实体的生命周期。实体的状态是可以变更的，这意味着我们不能根据实体的属性值进行判断，如果没有唯一的身份标识，就无法跟踪实体的状态变更，也就无法正确地保证实体从创建、更改到消亡的生命过程。\n\n\n一些实体只要求身份标识具有唯一性即可，如评论实体、博客实体或文章实体的身份标识，都可以使用自动增长的 Long 类型或者随机数与 UUID、GUID，这样的身份标识并没有任何业务含义。有些实体的身份标识则规定了一定的组合规则，例如公民实体、员工实体与订单实体的身份标识就不是随意生成的。遵循业务规则生成的身份标识体现了领域概念，例如公民实体的身份标识其实就是“身份证号”这一领域概念。定义规则的好处在于我们可以通过解析身份标识获取有用的领域信息，例如解析身份证号，可以直接获得该公民的部分基础信息，如籍贯、出生日期、性别等，解析订单号即可获知该订单的下单渠道、支付渠道、业务类型与下单日期等。\n\n\n在设计实体的身份标识时，通常可以将身份标识的类型分为两个层次：通用类型与领域类型。通用类型提供了系统所需的各种生成唯一标识的类型，如基于规则的标识、基于随机数的标识、支持分布式环境唯一性的标识等。这些类型都将放在系统层代码模型的 domain 包中，可以作为整个系统的共享内核\n\n总结大牛写的文章就是深入浅出，丰富饱满，还是多拜读，多温故，不是因为DDD他们变得这么优秀，而是他们本身就很优秀，也许他们心中早有DDD了，只是没有DDD这个名字而已\n希望有一天我也能写出这么好的文章\n","tags":["DDD"]},{"title":"面向对象是什么","url":"/blog/what-is-object-orientation.html","content":"近两年设计了几个系统，不管是直接使用传统设计ER图，还是使用4C建模，但在做架构评审时，ER却都是重中之重,让人不得不深思，编程思想经过了一代代发展，为什么还在围绕ER，在远古时代，没有OO,没有DDD，但为什么延续至今的伟大软件也比比皆是\n带着这个问题，需要回头看看，结构化编程为什么不行？面向对象因何而起，到底解决了什么问题？\n《架构整洁之道》也特别介绍了面向对象编程，面向对象究竟是什么，大多从三大特性：封装、继承、抽象说起，但其实这三种特性并不是面向对象语言特有\n结构化编程提到结构化编程就自然想到其中的顺序结构：代码按照编写的顺序执行，选择结构： if&#x2F;else，而循环结构： do&#x2F;while\n虽然这些对每个程序员都很熟悉，但其实在结构化编程之间还有非结构化编程，也就是goto语句时代，没有if else、while，一切都通过goto语句对程序控制，它可以让程序跑到任何地方执行，这样当代码规模变大之后，就几乎难以维护\n编程是一项难度很大的活动。因为一个程序会包含非常多的细节，远超一个人的认知能力范围，任何一个细微的错误都会导致整个程序出现问题。因此需要将大问题拆分成小问题，逐步递归下去，这样，一个大问题就会被拆解成一系列高级函数的组合，而这些高级函数各自再拆分成一系列低一级函数，一步步拆分下去，每一个函数都需要按照结构化编程方式进行开发，这也是现在常被使用的模块功能分解开发方式\n结构化编程中，各模块的依赖关系太强，不能有效隔离开来，一旦需求变动，就会牵一发而动全身，关联的模块由于依赖关系都得变动，那么组织大规模程序就不是它的强项\n面向对象正因为结构化编程的弊端，所以有了面向对象编程，可以更好的组织程序，相对结构局部性思维，我们有了更宏观视角：对象\n封装把一组相关联的数据和函数圈起来，使圈外的代码只能看见部分函数，数据则完全不可见；如类中的公共函数和私有成员变量\n提取一下关键字：\n\n数据，完全不可见\n函数，只能看见\n相关联\n\n这些似乎就是我们追求的高内聚，也是常提的充血模型，如此看，在实践中最基本的封装都没有达成\n到处是贫血模型，一个整体却分成两部分：满是大方法的上帝类service与只有getter和setter的model\nservice对外提供接口，model传输数据，数据库固化数据，哪有封装性，行为与数据割裂了\n怎么才能做到一个高内聚的封装特性呢？\n设计一个类，先要考虑其对象应该提供哪些行为。然后，我们根据这些行为提供对应的方法，最后才是考虑实现这些方法要有哪些字段\n并且对于这些字段尽可能不提供getter 和 setter，尤其是 setter\n暴露getter和setter，一是把实现细节暴露出来了；二是把数据当成了设计核心\n方法的命名，体现的是你的意图，而不是具体怎么做\n// 修改密码 public void setPassword(final String password) &#123;     this.password = password; &#125;  // 修改密码public void changePassword(final String password) &#123;    this.password = password;&#125;\n把setter改成具体的业务方法名，把意图体现出来，将意图与实现分离开来，这是一个优秀设计必须要考虑的问题\n构建一个内聚的单元，我们要减少这个单元对外的暴露，也就是定义中的【只能看到的函数】\n这句话的第一层含义是减少内部实现细节的暴露，它还有第二层含义，减少对外暴露的接口\n最小化接口暴露。也就是，每增加一个接口，你都要找到一个合适的理由。\n总结：基于行为进行封装，不要暴露实现细节，最小化接口暴露\n继承先看继承定义：\n\n继承（英语：inheritance）是面向对象软件技术当中的一个概念。这种技术使得复用以前的代码非常容易，能够大大缩短开发周期，降低开发费用继承就是子类继承父类的特征和行为，使得子类对象（实例）具有父类的属性和方法，或子类从父类继承方法，使得子类具有父类相同的行为\n\n从定义看，继承就是为了复用，把一些公共代码放到父类，之后在实现子类时，可以少写一些代码，消除重复，代码复用\n继承分为两类：实现继承与接口继承\nChild object = new Child();Parent object = new Child();\n但有个设计原则：组合优于继承Composition-over-inheritance\n为什么不推荐使用继承呢？\n继承意味着强耦合，而高内聚低耦合才符合我们的道，但其实并不是说不能使用继承，对于行为需要使用组合，而数据还得使用继承\n这样解释似乎不够形象，再进一步讲，继承也违背了《SOLID》中的OCP,继承虽然可以通过子类扩展新的行为，但因为子类可能直接依赖父类实现，导致一个变更可能会影响所有子类。也就是讲继承虽然能Open for extension，但很难做到Closed for modification\n借用阿里大牛的示例：\n有个游戏，基本规则就是玩家装备武器去攻击怪物\n\n玩家（Player）可以是战士（Fighter）、法师（Mage）、龙骑（Dragoon）\n怪物（Monster）可以是兽人（Orc）、精灵（Elf）、龙（Dragon），怪物有血量\n武器（Weapon）可以是剑（Sword）、法杖（Staff），武器有攻击力\n玩家可以装备一个武器，武器攻击可以是物理类型（0），火（1），冰（2）等，武器类型决定伤害类型\n\npublic abstract class Player &#123;      Weapon weapon&#125;public class Fighter extends Player &#123;&#125;public class Mage extends Player &#123;&#125;public class Dragoon extends Player &#123;&#125;public abstract class Weapon &#123;    int damage;    int damageType; // 0 - physical, 1 - fire, 2 - ice etc.&#125;public Sword extends Weapon &#123;&#125;public Staff extends Weapon &#123;&#125;\n\n攻击规则如下：\n\n兽人对物理攻击伤害减半\n精灵对魔法攻击伤害减半\n龙对物理和魔法攻击免疫，除非玩家是龙骑，则伤害加倍\n\npublic class Player &#123;    public void attack(Monster monster) &#123;        monster.receiveDamageBy(weapon, this);    &#125;&#125;public class Monster &#123;    public void receiveDamageBy(Weapon weapon, Player player) &#123;        this.health -= weapon.getDamage(); // 基础规则    &#125;&#125;public class Orc extends Monster &#123;    @Override    public void receiveDamageBy(Weapon weapon, Player player) &#123;        if (weapon.getDamageType() == 0) &#123;            this.setHealth(this.getHealth() - weapon.getDamage() / 2); // Orc的物理防御规则        &#125; else &#123;            super.receiveDamageBy(weapon, player);        &#125;    &#125;&#125;public class Dragon extends Monster &#123;    @Override    public void receiveDamageBy(Weapon weapon, Player player) &#123;        if (player instanceof Dragoon) &#123;            this.setHealth(this.getHealth() - weapon.getDamage() * 2); // 龙骑伤害规则        &#125;        // else no damage, 龙免疫力规则    &#125;&#125;\n\n如果此时，要增加一个武器类型：狙击枪，能够无视一切防御，此时需要修改\n\nWeapon,扩展狙击枪Gun\nPlayer和所有子类（是否能装备某个武器）\nMonster和所有子类（伤害计算逻辑）\n\npublic class Monster &#123;    public void receiveDamageBy(Weapon weapon, Player player) &#123;        this.health -= weapon.getDamage(); // 老的基础规则        if (Weapon instanceof Gun) &#123; // 新的逻辑            this.setHealth(0);        &#125;    &#125;&#125;public class Dragon extends Monster &#123;    public void receiveDamageBy(Weapon weapon, Player player) &#123;        if (Weapon instanceof Gun) &#123; // 新的逻辑                      super.receiveDamageBy(weapon, player);        &#125;        // 老的逻辑省略    &#125;&#125;\n\n由此可见，增加一个规则，几乎链路上的所有类都得修改一遍，越往后业务越复杂，每一次业务需求变更基本要重写一次，这也是为什么建议尽量不要违背OCP，最核心的原因就是现有逻辑的变更可能会影响一些原有代码，导致一些无法预见的影响。这个风险只能通过完整的单元测试覆盖来保障，但在实际开发中很难保障UT的覆盖率\n也由此可见继承的确不是代码复用的好方式\n从设计原则角度看，继承不是好的复用方式；从语言特性看，也不是鼓励的做法。一是像Java，只能单继承，一旦被继承就再也无法被其他继承，而且java中有Variable Hiding的局限性\n比如现在添加一个业务规则：\n\n战士只能装备剑\n法师只能装备法杖\n\n@Datapublic class Fighter extends Player &#123;    private Sword weapon;&#125;@Testpublic void testEquip() &#123;    Fighter fighter = new Fighter(&quot;Hero&quot;);    Sword sword = new Sword(&quot;Sword&quot;, 10);    fighter.setWeapon(sword);    Staff staff = new Staff(&quot;Staff&quot;, 10);    fighter.setWeapon(staff);    assertThat(fighter.getWeapon()).isInstanceOf(Staff.class); // 错误了&#125;\n\n其实只是修改了父类的weapon，并没有修改子类的；由此编程语言的强类型无法承载业务规则。\n继承并不是复用的唯一方法，如ruby中有mixin机制\n多态多态（Polymorphism）按字面的意思就是“多种状态”。在面向对象语言中，接口的多种不同的实现方式即为多态\n在上一讲，接口继承更多是多态特性\n只使用封装和继承的编程方式，称之为基于对象编程，而只有把多态加进来，才能称之为面向对象编程，有了多态，才将基于对象与面向对象区分开；有了多态，软件设计才有了更大的弹性\n多态虽好，但想要运用多态，需要构建出一个抽象，构建抽象需要找出不同事物的共同点，这也是最有挑战地方。在构建抽象上，接口扮演着重要角色：一接口将变的部分和不变部分隔离开来，接口是约定，约定是不变的，变化的是各自的实现；二接口是一个边界，系统模块间通信重要的就是通信协议，而接口就是通信协议的表达\nArrayList&lt;&gt; list = new ArrayList();List&lt;&gt; list = new ArrayList();\n二者之间的差别就在于变量的类型，是面向一个接口，还是面向一个具体的实现类;看似没什么意义，但在《SOLID》中可以发现，几乎所有原则都需要基于接口编程，才能达到目的\n而这也就是多态的威力\n就java这门语言，继承与多态相互依存，但对于其他语言并不是如此\n总结除了结构化编程和面向对象编程，现在还有函数式编程，然通过上面的阐述，回到开篇的问题，我应该是把编程语言与编程范式搞混了，像结构化编程、面向对象编程是一种编程范式，而具体的C、Java其实是编程语言，对于编程语言是年轻的，的确在很多伟大软件之后才诞生，但编程范式是一直存在的，面向对象范式并不是java之后才有\n更不是C语言不能创造伟大软件，语言不过是工具，而最最重要的是思维方式，最近思考为什么TDD，DDD这些驱动式开发都很难，关键还是思维方式的转变\n为什么都要看ER图呢，这里面又常被混淆的概念：数据模型与领域模型，下一篇再分解\nReference《架构整洁之道》\n《软件之美》\n","tags":["思维"]},{"title":"领域服务上抛异常还是返回错误码","url":"/blog/does-the-domain-service-throw-an-exception-or-return-an-error-code.html","content":"最近收到这样的问题：\n\n领域服务做业务逻辑校验时应该返回错误码还是抛出业务异常？\n\n这其实不算是领域服务的问题，而是Java异常处理问题。\n之前总结过一次如何处理异常\n上面的文章基本上就解决异常相关问题了。\n这儿再回顾总结一下：\n\n\n返回错误码在异常没有出现时，像C语言是如何处理问题的？\n在 C 语言中，错误码的返回方式有两种：一种是直接占用函数的返回值，函数正常执行的返回值放到出参中；另一种是将错误码定义为全局变量，在函数执行出错时，函数调用者通过这个全局变量来获取错误码\n// 错误码的返回方式一：pathname/flags/mode为入参；fd为出参，存储打开的文件句柄。int open(const char *pathname, int flags, mode_t mode, int* fd) &#123;  if (/*文件不存在*/) &#123;    return EEXIST;  &#125;    if (/*没有访问权限*/) &#123;    return EACCESS;  &#125;    if (/*打开文件成功*/) &#123;    return SUCCESS; // C语言中的宏定义：#define SUCCESS 0  &#125;  // ...&#125;//使用举例int fd;int result = open(“c:\\test.txt”, O_RDWR, S_IRWXU|S_IRWXG|S_IRWXO, &amp;fd);if (result == SUCCESS) &#123;  // 取出fd使用&#125; else if (result == EEXIST) &#123;  //...&#125; else if (result == EACESS) &#123;  //...&#125;// 错误码的返回方式二：函数返回打开的文件句柄，错误码放到errno中。int errno; // 线程安全的全局变量int open(const char *pathname, int flags, mode_t mode）&#123;  if (/*文件不存在*/) &#123;    errno = EEXIST;    return -1;  &#125;    if (/*没有访问权限*/) &#123;    errno = EACCESS;    return -1;  &#125;    // ...&#125;// 使用举例int hFile = open(“c:\\test.txt”, O_RDWR, S_IRWXU|S_IRWXG|S_IRWXO);if (-1 == hFile) &#123;  printf(&quot;Failed to open file, error no: %d.\\n&quot;, errno);  if (errno == EEXIST ) &#123;    // ...          &#125; else if(errno == EACCESS) &#123;    // ...      &#125;  // ...&#125;\n\n错误码没有性能问题，但带来了维护性，尤其没有了异常堆栈信息，失去了快速定位问题的能力。\n抛异常在OO世界中，更推荐使用异常方式，显得更OO些\nChecked ExceptionSpring创始人Rod Johnson列举了检查异常几个问题：\n1、太多的代码\n开发人员不得不捕捉他们无法处理的检查异常\n2、难以读懂的代码\n捕捉不能处理的异常并重新抛出，没有执行一点有用的功能，反而会使查找实际做某件事的代码变得更困难\n3、异常无休止封装\n4、易毁坏的方法签名\n一旦这么多调用者使用一个方法，添加一个额外的检查异常到该接口上将需要这么多代码被修改。也些违背OCP原则\n5、检查异常对接口不一定管用\n接口有很多种实现，有些实现会出现异常，但有些是不会出现异常的，比如存储数据，放在文件会抛IO相关异常，但数据是数据库，刚不是此异常。\nRuntime Exception运行期异常被很多大牛接受推荐，但也有弊病，就是调用方需要知道内部实现细节，了解抛出了些什么异常，需在javadoc中给出明确说明。\n当然我们现在可以使用AOP技术，对异常进行兜底处理，以防泄漏到用户层。\n性能当使用异常时，性能得确会下降，尤其调用链路很深时，更加明显。但异常总归是少数情况，不影响正常情况的性能。\n但有些系统对性能要求比较高，怎么办？如正常情况是百万QPS，就算出现少许异常情况，对系统可用性也带来不小的影响。\n怎么办？退回错误码时代\n但从设计角度可改良一下，可以不再简单返回错误码，如可以使用vavr的Either\nEither&lt;ExceptionMessage,Result&gt; do();\n\n让调用方式来最终确定，当either.isLeft()时，是向上抛异常，还是额外处理。\n良好实践使用检查异常还是运行时异常是个见解问题，不管如何选择，只要团队达成共识，统一规范就可以。\n良好的异常，不管是对开发人员，还是运维，用户都应该有全面友好的提示信息\n对开发人员，在异常中包含相关信息，使用getMessage()打印日志，方便定位问题\n对于用户，可以使用错误代码，字符串比数值语义更明确些。在spring初期代码中，Rod Johnson设计了一个接口ErrorCoded\npublic interface ErrorCoded &#123;\t\t/** Constant to indicate that this failure isn&#x27;t coded */\tpublic static final String UNCODED = &quot;uncoded&quot;;\t\t/** Return the error code associated with this failure. \t * The GUI can render this anyway it pleases, allowing for Int8ln etc.\t * @return a String error code associated with this failure\t */\tString getErrorCode();&#125;\n\n\n其实也不并是说所有场景都去使用异常，如openapi，最好使用errorCode。\n异常与契约乔新亮指出异常是那些让产品无法履行当初承诺用户的契约的问题。\n对于异常设计有5点认知：\n1、异常一定要消灭；有异常基本就意味着系统存在风险，一定要消灭异常\n2、异常一定要管理：消灭异常是个长期工程，短期要通过管理行为来进行控制\n3、对异常的处理水平，会极大影响产品的用户体验：用户规模越大，异常的影响往往越大\n4、每个异常都要有具体负责人\n5、与终端用户相关的异常，要以最高优先级处理\n异常设计包含：异常注册、异常事件触发、异常协作流程以及异常统计。\n要关注异常数据、异常发生频次、异常数据的增速和降速。\n总结回到起始问题，对于领域服务，自然OO更好些，抛出特定业务异常，业务语义更加清晰。\n性能问题，一是避免发生异常情况，二是通过横向扩展。毕竟业务可运维性更重要。\n","tags":["DDD"]},{"url":"/blog/.html","content":""},{"title":"领域驱动设计模式的收益与挑战","url":"/blog/benefits-and-challenges-of-domain-driven-design-patterns.html","content":"《软件学报》在2021年第32卷第9期刊登了一篇论文：《领域驱动设计模式的收益与挑战:系统综述》。这篇论文是学术界在这一领域开山之作。\n论文是对2003~2019年之间发表的相关文献进行识别、筛选、汇总和分析。\n揭示DDDP的应用情况，即哪些DDDP被应用到了软件开发中，以及其所带来的收益、挑战及相应的缓解挑战方法。\n对于长期在DDD中折腾的人，值得一读。\n一是可以看看学术界的研究成果\n二是对比自己实践，是否在康庄大道上\n如果你对学术性论文不感兴趣，可以仔细阅读这篇文章，我对论文做些简单摘抄，对比一下自己实践感悟\n基本介绍论文先对DDD的一些概念、特性作了介绍\n定义：\n\nDDD是一种软件设计中应该遵循的思维方式，其目标在于加快具有复杂需求的软件项目的研发速度\n\n理论：\n\n通过构建领域模型来解决软件开发的复杂性问题。因为在大多数软件项目中，最困难的往往是解决业务领域复杂性，而非技术复杂性\n\n特征：\n\n设计与开发的绑定，DDD强调软件设计概念必须在开发过程中得以成功实现\n\nDDDP:\n\nDDD方法中，将一组设计实践、技术和原则合并为标准模式，即所谓的领域驱动设计模式(domain driven design pattern，简称DDDP)\n\n基本原则\nEvans强调设计概念必须在代码中成功实现，否则它们将会变成抽象的讨论。DDD通过引入模型驱动设计建模范式及其构造块，弥补模型与可运行软件之间的差距\nDDD提倡迭代开发，领域驱动设计与具体实现过程间紧密关系，使得DDD比其他软件设计方法更具实用性\nDDD追求领域模型需要依靠头脑风暴的创造性和对领域的深入了解，因此在实践过程中，开发人员与领域专家之间需要展开紧密协作\nDDD是一种软件设计方法，而任何设计出来的领域模型都应该与架构无关。也就是除了领域模型，在软件开发过程中仍然需要架构设计，比如微服务架构或六边形架构\n\nDDD设计模式概览DDD由Evans作为一种大型模式语言引入，其由一组相互关联的模式组成。\n模式语言提供了讨论问题的交流术语，它定义了特定场景、特定问题的解决方案，其主要目的是帮助开发者解决在设计和编程中遇到的通用问题。\n模式语言在软件工程中被广泛地应用，比如设计模式、企业架构模式等。\nDDD与DDDP的关系，正如同OOD与面向对象设计模式的关系。\n对于DDD，最基本的模式是通用语言，它是一种供不同涉众（如开发人员和领域专家）共同使用的语言，主要用来辅助领域建模，，\n一种通用语言只适用于单个限界上下文，后者作为一个电焊工的模型边界来维护模型的完整性。\n根据Vernon的观点，除了通用语言之外的DDDP，要么属于战略设计模式，要么属于战术设计模式。\n战略设计模式旨在应对具有多个领域模型的大型软件开发项目的复杂性，其中，每个领域模型都属于单独的限界上下文。\n限界上下文以外的其他战略设计模式关注如何管理不同限界上下文之间的关系\n比如上下文映射负责描述不同领域模型间的通信，而职责分层则站在更高的抽象层级来组织不同领域模型间的概念依赖关系\n战术设计模式负责根据通用语言对单个限界上下文进行领域建模，并结合面向对象原则绑定领域建模和编码实现。包括实体、值对象、聚合、服务、资源库等。\n实体和值对象用于对具有不同领域特征的领域对象进行建模；\n聚合将一组领域对象绑定为一个整体，以控制事务；\n服务则充当领域模型接口，具有无状态特点；\n资源库用于封装领域对象的数据库访问操作\n\n感悟\n对于基础信息的介绍，可以说基本是符合当前DDD的理论知识，只是表述方式有所差异。但鉴于每个人认知差距，可能抓住的重点信息不同，从我个人认知角度，我来点评一下：\n首先是定义，论文指出DDD是一种思维方式。\n这是种很新颖的定义。在DDD系列文章中，我们也去追寻过DDD定义。但这种定义是第一次听说。\n软件设计中最困难的是什么？\n论文指出是解决业务领域复杂性，而非技术复杂性。\n这个应该会随着软件复杂性越来越高，人们的认知会越来越深。现在技术人员还是过于看重技术，甚至对技术驱动业务深信不疑。现实是怎么样？现在工具人的流行说法已经足以说明，驱动业务是少见的，而跟随业务是常态，成就业务已经了不得。\n为什么瀑布模型不适合软件行业，就因为隐藏的业务知识太多。不可能一次性就把所有业务知识提取出来，而且在软件开发进程中，业务可能还在变化中发展。\n借助敏捷中迭代式开发，一次次与领域专家交流的深入，才能慢慢挖掘出隐藏在业务知识中的复杂性。\n而DDD正是通过模型去捕获领域知识，对领域复杂性进行简化和提炼。\n所以整合起来看，DDD是一种迭代改进试错法，还不知道什么时候该停止，甚至停止的时候你也不知道得到的到底是垃圾还是宝藏。\n设计与开发绑定\n这一点，是相当重要。是DDD与别的分析方法重要区别。\n为什么DDD如此流行，可能跟很多技术大词一样，正如之前在中台文章所说，可能是应激者怕掉队，也可能是投机者想上位，很多人还是把它当成一种分析方法。\n如果只是一种分析法，我们之前使用的ER分析，OOA，都已经够用了。\n对于现流行说的DDD帮助微服务划分，那只是DDD中界限上下文这一个点，而且服务划分也不能只考虑领域界限，还有其它因素。\n因此需要多思考，为什么需要DDD，DDD到底有什么独到之处？\n我个人认为理由在Evans著作中提到的知识消化。学习者过多的精力放在了战术部分，什么是实体、领域服务、repository等等这些元素上。\n在编程实践中，我们希望实实在在的用上DDD元素，才表示我们是在进行DDD，而其实没有DDD，对OO的深刻理解，充血模型是自然而然的。\n然而，如果没有DDD战略部分，只有DDD战术元素，那只是DDD编码风格，而编码风格，没有高低之下，贫贱之分。\n何为知识消化？我特此画张图：\n\n业务方与技术方沟通业务需求，在交流中，对部分业务知识达到共识，这部分交流语言被标准化为统一语言；\n在不断地交流中，对于双方达成共识部分，凝炼成到模型中，对模型review，以确定描述了业务实际情况，发现缺乏或不适当概念时，进行修正，指取新的统一语言；\n当模型确认后，以模型为样本，使用代码实现它；\n上面是正向流程，技术方在重构代码时，也会同步修改模型，进来提取出新的统一语言，反哺业务方。\n通过正逆流程，达到修改统一语言就是修改模型，修改模型也就是修改代码；修改代码也是修改模型，修改模型也相继修改统一语言。\n这样打破了知识壁垒，给予业务方与技术方一种更好的协同方式。这就是DDD的精髓。让分析模型与实现模型融合了，不再像以前的方法一样分裂。\n\n研究结果\n如上图所示，应用DDDP的相关活动主要分为4类：领域分析、领域设计、领域模型实现和普适性活动。\n领域分析：与领域专家一起探索领域知识的过程。经过领域，将得到初始的领域模型；\n领域设计：指将模型分成不同部分（每个部分对应着独立的限界上下文），然后扩展和细化每个限界上下文的过程，以此为开发实现做准备\n领域模型实现：将模型转换为可运行代码，这一过程还通过检查模型为模型设计提供反馈\n普适性活动：在应用DDDP时，可能在领域分析，领域设计，领域模型实现这3个阶段都会发生的模切活动，比如构建和更新通用语言\n应用情况在基础研究集合中，出现频次到达3次以上的DDDP，以及对应的描述和提及这些模式的研究文献\n\n这些模式出现的频次并不平衡，战术设计模式被提及的频次明显高于战略设计，表明开发人员更容易注意到领域驱动设计的战术设计模式。\n总体而言，目前只有31.1%的DDDP在基础研究中得到探讨，这也表明当前学术界对DDDP的研究存在不足。\n应用DDDP的收益下图展示了应用DDDP所带来的收益在领域分析、领域模型实现以及普适性活动中的体现情况\n\n对每个阶段带来的收益细节详述一下\n领域设计应用DDDP收益在于使各个领域之间依赖关系更加明确，上下文映射和职责分层用于组织系统的不同部分：\n前者表示不同限界上下文之间的关系，每个上下文表示一个特定的领域；\n后者根据领域对象职责，将它们组织成具有清晰依赖关系的层次结构\n帮助开发人员更加深入地了解系统，降低认知复杂性，有助于分析系统架构\n领域模型实现应用DDDP有助于领域模型的落地实现。\n普适性活动可以提升软件架构的质量属性，如可维护性、可扩展性、可重用性和可测试性等\n应用DDDP的挑战下图列出了在领域分析、领域设计、领域模型实现和普适性活动中，应用DDDP可能面临的挑战以及相应的缓解方法\n\n\n\n感悟\n可以看出论文对DDDP应用的收益和挑战阐述得很详细。在现实实践中，挑战远比论文中提到的还要多。我觉得主要是两方面：\n一是对理论研究的不够深入，没有系统性学习\n二是过于关注战术问题，不深入战略部分而不知所以然，又对OO的理解不深入使其难以落地，从而抱怨DDD\n对于第一条\n1、从个人学习者角度，只能自己多看看市面上已经出版的书籍，碎片化时间系统性学习，而不是随便看看几篇文章，就以为理解DDD了，现在DDD就像个筐，什么东西都在往里装，就算是Evans开山之作，也有很多时代局限性；\n2、从团队角度讲，不要奢求团队每个人都去理解DDD，毕竟它的本身门槛就高，作为TL，需要自身内化DDD，制定规范，团队执行就可以，向有兴趣的同学传输背后理论。\n对于第二条\n3、除了需要系统性学习外，要明白DDD精髓与DDD编码风格是两码事，在实践DDD过程中，也带有个人经验特征，不仅要有自我理论作为背后支撑，也要认识到不是使用了战术元素，我们就是DDD了，而是要有DDD的知识消化过程。\n总结软件工程中是“没有银弹”的，任何理论方法都会存在一定的局限性和缺点，DDDP也是如此。因此应用各种DDDP带来的局限或者挑战，仍需要未来进一步探索和反思。\n也希望我的感悟能帮助到你，如果有兴趣可以再看看论文原稿。对于高阶程序员来讲，困难的不是能不能干出来，而是怎么干才舒坦。\n","tags":["DDD"]},{"title":"项目管理的窍门","url":"/blog/tips-for-project-management.html","content":"《技术为径：带领公司走向卓越的工程师》–项目管理进阶\n作为一个研发经理，你需要承担起为团队制订工作计划的责任。在你的上级管理层尝试制订整个季度，甚至整年的工作计划过程中，经常需要你来评估自己的团队是否能够承担某些项目，包括评估这些项目所需要的工作量，以及这些项目是否与你组员的技能相匹配。\n虽然作为一个团队经理，你可以将一些项目管理工作下放给你的技术小组长来进行，但是肯定还需要自己承担一部分相关工作。\n你所面临的主要任务是，决定哪些项目可以承担，而哪些项目需要推掉。同时，你可能还需要适应敏捷状态下需求的不断迭代，为每个项目预估一个大概的完成日期。\n若要做好对团队工作的管理工作，你需要对团队的工作节奏十分熟悉。万幸的是，有一些窍门可以帮助你做到这一点。\n敏捷与项目管理项目管理并不意味着进入瀑布式管理模式，从一开始就将项目中的每一个细节都计划清楚。\n然而，对于大部分团队来说，长期的、抽象的目标，以及短期的、具体的、面向长期抽象目标的工作计划是并存的。\n当需要实际规划小的项目目标时，团队应该采用敏捷过程来快速评估项目并且分解项目目标，这样效率最高。\n作为团队管理者，你不应该过多干预，甚至应该推动团队自主进行。你需要对更大范围的项目目标–那些需要数月，而不是数个星期才能完成的事情负起责任来。\n预留20%的工程时间预留20%的工程时间来处理研发可持续性工作。“研发可持续性工作”指的是添加测试用例、调试问题、重构老旧代码、更换编程语言和升级语言版本，以及其他类似的工程杂事等。\n如果能够坚持这样做，你就能将一些中等大小的陈旧代码逐渐消化、转换掉。每个季度做一点就够。随时清理陈旧系统，可以降低其维护难度，从而给团队留出更多时间来进行新功能的开发。\n就算不这样做，你也可以用这个时间来补偿项目过程中的意外情况。如果真的把项目研发计划填满100%，你很快会发现由于各种情况导致计划流产。监近交付时间时，管理有说“不”的义务。\n设定截止日期在项目管理中是很常见的，有时这个截止日期是团队自我设定的，也有的时候是来自更高管理层的要求。\n按照截止日期按时交付项目的唯一方法，就是在项目末期不停地裁剪末完成的项目需求。\n这就意味着，作为研发经理，你必须和自己麾下的技术小组长与产品负责人&#x2F;业务代表一起开会商讨到底哪些需求是必须交付的，而哪些需求是可以删减的。这意味着，作为研发经理，你经常需要对两边都说“不”。\n说到底，你需要向技术团队交付一系列定义清晰、实现成本合理的产品需求，同时需要向产品团队解释清楚完成所有需求所需的额外时间。\n更多的计划时间软件开发时间预估中有一个“翻倍定律”：当需要测算软件开发时间时，永远将你预期的时间翻一倍。\n不要每个需求都需要让技术团队预估实现时间研发经理的时间预估与项目计划职责的的原因之一，是因为工程师针对每个需求都交付一个预估时间，不仅浪费其时间，而且徒增其压力。\n管理层承担不确定性是责无旁贷的，管理都不应该将不确定性统统甩给团队成员来承担。\n管理者不仅仅是技术团队和公司其他部门的传声筒。这样不仅不解决问题，反倒干扰正在实际做事的人。但是，你也不能只是团队的“挡箭牌”，而不管公司其他部门的实际需求。\n你需要帮助公司建立一个针对新需求和用户反馈的持续沟通流程，减少意外情况和紧急需求的发生。\n","tags":["管理","读书"]}]